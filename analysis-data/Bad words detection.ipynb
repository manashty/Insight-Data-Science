{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get bad words from \n",
    "# https://github.com/turalus/encycloDB/tree/b1d16cca3957ae1ce72daa0c0c0f4982b0005dfd/Dirty%20Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up paths/ os\n",
    "import os\n",
    "import sys\n",
    "\n",
    "this_path=os.getcwd()\n",
    "os.chdir(\"../data\")\n",
    "sys.path.insert(0, this_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read list of dirty words from:\n",
    "# https://github.com/turalus/encycloDB/tree/b1d16cca3957ae1ce72daa0c0c0f4982b0005dfd/Dirty%20Words\n",
    "#df=pd.read_csv('')\n",
    "#DirtyWords=df['word'].values\n",
    "#del df\n",
    "\n",
    "f =  open('bad-words-banned-by-google.txt',\"r\",encoding='utf-8', errors='ignore')\n",
    "lines=f.readlines() \n",
    "DirtyWords = []\n",
    "for line in lines:\n",
    "    x=str(line).strip().replace('\\n','')\n",
    "    DirtyWords.append(x)\n",
    "\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3776\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>href</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>user id</th>\n",
       "      <th>tokens</th>\n",
       "      <th>text_short</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>post id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['category-applied-behavior-analysis-aba']</td>\n",
       "      <td>https://www.autismparentingmagazine.com/autism...</td>\n",
       "      <td>https://www.autismparentingmagazine.com/</td>\n",
       "      <td>For children with autism spectrum disorder (AS...</td>\n",
       "      <td>Autism, Head Banging and other Self Harming Be...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['autism', 'head', 'banging', 'and', 'other', ...</td>\n",
       "      <td>For children with autism spectrum disorder (AS...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           category  \\\n",
       "post id                                               \n",
       "0        ['category-applied-behavior-analysis-aba']   \n",
       "\n",
       "                                                      href  \\\n",
       "post id                                                      \n",
       "0        https://www.autismparentingmagazine.com/autism...   \n",
       "\n",
       "                                           source  \\\n",
       "post id                                             \n",
       "0        https://www.autismparentingmagazine.com/   \n",
       "\n",
       "                                                      text  \\\n",
       "post id                                                      \n",
       "0        For children with autism spectrum disorder (AS...   \n",
       "\n",
       "                                                     title  user id  \\\n",
       "post id                                                               \n",
       "0        Autism, Head Banging and other Self Harming Be...      NaN   \n",
       "\n",
       "                                                    tokens  \\\n",
       "post id                                                      \n",
       "0        ['autism', 'head', 'banging', 'and', 'other', ...   \n",
       "\n",
       "                                                text_short  \n",
       "post id                                                     \n",
       "0        For children with autism spectrum disorder (AS...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infile=\"articles-n-forums-posts.csv\"\n",
    "\n",
    "df=pd.read_csv(infile,index_col=0)\n",
    "print(len(df))\n",
    "df.head(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "post id\n",
       "0    [for, children, with, autism, spectrum, disord...\n",
       "1    [dr, stephen, shore, once, said, if, you, ve, ...\n",
       "2    [help, i, am, going, to, be, starting, applied...\n",
       "3    [how, do, you, handle, high, anxiety, of, a, c...\n",
       "4    [a, grandfather, from, singapore, asks, my, el...\n",
       "Name: tokens, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "tokenizer = nltk.RegexpTokenizer(r'\\w+')\n",
    "\n",
    "df['tokens'] = df['text'].map(lambda x: tokenizer.tokenize(x.lower()))\n",
    "df['tokens'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219\n"
     ]
    }
   ],
   "source": [
    "# Find users using offending words:\n",
    "\n",
    "list_of_bad_posts=[]\n",
    "tokens_list=df['tokens'].values\n",
    "post_ids=df.index\n",
    "for post_id,tokens in zip(post_ids,tokens_list):\n",
    "    if  any( x in DirtyWords for x in tokens) :\n",
    "        list_of_bad_posts.append(post_id)\n",
    "\n",
    "print(len(list_of_bad_posts))\n",
    "# No dirty words!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty dataframe with columns\n",
    "df2=pd.DataFrame(columns=['tokens','use dirty words'])\n",
    "df2.index.name='post id'\n",
    "df2['tokens'] = df['tokens']\n",
    "\n",
    "for ii in df2.index:\n",
    "    if ii in list_of_bad_posts:\n",
    "        df2.loc[ii,'use dirty words'] = 1\n",
    "    else:\n",
    "        df2.loc[ii,'use dirty words'] = 0\n",
    "#df2.head(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ ['my', 'nephew', 'who', 'is', 'four', 'years', 'has', 'very', 'bad', 'mood', 'swings', 'and', 'stops', 'what', 'he', 'is', 'doing', 'and', 'starts', 'opening', 'and', 'closing', 'of', 'his', 'hands', 'he', 'tells', 'his', 'mother', 'that', 'he', 'wants', 'to', 'break', 'her', 'bones', 'and', 'break', 'the', 'house', 'he', 'goes', 'to', 'the', 'bathroom', 'on', 'the', 'porch', 'and', 'steps', 'in', 'ti', 'and', 'thinks', 'it', 's', 'funny', 'he', 'is', 'in', 'time', 'out', 'at', 'school', '4', 'out', 'of', '5', 'days', 'and', 'the', 'daycare', 'provider', 'said', 'he', 'needs', 'to', 'be', 'seen', 'by', 'a', 'doctor', 'my', 'sister', 'is', 'so', 'frustrated', 'she', 'doesn', 't', 'know', 'what', 'to', 'do', 'other', 'things', 'he', 'does', 'is', 'spit', 'at', 'people', 'hit', 'others', 'punches', 'his', 'mom', 'yells', 'a', 'lot', 'calls', 'eveyone', 'stupid', 'says', 'he', 'wants', 'to', 'hurt', 'animals', 'and', 'people', 'his', 'speech', 'is', 'hard', 'to', 'understand', 'he', 'starts', 'a', 'conversation', 'and', 'be', 'fore', 'he', 'can', 'finish', 'he', 'll', 'stop', 'and', 'talk', 'about', 'something', 'completly', 'different', 'my', 'sister', 'doesn', 't', 'know', 'what', 'to', 'do', 'she', 'thinks', 'possible', 'autism', 'what', 'do', 'you', 'think'],\n",
       "       1], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = df2.loc[df2['use dirty words'] == 1 ].values\n",
    "tokens[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stupid\n",
      "stupid\n",
      "stupid\n",
      "asses\n",
      "cocks\n",
      "bloody\n",
      "omg\n",
      "hell\n",
      "nazi\n",
      "hell\n",
      "stupid\n",
      "bloody\n",
      "stupid\n",
      "stupid\n",
      "omg\n",
      "penis\n",
      "penis\n",
      "omg\n",
      "xxx\n",
      "sex\n",
      "sex\n",
      "sex\n",
      "sex\n",
      "sex\n",
      "pissed\n",
      "stupid\n",
      "stupid\n",
      "stupid\n",
      "stupid\n",
      "stupid\n",
      "stupid\n",
      "hell\n",
      "bloody\n",
      "hell\n",
      "hell\n",
      "stupid\n",
      "sex\n",
      "ass\n",
      "hell\n",
      "stupid\n",
      "stupid\n",
      "stupid\n",
      "hell\n",
      "bum\n",
      "butt\n",
      "sex\n",
      "stupid\n",
      "ejaculation\n",
      "orgasm\n",
      "stupid\n",
      "stupid\n",
      "stupid\n",
      "omg\n",
      "jerk\n",
      "bloody\n",
      "omg\n",
      "penis\n",
      "breasts\n",
      "stupid\n",
      "hell\n",
      "hell\n",
      "lmao\n",
      "sex\n",
      "sex\n",
      "stupid\n",
      "stupid\n",
      "xxx\n",
      "chink\n",
      "stupid\n",
      "stupid\n",
      "hell\n",
      "hell\n",
      "stupid\n",
      "stupid\n",
      "stupid\n",
      "stupid\n",
      "stupid\n",
      "stupid\n",
      "stupid\n",
      "vagina\n",
      "hell\n",
      "butt\n",
      "hell\n",
      "jerk\n",
      "asshole\n",
      "asshole\n",
      "bitches\n",
      "fucking\n",
      "fuck\n",
      "ass\n",
      "bloody\n",
      "shitty\n",
      "damn\n",
      "fucking\n",
      "hell\n",
      "ass\n",
      "sex\n",
      "ass\n",
      "screwing\n",
      "bloody\n",
      "pawn\n",
      "shit\n",
      "damn\n",
      "fucking\n",
      "fucked\n",
      "bitch\n",
      "asshole\n",
      "butt\n",
      "stupid\n",
      "porn\n",
      "jerk\n",
      "sex\n",
      "hell\n",
      "pissed\n",
      "pissing\n",
      "fucking\n",
      "fucking\n",
      "fucking\n",
      "breasts\n",
      "hell\n",
      "bitch\n",
      "ass\n",
      "ass\n",
      "hell\n",
      "wtf\n",
      "sex\n",
      "ass\n",
      "boob\n",
      "fucking\n",
      "fucking\n",
      "asshole\n",
      "fucking\n",
      "fucking\n",
      "hell\n",
      "fucking\n",
      "shit\n",
      "shitty\n",
      "rectum\n",
      "fuck\n",
      "shit\n",
      "fucking\n",
      "fucking\n",
      "shit\n",
      "ass\n",
      "butt\n",
      "whore\n",
      "shits\n",
      "hell\n",
      "stupid\n",
      "fuck\n",
      "hell\n",
      "butt\n",
      "hell\n",
      "fuck\n",
      "sex\n",
      "sex\n",
      "fucking\n",
      "shitty\n",
      "shitty\n",
      "fucking\n",
      "fucks\n",
      "jerk\n",
      "stupid\n",
      "stupid\n",
      "fuck\n",
      "bitch\n",
      "wtf\n",
      "fag\n",
      "shitty\n",
      "shit\n",
      "damn\n",
      "fucking\n",
      "hell\n",
      "nazi\n",
      "stupid\n",
      "hell\n",
      "vagina\n",
      "ass\n",
      "penis\n",
      "penis\n",
      "fuck\n",
      "bitch\n",
      "fuck\n",
      "hell\n",
      "sex\n",
      "shitty\n",
      "hell\n",
      "sex\n",
      "bitch\n",
      "ass\n",
      "sex\n",
      "sex\n",
      "hell\n",
      "stupid\n",
      "homo\n",
      "homo\n",
      "butt\n",
      "asshole\n",
      "hell\n",
      "pissed\n",
      "fuck\n",
      "bloody\n",
      "shit\n",
      "fucking\n",
      "dick\n",
      "wtf\n",
      "pissed\n",
      "stupid\n",
      "hell\n",
      "fuck\n",
      "stupid\n",
      "damn\n",
      "stupid\n",
      "fuck\n",
      "sex\n",
      "fuck\n",
      "fucked\n",
      "pissing\n",
      "stupid\n",
      "stupid\n",
      "stupid\n",
      "stupid\n",
      "stupid\n",
      "stupid\n",
      "sex\n",
      "sex\n",
      "damn\n",
      "fuck\n",
      "bum\n",
      "damn\n",
      "damn\n",
      "fuck\n",
      "fucks\n",
      "shit\n",
      "fucking\n",
      "asshole\n",
      "shit\n",
      "fucking\n",
      "stupid\n",
      "dick\n",
      "fucking\n",
      "shit\n",
      "pissed\n",
      "stupid\n",
      "stupid\n",
      "hell\n",
      "pissed\n",
      "fuck\n",
      "stupid\n",
      "stupid\n",
      "hell\n",
      "hell\n",
      "hell\n",
      "homo\n",
      "asshole\n",
      "fuck\n",
      "stupid\n",
      "fucked\n",
      "stupid\n",
      "stupid\n",
      "pissed\n",
      "damn\n",
      "asses\n",
      "shitty\n",
      "fucking\n",
      "fucking\n",
      "fucked\n",
      "asshole\n",
      "shitty\n",
      "omg\n",
      "fuck\n",
      "feck\n",
      "hell\n",
      "shitty\n",
      "goddamned\n",
      "fucked\n",
      "sex\n",
      "sex\n",
      "hell\n",
      "butt\n",
      "stupid\n",
      "shitty\n",
      "stupid\n",
      "shit\n",
      "pissed\n",
      "stupid\n",
      "stupid\n",
      "fucking\n",
      "bitch\n",
      "stupid\n",
      "pornography\n",
      "damn\n",
      "sex\n",
      "fucked\n",
      "shit\n",
      "stupid\n",
      "stupid\n",
      "shit\n",
      "shit\n",
      "stupid\n",
      "hell\n",
      "wtf\n",
      "faggot\n",
      "knob\n",
      "sex\n",
      "shit\n",
      "assholes\n",
      "asshole\n",
      "assholes\n",
      "damn\n",
      "hell\n",
      "hell\n",
      "erotic\n",
      "fuck\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for tt in tokens:\n",
    "    for x in tt[0]:\n",
    "        if x in DirtyWords:\n",
    "            print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2.to_csv(\"db-bad-words.csv\",header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
