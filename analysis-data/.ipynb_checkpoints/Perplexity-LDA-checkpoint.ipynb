{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perplexity\n",
    "\n",
    "Here I show perplexity as a metric to find the optimal number of topics.\n",
    "\n",
    "https://radimrehurek.com/gensim/models/ldamodel.html\n",
    "log_perplexity(chunk, total_docs=None)\n",
    "Calculate and return per-word likelihood bound, using the chunk of documents as evaluation corpus. Also output the calculated statistics. incl. perplexity=2^(-bound), to log at INFO level.\n",
    "\n",
    "\n",
    "https://stackoverflow.com/questions/21355156/topic-models-cross-validation-with-loglikelihood-or-perplexity\n",
    "\n",
    "\n",
    "http://qpleple.com/perplexity-to-evaluate-topic-models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from gensim import corpora, models, similarities\n",
    "from gensim import models\n",
    "\n",
    "from nlp_models import make_corpus,\\\n",
    "make_lsi_similarity_matrix,make_lda_similarity_matrix,get_model_score_wforums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up paths/ os\n",
    "import os\n",
    "import sys\n",
    "\n",
    "this_path=os.getcwd()\n",
    "os.chdir(\"../data\")\n",
    "sys.path.insert(0, this_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>href</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>category-applied-behavior-analysis-aba</td>\n",
       "      <td>https://www.autismparentingmagazine.com/autism...</td>\n",
       "      <td>https://www.autismparentingmagazine.com/</td>\n",
       "      <td>For children with autism spectrum disorder (AS...</td>\n",
       "      <td>Autism, Head Banging and other Self Harming Be...</td>\n",
       "      <td>['for', 'children', 'with', 'autism', 'spectru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>category-applied-behavior-analysis-aba</td>\n",
       "      <td>https://www.autismparentingmagazine.com/high-q...</td>\n",
       "      <td>https://www.autismparentingmagazine.com/</td>\n",
       "      <td>Dr. Stephen Shore once said “If you’ve met one...</td>\n",
       "      <td>High Quality ABA Treatment:  What Every Parent...</td>\n",
       "      <td>['dr', 'stephen', 'shore', 'once', 'said', 'if...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 category  \\\n",
       "0  category-applied-behavior-analysis-aba   \n",
       "1  category-applied-behavior-analysis-aba   \n",
       "\n",
       "                                                href  \\\n",
       "0  https://www.autismparentingmagazine.com/autism...   \n",
       "1  https://www.autismparentingmagazine.com/high-q...   \n",
       "\n",
       "                                     source  \\\n",
       "0  https://www.autismparentingmagazine.com/   \n",
       "1  https://www.autismparentingmagazine.com/   \n",
       "\n",
       "                                                text  \\\n",
       "0  For children with autism spectrum disorder (AS...   \n",
       "1  Dr. Stephen Shore once said “If you’ve met one...   \n",
       "\n",
       "                                               title  \\\n",
       "0  Autism, Head Banging and other Self Harming Be...   \n",
       "1  High Quality ABA Treatment:  What Every Parent...   \n",
       "\n",
       "                                              tokens  \n",
       "0  ['for', 'children', 'with', 'autism', 'spectru...  \n",
       "1  ['dr', 'stephen', 'shore', 'once', 'said', 'if...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Read dataframe\n",
    "#input_fname=\"AutismParentMagazine-posts-tokens.csv\"\n",
    "input_fname=\"articles-n-forums-posts.csv\"\n",
    "\n",
    "\n",
    "# Get categories and ids from dataset\n",
    "df = pd.read_csv(input_fname,index_col=0)\n",
    "\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract series from df:\n",
    "categories=df['category']\n",
    "ids=df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from ast import literal_eval  \n",
    "\n",
    "# Get similarity matrices\n",
    "documents = df['tokens'].values\n",
    "for idoc in range(len(documents)):\n",
    "    documents[idoc]=literal_eval(str(documents[idoc]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus,dictionary = make_corpus(documents)\n",
    "\n",
    "\n",
    "tfidf = models.TfidfModel(corpus)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "msk = np.random.rand(len(corpus)) < 0.6\n",
    "\n",
    "#corpus_train = documents[msk]\n",
    "#corpus_test = documents[~msk]\n",
    "#chunk=corpus[msk]\n",
    "\n",
    "#print(len(corpus))\n",
    "len_60p=int(len(corpus)*0.6)\n",
    "chunk1=corpus[:len_60p]\n",
    "chunk2=corpus[len_60p:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N. topics 2, perplexity 360.0696728366097 361.45266724792486\n",
      "N. topics 4, perplexity 325.8858135894025 332.686674179517\n",
      "N. topics 6, perplexity 354.2267446027712 358.1987930598974\n",
      "N. topics 8, perplexity 386.18857786038643 390.76466768637\n"
     ]
    }
   ],
   "source": [
    "for num_topics in range(2,10,2):\n",
    "    matsim,lda = make_lda_similarity_matrix(corpus, dictionary,num_topics)\n",
    "    #model_score= get_model_score_wforums(ids,matsim,categories)\n",
    "    perplexity1=np.power(2,-lda.log_perplexity(chunk1))\n",
    "    perplexity2=np.power(2,-lda.log_perplexity(chunk2))\n",
    "\n",
    "    print(\"N. topics {}, perplexity {} {}\".format(num_topics,perplexity1,perplexity2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N. topics 10, perplexity 395.56992640031956 408.29495488917405\n",
      "N. topics 20, perplexity 639.104536315101 700.7180692867495\n",
      "N. topics 30, perplexity 840.1677826198422 971.5546515713755\n",
      "N. topics 40, perplexity 1231.8815690096276 1475.337762588348\n",
      "N. topics 50, perplexity 1537.7432112379195 1879.2789870685658\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-7bde4847829b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mmatsim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_lda_similarity_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_topics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mperplexity1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_perplexity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mperplexity2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_perplexity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"N. topics {}, perplexity {} {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_topics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mperplexity1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mperplexity2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/rangel/anaconda3/envs/cdips2017/lib/python3.6/site-packages/gensim/models/ldamodel.py\u001b[0m in \u001b[0;36mlog_perplexity\u001b[0;34m(self, chunk, total_docs)\u001b[0m\n\u001b[1;32m    525\u001b[0m         \u001b[0mcorpus_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnt\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdocument\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocument\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m         \u001b[0msubsample_ratio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtotal_docs\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 527\u001b[0;31m         \u001b[0mperwordbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubsample_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubsample_ratio\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msubsample_ratio\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcorpus_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    528\u001b[0m         logger.info(\"%.3f per-word bound, %.1f perplexity estimate based on a held-out corpus of %i documents with %i words\" %\n\u001b[1;32m    529\u001b[0m                     (perwordbound, np.exp2(-perwordbound), len(chunk), corpus_words))\n",
      "\u001b[0;32m/Users/rangel/anaconda3/envs/cdips2017/lib/python3.6/site-packages/gensim/models/ldamodel.py\u001b[0m in \u001b[0;36mbound\u001b[0;34m(self, corpus, gamma, subsample_ratio)\u001b[0m\n\u001b[1;32m    732\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bound: at document #%i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mgamma\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0mgammad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0mgammad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/rangel/anaconda3/envs/cdips2017/lib/python3.6/site-packages/gensim/models/ldamodel.py\u001b[0m in \u001b[0;36minference\u001b[0;34m(self, chunk, collect_sstats)\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;31m# Initialize the variational distribution q(theta|gamma) for the chunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m         \u001b[0mgamma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m100.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_topics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0mElogtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdirichlet_expectation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m         \u001b[0mexpElogtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mElogtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for num_topics in range(10,100,10):\n",
    "    matsim,lda = make_lda_similarity_matrix(corpus, dictionary,num_topics)\n",
    "    perplexity1=np.power(2,-lda.log_perplexity(chunk1))\n",
    "    perplexity2=np.power(2,-lda.log_perplexity(chunk2))\n",
    "\n",
    "    print(\"N. topics {}, perplexity {} {}\".format(num_topics,perplexity1,perplexity2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
