{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import nltk\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from gensim import corpora, models, similarities\n",
    "def make_dictionary(documents):\n",
    "    \"\"\"\n",
    "    construct a dictionary, i.e. mapping btwn word ids and their freq of occurence in the whole corpus\n",
    "    filter dictionary to remove stopwords and words occuring < min_count times\n",
    "    \n",
    "    input: documents is an iterable consisting of all the words in the corpus \n",
    "    output: filtered dictionary\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    dictionary = corpora.Dictionary(documents)\n",
    "\n",
    "    stop_words = nltk.corpus.stopwords.words('english') \n",
    "    min_count = 2\n",
    "    stop_ids = [dictionary.token2id[word] for word in stop_words\n",
    "               if word in dictionary.token2id]\n",
    "    rare_ids = [id for id, freq in dictionary.dfs.items()\n",
    "                if freq < min_count]\n",
    "    dictionary.filter_tokens(stop_ids + rare_ids)\n",
    "    dictionary.compactify()\n",
    "    return(dictionary)\n",
    "\n",
    "def make_corpus(documents):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    dictionary = make_dictionary(documents)\n",
    "    # convert corpus to vectors using bag-of-words representation, i.e. tuples of word indices and word counts\n",
    "    corpus = [dictionary.doc2bow(words) for words in documents]\n",
    "    return(corpus, dictionary)\n",
    "\n",
    "def make_lsi_similarity_matrix(tfidf_corpus, dictionary):\n",
    "    \"\"\"\n",
    "    construct LSI (latent semantic indexing) model on Tfidf-transformed corpus, print model topics, \n",
    "    return similarity matrix.\n",
    "    \"\"\"\n",
    "    # construct model\n",
    "    lsi = models.lsimodel.LsiModel(tfidf_corpus, id2word=dictionary, num_topics=200) \n",
    "    lsi.save('similarity-matrix.lsi')\n",
    "    # create similarity matrix\n",
    "    matsim = similarities.MatrixSimilarity(lsi[tfidf_corpus], num_best=3)\n",
    "    return(matsim)\n",
    "\n",
    "def make_lda_similarity_matrix(corpus, dictionary):\n",
    "    \"\"\"\n",
    "    Latent Dirichlet Allocation (LDA) model\n",
    "    \"\"\"\n",
    "    # construct model\n",
    "    lda = models.ldamodel.LdaModel(corpus, id2word=dictionary, num_topics=200)\n",
    "    lda.save('similarity-matrix.lda')\n",
    "    # create similarity matrix\n",
    "    matsim = similarities.MatrixSimilarity(lda[corpus], num_best=3)\n",
    "    return(matsim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "      <th>href</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.autismparentingmagazine.com/</td>\n",
       "      <td>category-applied-behavior-analysis-aba</td>\n",
       "      <td>For children with autism spectrum disorder (AS...</td>\n",
       "      <td>https://www.autismparentingmagazine.com/autism...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.autismparentingmagazine.com/</td>\n",
       "      <td>category-applied-behavior-analysis-aba</td>\n",
       "      <td>Dr. Stephen Shore once said “If you’ve met one...</td>\n",
       "      <td>https://www.autismparentingmagazine.com/high-q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.autismparentingmagazine.com/</td>\n",
       "      <td>category-applied-behavior-analysis-aba</td>\n",
       "      <td>Help! I am going to be starting Applied Behav...</td>\n",
       "      <td>https://www.autismparentingmagazine.com/choosi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.autismparentingmagazine.com/</td>\n",
       "      <td>category-applied-behavior-analysis-aba</td>\n",
       "      <td>How do you handle high anxiety of a child on t...</td>\n",
       "      <td>https://www.autismparentingmagazine.com/help-a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.autismparentingmagazine.com/</td>\n",
       "      <td>category-applied-behavior-analysis-aba</td>\n",
       "      <td>A grandfather from Singapore asks… My eldest g...</td>\n",
       "      <td>https://www.autismparentingmagazine.com/help-i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     source  \\\n",
       "0  https://www.autismparentingmagazine.com/   \n",
       "1  https://www.autismparentingmagazine.com/   \n",
       "2  https://www.autismparentingmagazine.com/   \n",
       "3  https://www.autismparentingmagazine.com/   \n",
       "4  https://www.autismparentingmagazine.com/   \n",
       "\n",
       "                                 category  \\\n",
       "0  category-applied-behavior-analysis-aba   \n",
       "1  category-applied-behavior-analysis-aba   \n",
       "2  category-applied-behavior-analysis-aba   \n",
       "3  category-applied-behavior-analysis-aba   \n",
       "4  category-applied-behavior-analysis-aba   \n",
       "\n",
       "                                                text  \\\n",
       "0  For children with autism spectrum disorder (AS...   \n",
       "1  Dr. Stephen Shore once said “If you’ve met one...   \n",
       "2   Help! I am going to be starting Applied Behav...   \n",
       "3  How do you handle high anxiety of a child on t...   \n",
       "4  A grandfather from Singapore asks… My eldest g...   \n",
       "\n",
       "                                                href  \n",
       "0  https://www.autismparentingmagazine.com/autism...  \n",
       "1  https://www.autismparentingmagazine.com/high-q...  \n",
       "2  https://www.autismparentingmagazine.com/choosi...  \n",
       "3  https://www.autismparentingmagazine.com/help-a...  \n",
       "4  https://www.autismparentingmagazine.com/help-i...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read database of data\n",
    "os.chdir('../data')\n",
    "df=pd.read_csv(\"AutismParentMagazine-posts.csv\",index_col=0)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for children with autism spectrum disorder (asd), head banging is a common way to self-soothe and communicate needs. both neurotypical and autistic babies and toddlers seek to recreate the rhythm that stimulated their vestibular system while in utero. other rhythmic habits that fuel a child’s kinesthetic drive include head rolling, body rocking, biting, and thumb… continue reading\n",
      "\n",
      "['for', 'children', 'with', 'autism', 'spectrum', 'disorder', 'asd', 'head', 'banging', 'is', 'a', 'common', 'way', 'to', 'self', 'soothe', 'and', 'communicate', 'needs', 'both', 'neurotypical', 'and', 'autistic', 'babies', 'and', 'toddlers', 'seek', 'to', 'recreate', 'the', 'rhythm', 'that', 'stimulated', 'their', 'vestibular', 'system', 'while', 'in', 'utero', 'other', 'rhythmic', 'habits', 'that', 'fuel', 'a', 'child', 's', 'kinesthetic', 'drive', 'include', 'head', 'rolling', 'body', 'rocking', 'biting', 'and', 'thumb', 'continue', 'reading']\n"
     ]
    }
   ],
   "source": [
    "# Tokenize data\n",
    "import nltk\n",
    "tokenizer = nltk.RegexpTokenizer(r'\\w+')\n",
    "\n",
    "# Get list of tokens from text in first article:\n",
    "text = df['text'][0].lower()\n",
    "ttext = tokenizer.tokenize(text)\n",
    "print( text )\n",
    "print( ttext )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [for, children, with, autism, spectrum, disord...\n",
       "1    [dr, stephen, shore, once, said, if, you, ve, ...\n",
       "2    [help, i, am, going, to, be, starting, applied...\n",
       "3    [how, do, you, handle, high, anxiety, of, a, c...\n",
       "4    [a, grandfather, from, singapore, asks, my, el...\n",
       "Name: tokens, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a column with list of tokens:\n",
    "\n",
    "# 1) convert to lower case \n",
    "# 2) get tokens\n",
    "# 2) save data in a new column (tokens)\n",
    "df['tokens'] = df['text'].map(lambda x: tokenizer.tokenize(x.lower()))\n",
    "df['tokens'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get similarity matrices\n",
    "\n",
    "documents = df['tokens'].values\n",
    "corpus,dictionary = make_corpus(documents)\n",
    "tfidf = models.TfidfModel(corpus)\n",
    "lsi_matsim = make_lsi_similarity_matrix(tfidf[corpus], dictionary)\n",
    "lda_matsim = make_lda_similarity_matrix(corpus, dictionary)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot projection of articles onto 2 axes/topics defined by the model; for models operating on tfidf-transformed inputs (LSI, RP)\n",
    "def plot_axes_with_tfidf(x, y, model, corpus, tfidf, titles):\n",
    "    \"\"\"Plot each article title according to the projection of its text \n",
    "    into the given x and y topic axes of model.\n",
    "    \n",
    "    :param x: the index of the x axis to plot\n",
    "    :param y: the index of the y axis to plot\n",
    "    :param model: the gensim model to project into\n",
    "    :param corpus: the gensim corpus of documents\n",
    "    :param tfidf: a tfidf model for converting documents into tfidf space\n",
    "    :param titles: a list of article titles\n",
    "    \"\"\"\n",
    "    x_data = defaultdict(list) \n",
    "    y_data = defaultdict(list) \n",
    "    arts = defaultdict(list)  \n",
    "    for title, doc in zip(titles, corpus):\n",
    "        x_data[0].append((model[tfidf[doc]][x][1]))\n",
    "        y_data[0].append((model[tfidf[doc]][y][1]))\n",
    "        arts[0].append(title)\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    ax = plt.gca()\n",
    "    ax.set_xlabel('Topic '+str(x), fontsize=14)\n",
    "    ax.set_ylabel('Topic '+str(y), fontsize=14)\n",
    "    plt.scatter(x_data[0], y_data[0], s=40)\n",
    "    for art, x, y in zip(arts[0], x_data[0], y_data[0]):\n",
    "        ax.annotate(str(art), xy=(x, y), xycoords='data', xytext=(1, 1), \n",
    "        textcoords='offset points', size=10)\n",
    "    \n",
    "        \n",
    "# plot projection of articles onto 2 axes/topics defined by the model; for models operating on original corpus (LDA, HDP)\n",
    "def plot_axes(x, y, model, corpus, titles):\n",
    "    \"\"\"Plot each article title according to the projection of its text \n",
    "    into the given x and y topic axes of model.\n",
    "    \n",
    "    :param x: the index of the x axis to plot\n",
    "    :param y: the index of the y axis to plot\n",
    "    :param model: the gensim model to project into\n",
    "    :param corpus: the gensim corpus of documents\n",
    "    :param titles: a list of article titles\n",
    "    \"\"\"\n",
    "    x_data = defaultdict(list) \n",
    "    y_data = defaultdict(list) \n",
    "    arts = defaultdict(list)  \n",
    "    for title, doc in zip(titles, corpus):\n",
    "        x_data[0].append((model[doc][x][1]))\n",
    "        y_data[0].append((model[doc][y][1]))\n",
    "        arts[0].append(title)\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    ax = plt.gca()\n",
    "    ax.set_xlabel('Topic '+str(x), fontsize=14)\n",
    "    ax.set_ylabel('Topic '+str(y), fontsize=14)\n",
    "    plt.scatter(x_data[0], y_data[0], s=40)\n",
    "    for art, x, y in zip(arts[0], x_data[0], y_data[0]):\n",
    "        ax.annotate(str(art), xy=(x, y), xycoords='data', xytext=(1, 1), \n",
    "        textcoords='offset points', size=10)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'word_data_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-3b7b17a7a204>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlsi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLsiModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'similarity-matrix.lsi'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtitles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_data_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplot_axes_with_tfidf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlsi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtfidf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtfidf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtitles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'word_data_df' is not defined"
     ]
    }
   ],
   "source": [
    "lsi = models.LsiModel.load('similarity-matrix.lsi')\n",
    "titles = df['title']\n",
    "plot_axes_with_tfidf(x=0, y=1, model=lsi, corpus=corpus, tfidf=tfidf, titles=titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
