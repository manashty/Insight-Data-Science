{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation of models\n",
    "\n",
    "In our database of articles from \"AutismParentMagazine\" each article belong a **category**.\n",
    "\n",
    "Our models find similarities among articles, but how can we test that the similarities make sense?\n",
    "\n",
    "Let's validate the similarities against the catagories provided in the database.   \n",
    "\n",
    "The algorightm is, let's define a function to tell wether two articles $1$ and $2$ belong to the same category:     \n",
    "\n",
    "\\begin{eqnarray}\n",
    "f (1,2)  &=& 1 & \\mbox{ if } 1\\mbox{, } 2 \\mbox{ in same category, or}\\nonumber\\\\   \n",
    "         &=& 0 & \\mbox{ elsewhere.}\\nonumber\n",
    "\\end{eqnarray}\n",
    "\n",
    "Now, we can define a score for the model, as:\n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\mbox{score} \\sum_{i,j} f(i,j) / N\n",
    "\\end{eqnarray}\n",
    "for $i,j$ pair of articles, predicted to be top 3 predictions for each article.   \n",
    "\n",
    "So that if the model predict the top 3 similar articles to be in the same category as the original article, then the score is 1.   \n",
    "In other words, the closer the score is to 1, the better the model is.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from gensim import corpora, models, similarities\n",
    "\n",
    "\n",
    "def get_model_score(ids,matsim,categories):\n",
    "    num_of_predictions=3\n",
    "    model_score=0\n",
    "    for id,doc in zip(ids,matsim.index):\n",
    "        sims=matsim[doc]\n",
    "        for other_id,score in sims:\n",
    "            #print(\"ID {} OTHER_ID {} SCORE {}\".format(id,other_id,score))\n",
    "            category1=categories[id]\n",
    "            category2=categories[other_id]\n",
    "            if id != other_id:\n",
    "                if category1 == category2:\n",
    "                    model_score+=1\n",
    "    N=len(ids)*num_of_predictions\n",
    "    model_score=model_score/N\n",
    "    return model_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../data/')\n",
    "# Read dataframe\n",
    "input_fname=\"AutismParentMagazine-posts-tokens.csv\"\n",
    "\n",
    "\n",
    "# Get categories and ids from dataset\n",
    "df = pd.read_csv(input_fname,index_col=0)\n",
    "df.head(2)\n",
    "categories=df['category']\n",
    "ids=df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSI model score 0.6851851851851852\n",
      "LDA model score 0.24074074074074073\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Read models\n",
    "matsim = pickle.load(open(\"lsi-matsim.save\", \"rb\"))\n",
    "model_score= get_model_score(ids,matsim,categories)\n",
    "print(\"LSI model score {}\".format(model_score))\n",
    "\n",
    "# Read models\n",
    "matsim = pickle.load(open(\"lda-matsim.save\", \"rb\"))\n",
    "model_score= get_model_score(ids,matsim,categories)\n",
    "print(\"LDA model score {}\".format(model_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSI model score 0.24074074074074073\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
